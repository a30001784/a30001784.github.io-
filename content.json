{"meta":{"title":"带你走进美丽的墨尔本","subtitle":null,"description":null,"author":"Mark Wu","url":"http://blog.ozairs.com"},"pages":[{"title":"about","date":"2019-02-01T04:12:13.000Z","updated":"2019-02-01T07:12:13.040Z","comments":true,"path":"about/index-1.html","permalink":"http://blog.ozairs.com/about/index-1.html","excerpt":"","text":""},{"title":"tags","date":"2019-02-01T07:41:48.000Z","updated":"2019-03-08T23:14:56.361Z","comments":true,"path":"categories/index.html","permalink":"http://blog.ozairs.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2019-02-01T00:08:11.000Z","updated":"2019-02-01T03:08:11.104Z","comments":true,"path":"about/index.html","permalink":"http://blog.ozairs.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-02-01T07:41:48.000Z","updated":"2019-03-08T23:14:56.361Z","comments":true,"path":"tags/index.html","permalink":"http://blog.ozairs.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Ansible进阶手册","slug":"Ansible进阶手册","date":"2019-03-14T09:07:52.000Z","updated":"2019-03-14T10:05:28.786Z","comments":true,"path":"DevOps/Ansible进阶手册/","link":"","permalink":"http://blog.ozairs.com/DevOps/Ansible进阶手册/","excerpt":"","text":"1. Playbook contain plays, plays contain tasks, tasks call modules2. Tasks run sequentially3. Handlers are triggered by tasks, and are run once, at the end of the plays. Ansible has many different ways to alter how playbooks run by using with_items, failed_when, changed_when, until, ignore_errors Ansible roles are a special kind of playbook that are fully self-contained with tasks, variables, configurations templates and other supporting files. 一、Ansible与AWS配合1、通过boto函数查询EC2实例 >&gt;&gt; import boto.ec2 >&gt;&gt; conn = boto.ec2.connect_to_region(“ap-southeast-2”) >&gt;&gt; statuses = conn.get_all_instance_status() >&gt;&gt; statuses [InstanceStatus:i-040f7235964b7d201] 二 、关于Module的调用 通过命令行方式调用Module: 123ansible webservers -m service -a &quot;name=httpd state=started&quot;ansible webservers -m pingansible webservers -m command -a &quot;/sbin/reboot -t now&quot; 通过Playbook调用Module: 12- name: reboot the servers action: command /sbin/reboot -t now 可以缩写为： 12- name: reboot the servers command: /sbin/reboot -t now 另外一种传参方式： 1234- name: restart webserver service: name: httpd state: restarted Ansible Tower方式 Ansible帮助命令 ansible help | less ansible-doc command 三 、Ansible的三种使用方式 命令行方式： Playbook调用方式： Ansible Tower：","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"AWS云上的Puppet:快速入门参考部署","slug":"AWS云上的Puppet-快速入门参考部署","date":"2019-03-14T05:26:27.000Z","updated":"2019-03-14T05:43:21.823Z","comments":true,"path":"AWS/AWS云上的Puppet-快速入门参考部署/","link":"","permalink":"http://blog.ozairs.com/AWS/AWS云上的Puppet-快速入门参考部署/","excerpt":"","text":"本快速入门参考部署指南讨论在 Amazon Web Services (AWS) 云中部署和测试 Puppet Master 和 Puppet 代理所需的步骤。它还提供了用于查看和启动 AWS CloudFormation 模板（可自动进行部署）的链接，以及有关如何配置充当 Puppet 代理的 Amazon Elastic Compute Cloud (Amazon EC2) 实例的演练。 本指南面向计划在 AWS 云上实施或扩展 Puppet 工作负载的 IT 基础设施架构师、管理员和 DevOps 专家。 如果您拥有 AWS 账户且已熟悉 AWS 和 Puppet，可以启动快速入门以构建图 1 所示的架构。完成部署需要约 20 分钟。如果您是刚刚接触 AWS 或 Puppet，请查看实施详情，然后按照本指南后面部分提供的分步说明来启动快速入门。 https://fwd.aws/YBD5Y 如果您想更深一步地了解相关信息，则可以查看模板以了解自动执行此部署的 AWS CloudFormation 脚本。默认情况下，默认配置将部署三个使用 t2.medium 实例类型的服务器，但您也可以按需自定义模板。 https://fwd.aws/pkzpq 注意 运行本快速入门参考部署时，您需要支付所用的所有 AWS 服务的相关费用。价格可能会发生变化。有关完整详细信息，请参阅成本和许可证部分以及您所使用 AWS 服务的定价页面。 步骤 1.准备 AWS 账户 如果您还没有 AWS 账户，请按照屏幕说明在 https://aws.amazon.com 上创建一个。 作为注册流程的一部分，您会接到一个电话，并且需要通过手机键盘输入 PIN 码。 使用导航栏中的区域选择器选择要在 AWS 上将 Puppet 部署到的 AWS 区域。 Amazon EC2 位置由区域 和可用区 构成。区域分散存在，位于独立的地理区域。 图 2：选择 AWS 区域 提示 考虑选择最接近数据中心或企业网络的区域，以减少运行于 AWS 的系统与企业网络上的系统和用户之间的网络延迟。 在首选区域中创建一个密钥对。为此，在 Amazon EC2 控制台的导航窗格中，依次选择 Key Pairs (密钥对)、Create Key Pair (创建密钥对)，键入名称，然后选择 Create (创建)。 图 3：创建密钥对 Amazon EC2 使用公有密钥密码术来加密和解密登录信息。要登录实例，必须创建密钥对。对于 Windows 实例，我们使用密钥对通过 Amazon EC2 控制台获取管理员密码，然后使用远程桌面协议 (RDP) 登录，如 Amazon Elastic Compute Cloud 用户指南 中的分步说明所述。在 Linux 上，我们使用密钥对来对 SSH 登录进行身份验证。 如有必要，可针对 t2.medium 实例类型请求提高服务限制。为此，在 AWS Support Center 中，选择 Create Case，Service Limit Increase，EC2 instances，然后填写限制提高表中的字段。此实例类型的当前默认限制为 20 个实例。 如果您已有使用此实例类型的现有部署，并且可能会超过此参考部署的默认限制，则可能需要请求提高限制。新服务限制可能需要几天才能生效。有关更多信息，请参阅 AWS 文档中的 Amazon EC2 服务限制。 图 4：请求提高服务限制 步驟 2.启动 Puppet 堆栈此快速入门附带的自动化 AWS CloudFormation 模板将 Puppet 部署到 VPC 中。在启动堆栈之前，请确保您已完成前面的步骤。 在您的 AWS 账户中启动 AWS CloudFormation 模板。https://fwd.aws/YBD5Y 默认情况下，模板在 美国西部（俄勒冈） 区域中启动。您可以使用导航栏中的区域选择器来更改区域。 创建此堆栈需要大约 20 分钟时间。 注意 运行本快速入门参考部署时，您需要支付所用的 AWS 服务的费用。使用本快速入门不收取任何额外费用。有关完整详细信息，请参阅您将使用的每项 AWS 服务的定价页。 在 Select Template (选择模板) 页面上，保留 AWS CloudFormation 模板的默认 URL，然后选择 Next (下一步)。 在 Specify Details 页面上，查看模板的参数。下表描述了这些选项。 为 KeyPairName 参数提供值。此参数需要您进行输入。对于所有其他参数，模板提供可以自定义的默认设置。 安全配置： 参数标签 参数名称 默认值 说明 选择一个密钥对 KeyPairName 需要输入 公有/私有密钥对，使您能够在实例启动后安全地与它连接。创建 AWS 账户时，这是您在首选区域中创建的密钥对。 用于远程访问的源 IP RemoteAdminCIDR 需要输入 用于 SSH 和 RDP 访问的 CIDR 块或 IP 地址 (例如，1.1.1.1/32)。 AWS 快速入门配置： 参数标签 参数名称 默认值 说明 快速入门 S3 存储桶名称 QSS3BucketName aws-quickstart 安装快速入门模板和脚本的 S3 存储桶。如果您决定自定义或扩展快速入门以供您自己使用，请使用此参数来指定您为快速入门资产的副本创建的 S3 存储桶名称。存储桶名称可以包含数字、小写字母、大写字母和连字符，但不得以连字符开头或结尾。 快速入门 S3 键前缀 QSS3KeyPrefix quickstart-puppet/ S3 键名称前缀，用于模拟快速入门资产的副本的文件夹（如果您决定自定义或扩展快速入门以供您自己使用）。此前缀可以包含数字、小写字母、大写字母、连字符和正斜杠。 网络配置: 参数标签 参数名称 默认值 说明 VPC 的 CIDR 范围 VPCCIDR 10.0.0.0/16 Amazon VPC 的 CIDR 块。 VPC 中的子网的 CIDR 范围 SubnetCIDR 10.0.0.0/19 子网的 CIDR 块。 Puppet Master 的 IP 地址 PuppetMasterIP 10.0.0.10 Puppet Master 部署到的实例的 IP 地址。 Linux Puppet 代理的 IP 地址 PuppetAgentLinuxIP 10.0.0.11 Linux Puppet 代理部署到的实例的 IP 地址。 Windows Puppet 代理的 IP 地址 PuppetAgentWindowsIP 10.0.0.12 Windows Puppet 代理部署到的实例的 IP 地址。 在 Options (选项) 页面上，您可以为堆栈中的资源指定标签（键-值对）并设置其他选项。在完成此操作后，选择 Next (下一步)。 在 Review 页面上，查看并确认模板设置。选择 Capabilities 下的复选框，以确认模板将创建 IAM 资源。 选择 Create 以部署堆栈。 监控堆栈的状态。当状态显示 CREATE_COMPLETE 时，表示 Puppet 集群已准备就绪。 步驟 3.配置 Puppet 代理您可以按照本部分中的说明进行操作，来测试 AWS 上的 Puppet 设置。我们将查看 Puppet 代理的模块清单，应用配置并验证是否已成功应用配置。 审查模块和清单可通过多种方法将配置应用于代理节点（请参阅 Puppet 文档）。此快速入门对每个 Linux 和 Windows 节点使用模块，并在引导启动阶段将这些模块从 Amazon S3 下载到主节点。 Puppet 程序称作清单，它们是使用 Puppet 代码开发的。（有关 Puppet 语言的信息，请参阅 Puppet 文档。） 主清单的名称为 site.pp，并且位于清单文件夹中的主节点上。图 5 显示此快速入门中的主节点所使用的 site.pp 清单。 图 5：主清单 此清单包含三个节点声明： 第 1 行 – 定义默认情况下可应用于任何系统的节点块。我们不执行任何常见配置，因此大括号内没有代码。 第 3 行 – 为名为 linuxagent.example.com 的代理定义节点块。这是由快速入门启动的 Ubuntu 代理。我们引用名为 lampserver 的模块中的类，而不是将资源定义置于此节点块中。使用类是减少代码重复的绝佳方式。在这种情况下，当 Linux 代理应用其配置时，它将使用 lampserver 类中的代码来定义系统的状态。 第 7 行 – 为名为 windowsagent.example.com 的代理定义节点块。这是由快速入门启动的 Windows Server 2012 R2 代理。我们引用名为 iisserver 的模块中的类，而不是将资源定义置于此节点块中。当 Windows 代理应用其配置时，它将使用 iisserver 类中的代码来定义系统的状态。 接下来，我们来看看 lampserver 和 iisserver 类以了解其功能。 在名为 lampserver 的模块中定义 lampserver 类。模块的清单文件名为 init.pp，并且位于主节点上的 /etc/puppet/modules/lampserver/manifests 中。 图 6：lampserver 类 请注意以下与图 6 中显示的 lampserver 代码有关的内容： 第 1 行 – 这是主清单文件中引用的 lampserver 的类定义。 第 2 行 – exec 关键字定义资源声明。您可使用资源来描述系统的所需状态。在这里，我们使用 exec 资源来对节点执行 apt-update 命令。 第 6 行 – 包资源用于在节点上安装 Apache 2。请注意，require 语句可确保 apt-update 在能够安装此资源之前已运行。 第 11 行 – service 资源确保 Apache 2 服务正在运行。 第 15 行 – package 资源确保一旦成功执行 apt-update，就立即安装 MySQL 服务器。 第 20 行 – service 资源确保 MySQL 正在运行。 第 24 行 – package 资源确保一旦成功执行 apt-update，就立即安装 PHP 5。 第 29 行 – file 资源确保在默认 apache 根目录中创建名为 info.php 的新文件。这需要安装 Apache 2。PHP 代码将添加到文件内容中，以便在用户通过 Web 浏览器访问网站时提供有关 Web 服务器的信息性页面。 在名为 iisserver 的模块中定义 iisserver 类。模块的清单文件名为 init.pp，并且位于主节点上的 /etc/puppet/modules/iisserver/manifests 中。 图 7：iisserver 类 请注意以下与图 7 中显示的 iisserver 代码有关的内容： 第 1 行 – 这是主清单文件中引用的 iisserver 的类定义。 第 15 行 – windowsfeature 资源利用 Windows PowerShell 确保安装 IIS 和 ASP.NET 的所有必需组件。 第 19 行 – windowsfeature 资源安装用于 IIS 管理的管理工具。 第 25 行 – file 资源确保 Web 服务器根目录中有一个名为 info.aspx 的信息性 ASP.NET 网页。此网页的内容因空间限制而被截断 (图 7 中所示)，但它包含一个提供服务器相关信息的页面指令，就像 Linux 节点上的 info.php 一样。 除了创建您自己的模块之外，您还可以直接使用清单，或者利用 Puppet Forge 中预先存在的模块。有关编写模块和清单的详细信息，请参阅 Puppet 网站上的模块基础知识和培训课程。 连接到 Puppet 代理现在，您已了解示例模块的用途，已准备好远程连接到您的代理。 Linux 代理您将需要使用 SSH 从 VPC 外部连接到您的 Linux 代理。在 Amazon EC2 控制台中，选择标记有 LinuxAgent 的 EC2 实例，如图 8 所示。 图 8：选择 LinuxAgent 实例 在公有 DNS 名称中检索 LinuxAgent，按照适用于 Linux 实例的 Amazon EC2 用户指南中的说明操作，以将 SSH 客户端连接到实例。您将需要可用的密钥对才能建立远程 SSH 连接。 Windows 代理您可以使用 RDP 通过 Internet 连接到 Windows 代理。在 Amazon EC2 控制台中，选择标记有 WindowsAgent的 EC2 实例，如图 9 所示。 图 9：选择 WindowsAgent 实例 在公有 DNS 名称中检索 WindowsAgent，按照适用于 Microsoft Windows 实例的 Amazon EC2 用户指南中的说明操作，以建立连接。您将需要可用的密钥对才能解密 Windows 管理员密码并建立远程连接。 应用配置在此部分中，您将应用节点配置并验证一切是否已配置成功。 Linux 代理在通过 SSH 连接到 Linux 代理后，请运行以下命令以应用 lampserver 模块中的配置： 1sudo puppet agent --test 您应看到与图 10 中的内容类似的输出，这指示已成功应用配置。 图 10：Linux Puppet 代理输出 接下来，打开 Web 浏览器并导航到 info.php 页面。您将需要使用 LinuxAgent EC2 实例的公有 DNS 名称 — 例如，http://&lt;public DNS name&gt;/info.php。 图 11：测试 Apache Web 服务器 您应看到与图 11 中所示内容类似的 PHP 版本页面。这表示您已将配置成功应用于您的 Linux 代理。 Windows 代理在通过 RDP 连接到您的 Windows 代理后，在“Start”屏幕上查找 Start Command Prompt with Puppet 快捷方式。打开快捷方式的上下文 (右键单击) 菜单，然后选择 Run as administrator。运行以下命令以应用 iisserver 模块中的配置。 1puppet_interactive.bat 您应看到与图 12 中的内容类似的输出，这指示已成功应用配置。 图 12：Windows Puppet 代理输出 最后，打开 Web 浏览器并导航到 info.aspx 页面。您将需要使用 WindowsAgent EC2 实例的公有 DNS 名称 — 例如，http://&lt;public DNS name&gt;/info.aspx。 图 13：测试 IIS Web 服务器 您应看到与图 13 中所示内容类似的 IIS 版本页面。这表示您已将配置成功应用于您的 Windows 代理。","categories":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/categories/AWS/"}]},{"title":"2019年DevOps必备面试问题","slug":"2019年DevOps必备面试问题","date":"2019-03-14T02:51:03.000Z","updated":"2019-03-14T03:34:20.327Z","comments":true,"path":"DevOps/2019年DevOps必备面试问题/","link":"","permalink":"http://blog.ozairs.com/DevOps/2019年DevOps必备面试问题/","excerpt":"","text":"您是DevOps工程师还是想进入DevOps？那么，未来就是你的。顶级研究公司Forrester宣布2018年为“ 企业DevOps年 ”，并估计全球有50％的组织正在实施DevOps。 在这篇博客中，我列出了几十个可能的问题，面试官会问潜在的DevOps员工。此列表是根据Edureka教练的专业知识精心制作的，他们是行业专家，来自60个国家的近30,000名Edureka DevOps学习者的经验。 要理解的关键是DevOps不仅仅是一种技术集合，而是一种思维方式，一种文化。DevOps需要一种将运营与发展相结合的文化转变，并需要一个相互关联的技术工具链来促进协作变革。由于DevOps理念仍处于初期阶段，因此DevOps的应用以及适应和协作所需的带宽因组织而异。但是，您可以开发DevOps技能组合，使您成为任何类型组织的理想候选人。 如果您想以周到，有条理的方式开发DevOps技能并获得DevOps工程师认证，我们很乐意为您提供帮助。完成Edureka DevOps认证课程后，我们承诺您将能够处理业内各种DevOps角色。 成为DevOps工程师有哪些要求？ 在寻求填写DevOps角色时，组织会寻找一套清晰的技能。其中最重要的是： 具有基础架构自动化工具的经验，如Chef，Puppet，Ansible，SaltStack或Windows PowerShell DSC。 熟练使用Ruby，Python，PHP或Java等网络语言。 人际关系技巧，可帮助您跨团队和角色进行沟通和协作。 顶级Devops面试问题这些是您在DevOps求职面试中可能遇到的首要问题： 一般DevOps面试问题 此类别将包含与任何特定DevOps阶段无关的问题。这里的问题旨在测试您对DevOps的理解，而不是关注特定工具或阶段。 Q1。DevOps和Agile之间的根本区别是什么？两者之间的差异列于下表中。 特征 DevOps的 敏捷 敏捷 开发和运营方面的敏捷性 只有发展的敏捷性 流程/实践 涉及CI，CD，CT等流程。 涉及敏捷Scrum，敏捷看板等实践。 重点关注领域 及时性和质量同等重要 及时性是主要优先事项 发布周期/开发冲刺 较小的发布周期和即时反馈 较小的发布周期 反馈来源 反馈来自自我（监测工具） 反馈来自客户 工作范围 敏捷性和自动化需求 只有敏捷 Q2。DevOps需要什么？据我所知，这个答案应该从解释一般市场趋势开始。公司不是发布大量功能，而是试图通过一系列发布列表来查看是否可以将小功能传输给客户。这具有许多优点，例如来自客户的快速反馈，更好的软件质量等，这反过来导致高的客户满意度。为实现这一目标，公司必须： 增加部署频率 降低新版本的故障率 缩短了修复之间的准备时间 新版本崩溃时平均恢复时间更快 DevOps满足所有这些要求，有助于实现无缝的软件交付。您可以举出像Etsy，Google和亚马逊这样的公司的例子，这些公司已经采用了DevOps来达到甚至五年前无法想象的性能水平。他们每天进行数十，数百甚至数千次代码部署，同时提供世界级的稳定性，可靠性和安全性。 如果我必须测试你对DevOps的了解，你应该知道Agile和DevOps之间的区别。下一个问题是针对这一点的。 Q3。DevOps与Agile / SDLC有何不同？我建议你按照以下说明进行操作： 敏捷是一套关于如何生产即开发软件的价值观和原则。示例：如果您有一些想法，并且希望将这些想法转变为可用的软件，则可以使用敏捷值和原则作为实现此目的的方法。但是，该软件可能只适用于开发人员的笔记本电脑或测试环境。您希望以安全，简单的方式快速，轻松，可重复地将该软件移植到生产基础架构中。要做到这一点，您需要DevOps工具和技术。 您可以总结一下，敏捷软件开发方法侧重于软件的开发，但另一方面，DevOps负责开发以及以最安全和最可靠的方式部署软件。这是一个博客，将为您提供有关DevOps演变的更多信息。 现在请记住，您在之前的答案中包含了DevOps工具，因此请准备好回答与此相关的一些问题。 Q4。哪些是最顶级的DevOps工具？你做过哪些工具？最受欢迎的DevOps工具如下所述： Git：版本控制系统工具 Jenkins：持续集成工具 Selenium：连续测试工具 Puppet，Chef，Ansible：配置管理和部署工具 Nagios：持续监控工具 Docker：容器化工具 如果需要，您还可以提及任何其他工具，但请确保在答案中包含上述工具。答案的第二部分有两种可能性： 如果您有上述所有工具的经验，那么您可以说我已经使用所有这些工具来开发高质量的软件并轻松，经常和可靠地部署这些软件。 如果您只有上述某些工具的经验，那么请提及这些工具，并说我对这些工具有专业性，并对其余工具进行了概述。 我们的DevOps认证课程包括最流行的DevOps工具的实际操作培训。找出下一批次开始的时间。 Q5。所有这些工具如何协同工作？下面给出了一个通用的逻辑流程，其中所有内容都自动进行无缝交付 但是，根据要求，此流程可能因组织而异。 开发人员开发代码，此源代码由Git等版本控制系统工具管理。 开发人员将此代码发送到Git存储库，并且代码中所做的任何更改都将提交到此存储库。 Jenkins使用Git插件从存储库中提取此代码，并使用Ant或Maven等工具构建它。 配置管理工具，如puppet部署和配置测试环境，然后Jenkins在测试环境中发布此代码，使用selenium等工具进行测试。 一旦代码被测试，Jenkins就会将其发送到生产服务器上进行部署（甚至生产服务器也由puppet等工具进行配置和维护）。 部署后，Nagios等工具会持续监控。 Docker容器提供测试环境来测试构建功能。 Q6。DevOps有哪些优势？对于这个答案，您可以使用您过去的经验并解释DevOps如何帮助您完成上一份工作。如果您没有任何此类经验，那么您可以提及以下优势。 技术优势： 持续的软件交付 修复不太复杂的问题 更快地解决问题 商业利益： 更快速地传递功能 更稳定的操作环境 更多时间可用于增加价值（而不是修复/维护） Q7。DevOps帮助我们实现的最重要的事情是什么？据我所知，DevOps帮助我们实现的最重要的事情是尽可能快地将更改投入生产，同时最大限度地降低软件质量保证和合规性的风险。这是DevOps的主要目标。在DevOps教程博客中了解更多信息。但是，您可以添加DevOps的许多其他积极效果。例如，团队之间更清晰的沟通和更好的工作关系，即Ops团队和开发团队共同合作提供高质量的软件，从而提高客户满意度。 Q8。解释DevOps可用于工业/现实生活中的用例。有许多行业正在使用DevOps，所以你可以提到任何这些用例，你也可以参考下面的例子：Etsy是一个点对点的电子商务网站，专注于手工或古董物品和用品，以及独特的工厂制造的物品。Etsy在缓慢，痛苦的网站更新中挣扎，经常导致网站崩溃。它影响了数百万Etsy用户的销售，这些用户通过在线市场销售商品并冒险将其推向竞争对手。在新技术管理团队的帮助下，Etsy从其瀑布模型转变为更敏捷的方法，瀑布模型每周两次进行4小时全站点部署。如今，它拥有完全自动化的部署管道，据报道，其持续交付实践每天导致50多次部署，中断更少。 Q9。解释您在过去曾与之合作过的组织的软件开发方面和技术操作方面的理解和专业知识。对于这个答案，分享您过去的经验并尝试解释您在以前的工作中的灵活性。您可以参考以下示例：DevOps工程师几乎总是在24/7关键业务在线环境中工作。我适应了随叫随到的职责，可以承担实时，实时系统的责任。我成功实现了自动化流程，以支持持续的软件部署 我有使用公共/私有云，Chef或Puppet等工具，使用Python和PHP等工具编写脚本和自动化的经验，以及Agile的背景知识。 Q10。DevOps的反模式有哪些？通常遵循一种模式。如果其他人普遍采用的模式对您的组织不起作用，并且您继续盲目地遵循它，那么您实际上采用的是反模式。有关于DevOps的神话。其中一些包括： DevOps是一个过程 敏捷等于DevOps？ 我们需要一个单独的DevOps组 Devops将解决我们所有的问题 DevOps意味着开发人员管理生产 DevOps是开发驱动的发布管理 DevOps不是开发驱动的。 DevOps不是IT运营驱动的。 我们不能做DevOps - 我们是独一无二的 我们不能做DevOps - 我们遇到了错误的人 版本控制系统（VCS）面试问题现在让我们来看看有关VCS的一些访谈问题。如果您希望获得像Git这样的VCS的实际操作培训，它将包含在我们的DevOps认证课程中。 Q1。什么是版本控制？这可能是您在面试中将面临的最简单的问题。我的建议是首先给出版本控制的定义。它是一个记录文件或文件集随时间变化的系统，以便您以后可以调用特定版本。版本控制系统由一个中央共享存储库组成，队友可以在其中提交对文件或文件集的更改。然后你可以提到版本控制的用途。 版本控制允许您： 将文件还原为以前的状态。 将整个项目还原为以前的状态。 比较一段时间内的变化 查看最后一次修改可能导致问题的内容。 谁介绍了一个问题，何时。 Q2。使用版本控制有什么好处？我建议你包括版本控制的以下优点： 使用版本控制系统（VCS），所有团队成员都可以随时在任何文件上自由工作。稍后VCS将允许您将所有更改合并到一个通用版本中。 所有过去的版本和变体都整齐地打包在VCS中。当您需要它时，您可以随时请求任何版本，您将获得完整项目的快照。 每次保存项目的新版本时，VCS都要求您提供已更改内容的简短说明。此外，您还可以查看文件内容的确切更改内容。这可以让您知道谁在项目中做了哪些更改。 像Git这样的分布式VCS允许所有团队成员拥有项目的完整历史记录，因此如果中央服务器出现故障，您可以使用任何团队成员的本地Git存储库。 Q3。描述您使用的分支策略。这个问题被要求测试你的分支经验，告诉他们你在以前的工作中如何使用分支以及它的用途是什么，你可以参考以下几点： 功能分支功能分支模型保留分支内特定功能的所有更改。当通过自动化测试对功能进行全面测试和验证时，该分支将合并到主服务器中。 任务分支在此模型中，每个任务都在其自己的分支上实现，任务键包含在分支名称中。很容易看出哪个代码实现了哪个任务，只需在分支名称中查找任务键。 发布分支一旦开发分支为发布获得了足够的功能，您就可以克隆该分支以形成发布分支。创建此分支将启动下一个发布周期，因此在此之后不能添加任何新功能，只有错误修复，文档生成和其他面向发布的任务应该在此分支中。一旦准备好发布，该版本将合并到主服务器并标记版本号。此外，它应该合并回到开发分支，自发布以来可能已经取得了进展。 最后告诉他们分支策略因组织而异，所以我知道基本的分支操作，如删除，合并，检查分支等。 Q4。您熟悉哪种VCS工具？你可以提到你曾经使用的VCS工具：“我已经使用过Git，它对SVN等其他VCS工具的一个主要优势就是它是一个分布式版本控制系统。”分布式VCS工具不一定依靠中央服务器来存储项目文件的所有版本。相反，每个开发人员都“克隆”存储库的副本，并在自己的硬盘上拥有项目的完整历史记录。 Q5。什么是Git？我建议您首先解释一下git的体系结构来尝试这个问题，如下图所示。您可以参考下面给出的解释： Git是一个分布式版本控制系统（DVCS）。它可以跟踪文件的更改，并允许您恢复到任何特定的更改。 与SVN等其他版本控制系统（VCS）相比，它的分布式架构具有许多优势，一个主要优点是它不依赖于中央服务器来存储项目文件的所有版本。相反，每个开发人员“克隆”我在下图中使用“本地存储库”显示的存储库副本，并在其硬盘驱动器上具有项目的完整历史记录，以便在出现服务器中断时，恢复所需的全部内容是你队友的本地Git存储库之一。 还有一个中央云存储库，开发人员可以在其中提交更改并与其他团队成员共享，如图所示，所有协作者都在提交更改“远程存储库”。 Q6。解释一些基本的Git命令？以下是一些基本的Git命令： Q7。在Git中，您如何还原已经被推送并公开的提交？此问题可以有两个答案，因此请确保包含两个答案，因为根据具体情况可以使用以下任何选项： 在新提交中删除或修复错误文件，并将其推送到远程存储库。这是修复错误的最自然方式。对文件进行必要的更改后，将其提交到远程存储库，我将使用git commit -m“commit message” 创建一个新的提交，撤消在错误提交中所做的所有更改。为此，我将使用命令git revert Q8。你如何将N次提交压缩成一次提交？将N个提交压缩到单个提交中有两种选择。在您的答案中包括以下两个选项： 如果要从头开始编写新的提交消息，请使用以下命令git reset -soft HEAD~N &amp;&amp;git commit 如果你想用现有提交消息的串联开始编辑新的提交消息，那么你需要提取这些消息并将它们传递给Git commit，我将使用git reset -soft HEAD~N &amp;&amp;git commit -edit -m “$（git log -format =％B -reverse .HEAD @ {N}）” DevOps认证培训观看课程预览 Q9。什么是Git bisect？你怎么用它来确定（回归）bug的来源？我建议你先给出一个Git bisect的小定义，Git bisect用于查找通过二进制搜索引入bug的提交。Git bisect的命令是git bisect &lt;子命令&gt; 现在你已经提到了上面的命令，解释一下这个命令会做什么，这个命令使用二进制搜索算法来查找项目历史中哪个提交引入了一个bug。您可以通过首先告诉它已知包含该错误的“错误”提交以及在引入错误之前已知的“良好”提交来使用它。然后Git bisect在这两个端点之间选择一个提交，并询问您所选的提交是“好”还是“坏”。它继续缩小范围，直到找到引入更改的确切提交。 Q10。什么是Git rebase以及它如何在合并之前用于解决功能分支中的冲突？根据我的说法，您应首先说git rebase是一个命令，它将另一个分支合并到您当前正在工作的分支中，并将所有位于重新分支之前的本地提交移到该历史记录的顶部。科。现在，一旦您为一个示例定义了Git rebase时间，以显示如何在合并之前使用它来解决功能分支中的冲突，如果从master创建了一个功能分支，那么主分支已经收到了新的提交，Git rebase可用于将要素分支移动到主要提示。该命令有效地将重放在master的tip处的功能分支中所做的更改，从而允许在该过程中解决冲突。完成后，这将允许功能分支相对容易地合并到主服务器中，有时作为简单的快进操作。 Q11。如何配置Git存储库以在提交之前运行代码健全性检查工具，并在测试失败时阻止它们？我建议你先介绍一下理智检查，理智或烟雾测试 确定继续测试是否可行和合理。现在解释如何实现这一点，这可以通过与存储库的预提交钩子相关的简单脚本来完成。即使在您需要输入提交消息之前，也会在提交之前触发预提交挂钩。在此脚本中，可以运行其他工具，例如linters，并对提交到存储库中的更改执行完整性检查。最后给出一个例子，你可以参考下面的脚本：＃！/ bin / sh files = $（git diff -cached -name-only -diff-filter = ACM | grep’.go $’）if [-z files] ; 然后退出0 fi unfmtd = $（gofmt -l $ files）如果[-z unfmtd]; 然后退出0 fi echo“一些.go文件不是fmt’d” 退出1此脚本检查是否需要通过标准Go源代码格式化工具gofmt传递任何即将提交的.go文件。通过以非零状态退出，脚本有效地阻止将提交应用于存储库。 Q12。如何找到特定提交中已更改的文件列表？对于这个答案，而不是只是告诉命令，解释这个命令究竟会做什么，所以你可以这么说，为了获得在特定提交中更改的列表文件使用命令git diff-tree -r {hash}给定提交哈希，这将列出在该提交中更改或添加的所有文件。-r标志使命令列表单个文件，而不是仅将它们折叠到根目录名称中。你也可以包括下面提到的点，虽然它是完全可选的，但有助于给面试官留下深刻的印象。输出还将包含一些额外的信息，可以通过包含两个标志来轻松抑制：git diff-tree -no-commit-id -name-only -r {hash}这里-no-commit-id将禁止提交哈希值出现在输出中，而-name-only只会打印文件名而不是它们的路径。 Q13。每次存储库通过推送接收新提交时，如何设置脚本运行？每次存储库通过push接收新提交时，有三种方法可以配置脚本运行，需要根据需要触发脚本的时间来定义预接收，更新或后接收挂钩。 将提交提交到目标存储库时，将调用目标存储库中的预接收挂钩。绑定到此挂钩的任何脚本都将在更新任何引用之前执行。这是一个有用的钩子，用于运行有助于实施开发策略的脚本。 Update钩子以类似于预接收钩子的方式工作，并且在实际进行任何更新之前也会触发。但是，对于已推送到目标存储库的每个提交，都会调用一次update钩子。 最后，在将更新接受到目标存储库之后，将调用存储库中的post-receive挂钩。这是配置简单部署脚本，调用一些持续集成系统，向存储库维护人员发送通知电子邮件等的理想场所。 钩子是每个Git存储库的本地存储，并且没有版本化。脚本可以在“.git”目录内的hooks目录中创建，也可以在别处创建，并且可以在目录中放置这些脚本的链接。 Q14。如果分支已经合并为主分支，你怎么知道Git？我建议你包括下面提到的命令：git branch -merged列出已合并到当前分支的分支。git branch -no-merged列出了尚未合并的分支。 持续整合问题现在，让我们来看看持续集成面试问题： Q1。持续集成是什么意思？我将建议您通过给出持续集成（CI）的小定义来开始这个答案。这是一种开发实践，需要开发人员每天多次将代码集成到共享存储库中。然后通过自动构建验证每个签入，允许团队尽早发现问题。我建议您解释一下如何在以前的工作中实施它。您可以参考以下给出的示例： 在上图中： 开发人员将代码签入其私有工作区。 完成后，他们将更改提交到共享存储库（版本控制存储库）。 CI服务器监视存储库并在发生更改时检出更改。 然后，CI服务器将提取这些更改并构建系统，并运行单元和集成测试。 CI服务器现在将通知团队成功构建。 如果构建或测试失败，CI服务器将向团队发出警报。 该团队将尽早解决问题。 这个过程不断重复。 Q2。为什么需要开发和测试的持续集成？对于这个答案，您应该关注持续集成的需求。我的建议是在你的答案中提到以下解释：开发和测试的持续集成通过在完成所有开发之后替换传统的测试实践来提高软件质量并减少交付时间。它允许Dev团队尽早检测和定位问题，因为开发人员需要每天多次（更频繁地）将代码集成到共享存储库中。然后自动测试每个登记入住。 Q3。持续集成的成功因素有哪些？在这里，您必须提到持续集成的要求。您可以在答案中包含以下几点： 维护代码存储库 自动化构建 使构建自我测试 每个人每天承诺到基线 应该构建每个提交（到基线） 保持快速构建 在生产环境的克隆中进行测试 让您轻松获得最新的可交付成果 每个人都可以看到最新版本的结果 自动部署 Q4。解释如何将Jenkins从一台服务器移动或复制到另一台服务器？我将通过将jobs目录从旧服务器复制到新服务器来完成此任务。有多种方法可以做到这一点; 我在下面提到过它们：你可以： 只需复制相应的作业目录，即可将作业从一个Jenkins安装移动到另一个。 通过使用其他名称克隆作业目录来制作现有作业的副本。 通过重命名目录重命名现有作业。请注意，如果更改作业名称，则需要更改尝试调用重命名作业的任何其他作业。 Q5。解释如何在Jenkins中创建备份和复制文件？回答这个问题真的很直接。要创建备份，您需要做的就是定期备份JENKINS_HOME目录。这包含所有构建作业配置，从属节点配置和构建历史记录。要创建Jenkins设置的备份，只需复制此目录即可。您还可以复制作业目录以克隆或复制作业或重命名目录。 Q6。解释如何设置Jenkins工作？我对这个答案的解决方法是首先提一下如何创建Jenkins的工作。转到Jenkins首页，选择“New Job”，然后选择“Build a free-style software project”。然后你可以告诉这个自由式工作的元素： 可选的SCM，例如源代码所在的CVS或Subversion。 用于控制Jenkins何时执行构建的可选触发器。 某种构建脚本，用于执行实际工作的构建（ant，maven，shell脚本，批处理文件等）。 从构建中收集信息的可选步骤，例如归档工件和/或记录javadoc和测试结果。 使用构建结果通知其他人/系统的可选步骤，例如发送电子邮件，IM，更新问题跟踪器等。 Q7。提到Jenkins中一些有用的插件。下面，我提到了一些重要的插件： Maven 2项目 亚马逊EC2 HTML发布者 复制工件 加入 绿球 Q8。你如何保护Jenkins？我保护Jenkins的方式如下所述。如果您有任何其他方式，请在下面的评论部分中提及： 确保全球安全。 确保Jenkins与我公司的用户目录与适当的插件集成。 确保启用矩阵/项目矩阵以微调访问。 使用自定义版本控制的脚本自动化在Jenkins中设置权限/特权的过程。 限制对Jenkins数据/文件夹的物理访问。 定期对其进行安全审核。 Jenkins是DevOps中广泛使用的众多流行工具之一。 持续测试面试问题：现在让我们继续讨论持续测试问题。 Q1。什么是连续测试？我将建议您遵循以下提到的解释：持续测试是将自动化测试作为软件交付管道的一部分执行的过程，以获得与最新构建相关的业务风险的即时反馈。通过这种方式，每个构建都会持续测试，允许开发团队获得快速反馈，以便他们可以防止这些问题进入软件交付生命周期的下一阶段。这大大加快了开发人员的工作流程，因为无需手动重建项目并在进行更改后重新运行所有测试。 Q2。什么是自动化测试？自动化测试或测试自动化是自动化手动过程以测试被测应用程序/系统的过程。自动化测试涉及使用单独的测试工具，使您可以创建可以重复执行的测试脚本，而不需要任何手动干预。 Q3。 自动化测试有哪些好处**？**我列举了自动化测试的一些优点。在您的答案中包含这些内容，您可以添加自己的经验，了解Continuous Testing如何帮助您以前的公司： 支持执行重复的测试用例 有助于测试大型测试矩阵 启用并行执行 鼓励无人看管的执行 提高准确性，从而减少人为产生的错误 节省时间和金钱 Q4。如何在DevOps生命周期中自动化测试？我已经提到了一个通用流程，您可以在其中参考：在DevOps中，开发人员需要将源代码中的所有更改提交到共享存储库。像Jenkins这样的持续集成工具每次在代码中进行更改时都会从此共享存储库中提取代码，并将其部署到连续测试中，这些工作由Selenium等工具完成，如下图所示。通过这种方式，与传统方法不同，代码的任何变化都会不断进行测试。 Q5。**为什么持续测试对DevOps很重要？**您可以通过说“连续测试允许立即测试代码中的任何更改来回答这个问题。这避免了在周期结束时进行“大爆炸”测试所产生的问题，例如发布延迟和质量问题。通过这种方式，持续测试可以促进更频繁和更好的质量发布。“ Q6。连续测试工具的关键要素是什么？连续测试的关键要素是： 风险评估：它涵盖风险缓解任务，技术债务，质量评估和测试覆盖范围优化，以确保构建准备好向下一阶段发展。 策略分析：确保所有流程符合组织不断发展的业务和合规性要求。 要求可追溯性：确保满足真正的要求，不需要返工。对象评估用于确定哪些需求存在风险，按预期工作或需要进一步验证。 高级分析：它在静态代码分析，变更影响分析和范围评估/优先级划分等领域使用自动化，以便首先防止缺陷并在每次迭代中完成更多工作。 测试优化：确保测试产生准确的结果并提供可操作的结果。方面包括测试数据管理，测试优化管理和测试维护 服务虚拟化：它确保访问真实的测试环境。服务可视化使您能够访问所需测试阶段的虚拟表单，从而缩短测试环境设置和可用性的浪费时间。 Q7。您熟悉哪种测试工具以及该工具的优点是什么？这里提到您使用过的测试工具，并相应地构建您的答案。我已经提到了一个例子：我已经在Selenium上工作，以确保高质量和更频繁的发布。 Selenium的一些优点是： 它是免费和开源的 它拥有庞大的用户群和帮助社区 它具有跨浏览器兼容性（Firefox，Chrome，Internet Explorer，Safari等） 它具有出色的平台兼容性（Windows，Mac OS，Linux等） 它支持多种编程语言（Java，C＃，Ruby，Python，Pearl等） 它有新的和定期的存储库开发 它支持分布式测试 Q8。Selenium支持哪些测试类型？Selenium支持两种类型的测试：回归测试：它是在修复错误的区域周围重新测试产品的行为。功能测试：它指的是单独测试软件功能（功能点）。 Q9。什么是Selenium IDE？我的建议是通过定义Selenium IDE来开始这个答案。它是Selenium脚本的集成开发环境。它作为Firefox扩展实现，允许您记录，编辑和调试测试。Selenium IDE包含整个Selenium Core，允许您在他们将运行的实际环境中轻松快速地记录和回放测试。现在，您的答案中包含一些优势。凭借自动完成支持和快速移动命令的能力，无论您喜欢何种类型的测试，Selenium IDE都是创建Selenium测试的理想环境。 Q10。Selenium中的Assert和Verify命令有什么区别？我在下面提到了Assert和Verify命令之间的区别： 断言命令检查给定条件是真还是假。假设我们断言给定元素是否存在于网页上。如果条件为真，则程序控制将执行下一个测试步骤。但是，如果条件为假，则执行将停止，并且不会执行进一步的测试。 Verify命令还会检查给定条件是true还是false。无论条件是真还是假，程序执行都不会停止，即验证期间的任何故障都不会停止执行，并且所有测试步骤都将被执行。 Q11。如何使用WebDriver启动浏览器？以下语法可用于启动Browser：WebDriver driver = new FirefoxDriver（）;WebDriver driver = new ChromeDriver（）;WebDriver driver = new InternetExplorerDriver（）; Q12。**我什么时候应该使用Selenium Grid？**对于这个答案，我的建议是给出Selenium Grid的一个小定义。它可以用于在多个平台和浏览器上同时执行相同或不同的测试脚本，以实现分布式测试执行。这允许在不同环境下进行测试并显着节省执行时间。 在我们的DevOps认证课程中，通过现场讲师指导的在线课程学习自动化测试和其他DevOps概念。 立即使用DevOps进行自动化测试&gt;&gt; 配置管理面试问题现在让我们来看看你对Configuration Management的了解程度。 Q1。配置管理流程的目标是什么？配置管理（CM）的目的是通过使开发或部署过程可控且可重复，确保产品或系统在其整个生命周期中的完整性，从而创建更高质量的产品或系统。CM流程允许有序管理系统信息和系统更改，以便： 修改能力， 提高性能， 可靠性或可维护性， 延长寿命， 降低成本， 降低风险和 责任或纠正缺陷。 Q2。资产管理和配置管理有什么区别？以下是资产管理和配置管理之间的一些差异： Q3。资产和配置项有什么区别？据我说，你应该首先解释资产。它具有财务价值以及附加的折旧率。IT资产只是它的一个子集。任何具有成本的组织和组织都将其用于资产价值计算和税收计算中的相关收益属于资产管理，此类项目称为资产。另一方面，配置项可能有也可能没有分配给它的财务值。它不会有任何与之相关的折旧。因此，它的生命不依赖于其财务价值，而是取决于该项目对该组织过时的时间。 现在，您可以举例说明两者之间的相似性和差异：1）相似性：服务器 - 它既是资产又是CI。2）差异：建筑 - 这是一种资产，但不是CI。文档 - 它是CI但不是资产 Q4。您对“基础设施作为代码”有何看法？它如何适用于DevOps方法？它的目的是什么？作为代码的基础架构（IAC）是一种IT基础架构，运营团队可以使用它来自动管理和通过代码进行配置，而不是使用手动过程。更快部署的公司会将软件等基础设施视为可以使用DevOps工具和流程管理的代码。利用这些工具，您可以更轻松，快速，安全，可靠地更改基础架构。 Q5。Puppet，Chef，SaltStack和Ansible中哪一个是最好的配置管理（CM）工具？为什么？这取决于组织的需求，因此在所有这些工具上提到几点：Puppet是最古老，最成熟的CM工具。Puppet是一个基于Ruby的配置管理工具，虽然它有一些免费功能，但Puppet很棒的大部分内容仅在付费版本中可用。不需要大量额外功能的组织会发现Puppet很有用，但那些需要更多自定义的组织可能需要升级到付费版本。Chef是用Ruby编写的，因此可以由熟悉该语言的人定制。它还包括免费功能，如果需要，还可以从开源升级到企业级。最重要的是，它是一个非常灵活的产品。Ansible是一个非常安全的选项，因为它使用Secure Shell。它是一个简单的工具，但除了配置管理之外，它还提供了许多其他服务。它非常容易学习，因此非常适合那些没有专职IT人员但仍需要配置管理工具的人。SaltStack是基于python的开源CM工具，适用于大型企业，但其学习曲线相当低。 Q6。什么是Puppet？我会建议你先给出一个小小的Puppet定义。它是一个配置管理工具，用于自动执行管理任务。现在您应该描述其架构以及Puppet如何管理其代理。Puppet有一个Master-Slave架构，其中Slave必须首先向Master发送证书签名请求，Master必须签署该证书才能在Puppet Master和Puppet Slave之间建立安全连接，如下图所示。Puppet Slave向Puppet Master和Puppet Master发送请求，然后在Slave上推送配置。请参阅下面的图解释上述说明。 Q7。**在客户端使用Puppet Master进行身份验证之前，需要对其证书进行签名和接受。你将如何自动完成这项任务？**最简单的方法是在puppet.conf中启用自动签名。请注意这是一个安全风险。如果您仍想这样做： 防火墙您的Puppet大师 - 将端口tcp / 8140限制为仅您信任的网络。 为每个“信任区域”创建Puppet大师，并且只在该Puppet大师清单中包含可信节点。 切勿使用完整的通配符，例如*。 Q8。描述通过Puppet自动化流程所取得的最重要的收益。对于这个答案，我建议你解释一下你过去使用Puppet的经历。您可以参考以下示例：我使用Puppet自动配置和部署Linux和Windows机器。除了将处理时间从一周缩短到10分钟之外，我还使用了角色和配置文件模式，并在README中记录了每个模块的用途，以确保其他人可以使用Git更新模块。我写的模块仍然在使用，但是我的团队成员和社区成员对它们进行了改进 Q9。您使用哪些开源或社区工具来使Puppet更强大？在这里，您需要提及工具以及如何使用这些工具使Puppet更强大。以下是一个供您参考的示例：更改和请求通过Jira出票，我们通过内部流程管理请求。然后，我们使用Git和Puppet的Code Manager应用程序根据最佳实践管理Puppet代码。此外，我们使用烧杯测试框架通过Jenkins中的持续集成管道运行所有Puppet更改。 Q10。什么是Puppet清单？这是一个非常重要的问题，所以请确保您正确的流程。据我说，你应该首先定义清单。每个节点（或Puppet Agent）都在Puppet Master中获得了配置细节，用本机Puppet语言编写。这些细节用Puppet可以理解的语言编写，称为Manifest。它们由Puppet代码组成，其文件名使用.pp扩展名。现在举个例子。您可以在Puppet Master中编写一个清单，用于创建文件并在连接到Puppet Master的所有Puppet Agent（Slaves）上安装apache。 Q11。 什么是Puppet模块以及它与Puppet Manifest的不同之处？对于这个答案，您可以使用下面提到的解释：Puppet模块是清单和数据（例如事实，文件和模板）的集合，它们具有特定的目录结构。模块对于组织Puppet代码很有用，因为它们允许您将代码拆分为多个清单。使用模块来组织几乎所有的Puppet清单是最佳实践。Puppet程序称为Manifest，它由Puppet代码组成，其文件名使用.pp扩展名。 Q12。 什么是Puppet的Facter？你应该回答Facter在Puppet中做了什么，所以根据我的说法，你应该说，“Facter收集有关Puppet Agent的基本信息（事实），如硬件细节，网络设置，操作系统类型和版本，IP地址，MAC地址， SSH密钥等等。这些事实随后在Puppet Master的清单中作为变量提供。“ Q13。什么是Chef？通过定义Chef来开始这个答案。它是一个强大的自动化平台，可将基础架构转换为代码。Chef是一个工具，您可以编写用于自动化流程的脚本。什么过程？几乎与IT相关的任何事情。现在您可以解释Chef的架构，它包括： Chef Server： Chef Server是基础架构配置数据的中央存储。Chef Server存储配置节点所需的数据并提供搜索功能，这是一个功能强大的工具，允许您根据数据动态驱动节点配置。 Chef Node： Node是使用Chef-client配置的任何主机。Chef-client在您的节点上运行，与Chef Server联系以获取配置节点所需的信息。由于Node是运行Chef-client软件的机器，因此节点有时被称为“客户端”。 Chef Workstation： Chef Workstation是您用来修改cookbook和其他配置数据的主机。 Q14。Chef的资源是什么？我的建议是先定义资源。资源代表一个基础架构及其所需的状态，例如应安装的软件包，应运行的服务或应生成的文件。您应该解释资源的功能，包括以下几点： 描述配置项的所需状态。 声明将该项目置于所需状态所需的步骤。 指定资源类型，例如包，模板或服务。 根据需要列出其他详细信息（也称为资源属性）。 分为配方，描述工作配置。 Q15。Chef的食谱是什么意思？对于这个答案，我建议你使用上面提到的流程：首先定义食谱。Recipe是描述特定配置或策略的资源集合。配方描述了配置系统部分所需的一切。定义之后，通过包括以下几点来解释食谱的功能： 安装和配置软件组件。 管理文件。 部署应用程序。 执行其他食谱。 Q16。 Cookbook与Chef中的食谱有何不同？对此的答案非常直接。您可以简单地说，“Recipe是一组资源，主要配置软件包或某些基础架构。“食谱”将食谱和其他信息整合在一起，比单独使用“食谱”更易于管理。“ Q17。 如果未在Chef中指定Resource的操作，会发生什么？我的建议是首先直接回答：当您未指定资源的操作时，Chef会应用默认操作。现在用一个例子解释一下，下面的资源：文件’C：\\ Users \\ Administrator \\ chef-repo \\ settings.ini’做内容’greeting = hello world’结束与下面的资源相同：文件’C：\\ Users \\管理\\Chef回购\\的Settings.ini”做的动作：创建内容“的问候语=你好世界结束的原因是：创造是文件资源的默认操作。 Q18。什么是Ansible模块？模块被认为是Ansible的工作单元。每个模块大多是独立的，可以用标准的脚本语言编写，如Python，Perl，Ruby，bash等。模块的一个指导属性是幂等性，这意味着即使一个操作重复多次，例如，从停电中恢复，它将始终将系统置于同一状态。 Q19。什么是Ansible的剧本？Playbooks是Ansible的配置，部署和编排语言。他们可以描述您希望远程系统实施的策略，或者描述一般IT流程中的一系列步骤。Playbooks设计为人类可读的，并以基本文本语言开发。在基本级别，可以使用playbooks来管理远程计算机的配置和部署。 Q20。 如何查看所有ansible_变量的列表？Ansible默认收集有关所管理机器的“事实”，这些事实可以在Playbooks和模板中访问。要查看有关计算机的所有可用事实的列表，可以将“设置”模块作为临时操作运行：Ansible -m setup hostname这将打印出所有可用事实的字典对于那个特定的主人。 Q21。如何设置应用程序的部署顺序？WebLogic Server 8.1允许您选择应用程序的加载顺序。请参阅Application中的Application MBean Load Order属性。WebLogic Server在部署应用程序之前部署服务器级资源（第一个JDBC，然后是JMS）。应用程序按以下顺序部署：连接器，然后是EJB，然后是Web应用程序。如果应用程序是EAR，则按照在application.xml部署描述符中声明它们的顺序加载各个组件。 Q22。我是否可以刷新已部署应用程序的静态组件而无需重新部署整个应用程序？是的，您可以使用weblogic.Deployer指定组件并使用以下语法定位服务器：java weblogic.Deployer -adminurl http：// admin：7001 -name appname -targets server1，server2 -deploy jsps / * .jsp Q23。如何关闭自动部署功能？自动部署功能每三秒检查一次应用程序文件夹，以确定是否有任何新应用程序或对现有应用程序的任何更改，然后动态部署这些更改。 为在开发模式下运行的服务器启用了自动部署功能。要禁用自动部署功能，请使用以下方法之一将服务器置于生产模式： 在管理控制台中，单击左窗格中的域名，然后在右窗格中选择“生产模式”复选框。 在命令行中，在启动域的管理服务器时包括以下参数：-Dweblogic.ProductionModeEnabled = true 为给定域中的所有WebLogic Server实例设置生产模式。 Q24。我什么时候应该使用external_stage选项？如果您想自己暂存应用程序，请使用weblogic.Deployer设置-external_stage，并希望通过自己的方式将其复制到目标。 持续监控面试问题让我们测试您对持续监控的了解。 Q1。为什么需要持续监控？我建议您使用下面提到的流程：持续监控可以及时发现问题或缺陷，并采取快速纠正措施，有助于降低组织的费用。持续监控提供解决方案，解决三个操作规程，称为： 持续审计 连续控制监测 持续交易检查 Q2。什么是Nagios？您可以通过首先提到Nagios是监视工具之一来回答这个问题。它用于DevOps文化中的系统，应用程序，服务和业务流程等的连续监视。如果发生故障，Nagios可以向技术人员提醒问题，允许他们在中断影响业务流程，最终用户或客户之前开始修复流程。使用Nagios，您无需解释为什么不可见的基础架构中断会影响您组织的底线。现在，一旦你定义了什么是Nagios，你可以提到使用Nagios可以实现的各种事情。通过使用Nagios，您可以： 在过时的系统导致故障之前规划基础架构升级。 在出现问题的第一个迹象时回答问题。 检测到问题时自动修复问题。 协调技术团队的回应。 确保您的组织的SLA得到满足。 确保IT基础架构中断对组织的底线影响最小。 监控整个基础架构和业务流程。 这就完成了这个问题的答案。可以根据讨论的方向添加诸如优点等的进一步细节。 Q3。Nagios如何运作？我将建议您按照以下解释来解答：Nagios在服务器上运行，通常作为守护进程或服务运行。Nagios定期运行驻留在同一服务器上的插件，它们会联系您网络或Internet上的主机或服务器。可以使用Web界面查看状态信息。如果发生某些事情，您还可以收到电子邮件或短信通知Nagios守护程序的行为类似于在某些时刻运行某些脚本的调度程序。它存储这些脚本的结果，并在这些结果发生变化时运行其他脚本。 现在期待关于Nagios组件的一些问题，如插件，NRPE等。 Q4。什么是Nagios的插件？通过定义插件开始这个答案。它们是脚本（Perl脚本，Shell脚本等），可以从命令行运行以检查主机或服务的状态。Nagios使用插件的结果来确定网络上主机和服务的当前状态。一旦定义了插件，解释为什么我们需要插件。只要需要检查主机或服务的状态，Nagios就会执行插件。插件将执行检查，然后只是将结果返回给Nagios。Nagios将处理从插件接收的结果并采取必要的操作。 Q5。Nagios中的NRPE（Nagios Remote Plugin Executor）是什么？对于这个答案，给出插件的简要定义。NRPE插件旨在允许您在远程Linux / Unix计算机上执行Nagios插件。这样做的主要原因是允许Nagios监视远程计算机上的“本地”资源（如CPU负载，内存使用情况等）。由于这些公共资源通常不会暴露给外部计算机，因此必须在远程Linux / Unix计算机上安装NRPE之类的代理。 我将建议您根据下图所示解释NRPE架构。NRPE插件由两部分组成： check_nrpe插件，驻留在本地监视机器上。 NRPE守护程序，在远程Linux / Unix机器上运行。 监视主机和远程主机之间存在SSL（安全套接字层）连接，如下图所示。 Q6。你对Nagios的被动检查是什么意思？据我所知，答案应该从解释被动检查开始。它们由外部应用程序/进程启动和执行，被动检查结果将提交给Nagios进行处理。然后解释被动检查的必要性。它们对于监视异步的服务非常有用，并且无法通过定期轮询其状态来有效监视。它们还可用于监视位于防火墙后面的服务，并且无法从监视主机主动检查。 Q7。 Nagios何时检查外部命令？确保在解释过程中坚持这个问题，所以我建议你按照下面提到的流程。Nagios在以下条件下检查外部命令： 由主配置文件中的command_check_interval选项指定的定期间隔，或 事件处理程序执行后立即执行。这是外部命令检查的常规循环的补充，并且在事件处理程序向Nagios提交命令时提供立即操作。 Q8。**Nagios中的主动和被动检查有什么区别？**对于这个答案，首先指出主动和被动检查的基本区别。主动检查和被动检查之间的主要区别在于Active检查由Nagios启动和执行，而被动检查由外部应用程序执行。如果您的面试官看起来不相信上述说明，那么您还可以提及主动和被动检查的一些关键功能：被动检查对于监控以下服务非常有用： 本质上是异步的，无法通过定期轮询其状态来有效监控。 位于防火墙后面，无法从监控主机主动检查。 Actives检查的主要功能如下： Nagios流程启动主动检查。 主动检查定期运行。 Q9。Nagios如何帮助分布式监控？面试官将期待与Nagios的分布式架构相关的答案。因此，我建议您以下面提到的格式回答：使用Nagios，您可以使用分布式监控方案监控整个企业，Nagios的本地从属实例执行监控任务并将结果报告给单个主站。您可以管理主服务器的所有配置，通知和报告，而从服务器可以完成所有工作。这种设计利用了Nagios利用被动检查的能力，即外部应用程序或将结果发送回Nagios的过程。在分布式配置中，这些外部应用程序是Nagios的其他实例。 Q10。解释Nagios的主要配置文件及其位置？首先提一下这个主配置文件包含的内容及其功能。主配置文件包含许多影响Nagios守护程序运行方式的指令。Nagios守护程序和CGI都读取此配置文件（它指定主配置文件的位置）。现在您可以知道它的存在位置以及创建方式。运行configure脚本时，将在Nagios分发的基本目录中创建示例主配置文件。主配置文件的默认名称是nagios.cfg。它通常放在Nagios安装的etc /子目录中（即/ usr / local / nagios / etc /）。 Q11。解释Flaip Detection在Nagios中的工作原理？我会建议你先解释Flapping。当服务或主机过于频繁地更改状态时会发生抖动，这会导致大量问题和恢复通知。定义Flapping后，解释Nagios如何检测Flapping。每当Nagios检查主机或服务的状态时，它将检查它是否已经开始或停止振荡。Nagios遵循以下给定的程序来做到这一点： 存储分析历史检查结果的主机或服务的最后21次检查的结果，并确定状态更改/转换发生的位置 使用状态转换来确定主机或服务的百分比状态更改值（更改度量） 比较百分比状态变化值与低和高拍打阈值 当主机或服务的百分比状态变化首先超过高振荡阈值时，确定主机或服务已开始振荡。当主机或服务的百分比状态低于低抖动阈值时，确定主机或服务已停止振荡。 Q12。在Nagios中影响递归和继承的三个主要变量是什么？根据我的说法，这个答案的正确格式应该是：首先命名变量，然后对每个变量做一个小解释： 名称 使用 寄存器 然后给出每个变量的简要说明。Name是其他对象使用的占位符。使用定义应使用其属性的“父”对象。寄存器的值可以为0（表示只有模板）和1（实际对象）。寄存器值永远不会被继承。 Q13。Nagios的意思是面向对象？回答这个问题非常直接。我将回答这个问题，“Nagios的一个特性是对象配置格式，因为您可以创建从其他对象定义继承属性的对象定义，从而创建名称。这简化并阐明了各个组件之间的关系。“ Q14。什么是Nagios的州跟踪？我会建议你先介绍一下State Salking。它用于记录目的。当为特定主机或服务启用Stalking时，Nagios将非常仔细地监视该主机或服务，并记录它在检查结果输出中看到的任何更改。根据您和访调员之间的讨论，您还可以添加“在以后分析日志文件时非常有用。在正常情况下，只有在主机或服务自上次检查后状态发生变化时，才会记录主机或服务检查的结果。“ 想要接受像Nagios这样的监控工具的培训吗？想获得DevOps工程师认证吗？请务必查看我们的DevOps硕士课程。 容器化和虚拟化面试问题让我们看看您对容器和虚拟机的了解程度。 Q1。什么是容器？我的建议是首先解释容器化的必要性，容器用于提供从开发人员的笔记本电脑到测试环境，从临时环境到生产的一致计算环境。现在给出一个容器的定义，一个容器由一个完整的运行时环境组成：一个应用程序，以及它所有的依赖项，库和其他二进制文件，以及运行它所需的配置文件，捆绑到一个包中。容纳应用程序平台及其依赖项消除了操作系统分发和底层基础架构的差异。 Q2。容器化相比虚拟化有哪些优势？以下是容器化优于虚拟化的优势： 容器提供实时配置和可伸缩性，但VM提供缓慢的配置 与VM相比，容器是轻量级的 与容器相比，VM的性能有限 与VM相比，容器具有更好的资源利用率 Q3。容器（在我们的例子中是Docker）与虚拟机管理程序虚拟化（vSphere）有何不同？有什么好处？以下是一些差异。确保在答案中包含这些差异： Q4。什么是Docker图像？我建议你使用下面提到的流程：Docker镜像是Docker容器的来源。换句话说，Docker镜像用于创建容器。使用build命令创建映像，并且在使用run启动时它们将生成容器。图像存储在Docker注册表中，例如registry.hub.docker.com，因为它们可能变得非常大，图像被设计为由其他图像层组成，允许在通过网络传输图像时发送最少量的数据。提示：请注意Dockerhub，以便回答有关预先可用图像的问题。 Q5。什么是Docker容器？这是一个非常重要的问题，所以请确保您不偏离主题。我建议您遵循下面提到的格式：Docker容器包括应用程序及其所有依赖项，但与其他容器共享内核，在主机操作系统的用户空间中作为独立进程运行。Docker容器不依赖于任何特定的基础架构：它们可以在任何计算机，任何基础架构和任何云中运行。现在解释如何创建Docker容器，可以通过创建Docker镜像然后运行它来创建Docker容器，也可以使用Dockerhub上存在的Docker镜像。Docker容器基本上是Docker镜像的运行时实例。 Q6。**什么是Docker中心？**回答这个问题非常直接。Docker hub是一个基于云的注册表服务，允许您链接到代码存储库，构建映像并测试它们，存储手动推送的映像以及指向Docker云的链接，以便您可以将映像部署到主机。它为整个开发流程中的容器映像发现，分发和变更管理，用户和团队协作以及工作流自动化提供了集中资源。 Q7。 Docker与其他容器技术有何不同？据我所知，您的答案应该在以下几点：Docker容器易于在云中部署。与其他技术相比，它可以在相同的硬件上运行更多的应用程序，使开发人员可以轻松快速创建，可立即运行的容器化应用程序，并使管理和部署应用程序变得更加容易。您甚至可以与您的应用程序共享容器。如果你还有一些要点可以添加，你可以这样做，但要确保上面的解释在你的答案中。 Q8。 什么是Docker Swarm？你应该通过解释Docker Swarn来开始这个答案。它是Docker的本机群集，它将Docker主机池转变为单个虚拟Docker主机。Docker Swarm提供标准的Docker API，任何已经与Docker守护进程通信的工具都可以使用Swarm透明地扩展到多个主机。我还建议您添加一些支持的工具： Dokku Docker撰写 Docker Machine Jenkins Q9。Dockerfile用于什么？根据我的回答应该从解释Dockerfile的使用开始。Docker可以通过读取Dockerfile中的指令自动构建图像。现在我建议你给出一个Dockerfle的小定义。Dockerfile是一个文本文档，其中包含用户可以在命令行上调用以组合图像的所有命令。使用docker构建用户可以创建一个连续执行多个命令行指令的自动构建。 现在期待一些问题来测试您使用Docker的体验。 Q10。 我可以在Docker中使用json而不是yaml作为我的compose文件吗？你可以使用json而不是yaml作为你的compose文件，使用带有compose的json文件，指定用于例如的文件名：docker-compose -f docker-compose.json up Q11。 告诉我们你在过去的职位中如何使用Docker？解释您如何使用Docker来帮助快速部署。解释你如何使用脚本化Docker并将Docker与Puppet，Chef或Jenkins等其他工具一起使用。如果您在Docker中没有过去的实践经验，并且在类似的空间中有过其他工具的经验，请诚实并解释相同的内容。在这种情况下，如果您可以在功能方面与Docker比较其他工具，这是有意义的。 Q12。如何创建Docker容器？我建议你直接回答这个问题。我们可以使用以下命令使用Docker镜像创建Docker容器：docker run -t -i 此命令将创建并启动容器。您还应该添加，如果要检查主机上具有状态的所有正在运行的容器的列表，请使用以下命令：docker ps -a Q13。如何停止并重新启动Docker容器？为了停止Docker容器，您可以使用以下命令：docker stop &lt;容器ID&gt;现在重新启动Docker容器，您可以使用：docker restart &lt;容器ID&gt; Q14。Docker容器可以扩展多远？像谷歌和Twitter这样的大型网络部署，以及像Heroku和dotCloud这样的平台提供商都运行在容器技术上，并行运行数十万甚至数百万个容器。 Q15。Docker运行的平台是什么？我将通过说Docker仅在Linux和云平台上运行来开始这个答案，然后我将提到以下Linux供应商： Ubuntu 12.04,13.04等 Fedora 19/20 + RHEL 6.5+ CentOS 6+ Gentoo的 ArchLinux的 openSUSE 12.3+ CRUX 3.0+ 云： 亚马逊EC2 Google Compute Engine Microsoft Azure Rackspace公司 请注意，Docker无法在Windows或Mac上运行。 Q16。当Docker容器退出时，我会丢失数据吗？你可以回答这个问题，当Dcoker容器退出时，我不会丢失我的数据。在您明确删除容器之前，应用程序写入磁盘的任何数据都会保留在其容器中。即使在容器停止之后，容器的文件系统仍然存在。 而且，就是这样！ 我希望这些问题可以帮助您破解DevOps面试。如果您对我们有任何疑问，请在评论部分提及，我们会尽快回复您。 如果您希望为DevOps角色构建强大的简历，请查看我们为您编写的博客。 您还可以通过Facebook，Twitter，Instagram，YouTube，LinkedIn甚至Pinterest与我们联系！ 想要开始您的DevOps学习之旅吗？没有比Edureka更好的地方了。我们的荒谬承诺保证了它！","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/tags/DevOps/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"利用 Puppet 实现自动化管理配置 Linux 计算机集群","slug":"利用-Puppet-实现自动化管理配置-Linux-计算机集群","date":"2019-03-14T01:18:33.000Z","updated":"2019-03-14T03:39:22.101Z","comments":true,"path":"DevOps/Puppet/利用-Puppet-实现自动化管理配置-Linux-计算机集群/","link":"","permalink":"http://blog.ozairs.com/DevOps/Puppet/利用-Puppet-实现自动化管理配置-Linux-计算机集群/","excerpt":"","text":"Puppet：开源系统配置和管理工具随着虚拟化和云计算技术的兴起，计算机集群的自动化管理和配置成为了数据中心运维管理的热点。对于 IaaS、Paas、Saas 来说，随着业务需求的提升，后台计算机集群的数量也会线性增加。对于数据中心的运维人员来说，如何自动化管理、配置这些大规模的计算机集群节点，对于数据中心的稳定运行以及运维成本控制都显得至关重要。 Puppet 是一个开源系统配置管理工具，它有着简明的架构以及良好的扩展性；同时，Puppet 还提供了自有的系统配置描述语言以及完善的公用库，非常适合用于管理和部署大规模集群系统。 Puppet 的系统架构Puppet 使用简明的 C/S 架构，分为 Puppet Server 和 Puppet Node。 图 1. Puppet 的架构 Puppet Server Puppet Server 是配置和管理整个集群的大脑，管理着所有节点。系统管理员在 Puppet Server 上用 Puppet 特有的配置描述语言为各个节点编写配置文件 (manifest)，配置文件描述了节点的目标状态——资源的集合。这些资源可以是文件、服务、软件包等等。各个节点会周期性的查询 Puppet Server，获得自己的最新配置文件，并且在本地应用这些配置文件，使得自身的资源和状态达到配置文件要求。 Puppet Node(Agent) 被 Puppet Master 管理着的计算机节点称为 Puppet node。Puppet node 会周期性的查询 Puppet Master，来获取自己的配置文件，并且在本地应用。在每次应用配置文件之后，Puppet node 会提供上传一份报告给 Puppet Master，以便以后的统计和分析。系统管理员也可以手动地在 Puppet Node 上执行命令，让 Puppet Node 立即查询 Puppet Server 获取自身最新的配置文件，并且在本地应用。 Puppet 的工作流程Puppet 的工作流程可以概括成这几步：定义、模拟、应用、报告。 图 2. Puppet 的工作流程 定义 (Define)管理员为各个节点编写配置文件，配置文件中定义了该节点所需要的资源的集合以及资源之间的关系。这些资源可以是文件、服务、软件包、可执行的命令等等。Puppet 内置的配置管理语言对这些资源提供了较为完整的底层抽象，减轻了编写配置文件的复杂度。 模拟 (Simulate)根据节点的配置文件，我们可以了解到该节点需要什么样的资源并且处于什么样的状态。配置文件描述了节点的状态，而不是具体的配置步骤。Puppet 会将配置文件 Manifest 编译成更为详细的一种配置文件 Catalog。通过 Catalog，Puppet 会根据节点的当前状态，模拟出节点达到该目标状态所需要的步骤。 应用 (Enforce)节点周期性地向 Puppet Server 来请求自己最新的配置文件。Puppet 会将节点的实际状态与节点配置文件中所表述的目标状态做比较，并根据得到的所需要的步骤，对节点执行操作，使其达到配置文件所表述的状态。 报告 (Report)当每次应用执行过后，节点都会给 Puppet Server 发送一份运行报告，报告该节点的状态，以便以后的分析和统计。 Puppet 配置语言介绍Puppet 配置管理语言中的核心概念是资源，资源可以是一个软件包，一个文件，一种服务等等。一个节点的状态可以用资源的集合以及他们之间的关系来表示。管理员不需要详细地描述配置和部署系统的具体步骤，Puppet 只需要管理员来描述系统的目标状态，即资源的集合以及它们之间的关系。Puppet 内置的执行引擎会根据节点的现有状态将配置文件转化为具体的执行步骤并且执行。 在 Puppet 中，类是一系列相关资源的集合；模块是一系列类的集合。Puppet 内置提供了一些常用的类和模块，同时用户可以定义自己的类和模块。通过类和模块使用，配置模块重用和共享变的非常容易。 安装和配置环境配置由于 Puppet Server 和节点之间通过主机名来通信，所以需要双方可以通过彼此的主机名来找到对应的 IP 地址。可以通过配置 DNS 或者配置/ets/hosts 文件来实现。 安装准备在安装官方提供的开源版本的 Puppet 软件之前，Puppet Server 和 agent 首先需要都安装官方的软件源 (Puppet 对各种 Linux 发行版都有提供支持，本文以 Ubuntu 14.04 系统为例)： 下载官方软件源的安装包： 1`wget https://apt.puppetlabs.com/puppetlabs-release-pc1-trusty.deb` 更新软件源： 1`sudo dpkg -i puppetlabs-release-pc1-trusty.deb``sudo apt-get update` 安装 Puppet Server 1`sudo apt-get install puppetserver` 启动 PuppetServer 1`sudo service puppetservice start` 安装 PuppetAgent 1`sudo apt-get install puppet-agent` 编辑/etc/puppetlabs/puppet/puppet.conf 文件，设置该 agent 的 puppet server 的地址： 1`[main]``server = puppetmaster` 注：puppetmaster 是 puppetserver 的主机名。 启动 puppet service 1`sudo /opt/puppetlabs/bin/puppet resource service puppet ensure=running enable=true` 编写第一个配置文件第一个 Hello World 配置文件作为第一个实例配置文件，我们想让节点做一件最简单的事情：在/etc/文件夹下面创建一个文件 helloworld.txt，文件的内容是”hello world from puppet!\\n”。 首先我们在 puppetserver 上进入/etc/puppetlabs/code/environments/production/manifests 文件夹，创建 site.pp 文件： 1`node puppetagent &#123;` `file &#123; &apos;helloworld&apos;:` ` ``path =&gt; &apos;/etc/helloworld.txt&apos;,`` ``owner =&gt; &apos;root&apos;,`` ``group =&gt; &apos;root&apos;,`` ``mode =&gt; &apos;655&apos;,`` ``content =&gt; &quot;hello world from puppet!\\n&quot;,`` ``&#125;` `&#125;` site.pp 就是节点的配置文件，里面可以包含对各个节点的配置描述。在实例配置文件中，”puppetagent”就是节点的主机名。包含在 puppetagent 中的配置描述就是该节点的资源集合的描述。 配置文件创建好后，节点会周期性地查询 PuppetServer 来获取自己的配置文件并在本地应用。当然 Puppet 也支持手动获取自己的配置。在本例中，我们通过手动的方式来进行配置更新。我们在 PuppetAgent 上手动执行命令： 1`root@puppetAgent:/opt/puppetlabs/bin# ./puppet agent --test``2016-05-21 14:24:14.858673 WARN puppetlabs.facter - locale environment variables were bad; `` ``continuing with LANG=C LC_ALL=C``Info: Using configured environment &apos;production&apos;``Info: Retrieving pluginfacts``Info: Retrieving plugin``Info: Caching catalog for puppetagent``Info: Applying configuration version &apos;1463811856&apos;``Notice: /Stage[main]/Main/Node[puppetagent]/File[helloworld]/ensure: `` ``defined content as &apos;&#123;md5&#125;c3aa68786c58c94ef6f3e2399920f268&apos;``Notice: Applied catalog in 0.02 seconds``root@puppetAgent:/opt/puppetlabs/bin# cat /etc/helloworld.txt ``hello world from puppet!` 我们看到节点成功从 Puppet Server 获取配置文件，并且在本地应用，对应的文件成功创建。 进阶：执行脚本任务作为进阶的任务，我们希望节点可以执行一些更加复杂一点的任务。我们希望节点可以从 PuppetServer 获取一个命令脚本，并且执行该脚本。 我们首先在/etc/puppetlabs/code/environments/production/modules 中创建一个名叫”test”的模块，在 test 模块下面创建一个”files”文件夹。在这个文件夹里的文件是可以被节点获取的。然后我们在这个”files”文件夹里创建一个 shell 脚本 test.sh，路径如下： /etc/puppetlabs/code/environments/production/modules/test/files/test.sh test.sh 文件内容： 1`touch /etc/helloworld.log``echo &quot;helloworld&quot; &gt;&gt; /etc/helloworld.log` 该脚本会在/etc/目录下创建 helloworld.log 文件，然后在文件里添加”hello world”内容。 进入目录/etc/puppetlabs/code/environments/production/manifests，然后我们再来编辑 site.pp 文件： 1`node puppetagent &#123;``file &#123; &apos;test.sh&apos;:`` ``path =&gt; &apos;/etc/test.sh&apos;,`` ``owner =&gt; &apos;root&apos;,`` ``group =&gt; &apos;root&apos;,`` ``mode =&gt; &apos;655&apos;,`` ``source =&gt; &apos;puppet:///modules/test/test.sh&apos;,`` ``&#125;``exec &#123; &apos;execute &apos;:`` ``command =&gt; &apos;bash /etc/test.sh&apos;,`` ``require =&gt; File[&apos;test.sh&apos;],`` ``path =&gt; [&quot;/bin/&quot;],``&#125;``&#125;` 其中，我们定义了两个资源：一个文件资源和一个执行命令资源。同时这两个资源有依赖关系，命令执行资源依赖于文件资源，所以 Puppet 会优先处理文件资源。执行命令资源会在文件资源存在后再执行。 我们看下客户端的执行结果： 1`root@puppetAgent:/opt/puppetlabs/bin# ./puppet agent --test``2016-05-21 15:39:39.817370 WARN puppetlabs.facter - locale environment variables were bad; `` ``continuing with LANG=C LC_ALL=C``Info: Using configured environment &apos;production&apos;``Info: Retrieving pluginfacts``Info: Retrieving plugin``Info: Caching catalog for puppetagent``Info: Applying configuration version &apos;1463816381&apos;``Notice: /Stage[main]/Main/Node[puppetagent]/File[test.sh]/ensure: `` ``defined content as &apos;&#123;md5&#125;2ce060ad2ddab2fe416ca8fb6f8da32a&apos;``Notice: /Stage[main]/Main/Node[puppetagent]/Exec[execute ]/returns: executed successfully``Notice: Applied catalog in 0.05 seconds``root@puppetAgent:/opt/puppetlabs/bin# cat /etc/helloworld.log ``helloworld` 我们可以看到，helloworld.log 文件被正确的创建，说明脚本文件被正确地执行。 结束语Puppet 是基于 Ruby 的开源系统配置和管理工具，它提供的独特的系统配置语言极大程度地简化了系统管理员管理和配置系统的过程。本文首先介绍了 Puppet 的系统架构和工作流程，并且介绍了 Puppet 独特的系统配置语言，之后我们简单介绍了安装和配置 Puppet 的具体步骤。最后，本文以两个实例介绍了如何在 Puppet 中为节点编写配置文件，来达到创建文件和执行命令的效果。希望本文能对系统管理员，Puppet 初学者有所帮助。 问题集问题1: Exiting; no certificate found and waitforcert is disabled 解决方案： https://fvtool.wordpress.com/2013/04/15/exiting-no-certificate-found-and-waitforcert-is-disabled-installing-puppet/","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}],"tags":[{"name":"Puppet","slug":"Puppet","permalink":"http://blog.ozairs.com/tags/Puppet/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}]},{"title":"Puppet实用命令指南","slug":"Puppet_command","date":"2019-03-14T00:45:41.000Z","updated":"2019-03-14T03:36:15.747Z","comments":true,"path":"DevOps/Puppet/Puppet_command/","link":"","permalink":"http://blog.ozairs.com/DevOps/Puppet/Puppet_command/","excerpt":"","text":"1、下载安装r10k Modulepuppet module install puppet/r10k –modulepath=/etc/puppetlabs/code/modules 2、puppet code与github repo同步r10k deploy environment -p","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}],"tags":[{"name":"Puppet","slug":"Puppet","permalink":"http://blog.ozairs.com/tags/Puppet/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"},{"name":"Puppet","slug":"DevOps/Puppet","permalink":"http://blog.ozairs.com/categories/DevOps/Puppet/"}]},{"title":"","slug":"Git实用教程","date":"2019-03-13T11:16:43.451Z","updated":"2019-03-14T05:39:32.416Z","comments":true,"path":"uncategorized/Git实用教程/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Git实用教程/","excerpt":"","text":"&lt;Git实用教程&gt; 1、Git创建和切换Branch git brach example git checkout ‘example’ 2、查看Branch，Branch改名和删除Branch git branch git branch -m originname newname git branch -D branchname 3、提交代码到Staging Enviroment git add example （git add . ） 4、提交代码到正式环境 git commit -m “comment” 5、合并不同 branch的代码 git merge branchname 6、查看代码日志 git log","categories":[],"tags":[],"keywords":[]},{"title":"Git 和 GitHub 基础配置","slug":"Git-和-GitHub-基础配置","date":"2019-03-13T10:43:27.000Z","updated":"2019-03-13T10:52:52.605Z","comments":true,"path":"DevOps/Git-和-GitHub-基础配置/","link":"","permalink":"http://blog.ozairs.com/DevOps/Git-和-GitHub-基础配置/","excerpt":"","text":"前言在本系列的第一篇文章中着重介绍了 Git 的基础特性。本文作为本系列的第二篇文章将介绍 Git 和 GitHub 的基础配置，包括 Git 安装、使用 Git 克隆 GitHub 上的代码库、使用 Git 克隆远端代码仓库、Git 的基本配置和设置忽略提交规则。您在阅读完本文将有能力完成本地 Git 环境的基础配置，为接下来的 Git 日常使用做基础。 GitHub 是一个代码托管平台，如果开发者想要在本地进行开发工作，那么就需要使用到 Git 的客户端工具来连接到 GitHub，再克隆代码到本地。如果您是重度的 GUI 使用者，那么有很多 GUI 客户端可以选择，在 Git 的官网就专门有个页面列出了业内的 GUI 客户端。 但遗憾的是往往 GUI 客户端只能提供 Git 部分的功能，如果想要享受到 Git 自底向上强大的功能，使用命令行的方式来操作 Git 是不二之选。建议无论您是否擅长使用命令行工作，都可以尝试使用命令行方式来操作 Git。本文将只介绍如何从命令行来连接到 GitHub。 安装 Git使用命令行方式操作 Git 工具，需要本地安装 Git。注意，这里没有使用 “Git 客户端” 一词，因为 Git 作为一个开源版本控制系统，本身既可以作为客户端工具，也可以用于建立服务器端代码库，所以本质上 Git 作为工具来讲没有客户端和服务器端之分。 本地安装 Git 十分简单。 对于 Windows 用户，可以下载 Git For Windows 工具。下载安装成功之后，我们可以得到一个 Git Bash 工具，它是一个类 Linux Bash 工具。在该工具中我们可以直接执行 Git 相关命令。 对于 Mac 和 Linux 用户，只需通过对应的包管理工具安装即可，如清单 1 所示： 清单 1. Mac 和 Linux 下安装 Git1`$ brew install git # For Mac``$ apt-get install git # For Ubuntu``# yum install git # For RedHat EL, CentOS` 使用 Git 克隆 GitHub 代码库安装 Git 成功之后，我们就可以使用 Git 克隆 GitHub 上的代码库，本节仍然以我的代码库 repo-for-developerworks 为例。 GitHub 提供了两种克隆方式：HTTPS 和 SSH。我们可以点击仓库页面上的 Clone or download 按钮来查看用于克隆的链接，同时可以点击浮动框右上角的 Use SSH/Use HTTPS 换我们想要克隆的 link，如图 2 和 图 3 所示。注意，这里只是切换查看不同的链接，而不是设置代码库不同的链接方式。 由此我们可以获得两个 URL： HTTPS 链接：https://github.com/caozhi/repo-for-developerworks.git SSH 链接：`git@github.com:caozhi/repo-for-developerworks.git` 使用 HTTPS 进行克隆由于代码库是开放的，因此使用 HTTPS 方式克隆时，无需 GitHub 用户名密码，如清单 2 所示： 清单 2. 使用 HTTPS 进行克隆1`caozhi@ clone$ git clone https://github.com/caozhi/repo-for-developerworks.git``Cloning into &apos;repo-for-developerworks&apos;...``remote: Counting objects: 14, done.``remote: Compressing objects: 100% (9/9), done.``remote: Total 14 (delta 3), reused 5 (delta 1), pack-reused 0``Unpacking objects: 100% (14/14), done.` 顺便提一下，进行 pull 和 fetch 操作时也无需用户名密码认证。因为 GitHub 的机制允许随意免费下载任何公开的代码库，如若要 push 代码需经过认证或者经过作者同意才可。当要进行 push 时，会出现提示要求输入用户名密码，如清单 3 所示： 清单 3. HTTPS 方式下 push 代码1`caozhi@ repo-for-developerworks$ echo change &gt;&gt; README.md ## make some modification``caozhi@ repo-for-developerworks$ git add .``caozhi@ repo-for-developerworks$ git commit -m &quot;changes&quot;``[master d774ecf] changes`` ``1 file changed, 1 insertion(+)``caozhi@ repo-for-developerworks$ git push``Username for &apos;https://github.com&apos;: caozhi0321@gmail.com ## Enter GitHub account name``Password for &apos;https://caozhi0321@gmail.com@github.com&apos;: ## Enter Password``Counting objects: 6, done.``Delta compression using up to 8 threads.``Compressing objects: 100% (4/4), done.``Writing objects: 100% (6/6), 528 bytes | 528.00 KiB/s, done.``Total 6 (delta 2), reused 0 (delta 0)``remote: Resolving deltas: 100% (2/2), completed with 1 local object.``To https://github.com/caozhi/repo-for-developerworks.git`` ``075c130..d774ecf master -&gt; master` 使用 SSH 进行克隆使用 SSH 方式进行克隆，需要一步额外的配置 SSH-KEY 的操作。首先需要本地生成一个 SSH Key。我们可以借助 ssh-keygen 工具生成一对 RSA 的秘钥：私钥id_rsa 和公钥 id_rsa.pub。生成的秘钥文件会默认放在 home 目录下的 .ssh 目录下。 先将 id_rsa.pub 公钥文件的内容复制到剪贴板，如图 5 所示，使用 cat id_rsa.pub 命令可以查看公钥内容，随后将该公钥导入到 GitHub 里的账户之下。 在 GitHub 页面右上角的头像里点击展开一个下拉菜单，点击 Settings 可以打开个设置页面。 打开 SSH and GPG keys 的配置页面，点击右上角的 New SSH key 按钮。 在打开的页面中先设置一个您想导入的公钥的名称，再将前面复制的公钥内容粘贴到大文本框中，点击 Add SSH key 即可。 页面自动跳转回 SSH and GPG keys 设置页面，您可以看到在我的账号下成功新增了一个 SSH Key。 此时我们可以使用 SSH 的方式进行代码克隆，还可以使用 ssh -T 命令检测是否配置成功, 如清单 4 和 5 所示： 清单 4. 使用 SSH 方式克隆1`caozhi@ $ git clone git@github.com:caozhi/repo-for-developerworks.git``Cloning into &apos;repo-for-developerworks&apos;...``remote: Counting objects: 20, done.``remote: Compressing objects: 100% (12/12), done.``remote: Total 20 (delta 5), reused 10 (delta 2), pack-reused 0``Receiving objects: 100% (20/20), done.``Resolving deltas: 100% (5/5), done.` 清单 5. 检测 SSH 是否配置成功1`caozhi@bogon:~$ ssh -T git@github.com``Hi caozhi! You&apos;ve successfully authenticated, but GitHub does not provide shell access.` 使用 SSH 的方式进行克隆，将使得我们本地与 GitHub 之间建立了信任连接，也就意味着之后所有需要进行用户认证的地方都不再需要显式地用户名密码认证。例如 git push 会直接通过 SSH 进行认证。经验表明，使用 SSH 的另一个好处是在网络环境较差的情况下，其稳定性要高于 HTTPS 连接。 至此，我们成功地使用 Git 命令行方式克隆了代码库，之后就可以进行正常的日常开发。 使用 Git 克隆远程仓库当一个开发者刚进入某一项目，一般来说他所要做的第一件事是克隆远程仓库到本地，以进行本地开发工作。远程仓库可以是来自于 GitHub 或者 GitLab 等代码托管服务，也可以是项目组自己所搭设的 Git 服务器。无论是哪种远程仓库，都可以使用 git clone 命令 git clone &lt;repository&gt; [local_path] 将其从远端克隆到本地。命令中间的 &lt;repository&gt; 根据远端仓库提供的连接方式不同，其形式可能不同，例如： GitHub 的 HTTPS 连接：https://github.com/caozhi/repo-for-developerworks.git GitHub 的 SSH 连接：`git@github.com:caozhi/repo-for-developerworks.git` 自建仓库的 SSH 连接：`git_user@192.168.0.1:/usr/local/repo-for-developerworks.git` 其中前两种 GitHub 的连接方式，其仓库的连接字符串可以在 GitHub 的对应仓库页面中找到，如前图 2 和图 3所示。 第三种自建仓库的 URL 一般需要提供远端服务器上的账号、host 和路径。以上面例子中的连接字符串 `git_user@192.168.0.1:/usr/local/repo-for-developerworks.git` 为例： git_user 是服务器上对代码库目录有访问权限的账号。 192.168.0.1 是远端服务器的 IP，也可以是主机名或者 URL。 /usr/local/repo-for-developerworks.git 是服务器上代码库的根目录。 git clone 命令中的 local_path 指定了本地想要存放代码库的地址。该参数是可选参数，如果不指定该参数就会在本地新建一个以远程仓库名为命名的目录，然后以该目录为代码库根目录。图 10 展示了在空目录 clone_demo 中执行不带 local_path 参数的 clone 命令： 从截图可以看到，git clone 命令在 clone_demo 目录中创建了一个 repo-for-developerworks 的代码库目录。 从截图可以看到，git clone 命令在 clone_demo 目录中新建了一个我们指定的local_dev-repo 目录，并将其作为本地代码库的根目录。 我们知道一般操作系统将一个英文句点表示当前目录，因此从截图可以看出，当 local_path 指定为当前目录时，git clone 命令会直接将当前目录作为本地代码库的根目录。 当然 Git 还提供其它的连接方式如 File、FTP。感兴趣的读者可以自己使用 Git 搭一个 Git 服务器尝试使用 File 和 FTP 方式进行连接。 默认情况下，git clone 会将远端代码库全部克隆到本地。Git 还支持只克隆特定分支到本地。我们可以使用 git clone -b **branchname** --single-branch git@URL local_path 命令。 Git 的基本配置在克隆了代码库之后，我们一般仍需要对 Git 做一些基本的配置才能使用 Git 进行日常工作。Git 配置的作用域主要有三种：System、Global 和 Local，分别对应的配置文件地址为： System：/etc/gitconfig。系统级别有效。 Global：home 目录下的 ~/.gitconfig 文件。用户级别有效。 Local：代码库目录的 .git/config 文件。代码库级别有效。 另外我们也可以使用 git config --system -l，git config --global -l，git config --local -l 命令分别列出三个作用域下的配置。跟 Linux 操作系统的环境变量配置类似，Git 在执行命令中会首先查看 local 配置，如果没有找到所需配置会再查看 global 配置，最后再查看 system 配置。 在使用 git config 命令进行配置的时候，也可以使用 git config --system，git config --global，git config --local 三种不同的选项来修改不同作用域的配置。 下面介绍一些重要或有用的 Git 配置。 配置 user 信息配置 user 信息在 Git 中是十分重要的一个步骤, username 和 email 不能为空，它们将会被记录在每一条该 user 的 commit 信息中。 我们可以配置 user.name 和 user.email 的值来配置 user 信息，如清单 6 所示: 清单 6. 配置 user.name 和 user.email1`git config --global user.name &quot;caozhi&quot;``git config --global user.email &quot;caozhi0321@gmail.com&quot;` 也可以将上述命令中的 –global改成 –local来修改只对代码库作用域有效的配置。 配置命令的别名Git 提供了很多有用的命令，我们可以将一些比较常用的命令设置上别名，提高工作效率。例如我们可以将 git log --abbrev-commit 设置一个别名 lg，使得查看 log 时只需要显示 commit id 的短名称，如: git config --global alias.lg &quot;log --abbrev-commit&quot; 设置成功后就可以使用 git lg 来查看 commit 日志。 当然还可以设置一些其它的别名，如清单 7 所示: 清单 7. 配置 st 和 cm 别1`git config --global alias.st &quot;status&quot;``git config --global alias.cm &quot;commit&quot;` 别名可以根据自己的喜好和习惯去设置。将常用的命令设为短别名将大大提高工作效率。 查看配置配置成功后可以使用 git config --global -l 命令查看配置。 使用 Config 文件进行配置除了使用命令之外，也可以直接编辑 config 文件进行相关配置。 设置 Git 忽略提交规则在进行完代码库克隆和简单的配置之后，接下来我们可以根据项目需要配置一些文件忽略规则。跟大多数的代码库管理工具一样，Git 也可以对不需要被代码库所管理的文件或文件类型进行配置，使得提交代码时，这些文件不会被提交到代码库中。Git 是通过忽略清单.gitignore 文件进行配置的。 通常我们会考虑将如下类型的文件添加到忽略清单中: 编译过程的中间文件，例如 *.class 文件、*.o 文件、*.obj 文件等。 外部依赖的包或者工程编译的包，例如 jar 包、lib 包、dll 包或 war 包等。在有的项目实践中，可能会将这类依赖包也放到代码库中进行管理，通常这不是一个很好的策略，因为这样会显著地增加代码库的大小，降低开发者的工作效率。比较合理的方式是通过构建工具的依赖管理功能来管理这些依赖包，例如 Maven、Gradle 等。 编译过程中，通过某种机制自动生成的代码。某些项目中，可能会使用脚本或者 xsd schema 文件来生成代码；这类代码只需要将用于自动生成的脚本或者 schema 文件管理起来即可。 项目的配置文件。同一项目组的不同开发者可能有不同的项目配置，或者配置中包含敏感信息，例如账号密码等，这类配置文件也应该放到 ignore 清单里。 某些 IDE 的工程配置文件，例如 Eclipse 的 setting 和 project 文件、Idea 的.idea 目录等。 一些自动生成的系统文件，例如 Windows 的 Thumbs.db 或者 MacOS 的.DS_Store 文件等。 项目或者 IDE 的日志文件。 .gitignore 文件每行表示一个匹配模式（# 开头的行或者空行除外，# 用于注释）。它使用 glob 模式来进行匹配，glob 模式是一种简化的正则表达式，常用于来进行路径的模式匹配。我们可以在代码库的根目录或者任意子目录添加.gitignore 文件，特定目录下的.gitignore 文件使得忽略规则只在该目录及其子目录下有效。表 1 列出了常用的一些匹配模式的写法： 表 1. 常用匹配模式 模式 含义 示例 完整路径 忽略完整路径所定义的文件 dev/dev.conf /path 以 / 开头，只匹配当前目录下路径为 path 的文件 /a.java /a.cpp path 不以 / 开头，匹配当前目录及其子目录下所有文件 *.o web.xml path/ 以 / 结尾，用以只匹配目录；path 目录及其子目录和文件会被忽略；如果 path 是个文件，则不会被忽略 .settings/ 带 * 号的模式 置于文件中，用于匹配所有满足规则的文件 *.zip *.jar 带 ** 的模式 置于路径中，用于匹配满足 ** 前后的所有路径 Dev/**/dev.conf**/*.jar !path 在 ignore 文件中如果前面已经定义了某个模式，但是又有一些特殊文件我们不想被忽略，我们可以用 ! 来匹配 *.jar ## 忽略所有 jar 包 !server.jar ##希望 server.jar仍被跟踪 注意： 当某个文件已经被提交到代码库中被 Git 所管理起来之后，将该文件再添加进 .gitignore 文件是无效的，对该文件进行修改时，执行 git status 操作之后仍然会提示该文件已被修改。针对已经提交代码库的文件我们又想忽略其修改的场景，将会在本系列第四篇文章中介绍。 每个目录下都可以放单独的 .gitignore 文件以控制子目录的忽略规则。 即使已经在忽略列表里，当我们确实想要提交一些符合忽略规则的文件时，仍可以使用 git -f add 加具体的文件路径的方式将这些文件提交到库中。 GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表模板，可以在 https://github.com/github/gitignore 找到它。 结束语为使用 Git 和 GitHub 进行日常开发做准备，本文详细通过一些列演示向读者讲解了如何采用 SSH 和 HTTPS 两种方式从 GitHub 克隆代码库，如何进行本地 Git 开发环境的基础配置，如何配置 .gitignore 文件等。相信您在阅读完本文之后将有能力自己初始化一套本地的 Git 环境。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"git","slug":"git","permalink":"http://blog.ozairs.com/tags/git/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"Azure上的Terraform文档","slug":"Azure上的Terraform文档","date":"2019-03-13T03:48:43.000Z","updated":"2019-03-13T03:53:37.553Z","comments":true,"path":"DevOps/Azure上的Terraform文档/","link":"","permalink":"http://blog.ozairs.com/DevOps/Azure上的Terraform文档/","excerpt":"","text":"使用 Terraform 在 Azure 上可靠地版本化和创建基础结构。 使用我们的快速入门和教程了解如何创建资源、使用 Azure Terraform 模块和维护包含代码的基础结构。 快速入门配置 Terraform 并使用它在 Azure 中创建 Linux VM。 安装和配置 Terraform 创建 Linux VM 分步教程了解如何通过 Terraform 从代码创建 Azure 计算和网络基础结构。 使用 AKS 创建 Kubernetes 群集。 将 AKS 与作为入口控制器的应用程序网关配合使用来创建 Kubernetes 群集。 使用 Azure 市场映像创建启用了 MSI 身份验证的 Terraform VM。 使用 Azure Terraform 模块创建负载均衡的 VM 群集。 在 Azure Cloud Shell 中创建负载均衡的 VM 群集。 为 VM 规模集配置网络和存储 从 Packer 自定义映像预配 VM 规模集 示例常见部署任务的示例配置模板。 GitHub 引用 Azure Terraform 模块用于数据库的 Azure RM 用于负载均衡器的 Azure RM Azure RM 计算组 Azure RM 网络 Azure RM 计算","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/tags/Terraform/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"通过混沌式创新建立和增强应用程序价值","slug":"通过混沌式创新建立和增强应用程序价值","date":"2019-03-12T21:43:19.000Z","updated":"2019-03-13T11:34:06.083Z","comments":true,"path":"评论/通过混沌式创新建立和增强应用程序价值/","link":"","permalink":"http://blog.ozairs.com/评论/通过混沌式创新建立和增强应用程序价值/","excerpt":"","text":"应用程序现在是数字业务开发和交付其产品和服务的主要工具。此外，今天最知名的数字巨头（Facebook或Lyft）的估值飙升可归因于这些公司的应用程序组合。 简而言之，应用程序及其操作的数据是现代数字经济的货币。对于越来越多的公司来说，它们是一种资产负债表上的资产，这种资产可以带来巨大的价值创造。但也是一种可以被利用并带来可怕的价值破坏的资产。公司市值的单日跌幅最大 Facebook在2018年7月底的120亿美元下跌，占市值的19％ ，发生在该公司告诉投资者在剑桥分析公司丑闻导致用户增长放缓之后来自87m Facebook数据的数据被用来使外国势力干涉2016年美国总统选举。 虽然Facebook是数字原生的极端例子，但即使对于有抱负的数字公司来说，这一教训仍然适用。有效管理这个有价值但易受攻击的资源，一个组织的应用程序组合，必须超越IT的范围，扩展到整个C-Suite。随着应用程序的提升不仅仅是公司如何开展业务并越来越成为业务本身的基本要素，企业IT的角色也必须发展。在应用经济中，企业IT有两个必要条件：1）拥抱和实现混沌创新; 2）最大限度地降低企业风险。 混乱的创新？混乱长期以来被用作公司释放创新的工具。一些例子： 英特尔的安迪格罗夫曾经告诉人们，他们需要“让混沌统治，然后再陷入混乱”。这种方法在组织内部创造了一种文化，使混乱得以蓬勃发展，允许人们在正常模式之外思考，花时间进行实验，并提出真正伟大的想法。 谷歌创始人拉里佩奇和谢尔盖布林在他们2004年的首次公开招股信中强调了混沌创新需求背后的想法。这封信清楚地表明，“除了他们的常规项目之外，我们还鼓励我们的员工将20％的时间花在他们认为最有利于Google的事情上。” 这种方法带来了许多创新，包括AdSense，Gmail以及其他一些结构良好和大写的创意。 作为一名前管理顾问，我经常被问到这种思维方式是否适用于不仅仅是技术公司。MTV 最近调查了千禧一代的工作习惯，发现78％的人认为有一个“其他兴趣爱好可能很重要成为一个不同的职业。众所周知，各种类型的公司都明确容忍边工作边创业。 这些对混乱友好的公司了解这种开放性的好处。事实上，许多初创企业都是由在其他地方工作的同时创办公司的创始人孵化出来的，然后退出全职追求他们的激情。根据塔克商学院教授克里斯特里布尔（Chris Trimble）的说法，这些类型的政策让员工体验到了自由以及无法完全接受它的挫折：最好的混乱创新！ 对于当前和有抱负的数字业务，当应用程序开发人员可以自由地构建和部署新应用程序而不受可用性，稳定性，安全性或合规性问题的影响时，混乱的创新会蓬勃发展。开发人员供不应求。作为应用经济中最稀缺的资源，开发商浪费的每一秒都会影响公司的价值创造率。认真建立和增强应用资本的公司非常需要能够节省开发人员时间，减少不必要的复杂性和专业知识的解决方案，并使他们专注于快速部署他们关心的代码，并且业务价值最高。 F5如何帮助F5是多云应用服务的领导者。我们的多云应用程序服务以多种方式增强和保护您的应用程序价值。以下是一些： 改善应用程序的性能和最终用户体验 - 简而言之，我们世界一流的应用程序服务使您的应用程序更快。 通过提供现成的一流应用服务，提高开发人员的工作效率; 通过与CI / CD工具链的集成以及强大的自动化和编排解决方案; 通过简化政策附件和自助服务工具的工作流程; 并通过为应用程序本身提供可操作的见解。 改善您的企业安全/风险态势 - 提供易于连接的安全服务; 跨应用程序的一致策略管理，无论他们身在何处; 整个应用程序组合中的可视性和可视性。 为何选择F5？为什么不是其他应用服务提供商 我们的价值主张很简单： F5拥有业内最广泛，最深入的应用服务组合 F5为任何供应商提供最灵活的消费和多云部署选项 F5通过世界一流的客户支持组织为其提供支持 当F5成为企业级基础架构的核心部分时，它为业务提供了一定程度的保证，即其应用程序组合仍然可用，可靠且安全。 概括为了在数字经济中生存，每家公司都必须增强和保护他们的应用资本。该解决方案是一套一致的应用程序服务，可以应用于任何地方的任何应用程序。F5业界领先的多云应用服务可提高应用程序的性能和最终用户体验，提高开发人员的工作效率，并改善企业安全/风险状况。F5是增强和保护您的应用程序资本的最佳合作伙伴。","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"F5","slug":"F5","permalink":"http://blog.ozairs.com/tags/F5/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"Ansible入门教程","slug":"Ansible入门教程","date":"2019-03-12T10:44:39.000Z","updated":"2019-03-12T10:53:35.723Z","comments":true,"path":"DevOps/Ansible入门教程/","link":"","permalink":"http://blog.ozairs.com/DevOps/Ansible入门教程/","excerpt":"","text":"关于Ansible的一个好处是，将bash脚本转换为可执行任务是非常容易的。我们可以编写自己的配置程序，但是Ansible更加干净，因为它可以自动在执行任务之前获取上下文。ansible任务是幂等的，没有大量额外的编码，ansible可以一次又一次地安全运，而bash命令这种幂等性。 Ansible使用“facts”来确保任务的幂等安全运行， 它是在运行任务之前收集的系统和环境信息。ansible使用这些facts来检查状态，看看是否需要改变某些东西以获得所需的结果。这使得ansible可以让服务器一次又一次地运行可复制的任务。 1 安装当然我们需要先安装Ansible。任务可以从任何可安装的机器上运行。 1.1 Ubuntu在Ubuntu 16.04上安装Ansible的方法。 1sudo apt-get install -y ansible1 apt-get安装的ansible版本很低，建议使用pip方式安装 1sudo pip install ansible1 2 配置ansible的默认配置文件路径为 /etc/ansible，然而，一个常见的用途是将其安装在一个virtualenv中，在这种情况下，我们一般不会使用这些默认文件。我们可以根据需要在本地目录中创建配置文件。 2.1 管理服务器：Inventory文件您可以创建一个inventory文件，用于定义将要管理的服务器。这个文件可以命名为任何名字，但我们通常会命名为hosts或者项目的名称。在hosts文件中，我们可以定义一些要管理的服务器。这里我们将定义我们可能要在“web”标签下管理的两个服务器。标签是任意的。 123[web]192.168.22.10192.168.22.11123 现在已经够好了，如果需要，我们可以定义主机范围，多个组，可重用变量，并使用其他花哨的设置，包括创建动态的inventory。当我们在本地机器运行ansible时，我们不需要关心inventory文件中的内容，我将告诉您在本地和远程服务器上运行ansible。现在，让我们将hosts文件设置为指向本地主机local和remote虚拟远程主机。hosts文件： 12345[local]127.0.0.1[remote]192.168.1.212345 与本地主机和远程服务器连接的命令。 2.2 基础：运行命令我们开始对服务器运行任务。ansible会假定你的服务器具有SSH访问权限，通常基于SSH-Key。因为Ansible使用SSH，所以它需要能够SSH连接到服务器。但是，ansible将尝试以正在运行的当前用户身份进行连接。如果我正在运行ansible的用户是ubuntu，它将尝试以ubuntu连接其他服务器。 123456789# Run against localhost$ ansible -i ./hosts --connection=local local -m ping# Run against remote server$ ansible -i ./hosts remote -m ping127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125;123456789 如果你是在cygwin下运行，遇到了“Failed to connect to the host via ssh: mux_client_request_session: read from master failed”的错误，可以执行: 1ansible -i ./hosts remote -v -m ping -u root --private-key=~/.ssh/id_rsa1 使用–connection=local告诉ansible不尝试通过SSH运行命令，因为我们只是影响本地主机。但是，我们仍然需要一个hosts文件，告诉我们连接到哪里。在任何情况下，我们可以看到从ansible得到的输出是一些JSON，它告诉我们Task（我们对ping模块的调用）是否进行了任何更改和结果。 命令说明： 12345678910-i ./hosts - 设置库存文件，命名为 hostsremote，local，all-使用这个标签的下定义的服务器hosts清单文件。“all”是针对文件中定义的每个服务器运行的特殊关键字-m ping- 使用“ping”模块，它只是运行ping命令并返回结果-c local| --connection=local - 在本地服务器上运行命令，而不是SSH一些常用命令：-i PATH --inventory=PATH 指定host文件的路径，默认是在/etc/ansible/hosts--private-key=PRIVATE_KEY_FILE_PATH 使用指定路径的秘钥建立认证连接-m DIRECTORY --module-path=DIRECTORY 指定module的目录来加载module，默认是/usr/share/ansible-c CONNECTION --connection=CONNECTION 指定建立连接的类型，一般有ssh ，local12345678910 2.2.1 模块（Modules）ansible使用“模块”来完成大部分的任务。模块可以做安装软件，复制文件，使用模板等等。 模块是使用Ansible 的方法因为它们可以使用可用的上下文（“Facts”），以便确定要完成任务需要做什么操作。如果我们没有模块，我们将运行任意的shell命令，我们也可以使用bash脚本。这是一个任意shell命令看起来像在Ansible（它使用的shell模块！）： 1234567# Run against a local serveransible -i ./hosts local --connection=local -b --become-user=root \\ -m shell -a &apos;apt-get install nginx&apos;# Run against a remote serveransible -i ./hosts remote -b --become-user=root all \\ -m shell -a &apos;apt-get install nginx&apos;1234567 这里，sudo apt-get install nginx命令将使用“shell”模块运行。命令说明: 123-b - “成为”，在运行命令时告诉可以成为另一个用户。--become-user=root - 以用户“root”运行以下命令（例如，使用命令使用“sudo”）。我们可以在此定义任何现有的用户。-a 用于将任何参数传递给定义的模块 -m123 但是这并不是特别强大。尽管能够一次在所有服务器上运行这些命令，但是我们仍然只能完成任何bash脚本可能执行的操作。如果我们使用了更合适的模块，我们可以运行命令来保证结果。可靠的模块确保我们可以一次又一次地运行相同的任务，而不会影响最终结果。要在Debian / Ubuntu服务器上安装软件，“apt”模块将运行相同的命令，但确保幂等。 12345678910111213141516171819# Run against a local serveransible -i ./hosts local --connection=local -b --become-user=root \\ -m apt -a &apos;name=nginx state=installed update_cache=true&apos;127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: false&#125;# Run against a remote serveransible -i ./hosts remote -b --become-user=root \\ -m apt -a &apos;name=nginx state=installed update_cache=true&apos;127.0.0.1 | success &gt;&gt; &#123; &quot;changed&quot;: false&#125;or：ansible -i ./hosts remote -v -m apt -a &apos;name=nginx state=installed update_cache=true&apos; -u test -s -K --private-key=~/.ssh/id_rsa12345678910111213141516171819 这将使用apt模块来更新存储库缓存并安装Nginx（如果没有安装）。运行任务的结果是”changed”: false。这表明没有变化; 我已经使用该shell模块安装了Nginx 。好的是，我可以一遍又一遍地运行这个命令，而不用担心它会改变预期的结果 - Nginx已经安装，Ansible知道，并且不尝试重新安装它。命令说明: 12345678910111213-i ./hosts - 设置inventory文件，命名为 hosts-b - “成”，告诉可以成为另一个用户来运行命令--become-user=root - 以用户“root”运行以下命令（例如，使用“sudo”命令）local| remote - 从库存文件中的本地或远程定义的主机上运行-m apt- 使用apt模块-a &apos;name=nginx state=installed update_cache=true&apos; - 提供apt模块的参数，包括软件包名称，所需的结束状态以及是否更新软件包存储库缓存常用命令：-u USERNAME --user=USERNAME 指定移动端的执行用户-U SUDO_USERNAME --sudo-user=USERNAME-s --sudo -u指定用户的时候，使用sudo获得root权限-k --ask-pass 提示输入ssh的密码，而不是使用基于ssh的密钥认证-K --ask-sudo-pass 提示输入sudo密码，与--sudo一起使用12345678910111213 我们可以通过这种特殊方式运行我们所需要的所有任务（通过模块），但是让我们来做这个更具管理性。我们将把这个任务移动到一个Playbook中，它可以运行和协调多个Tasks。 2.3 剧本（Playbooks）Playbook可以运行多个任务，并提供一些更高级的功能。让我们将上述任务移到一本剧本中。在ansible中剧本（playbooks）和角色（roles）都使用Yaml文件定义。创建文件nginx.yml： 123456789101112---# hosts could have been &quot;remote&quot; or &quot;all&quot; as well- hosts: local connection: local become: yes become_user: root tasks: - name: Install Nginx apt: name: nginx state: installed update_cache: true123456789101112 此任务与我们的ad-hoc命令完全相同，包括设置本地连接的使用。这将使用inventory文件中[local]标签下的服务器hosts。如果我们没有使用本地连接，我们会这样做： 12345678910---- hosts: remote become: yes become_user: root tasks: - name: Install Nginx apt: name: nginx state: installed update_cache: true12345678910 这将使用inventory文件中[remote]标签下的服务器hosts。 在我们的Tasks文件中使用become并become_user再次使用Ansible来sudo以root用户身份运行命令，然后传递Playbook文件。 使用一个yaml playbook文件，我们需要使用这个ansible-playbook命令，现在就更容易运行： 123456789101112$ ansible-playbook -i ./hosts nginx.ymlPLAY [local] ******************************************************************GATHERING FACTS ***************************************************************ok: [127.0.0.1]TASK: [Install Nginx] *********************************************************ok: [127.0.0.1]PLAY RECAP ********************************************************************127.0.0.1 : ok=2 changed=0 unreachable=0 failed=0123456789101112 我们在运行过程中获得了一些有用的反馈，包括“可执行任务”运行及其结果。在这里我们看到所有运行都OK，但没有改变。我已经安装了Nginx 2.3.1 处理程序（Handlers）处理程序与任务完全相同（它可以做task可以做的任何事），但只有当另一个任务调用它时才会运行。您可以将其视为事件系统的一部分; 处理程序将通过其侦听的事件调用进行操作。这对于运行任务后可能需要的“辅助”操作非常有用，例如在配置更改后安装或重新加载服务后启动新服务。 123456789101112131415161718192021---# Example shows using the local machine still# Remove &apos;connection&apos; and set hosts to &apos;remote&apos; for a remote connection- hosts: local connection: local become: yes become_user: root tasks: - name: Install Nginx apt: name: nginx state: installed update_cache: true notify: - Start Nginx handlers: - name: Start Nginx service: name: nginx state: started123456789101112131415161718192021 这里我们添加一个notify指令到安装任务。这将在任务运行后通知名为“Start Nginx”的处理程序。 然后我们可以创建名为“Start Nginx”的处理程序。此处理程序是通知“Start Nginx”时调用的任务。这个特定的处理程序使用服务模块，它可以启动，停止，重启，重新加载（等等）系统服务。在这种情况下，我们告诉Ansible，我们要启动Nginx。让我们再次运行这本Playbook： 123456789101112131415$ ansible-playbook -i ./hosts nginx.ymlPLAY [local] ******************************************************************GATHERING FACTS ***************************************************************ok: [127.0.0.1]TASK: [Install Nginx] *********************************************************ok: [127.0.0.1]NOTIFIED: [nginx | Start Nginx] ***********************************************ok: [127.0.0.1]PLAY RECAP ********************************************************************127.0.0.1 : ok=2 changed=0 unreachable=0 failed=0123456789101112131415 我们得到类似的输出，但是这次Handler是运行的。通知程序只在运行任务时运行。 Note：如果我已经安装了Nginx，则安装Nginx任务将不会运行，通知程序也将不会被调用。我们可以使用Playbook来运行多个任务，添加变量，定义其他设置，甚至包括其他的剧本。 2.3.2 更多的任务（More Tasks）接下来，我们可以为此Playbook添加更多的任务，并探索其他一些功能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445---# Example shows using the local machine still# Remove &apos;connection&apos; and set hosts to &apos;remote&apos; for a remote connection- hosts: local connection: local become: yes become_user: root vars: - docroot: /var/www/serversforhackers.com/public tasks: - name: Add Nginx Repository apt_repository: repo: ppa:nginx/stable state: present register: ppastable - name: Install Nginx apt: pkg: nginx state: installed update_cache: true when: ppastable|success notify: - Start Nginx - name: Create Web Root file: path: &apos;&#123;&#123; docroot &#125;&#125;&apos; mode: 775 state: directory owner: www-data group: www-data notify: - Reload Nginx handlers: - name: Start Nginx service: name: nginx state: started - name: Reload Nginx service: name: nginx state: reloaded123456789101112131415161718192021222324252627282930313233343536373839404142434445 现在有三个任务： 123Add Nginx Repository- 使用apt_repository模块添加Nginx稳定PPA以获取最新的稳定版本的Nginx 。Install Nginx - 使用Apt模块安装Nginx。Create Web Root - 最后创建一个Web根目录。123 新的register和when指令，可以实现在某些事情发生后让ansible执行任务的功能。 Note: 您还可以注册模块操作的结果，并使用定义的变量根据注册（register）的变量值有条件（when）地执行操作。例如，注册通过shell模块运行命令的结果可以让您访问该命令的stdout。同时还使用了一个变量。docroot变量在定义vars部分。然后将其用作创建定义目录的文件模块的目标参数。 需要注意的是，path配置使用括号NaN，这是Jinja2的模板。为了使Ansible能够在括号内解析Jinja2模板变量，该行必须是单引号或双引号 - 例如，path: ‘’而不是path: 。不使用引号将导致错误。这个playbook可以用通常的命令运行： 1ansible-playbook -i ./hosts nginx.yml1 所以，我们已经运行了一些ad-hoc命令，使用了可复制的模块，并将一些相关任务组织到一个手册中。 接下来，我们将通过将Playbook组织成一个角色进一步获得可靠性，这有助于我们组织相关项目，如文件和模板，同时还帮助我们组织更复杂的相关任务和操作。 2.4 角色（roles）角色很适合组织多个相关任务并封装完成这些任务所需的数据。例如，安装Nginx可能涉及添加软件包存储库，安装软件包和设置配置。此外，真实的配置通常需要额外的数据，如变量，文件，动态模板等等。这些工具可以与Playbook一起使用，但是我们可以通过将相关任务和数据组织成一个角色（role， 相关的结构）很快就能做得更好。角色有一个这样的目录结构： 12345678roles rolename - files - handlers - meta - templates - tasks - vars12345678 在每个子目录中（eg： files，handlers等等），Ansible将自动搜索并读取叫做main.yml的yaml文件。接下来我们将分解nginx.yml文件内容为不同的组件，并将每个组件放在相应的目录中，以创建一个更干净，更完整的配置工具集。 2.4.1 创建角色（Creating a Role）我们可以使用ansible-galaxy命令来创建一个新角色。此工具可用于将角色保存到Ansible的公共注册表，但是我通常只是使用它来在本地创建role的基础目录结构。 我们来看看如何设置： 123456789101112# Head to our previously created directorycd ~/ansible-example# In case we left our virtualenv at some point source .venv/bin/activate# Create a roles directorymkdir rolescd roles# Bootstrap a new role named &quot;nginx&quot;ansible-galaxy init nginx123456789101112 目录名称roles是一种惯例，在运行一个playbook时可以用来查找角色。该目录应该始终被命名roles，但并不强制。在roles目录中运行 ansible-galaxy init nginx 命令将创建新角色所需的目录和文件。 我们来看看我们新建的nginx角色的每个部分~/ansible-example/roles/nginx。 2.4.2 文件（files）首先，在files目录中，我们可以添加我们要复制到我们的服务器中的文件。对于nginx，我经常复制H5BP的Nginx组件配置。我只需从Github下载最新的信息，进行一些调整，并将它们放入files目录中。 12345~/ansible-example - roles - - nginx - - - files - - - - h5bp12345 我们稍后会看到，H5BP配置文件将通过复制模块添加到服务器。 2.4.3 处理程序（handlers）我们可以把曾经在nginx.yml 剧本中的定义的所有处理程序放入到handlers目录中。约定必须包含main.yml文件。 handlers/main.yml 内容： 12345678910---- name: Start Nginx service: name: nginx state: started- name: Reload Nginx service: name: nginx state: reloaded12345678910 一旦handlers/main.yml中的处理程序定义好了，我们可以自由地从其他的yaml配置中引用它们。 2.4.4 元（meta）meta目录中的main.yml文件包含Role元数据，包含的依赖关系。如果这个角色依赖于另一个角色，我们可以在这里定义。例如，nginx角色取决于安装SSL证书的ssl角色。约定必须包含main.yml文件。meta/main.yml 内容： 123---dependencies: - &#123; role: ssl &#125;123 如果我调用了“nginx”角色，它将尝试首先运行“ssl”角色。否则我们可以省略此文件，或将角色定义为没有依赖关系： 12---dependencies: []12 2.4.5 模板（templates）基于Python的Jinja2模板引擎（和django的模板引擎很类似），模板文件可以包含模板变量。这里的文件应该以.j2为类型后缀（eg.uwsgi.j2），提倡但是不强制，也可以取其他的名字。类似于files，在templates目录中没有main.yml文件，只包含.j2后缀的模板文件。这是一个Nginx服务器（“虚拟主机”）配置的例子。请注意，它使用了稍后在vars/main.yml文件中定义的一些变量。我们的示例中的Nginx配置文件位于templates/serversforhackers.com.conf.j2： 1234567891011121314151617181920212223242526272829303132333435363738server &#123; # Enforce the use of HTTPS listen 80 default_server; server_name &#123;&#123; domain &#125;&#125;; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443 ssl default_server; root /var/www/&#123;&#123; domain &#125;&#125;/public; index index.html index.htm index.php; access_log /var/log/nginx/&#123;&#123; domain &#125;&#125;.log; error_log /var/log/nginx/&#123;&#123; domain &#125;&#125;-error.log error; server_name &#123;&#123; domain &#125;&#125;; charset utf-8; include h5bp/basic.conf; ssl_certificate &#123;&#123; ssl_crt &#125;&#125;; ssl_certificate_key &#123;&#123; ssl_key &#125;&#125;; include h5bp/directive-only/ssl.conf; location / &#123; try_files $uri $uri/ /index.php$is_args$args; &#125; location = /favicon.ico &#123; log_not_found off; access_log off; &#125; location = /robots.txt &#123; log_not_found off; access_log off; &#125; location ~ \\.php$ &#123; include snippets/fastcgi.conf; fastcgi_pass unix:/var/run/php7.1-fpm.sock; &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738 这是一个相当标准的用于PHP应用程序的Nginx配置。这里有三个变量： 域ssl_crtssl_key这三个变量将在变量部分（vars）中定义。 2.4.6 变量（vars）在使用任务集成所有事情之前，让我们来看看变量。该vars目录包含一个main.yml文件（如handlers和meta目录一样），在main.yml中我们可以列出将要使用的所有变量。以下是该vars/main.yml文件的内容： 1234---domain: serversforhackers.comssl_key: /etc/ssl/sfh/sfh.keyssl_crt: /etc/ssl/sfh/sfh.crt1234 我们可以在这个角色的其他地方使用这三个变量。我们在上面的模板中看到它们的使用，但是我们也可以在我们定义的任务中看到它们。 Note:如果您有敏感信息添加到变量文件中，则可以使用ansible-vault加密文件，下面将对此进行说明。2.4.7 任务（tasks）终于到了将一切都是放在一系列的任务中的时候了。使用角色时运行的主文件是tasks/main.yml文件。看看我们的用例将会是什么样的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364---- name: Add Nginx Repository apt_repository: repo: ppa:nginx/stable state: present- name: Install Nginx apt: pkg: nginx state: installed update_cache: true notify: - Start Nginx- name: Add H5BP Config copy: src: h5bp dest: /etc/nginx owner: root group: root- name: Disable Default Site Configuration file: dest: /etc/nginx/sites-enabled/default state: absent# `dest` in quotes as a variable is used!- name: Add SFH Site Config register: sfhconfig template: src: serversforhackers.com.j2 dest: &apos;/etc/nginx/sites-available/&#123;&#123; domain &#125;&#125;.conf&apos; owner: root group: root# `src`/`dest` in quotes as a variable is used!- name: Enable SFH Site Config file: src: &apos;/etc/nginx/sites-available/&#123;&#123; domain &#125;&#125;.conf&apos; dest: &apos;/etc/nginx/sites-enabled/&#123;&#123; domain &#125;&#125;.conf&apos; state: link# `dest` in quotes as a variable is used!- name: Create Web root file: dest: &apos;/var/www/&#123;&#123; domain &#125;&#125;/public&apos; mode: 775 state: directory owner: www-data group: www-data notify: - Reload Nginx# `dest` in quotes as a variable is used!- name: Web Root Permissions file: dest: &apos;/var/www/&#123;&#123; domain &#125;&#125;&apos; mode: 775 state: directory owner: www-data group: www-data recurse: yes notify: - Reload Nginx12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 这一系列任务使得Nginx能被完整的安装。任务按照出现的顺序完成以下工作： 123456781 添加nginx / stable库2 安装并启动Nginx3 添加H5BP配置文件4 从sites-enabled目录中删除文件的符号链接来禁用默认的Nginx配置5 将serversforhackers.com.conf.j2虚拟主机模板复制到Nginx配置中，渲染模板6 通过将其符号链接到sites-enabled目录来启用Nginx服务器配置7 创建Web根目录8 更改项目根目录的权限（递归），该目录位于之前创建的Web根目录之上12345678 有一些新的模块（和一些我们已经涵盖的新用途），包括复制，模板和文件模块。通过设置每个模块的参数，我们可以做一些有趣的事情，例如确保文件“不存在”（如果存在则删除它们）的state: absent，或者通过创建一个文件作为符号链接的state: link。您应该检查每个模块的文档，以查看可以用它们完成哪些有趣和有用的事情。 2.4.8 运行角色（Running the Role）要对服务器运行一个或多个角色，我们将重新使用另一个playbook。该playbook与roles目录位于同一个目录中，同一层级。当我们用ansible-playbook命令运行的时候需要先cd进入到该目录中。让我们创建一个“主”的yaml文件（被ansible-playbook命令执行的文件），该文件定义要使用的角色以及运行它们的主机：文件~/ansible-example/server.yml位于与roles目录相同的目录中： 123456---# run locally here, yadda yadda yadda- hosts: local connection: local roles: - nginx123456 所以，我们只是定义角色，而不是在本Playbook文件中定义所有的变量和任务。角色负责具体细节。 然后我们可以运行角色： 1ansible-playbook -i ./hosts server.yml1 以下是运行Nginx角色的Playbook文件的输出： 12345678910111213141516171819202122232425262728293031323334353637PLAY [all] ********************************************************************GATHERING FACTS ***************************************************************ok: [127.0.0.1]TASK: [nginx | Add Nginx Repository] ******************************************changed: [127.0.0.1]TASK: [nginx | Install Nginx] *************************************************changed: [127.0.0.1]TASK: [nginx | Add H5BP Config] ***********************************************changed: [127.0.0.1]TASK: [nginx | Disable Default Site] ******************************************changed: [127.0.0.1]TASK: [nginx | Add SFH Site Config] *******************************************changed: [127.0.0.1]TASK: [nginx | Enable SFH Site Config] ****************************************changed: [127.0.0.1]TASK: [nginx | Create Web root] ***********************************************changed: [127.0.0.1]TASK: [nginx | Web Root Permissions] ******************************************ok: [127.0.0.1]NOTIFIED: [nginx | Start Nginx] ***********************************************ok: [127.0.0.1]NOTIFIED: [nginx | Reload Nginx] **********************************************changed: [127.0.0.1]PLAY RECAP ********************************************************************127.0.0.1 : ok=8 changed=7 unreachable=0 failed=012345678910111213141516171819202122232425262728293031323334353637 我们将所有各种组件放在一起，形成一致的角色，现在已经安装并配置了Nginx！ 2.5 事实(Facts)请注意，运行剧本时的第一行总是“收集事实”。在运行任何任务之前，Ansible将收集有关其配置的系统的信息。这些被称为事实，并且包括广泛的系统信息，如CPU核心数量，可用的ipv4和ipv6网络，挂载的磁盘，Linux发行版等等。 事实在“任务”或“模板”配置中通常很有用。例如，Nginx通常设置为使用与CPU内核一样多的工作处理器。知道这一点，您可以选择如下设置nginx.conf.j2文件的模板： 12345user www-data;worker_processes &#123;&#123; ansible_processor_cores &#125;&#125;;pid /var/run/nginx.pid;# And other configurations...12345 或者如果你具有多个CPU的服务器，则可以使用： 12345user www-data;worker_processes &#123;&#123; ansible_processor_cores * ansible_processor_count &#125;&#125;;pid /var/run/nginx.pid;# And other configurations...12345 所有的ansible facts全局变量都是以“anisble_”为前缀，并且可以在其他任何地方使用。尝试对你的本地机器运行以下内容以查看可用的事实： 123456# Run against a local server# Note that we say to use &quot;localhost&quot; instead of defining a hosts file here!ansible -m setup --connection=local localhost# Run against a remote serveransible -i ./hosts remote -m setup123456 2.6 加密（Vault）我们经常需要将敏感数据存储在我们的模板，文件或变量文件中; 这样安全性有一定要求的情况是不可避免的（当我们将这些敏感数据文件推送到远程Git仓库时，这是一个痛苦的事情）。Ansible有一个叫做Ansible Vault的解决方案。Vault允许您加密任何Yaml文件，通常将其作用与变量文件，Vault不会加密文件和模板，只能使用Yaml文件。在创建加密文件时，系统会询问您必须使用的密码，以便稍后在调用角色或Playbook时进行编辑。将密码保存在安全的地方。 例如我们可以创建一个新的变量文件： 12ansible-vault create vars/main.ymlVault Password:12 输入加密密码后，该文件将在您的默认编辑器（通常是Vim或Nano）中打开。默认使用的编辑器由EDITOR环境变量定义。默认值通常是Vim。如果您不是Vim用户，可以通过设置环境变量来快速更改： 1EDITOR=nano ansible-vault edit vars/main.yml1 在大多数情况下，我们将使用ansible-vault create|edit /path/to/file.yml。更多可用的命令如下： 12345create - 创建一个新文件并进行加密decrypt - 从加密文件创建明文文件edit - 编辑已经存在的加密文件encrypt - 加密现有的纯文本文件rekey - 在加密文件中设置新密码12345 如果你有一个现有的配置文件要加密，请使用 ansible-vault encrypt /path/to/file.yml。 示例： users角色我们创建一个名为“users”的角色： 12cd ~/ansible-example/rolesansible-galaxy init users12 创建新用户并设置密码时，我使用Vault 。在用户角色中，您可以设置带有用户密码和公钥的变量文件，以添加到用户的authorized_keys文件（从而提供SSH访问权限）。公共SSH密钥在技术上是安全的，一般公众可以看到 - 所有人都可以使用它来允许你访问自己的服务器。在没有配对私钥的情况下，公钥是不能获得系统访问权限的，我们没有将密钥加入此角色。以下是可以使用Vault创建和加密的示例变量文件。在编辑它时，它是纯文本。 ~/ansible-example/roles/users/vars/main.yml： 123admin_password: $6$lpQ1DqjZQ25gq9YW$mHZAmGhFpPVVv0JCYUFaDovu8u5EqvQi.Ihdeploy_password: $6$edOqVumZrYW9$d5zj1Ok/G80DrnckixhkQDpXl0fACDfNx2EHnCcommon_public_key: ssh-rsa ALongSSHPublicKeyHere123 请注意，用户的密码也是散列的。您可以阅读Ansible有关生成加密密码的文档，用户模块需要设置用户密码。作为一个快速入门，它在Ubuntu上看起来像这样： 1234567# The whois package makes the mkpasswd# command available on Ubuntu$ sudo apt-get install -y whois# Create a password hash$ mkpasswd --method=SHA-512Password:1234567 这将生成一个散列密码供你与user模块一起使用。 Note：变量文件中的密码是散列的，但我仍然喜欢加密包含散列密码的yaml文件。这些文件通常包含未标记的数据，如API令牌或SSH私钥，使加密非常重要。一旦你设置了用户密码并将公钥添加到变量文件中，我们就可以加密此文件，然后在任务中使用这些加密变量。 1ansible-vault encrypt roles/users/vars/main.yml1 然后我们可以编辑我们的任务文件，使用（加密）变量添加新用户： 这是文件~/ansible-example/roles/users/tasks/main.yml： 12345678910111213141516171819202122232425262728---- name: Create Admin User user: name: admin password: &apos;&#123;&#123; admin_password &#125;&#125;&apos; groups: sudo append: yes shell: /bin/bash- name: Add Admin Authorized Key authorized_key: user: admin key: &apos;&#123;&#123; common_public_key &#125;&#125;&apos; state: present- name: Create Deploy User user: name: deploy password: &apos;&#123;&#123; deploy_password &#125;&#125;&apos; groups: www-data append: yes shell: /bin/bash- name: Add Deployer Authorized Key authorized_key: user: deploy key: &apos;&#123;&#123; common_public_key &#125;&#125;&apos; state: present12345678910111213141516171819202122232425262728 这些任务使用该user模块来创建新用户，传递变量文件中设置的密码。它还使用该authorized_key模块将SSH公钥作为SSH授权密钥添加到每个用户的服务器中。加密变量的使用像在常规任务文件中使用一样。但是，为了运行此角色，我们需要告诉Ansible请求输入vault密码，以便它可以解密变量。编辑我们的server.ymlPlaybook文件，调用user角色： 12345678---# Local connection here, yadda yadda yadda- hosts: local connection: local sudo: yes roles: - nginx - user12345678 要运行此Playbook，我们需要告知Ansible请求vault的密码，因为我们正在运行包含加密文件的角色： 1ansible-playbook --ask-vault-pass -i ./hosts server.yml1 3 总结本篇文章带着做了如下工作： 安装了ansible 配置了ansible inventory文件（仅在不使用connection: local 时才需要） 同时在多个服务器上执行幂等的 ad-hoc命令 创建一个基本的Playbook来运行多个任务（tasks），并使用了处理程序（handlers） 将多个任务抽象为一个角色，以保持所有Nginx相关的操作在一个角色内 展示了如何设置依赖关系 展示了如何注册任务的“依赖”执行关系，当一个任务执行成功后再执行另一个任务 展示了如何在我们的任务中使用更多的模板，文件和变量 展示了如何整合使用ansible事实(facts) 展示了如何使用ansible的vault来增加我们的变量的安全性","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.ozairs.com/tags/Ansible/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"马克·扎克伯格：关于Facebook的事实","slug":"马克·扎克伯格：关于Facebook的事实","date":"2019-03-12T07:31:04.000Z","updated":"2019-03-12T07:35:37.837Z","comments":true,"path":"评论/马克·扎克伯格：关于Facebook的事实/","link":"","permalink":"http://blog.ozairs.com/评论/马克·扎克伯格：关于Facebook的事实/","excerpt":"","text":"Facebook 下个月将满15岁。当我开始Facebook时，我并没有尝试建立一家全球性公司。我意识到你几乎可以找到互联网上的任何东西 - 音乐，书籍和信息 - 除了最重要的东西：人。所以我建立了一个人们可以用来连接和互相学习的服务。多年来，数十亿人发现这很有用，我们已经建立了更多的服务，世界各地的人们每天都喜欢和使用它们。 最近我听到很多关于我们商业模式的问题，所以我想解释一下我们如何运作的原则。 我相信每个人都应该有发言权并能够联系。如果我们致力于为每个人服务，那么我们需要一个每个人都能负担得起的服务。最好的方法是免费提供服务，广告使我们能够做到。 人们一直告诉我们，如果他们要看广告，他们希望它们具有相关性。这意味着我们需要了解他们的兴趣。因此，基于人们喜欢的页面，点击的内容以及其他信号，我们会创建类别 - 例如，喜欢有关园艺和西班牙生活的页面的人 - 然后向广告客户收取费用以向该类别展示广告。虽然在互联网出现之前广告已经存在，但在线广告可以实现更精确的定位，从而实现更具相关性的广告。 互联网还可以提供更大的透明度，并控制您所看到的广告，而不是电视，广播或印刷品。在Facebook上，您可以控制我们用来向您展示广告的信息，并且您可以阻止任何广告客户与您联系。您可以找到为什么看到广告并更改偏好以获取您感兴趣的广告。您还可以使用我们的透明度工具查看广告客户向其他人展示的每个广告。 不过，有些人担心这种模式的复杂性。在普通交易中，您向公司支付其提供的产品或服务。在这里，您可以免费获得我们的服务 - 我们会与广告客户分开工作，向您展示相关广告。这个模型可能会感觉不透明，我们都不信任我们不理解的系统。 有时这意味着人们认为我们做的事情是我们不做的。例如，我们不会出售人们的数据，即使经常报告我们这样做。事实上，向广告商出售人们的信息将违背我们的商业利益，因为这会降低我们对广告商的服务的独特价值。我们有强烈的动机来保护人们的信息不被其他任何人访问。 有人担心广告会导致我们与使用我们服务的人之间的利益错位。我经常被问到是否有动力增加Facebook的参与度，因为这会产生更多的广告房地产，即使这不符合人们的最佳利益。 我们非常注重帮助人们分享和联系更多，因为我们服务的目的是帮助人们与家人，朋友和社区保持联系。但从商业角度来看，重要的是他们的时间花得很好，或者他们不会长期使用我们的服务。Clickbait和其他垃圾可能在短期内推动参与，但我们故意展示这一点是愚蠢的，因为它不是人们想要的。 另一个问题是，我们是否会留下有害或分裂的内容，因为它会促进参与。我们没有。人们一直告诉我们他们不想看到这些内容。广告商不希望他们的品牌靠近它。坏内容仍然存在的唯一原因是我们用来审查它的人和人工智能系统并不完美 - 不是因为我们有动机忽视它。我们的系统仍在不断发展和完善。 最后，重要的问题是广告模式是否鼓励像我们这样的公司使用和存储比我们更多的信息。 毫无疑问，我们会收集一些广告信息，但这些信息对于安全和运营我们的服务通常也很重要。例如，公司经常将代码放在他们的应用程序和网站中，因此当一个人签出某个项目时，他们会发送提醒以完成购买。但是这种类型的信号对于检测欺诈或虚假账户也很重要。 我们让人们完全控制我们是否将这些信息用于广告，但我们不会让他们控制我们如何使用它来保护安全或运营我们的服务。当我们要求人们允许使用这些信息来改进他们的广告时，作为我们遵守欧盟通用数据保护法规的一部分，绝大多数人同意，因为他们更喜欢更相关的广告。 最后，我认为数据最重要的原则是透明度，选择和控制。我们需要明确我们使用信息的方式，人们需要明确选择如何使用信息。我们认为，通过互联网对这些原则进行编纂的监管对每个人都有好处。 要做到这一点很重要，因为这种商业模式有明显的好处。数十亿人获得免费服务，与他们关心的人保持联系并表达自己。小型企业 - 创造了全球大部分就业机会和经济增长 - 可以获得帮助他们茁壮成长的工具。Facebook上有超过9000万家小企业，它们构成了我们业务的很大一部分。大多数人买不起电视广告或广告牌，但现在他们可以使用大公司之前可以使用的工具。在一项全球调查中，Facebook上有一半的企业表示，自从他们加入以来，他们已经雇佣了更多的人。他们正在利用我们的服务创造数百万个就业机会。 对我们而言，技术始终是将权力交给尽可能多的人。如果你相信一个每个人都有机会利用自己的声音和平等的机会被人聆听的世界，任何人都可以从头开始创业，那么构建为每个人服务的技术都很重要。这就是我们每天都在建设的世界，我们的商业模式使其成为可能。 扎克伯格先生是Facebook的创始人兼首席执行官。","categories":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}],"tags":[{"name":"Facebook","slug":"Facebook","permalink":"http://blog.ozairs.com/tags/Facebook/"}],"keywords":[{"name":"评论","slug":"评论","permalink":"http://blog.ozairs.com/categories/评论/"}]},{"title":"跨平台配置工具Terraform常用命令","slug":"跨平台配置工具Terraform常用命令","date":"2019-03-11T08:57:13.000Z","updated":"2019-03-11T09:07:31.479Z","comments":true,"path":"DevOps/跨平台配置工具Terraform常用命令/","link":"","permalink":"http://blog.ozairs.com/DevOps/跨平台配置工具Terraform常用命令/","excerpt":"","text":"Terraform是一个 IT 基础架构自动化编排工具，它的口号是 “Write, Plan, and create Infrastructure as Code”, 基础架构即代码。具体的说就是可以用代码来管理维护 IT 资源，比如针对 AWS，我们可以用它创建，修改，删除 S3 Bucket, Lambda, EC2 实例，Kinesis， VPC 等各种资源。并且在真正运行之前可以看到执行计划(即干运行-dryrun)。由于状态保存到文件中，因此能够离线方式查看资源情况 – 当然，前提是不要在 Terraform 之外对资源进行修改。 Terraform 配置的状态除了能够保存在本地文件中，也可以保存到 Consul, S3, azure, http, swift 等处。 Terraform 是一个高度可扩展的工具，通过 Provider 来支持新的基础架构，AWS 不过为目前官方内建 68 个 Providers 中的一个。其他能用 Terraform 的地方有 Alicloud(阿里云, 实名制备案才能用), Google Cloud, Heroku, Kubernetes, Microsoft Azure, MySQL, RabbitMQ, Docker 等等。愿意的话可以写自己的 Provider, 如搞个 Kafka 的话，用来管理 Topic 等的创建，维护工作。 Terraform 之前我们对 AWS 的操作用的是 awscli, 或 Serverless。awscli 什么都能做，但它是无状态的，必须明确用不同的命令来创建，修改和删除。Serverless 不是用来管理基础架构的，用它创建 Lambda 时创建资源都是很麻烦的事。AWS 提供的 CloudFormation 才是与 Terraform 较类似的工具，但是看到用法就头疼。 下面从最简单例子开始，看看怎么用 Terraform 创建，删改，修改 S3 Bucket。本地系统为 Mac OS。 1. Terraform 安装 brew install terraform 安装后 shell 命令就是 terraform, 常用的是 terraform init, terraform plan, terraform apply 2. 创建配置文件像 git 一样，每个 Terraform 项目需要自己单独的目录空间，所以我们创建一个 terraform-learning 目录 mkdir terraform-learningcd terraform-learning 该目录下的所有 *.tf 文件都会被 Terraform 加载，在初始化 Terraform 工作空间之前必须至少要有一个 *.tf 文件。我们这里建立文件 main.tf, 内容如下 Terraform 配置的语法是该公司 HashiCorp 独创的 HCL(HashiCorp configuration language), 它可以兼容 JSON 格式。 上面 tf 文件在 Vim 中的语法加亮是安装的 hashivim/vim-terraform 插件。 我们写好了 *.tf 文件后可以调用 terraform fmt 对配置文件进行格式化，它比较喜欢被 Java 弃用的等号对齐的格式。 3. 配置文件介绍从正式跨入 terraform 命令正题之前先来大概的介绍一下上面那个 main.tf 文件。 1) provider “aws” 部分，它指定选用什么 provider, 以及验证信息。aws 既允许指定 access_key 和 secret_key provider “aws” { region = “us-east-1” access_key = “your-access-key-here” secret_key = “your-secret-key-here”} 也能够指定证书文件中的 profile provider “aws” { region = “us-east-1” shared_credentials_file = “~/.aws/credentials” //不指定的话，默认值是 “~/.aws/credentials” profile = “yanbin” //不指定的话，默认值是 “default”} 如果是使用 shared_credentials_file 中的 profile, 请确定您以预先生成好的 credentials 文件及有效的 profile。 更多关于 AWS Provider 的配置请参考 https://www.terraform.io/docs/providers/aws/index.html 2) resource “aws_s3_bucket” “s3_bucket” 部分 这只是我们今天举的一个小例子，点击链接 aws_s3_bucket 查看 S3 Bucket 所有的配置项。Terraform 能够管理的所有 AWS 资源也能从前面那个链接中看到。 如果 bucket yanbin-test-bucket 不存在的话，运行 terraform apply 将会创建它，否则试图更新该 bucket。此例子只指定了 bucket 的 acl 和 tag 信息。terraform destroy 用来删除已存在的 bucket。 注意：terraform 配置文件中只指定要管理的资源对象，并不关心操作资源的行为–创建，修改，删除操作。操作行为与 Terraform 的状态有关系，无则创建，有则修改，更名会拆分为除旧立新两个操作，terraform destroy 用于显式删除资源。后面实例操作时会讲到。 注：resource &quot;aws_s3_bucket&quot; &quot;s3_bucket&quot; { 中，resource 后第一个是 type, 即资源名，第二个参是 name。其实 “s3_bucket” 在这里没什么用，只是一个描述或助记符而已。(2017-08-28): 更正一下，在作为变量引用的时候就要用到它，例如在后面要为 Lambda 创建一个 S3 Event 的 Trigger, 就要写成 event_source_arn = &quot;${aws_s3_bucket.s3_bucket.arn}&quot;, 引用时不需要知道实际的名称。 4. 初始化工作目录在初始化 Terraform 工作目录之前， 其他命令如 apply, plan 多是不可用的，提示需要初始化工作目录，命令是 terraform init 它要做的事情像是 git init 加上 npm install，执行完了 terraform init 之后会在当前目录中生成 .terraform 目录，并依照 *.tf 文件中的配置下载相应的插件。 5. 执行 Terraform 管理命令有了前面的准备之后，终于可以开始运行 Terraform 的管理命令了。Terraform 在正式执行之前提供了预览执行计划的机会，让我们清楚的了解将要做什么 terraform plan 由此计划还能知道关于 aws_s3_bucket 有些什么配置项，比如配置中可以加上 acceleration_status = &quot;Enabled&quot; terraform apply 这样便在 AWS 上创建了一个 S3 bucket “yanbin-test-bucket”, 同时会在当前目录中生成一个状态文件 terraform.tfstate, 它是一个标准的 JSON 文件。这个文件对 Terraform 来说很重要，它会影响 terraform plan 的决策，虽然不会影响到实际的执行效果。我们可以把它存到远端，如 S3 或 Consul。terraform state [list|mv|pull|push|rm|show] 用来操作状态文件。 此时什么也不改，再次执行 terraform plan, 会显示没什么要做的 aws_s3_bucket.s3_bucket: Refreshing state… (ID: yanbin-test-bucket)No changes. Infrastructure is up-to-date. 如果对 main.tf 作点小改，改个 tag 属性，再次 terraform plan ~ aws_s3_bucket.s3_buckettags.Name: “Created by Terraform” =&gt; “sCreated by Terraform” Plan: 0 to add, 1 to change, 0 to destroy. 为什么说 terraform plan 是基于状态文件 terraform.tfstate 作出的呢？我们可以删除这个状态文件，然后执行 terraform plan 看看 + aws_s3_bucket.s3_bucket ….. bucket: “yanbin-test-bucket” …… tags.Environment: “QA” …… Plan: 1 to add, 0 to change, 0 to destroy. Terraform 由于缺乏 terraform.tfstate 对比，所以认为是要添加一个 bucket, 但是实际执行 terraform apply 时，连接到远端 AWS, 发现该 bucket 已存在就只是进行更新。terraform apply 总能给出正确的操作结果。同理如果状态文件中说有那个 bucket, terraform plan 会说是更新，但 AWS 没有那个 bucket，实际执行 terraform apply 也会进行添加的。 资源更名如果把 main.tf 中的 bucket = “yanbin-test-bucket” 改成 bucket = “yanbin-test-bucket-rename” 即欲为 bucket 更名，用 terraform plan 看下计划 实际上 terraform apply 也是先删除旧的，再创建新的。Terraform 像 git 一样用不同颜色和 +/- 号来显示变动操作 最后是 terraform destroy 命令，把 *.tf 文件中配置的所有资源从 AWS 上清理掉。 关于 Terraform 工作目录中文件命名Terraform 运行时会读取工作目录中所有的 *.tf, *.tfvars 文件，所以我们不必把所有的东西都写在单个文件中去，应按职责分列在不同的文件中，例如： provider.tf – provider 配置terraform.tfvars – 配置 provider 要用到的变量varable.tf – 通用变量resource.tf – 资源定义data.tf – 包文件定义output.tf – 输出 以此篇最简单的入门出发，以后可以深入了解 Lambda, Lambda 触发器，及 API Gateway, EC2 实例怎么用 Terraform 来管理，也知晓了资源的可用属性应该到哪里去查。 一个小提示：在执行像 terraform plan 或 terraform apply 等命令的时候，可以按下 ctrl + c 让控制台输出详细的日志信息。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Terraform","slug":"Terraform","permalink":"http://blog.ozairs.com/tags/Terraform/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"Kubernetes之kubectl常用命令","slug":"Kubernetes之kubectl常用命令","date":"2019-03-10T06:03:57.000Z","updated":"2019-03-10T06:07:37.242Z","comments":true,"path":"DevOps/Kubernetes之kubectl常用命令/","link":"","permalink":"http://blog.ozairs.com/DevOps/Kubernetes之kubectl常用命令/","excerpt":"","text":"这篇主要介绍一下kubernetes相关的命令，供初接触kubernetes的参考。 kubernetes通过kube-apiserver作为整个集群管理的入口。Apiserver是整个集群的主管理节点，用户通过Apiserver配置和组织集群，同时集群中各个节点同etcd存储的交互也是通过Apiserver进行交互。Apiserver实现了一套RESTfull的接口，用户可以直接使用API同Apiserver交互。另外官方还提供了一个客户端kubectl随工具集打包，用于可直接通过kubectl以命令行的方式同集群交互。 由于博主水平有限，本文主要介绍一些博主在日常中经常使用到的命令，另外最近正式release的kubernetes 1.2中新加入的的一些feature，由于博主也还没有深入研究，所以不会太多涉及。 Help类似于所有的命令行工具工具，kubectl也可以直接执行或 | 可获得命令的帮助信息。如下图所示，kubectl使用方式为：Usage： kubectl [flags] kubectl [commond]另外所有的命令选项都可以通过执行 –help获得特定命令的帮助信息。 getget命令用于获取集群的一个或一些resource信息。使用–help查看详细信息。kubectl的帮助信息、示例相当详细，而且简单易懂。建议大家习惯使用帮助信息。kubectl可以列出集群所有resource的详细。resource包括集群节点、运行的pod，ReplicationController，service等。Usage:kubectl get [(-o|–output=)json|yaml|wide|go-template=…|go-template-file=…|jsonpath=…|jsonpath-file=…] (TYPE [NAME | -l label] | TYPE/NAME …) [flags] [flags]1）例如获取pod信息，可以直接使用”kubectl get po“获取当前运行的所有pods的信息，或使用”kubectl get po -o wide“获取pod运行在哪个节点上的信息。注:集群中可以创建多个namespace，未显示的指定namespace的情况下，所有操作都是针对default namespace。如下图所示列出了default 和kube-system的pods： 2）获取namespace信息 kubectl get namespace3）类似可以使用”kubectl get rc”, “kubectl get svc”, “kubectl get nodes”等获取其他resource信息。4）获取一些更具体的信息，可以通过使用选项“-o”。如：（1）kubectl get po -o yaml 以yawl格式输出pod的详细信息。 （2）kubectl get po -o json 以jison格式输出pod的详细信息。 （3）另外还可以使用”-o=custom-columns=“定义直接获取指定内容的值。如前面使用json和ymal格式的输出中，metadata.labels.app的值可以使用如下命令获取。kubectl get po rc-nginx-2-btv4j -o=custom-columns=LABELS:.metadata.labels.app其中LABELS为显示的列标题，”.metadata.labels.app”为查询的域名 （4）其他资源也可以使用类似的方式。 describedescribe类似于get，同样用于获取resource的相关信息。不同的是，get获得的是更详细的resource个性的详细信息，describe获得的是resource集群相关的信息。describe命令同get类似，但是describe不支持-o选项，对于同一类型resource，describe输出的信息格式，内容域相同。 注：如果发现是查询某个resource的信息，使用get命令能够获取更加详尽的信息。但是如果想要查询某个resource的状态，如某个pod并不是在running状态，这时需要获取更详尽的状态信息时，就应该使用describe命令。kubectl describe po rc-nginx-2-btv4j createkubectl命令用于根据文件或输入创建集群resource。如果已经定义了相应resource的yaml或son文件，直接kubectl create -f filename即可创建文件内定义的resource。也可以直接只用子命令[namespace/secret/configmap/serviceaccount]等直接创建相应的resource。从追踪和维护的角度出发，建议使用json或yaml的方式定义资源。 如，前面get中获取的两个nginx pod的replication controller文件内容如下。文件名为：rc-nginx.yamlapiVersion: v1kind: ReplicationControllermetadata: name: rc-nginx-2spec: replicas: 2 template: metadata: labels:app: nginx-2 spec: containers: name: nginx-2image: xingwangc.docker.rg/nginxports: containerPort: 80直接使用create则可以基于rc-nginx.yaml文件创建出ReplicationController（rc），rc会创建两个副本：kubectl create -f rc-nginx.yaml创建后，使用“kubectl get rc”可以看到一个名为rc-nginx-2的ReplicationController将被创建，同时“kubectl get po”的结果中会多出两个前缀为“rc-nginx-2-”的pod。关于kubernetes集群中resource，pod， ReplicationController…等后续会新开博文详细介绍。 replacereplace命令用于对已有资源进行更新、替换。如前面create中创建的nginx，当我们需要更新resource的一些属性的时候，如果修改副本数量，增加、修改label，更改image版本，修改端口等。都可以直接修改原yaml文件，然后执行replace命令。 注：名字不能被更更新。另外，如果是更新label，原有标签的pod将会与更新label后的rc断开联系，有新label的rc将会创建指定副本数的新的pod，但是默认并不会删除原来的pod。所以此时如果使用get po将会发现pod数翻倍，进一步check会发现原来的pod已经不会被新rc控制，此处只介绍命令不详谈此问题，好奇者可自行实验。kubectl replace -f rc-nginx.yaml patch如果一个容器已经在运行，这时需要对一些容器属性进行修改，又不想删除容器，或不方便通过replace的方式进行更新。kubernetes还提供了一种在容器运行时，直接对容器进行修改的方式，就是patch命令。 如前面创建pod的label是app=nginx-2，如果在运行过程中，需要把其label改为app=nginx-3，这patch命令如下：kubectl patch pod rc-nginx-2-kpiqt -p ‘{“metadata”:{“labels”:{“app”:”nginx-3”}}}’ edit edit提供了另一种更新resource源的操作，通过edit能够灵活的在一个common的resource基础上，发展出更过的significant resource。例如，使用edit直接更新前面创建的pod的命令为： kubectl edit po rc-nginx-btv4j 上面命令的效果等效于： kubectl get po rc-nginx-btv4j -o yaml &gt;&gt; /tmp/nginx-tmp.yaml vim /tmp/nginx-tmp.yaml /do some changes here / kubectl replace -f /tmp/nginx-tmp.yaml Delete 根据resource名或label删除resource。 kubectl delete -f rc-nginx.yaml kubectl delete po rc-nginx-btv4j kubectl delete po -lapp=nginx-2 apply apply命令提供了比patch，edit等更严格的更新resource的方式。通过apply，用户可以将resource的configuration使用source control的方式维护在版本库中。每次有更新时，将配置文件push到server，然后使用kubectl apply将更新应用到resource。kubernetes会在引用更新前将当前配置文件中的配置同已经应用的配置做比较，并只更新更改的部分，而不会主动更改任何用户未指定的部分。 apply命令的使用方式同replace相同，不同的是，apply不会删除原有resource，然后创建新的。apply直接在原有resource的基础上进行更新。同时kubectl apply还会resource中添加一条注释，标记当前的apply。类似于git操作。 logslogs命令用于显示pod运行中，容器内程序输出到标准输出的内容。跟docker的logs命令类似。如果要获得tail -f 的方式，也可以使用-f选项。kubectl logs rc-nginx-2-kpiqt rolling-update rolling-update是一个非常重要的命令，对于已经部署并且正在运行的业务，rolling-update提供了不中断业务的更新方式。rolling-update每次起一个新的pod，等新pod完全起来后删除一个旧的pod，然后再起一个新的pod替换旧的pod，直到替换掉所有的pod。 rolling-update需要确保新的版本有不同的name，Version和label，否则会报错 。 kubectl rolling-update rc-nginx-2 -f rc-nginx.yaml 如果在升级过程中，发现有问题还可以中途停止update，并回滚到前面版本 kubectl rolling-update rc-nginx-2 —rollback rolling-update还有很多其他选项提供丰富的功能，如—update-period指定间隔周期，使用时可以使用-h查看help信息 scale scale用于程序在负载加重或缩小时副本进行扩容或缩小，如前面创建的nginx有两个副本，可以轻松的使用scale命令对副本数进行扩展或缩小。 扩展副本数到4： kubectl scale rc rc-nginx-3 —replicas=4 重新缩减副本数到2： kubectl scale rc rc-nginx-3 —replicas=2 autoscale scale虽然能够很方便的对副本数进行扩展或缩小，但是仍然需要人工介入，不能实时自动的根据系统负载对副本数进行扩、缩。autoscale命令提供了自动根据pod负载对其副本进行扩缩的功能。 autoscale命令会给一个rc指定一个副本数的范围，在实际运行中根据pod中运行的程序的负载自动在指定的范围内对pod进行扩容或缩容。如前面创建的nginx，可以用如下命令指定副本范围在1~4 kubectl autoscale rc rc-nginx-3 —min=1 —max=4 cordon, drain, uncordon 这三个命令是正式release的1.2新加入的命令，三个命令一起介绍，是因为三个命令配合使用可以实现节点的维护。在1.2之前，因为没有相应的命令支持，如果要维护一个节点，只能stop该节点上的kubelet将该节点退出集群，是集群不在将新的pod调度到该节点上。如果该节点上本生就没有pod在运行，则不会对业务有任何影响。如果该节点上有pod正在运行，kubelet停止后，master会发现该节点不可达，而将该节点标记为notReady状态，不会将新的节点调度到该节点上。同时，会在其他节点上创建新的pod替换该节点上的pod。这种方式虽然能够保证集群的健壮性，但是任然有些暴力，如果业务只有一个副本，而且该副本正好运行在被维护节点上的话，可能仍然会造成业务的短暂中断。 1.2中新加入的这3个命令可以保证维护节点时，平滑的将被维护节点上的业务迁移到其他节点上，保证业务不受影响。如下图所示是一个整个的节点维护的流程（为了方便demo增加了一些查看节点信息的操作）：1）首先查看当前集群所有节点状态，可以看到共四个节点都处于ready状态；2）查看当前nginx两个副本分别运行在d-node1和k-node2两个节点上；3）使用cordon命令将d-node1标记为不可调度；4）再使用kubectl get nodes查看节点状态，发现d-node1虽然还处于Ready状态，但是同时还被禁能了调度，这意味着新的pod将不会被调度到d-node1上。4）再查看nginx状态，没有任何变化，两个副本仍运行在d-node1和k-node2上；5）执行drain命令，将运行在d-node1上运行的pod平滑的赶到其他节点上；6）再查看nginx的状态发现，d-node1上的副本已经被迁移到k-node1上；这时候就可以对d-node1进行一些节点维护的操作，如升级内核，升级Docker等；7）节点维护完后，使用uncordon命令解锁d-node1，使其重新变得可调度；8）检查节点状态，发现d-node1重新变回Ready状态。 attach attach命令类似于docker的attach命令，可以直接查看容器中以daemon形式运行的进程的输出，效果类似于logs -f，退出查看使用ctrl-c。如果一个pod中有多个容器，要查看具体的某个容器的的输出，需要在pod名后使用-c containers name指定运行的容器。如下示例的命令为查看kube-system namespace中的kube-dns-v9-rcfuk pod中的skydns容器的输出。 kubectl attach kube-dns-v9-rcfuk -c skydns —namespace=kube-system exec exec命令同样类似于docker的exec命令，为在一个已经运行的容器中执行一条shell命令，如果一个pod容器中，有多个容器，需要使用-c选项指定容器。 port-forward 转发一个本地端口到容器端口，博主一般都是使用yaml的方式编排容器，所以基本不使用此命令。 proxy 博主只尝试过使用nginx作为kubernetes多master HA方式的代理，没有使用过此命令为kubernetes api server运行过proxy run 类似于docker的run命令，直接运行一个image。 label 为kubernetes集群的resource打标签，如前面实例中提到的为rc打标签对rc分组。还可以对nodes打标签，这样在编排容器时，可以为容器指定nodeSelector将容器调度到指定lable的机器上，如如果集群中有IO密集型，计算密集型的机器分组，可以将不同的机器打上不同标签，然后将不同特征的容器调度到不同分组上。 在1.2之前的版本中，使用kubectl get nodes则可以列出所有节点的信息，包括节点标签，1.2版本中不再列出节点的标签信息，如果需要查看节点被打了哪些标签，需要使用describe查看节点的信息。 其他其他还有如cluster-info信息可以查看当前集群的一些信息，Version查看集群版本信息等，还有一些集群配置相关的命令等。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://blog.ozairs.com/tags/Kubernetes/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"停止、删除所有的docker容器和镜像","slug":"停止、删除所有的docker容器和镜像","date":"2019-03-09T23:48:08.000Z","updated":"2019-03-09T23:51:57.312Z","comments":true,"path":"DevOps/停止、删除所有的docker容器和镜像/","link":"","permalink":"http://blog.ozairs.com/DevOps/停止、删除所有的docker容器和镜像/","excerpt":"","text":"这些命令总是记不住，或者说不用心去记，所以记录在本文中，以便将来查询。 列出所有的容器 ID1docker ps -aq 停止所有的容器1docker stop $(docker ps -aq) 删除所有的容器1docker rm $(docker ps -aq) 删除所有的镜像1docker rmi $(docker images -q) 复制文件12docker cp mycontainer:/opt/file.txt /opt/local/docker cp /opt/local/file.txt mycontainer:/opt/ 更新: @snakeliwei 的提醒， 现在的docker有了专门清理资源(container、image、网络)的命令。 docker 1.13 中增加了 docker system prune的命令，针对container、image可以使用docker container prune、docker image prune命令。 docker image prune --force --all或者docker image prune -f -a` : 删除所有不使用的镜像 docker container prune -f: 删除所有停止的容器","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.ozairs.com/tags/Docker/"}],"keywords":[{"name":"DevOps","slug":"DevOps","permalink":"http://blog.ozairs.com/categories/DevOps/"}]},{"title":"科恩兄弟电影：《巴斯特·斯克鲁格斯的歌谣》赏析","slug":"科恩兄弟电影：《巴斯特·斯克鲁格斯的歌谣》赏析","date":"2019-03-08T22:47:51.000Z","updated":"2019-03-08T23:43:35.090Z","comments":true,"path":"电影/科恩兄弟电影：《巴斯特·斯克鲁格斯的歌谣》赏析/","link":"","permalink":"http://blog.ozairs.com/电影/科恩兄弟电影：《巴斯特·斯克鲁格斯的歌谣》赏析/","excerpt":"","text":"如果要选当代文学性最强的一个（对）美国导演，我首推科恩兄弟（兄：乔尔·科恩Joel Coen；弟：伊桑·科恩Ethan Coen）： 从处女作《血迷宫》（Blood Simple）开始，科恩兄弟的影片就带有十分强烈的后现代性和黑色幽默，剧情环环相扣、步步为营，诸多巧合汇集在一起的“滚雪球式”故事让人们记住了这对锋芒毕露的电影人。 在《巴顿·芬克》（Barton Fink）中兄弟俩将自己的存在主义观点和意识流手法融入作品中，讲述一位剧作家的创作焦虑，隐晦复杂的戏中戏文本嵌套，现实世界与意识世界的交叠让人们看清了科恩兄弟思想的深邃。这部作品也为兄弟俩带来了第一座金棕榈。 后来斩获奥斯卡最佳影片的《老无所依》其片名（No Country ForOld Man）来自叶芝的长诗《驶向拜占庭》。这部影片被称作是“西部片的终结”：凶手逃了，赃款散了，警察老了，是一次完完全全的反类型。影片原作来自“海明威与福克纳的唯一继承者”科马克·麦卡锡（Cormac McCarthy），科恩兄弟将他笔下那个蛮荒苍凉的西部世界完美地复刻了下来。 如今，科恩兄弟已经成为美国家喻户晓的导演，他们作品序列中的元素也日渐丰富，包括歌舞（《醉乡民谣》《凯撒万岁》等）、宗教元素（《逃狱三王》《老妇杀手》等）以及各种类型片都有涉猎。但始终贯彻的一点是他们对生活无常的透彻洞悉。 今年亮相于威尼斯电影节的新作《巴斯特·斯克鲁格斯的歌谣》（The Ballads of Buster Scruggs）由网飞Netflix出品，将六个独立的短篇故事合为一部长片，斩获了威尼斯最佳原创剧本。六个故事均是发生在18-19世纪的美国西部，神秘莫测而又无法无天的西部世界正是科恩兄弟故事展开的最佳舞台。 六个故事影调鲜明，从各个层次各个视角展现西部世界。别具一格的表演风格，精准的剪辑节奏，以及熟悉的世事无常的突转。每一个故事都充满了科恩兄弟的奇思妙想，每一个故事都是充满着黑色幽默的寓言故事。 在接下来的文章里，我将和大家谈谈自己对这六个故事的个人理解，所以真的真的会剧透，建议大家先去看原片啦！ 一、《巴斯特·斯克鲁格斯的歌谣》The Ballad of Buster Scruggs You see’em, you play’em. 看了牌就得玩。 故事简介：身着一袭白衣的通缉犯牛仔巴斯特·斯克鲁格斯是声名远扬的神枪手，他虽然是不法之徒却贯彻着自己的原则，绝不惹是生非，但也绝不忍气吞声。他一人一马地流浪，一路上免不了发生些流血事件。最后他遇到了另一个神枪手，死在了他的枪口下。 在故事的开头，巴斯特有一段这样的独白： 这是巴斯特的信条，他相信“愿赌服输”，为自己无力改变的事情而动肝火是很没有必要的。之后他在一间酒吧里，他坐上了一个虚位以待的牌局，可放下的牌实在不好，在看了之后巴斯特反悔了。这是他“不愿意赌的局”。但其余的人告诉他：“看了牌就得玩。”有个人甚至拿枪威胁他（这违反店内需要寄存武器的规定）。没有赢的把握，巴斯特宁愿退出，他说： 拿枪指着他的人（名叫乔Joe）却不以为然，倚仗着武器的淫威逼迫巴斯特。但最终他被巴斯特的天秀操作撂倒了。死者的弟弟叫嚣着要巴斯特出来决斗，但也很快被巴斯特精湛的射技干掉。 接下来登场的牛仔也要求决斗，巴斯特欣然接受，在他看来不过是又多一个手下败将而已： 但这一次被撂倒的却是他自己。巴斯特死后的灵魂与牛仔合唱了一曲 When The Cowboy Trades His Spurs For Wings（《当牛仔的马刺换作翅膀》）。 这个故事是在用“牌局”和“决斗”做讽刺：人们往往在自以为胜券在握时遭遇失败，就如同手持武器的乔和十分自地信迈向决斗地点的巴斯特。在很多时候这种“牌局”是没有选择权的，你能做的唯有选择豁达地释然，一如开头巴斯特的独白。在踏上这条路的时候，巴斯特已然做好了觉悟。 有意思的是科恩兄弟用两个构图完全一致的镜头，暗示了这种际遇的传递： 这个身着一袭黑衣的牛仔，也会遇到下一个比他更快的神枪手。 这个故事糅合了最多的科恩元素，情节突转、类型片戏仿（牛仔决斗）、黑色幽默、宗教情怀和歌舞桥段，于是这个短篇可以总领整部影片，相信兄弟俩也拍得很过瘾。 二、《阿尔戈多内斯附近》Near Algodones 故事简介：一个走投无路的牛仔决定抢劫银行，但却失败了被拘捕。在即将被处以绞刑的时候，一群印第安人土著截杀了执法者；牛仔被路过的牧牛人所救，但那个牧牛人实际上是个盗牛贼，牛仔被诬陷并被送到镇上处死。 这个故事的架构就十分简单了，是典型的“塞翁失马”模式，用一次次的突转来表现旦夕祸福、造化弄人。在最后的绞刑架上，牛仔对旁边泣不成声的人说： 在死之前，牛仔还和看台下的一个姑娘对上眼了。这实在是很残忍的事，在你准备接受死亡的命运之后，你又产生了对生的渴求，实在是死不瞑目的折磨。但好歹，处刑的人用麻袋帮你合上了眼睛。 三、《饭票》（Meal Ticket） The quality of mercy is not strained, it droppeth like gentle rainfrom heaven. 慈悲不是出于勉强，它就像甘霖一样从天上降下尘世。 故事简介：一个男人依靠着一个没有四肢的残疾演说家卖艺维生。但越来越菲薄的收入令他不再信任这位少年，尤其在他看到一只“会算数的鸡”吸引了一大群人的目光之后，他决定替换掉自己的“演员”。 这是整部影片中文学性最为集中的一篇，尤其反映在残疾演说家的台词里，引用了雪莱的《奥斯曼狄斯》、《圣经·创世纪》该隐与约伯的故事、林肯的葛底斯堡演说，其间穿插着莎士比亚的商籁诗句和《暴风雨》台词。这样的演说注定是令人费解的拼凑文本，但演说家生动俄演绎还是让不少听众产生了敬畏之心。 故事在愈发酷冽的蓝色影调里发展着，男人和少年的关系在不断地发生微妙的转变。最终他抛弃了少年，而收获了一只“天才阉鸡”。 这个短篇开头的引语出自莎翁的《威尼斯商人》，这或许是唯利是图的商人们的自我开脱之词，在这里则是少年内心的真实写照，也是对那个男人的穷形尽相。有趣的是篇名“饭票”的讽刺意味，男人与少年实际上是相依为命，互相提供所需，彼此都是对方的“饭票”。他买下了那只鸡，却不明白“算数”是如何做到的，迎接他的必将是一个饥寒交迫的寒冬。 四、《黄金谷》（All GoldCanyon） 这儿是峡谷的碧绿心脏，布局呆板的峭壁一到这里，豁然开朗，一改粗犷的格调，形成一个隐蔽的小天地，洋溢着甜蜜、丰满、柔和的情趣。这儿的一切都在安息，甚至狭窄的小溪也收住了汹涌的奔腾，渐渐变成了恬静的池塘。一头绛红的、角上丫杈很多的公鹿，低垂着头，半闭着眼睛，站在深及膝盖的水里，正在打盹儿。故事简介：淘金老人来到一片风景绝好的土地，希望能够找到属于自己的金矿。就在他辛劳了无数个日夜后终于寻到矿脉之时，他被人从背后用枪袭击了…… 这个故事并非科恩兄弟原创，而是改编自美国著名短篇小说家杰克·伦敦（Jack London）的同名作品，影片中出现的句子也是原作的引文。 杰克·伦敦用生动隽永的文笔展示了他自己的生态观：“飘动的声音和飘忽的颜色，似乎共同编织出一片精美、无形的轻纱，而它就是这里的精神。这是和平的精神，没有死亡，只有安然跳动的生命，安谧却不死寂，……这里的精神是具有生命气息的和平精神，一切都陶醉在繁荣的安逸与满足中，丝毫不受远方战争传闻的搅扰。” 但是淘金者的到来打破了这一切，他开掘土地、钓捕银鱼、还偷走了一颗鸟蛋，他惊扰了这里的生灵，随即将那一片“轻纱”撕破了。没有战争搅扰的大自然，也就迎来了淘金者和偷袭者之间的争斗。我们会很自然地生发联想，这就是人类亘古以来就有的习性：争抢资源，引发战争，破坏自然；在我们尚未脱离对自然秩序的崇拜的时代，我们会敬畏、会感恩，而当我们逐渐把握了自然规律并想改造自然之后，我们就成为了自然精神的入侵者和破坏者。 在这个故事中，偷袭者是妄图不劳而获的人，但最终被淘金老人反杀；而当老人离开这里的时候，慷慨馈赠他金矿的自然只是重归了和平却没有报复他。看着那一地满目疮痍的矿洞，我们需要警醒：不是不报，时候未到。 从技法上而言，淘金老人与偷袭者之间的争斗既是故事的一部分，又与整个故事产生了相互映照：即老人是弱势的、被劫掠的，类似于大自然；偷袭者是强势的、施暴的，类似于破坏自然者。因此这个故事这看上去只是一个“绿水青山就是金山银山”的口号宣传片，其内在层次还是十分丰富的，这便是科恩兄弟故事的魅力所在。 五、《受惊的女子》The Gal Who Got Rattled Mr.Arthur had no idea about what he would say to Billy Knapp.亚瑟先生不知道该如何向比利·奈普开口。故事简介：隆格巴小姐为了一个潜在的结婚对象将要随车队搬迁至俄勒冈。在途中她的哥哥感染霍乱去世，隆格巴小姐决定继续前进，马车领队比利·奈普则趁机向她表达结婚意向。但隆格巴小姐为了她的狗与大部队走散，在印第安人的袭击中饮弹自尽。 这个短篇中隆格巴小姐一直处于“受惊”的不安状态，这种状态既是瞬时的“受惊吓”，比如当她以为自己的狗被一枪打死之后她放下捂住耳朵的手，随即又被接连的两声枪响吓到： 更是一种无所适从的彷徨，比如本来该由她哥哥来撮合她和未婚夫的婚事，在她哥哥死后就没有人帮她介绍了，而她又举目无亲，不知该去往未知的俄勒冈还是该回到无依无靠的故地。 但真正让这个短篇得名的是隆格巴小姐最后的举动。她和另一个领队亚瑟先生受到了印第安人的包围，亚瑟给了她一把手枪并告诫她，必要的时候就用这把枪自尽，被印第安人逮到是绝对的生不如死。就在亚瑟先生费尽千辛万苦击退了印第安人之后，他却发现隆格巴小姐已经自杀了。所以这才是真正“got rattled”的时候。 亚瑟先生很是悔恨，如果他没有向隆格巴小姐交代那些话，或许她就不会死了。所以当他回到车队的时候，“不知道该如何向比利·奈普开口”。 其实自杀这一枪是隆格巴小姐的性格与处境使然，她本人是唯唯诺诺、谨小慎微的人，而又独自面对了亲人的离去，不知道生活该如何继续下去。在这种精神上的高压之下，她的弦最终被印第安人切断了。 有趣的是，如果我们再往回倒一点，如果隆格巴小姐没有去找她的那只狗就不会和大部队走散了，如果比利·奈普当时把那只狗打死就好了。这就是科恩兄弟的编剧惯例了：用看似微不足道的细节买下伏笔，事件与事件的相互关联最终导向了无可挽回的结局，也就是“节外生枝”与“滚雪球”。 隆格巴小姐的扮演者佐伊·卡赞（Zoe Kazan）奉献了十分精湛的表演，将科恩影片中独有的悲哀与滑稽的混合表现得十分自然而又不失夸张的喜感： Is it？这个短篇的文字技巧是“开头与结尾的移位”，开篇的引文部分其实是故事的结尾，而故事的结尾暗示着无数情节的开始：亚瑟先生将怎么去措辞，比利·奈普将对此产生什么反应等等。故事的主线是隆格巴小姐的受惊自尽，支线则是比利·奈普对她的求婚，主线结束之后，支线留作结尾形成了“复调式”的故事体式，大大拓宽了文本的阅读空间。 六、《遗体》The Mortal Remains Whether or not he heard, the coachman did not slow.不论他是否听见，马车夫都不会慢下来。 故事简介：五个身份不同的陌生人：一个法国男人，一个皮草猎人，一个贵妇人，一胖一瘦两个赏金猎人（他们要将通缉犯的遗体运往镇上的警署）；一同乘马车前往一个共同的目的地。期间贵妇突发了哮喘，法国男人让马车夫停车，但他充耳不闻。马车夫一直前进着，直到一处旅馆门口停下。 这个故事架构非常简单，但却异常精彩，它表现了科恩兄弟极高的文学造诣，通篇只有两个场景：马车内和目的地，但却有十分充足的戏剧张力。故事中的对白非常冗杂，意涵丰富，值得细读，在这里主要是想集中讨论这个故事的两种解读：（1）这个故事是实指，就是五个人一同前往一个共同的目的地，他们身份明确，目的地也明确（片中说是摩根堡），马车夫不愿意停下来可能只是出于某种意愿。他们最后下榻到同一处旅馆。 （2）这个故事是虚指，象征的是人走向死亡的全过程。两个赏金猎人相当于是摆渡人，而这永远不会慢下来的马车就是永远不会停留的“时间”。最后停留的终点就是“死亡”。 对第二种解读的佐证能够很轻易地在片中找到，比如两个赏金猎人自称“死神”“灵魂的收割者”，在他们眼中只有两种人：“活人”与“死人”；故事发生的整个时间段是从日薄西山到彻底的冷夜；旅馆大门的雕刻装饰是天使与恶魔（公羊头代表撒旦）等等。但是这些证据都可以有非象征性的解读，故事耐人寻味的含蓄正在于此。 片中比较重要的一段话是赏金猎人所讲的“夜归人”（The Midnight Caller）故事，这是一个家喻户晓从小听到大的故事，但每每听我们都还是会被吸引： 这段话的妙处在于文本意涵的层层嵌套：最里面是这个“夜归人”故事；在这之外是听故事的人，他们喜欢这个故事既与自己相关又与自己无关；在这之外是这个现象的叙述者：赏金猎人，叙述的对象是对面的几个乘客，让他们联想自己是否有相同的经验；最后是银幕外的我们，当我们在听这整个故事的时候，我们是否也产生了相同的想法？ 我们再来看这个故事的标题：遗体，英文原名是the mortal remains，即凡人的遗留物。当片中的人物意识到自己的处境不对的时候，我们也就该意识到这个“遗体”指代的自然不是两位赏金猎人运送的遗体，而是这三位乘客—— 再扩大一点，是每一个人：没有人会永垂不朽，所有人都是暂时活动着的“遗体”。","categories":[{"name":"电影","slug":"电影","permalink":"http://blog.ozairs.com/categories/电影/"}],"tags":[{"name":"电影","slug":"电影","permalink":"http://blog.ozairs.com/tags/电影/"}],"keywords":[{"name":"电影","slug":"电影","permalink":"http://blog.ozairs.com/categories/电影/"}]},{"title":"世界上十大图书馆之一——维多利亚州立图书馆","slug":"世界上十大图书馆之一——维多利亚州立图书馆","date":"2019-03-08T04:01:41.000Z","updated":"2019-03-08T23:50:45.407Z","comments":true,"path":"旅行/世界上十大图书馆之一——维多利亚州立图书馆/","link":"","permalink":"http://blog.ozairs.com/旅行/世界上十大图书馆之一——维多利亚州立图书馆/","excerpt":"","text":"维多利亚州立图书馆State Library of Victoria位于墨尔本的市中心，地理位置绝佳，就在热闹的Melbourne Central车站正对面。 在图￼书馆前方大草皮上是大家歇息的好去处，只要有太阳的时候，墨尔本人是绝对不会错过在这里晒日光浴的任何机会。 距离图书馆入口处不远的地方，有大西洋棋让大家切磋一下棋艺。 而在Swanston St and La Trobe St交叉口的人行道上，有个像是图书馆沉到地底的公共艺术。 图书馆前方有不少铜像，正前方的雕像是大法官Redmond Barry。 这座图书馆成立于1854年，与墨尔本大学同年完工。州立图书馆为当地建筑师Joseph Reed设计，在之前的文章介绍过，这位设计师还包办设计了墨尔本其它著名的建筑物。像是皇家展览馆、墨尔本市政厅、圣米迦勒联合教会等等 在1856年维多利亚州立图书馆正式对外开放，经过了一个半世纪的发展，藏书体系越来越完善，目前该馆有超过两百多万的图书，以及一百多万件的地图、手稿、报册、图册等文献，馆藏范围种类繁多，史料价值高，完整的保存着维多利亚的文化。 图书馆内部有宽敞的展览大厅、画廊、简报厅、会议室、书报区，还有一个放置电玩的多媒体休闲室，馆方也充分的利用这些场地举办论坛、表演、讲座等活动。 除了丰富的藏书外，馆内还有陈列油画、雕像等艺术品，是一个集学习、哲学、科学及艺术的殿堂，在此不仅仅为学生、作家和爱思考的人提供一个便利的资源中心，它也是维多利亚州人文历史的主要记载地。 大部分游客都是为了馆内的圆顶阅览室而来，这部分于1913年开放，其八角空间可容纳一万本书及五百位以上的阅览者。 阅览室上方的圆顶，采用自然透光的设计，1913年由三位建筑师Bates、Peebles、Smarts的设计，仿效英国图书馆The British Library和华盛顿国会图书馆Library of Congress的圆顶。 楼梯旁还保留着早期的旋转楼梯，但现今已不再使用。 在图书馆的顶楼还有一幅三公尺高的莎士比亚之窗Shakespeare window，是澳大利亚第一幅人物像彩色玻璃拼花窗Stained glass window。 墨尔本能有个这么美的图书馆实在太幸运了，若是有机会来到墨尔本的话一定要来这走走。","categories":[{"name":"旅行","slug":"旅行","permalink":"http://blog.ozairs.com/categories/旅行/"}],"tags":[{"name":"澳洲","slug":"澳洲","permalink":"http://blog.ozairs.com/tags/澳洲/"}],"keywords":[{"name":"旅行","slug":"旅行","permalink":"http://blog.ozairs.com/categories/旅行/"}]},{"title":"墨尔本斯巴达挑战赛侧记","slug":"墨尔本斯巴达挑战赛侧记","date":"2019-03-02T10:54:01.000Z","updated":"2019-03-02T11:33:31.534Z","comments":true,"path":"uncategorized/墨尔本斯巴达挑战赛侧记/","link":"","permalink":"http://blog.ozairs.com/uncategorized/墨尔本斯巴达挑战赛侧记/","excerpt":"","text":"今年是墨尔本斯巴达越野挑战赛正赛的日子，虽然墨尔本的气温仍然居高不下，但是依然无法抵挡大批粉丝对于这项赛事的热情。今年的比赛得到了凯西市政府的大力支持，作为东道主，我也有幸作为志愿者参加了这项一年一度的重要赛事。 【赛事的主旨】 今年的墨尔本斯巴达挑战赛，是首次在凯西市举办，在Tooradin Estate的一个史诗般的新场地中，选手们有机会穿越泥泞，跳过火，征服障碍。 斯巴达挑战的宗旨，就是要让选手们组成一个团队或独自行进，并找出像斯巴达一样参加比赛意味着什么通过挑战赛，选手们将会看到自己征服障碍，如奥林巴斯，长矛，大力神升降机，戒指等等！ 【赛事的类型】 1、5公里竞速赛 这是斯巴达挑战赛最短的距离，选手们需要翻越20-23 障碍。比赛适合各级运动员使用; 从斯巴达的第一次选手到经验丰富的选手。 2、斯巴达超级赛，13公里，24-29 障碍 这是斯巴达挑战赛中距离赛事。由于比竞速赛的距离更长，障碍更多，超级赛将测试您的耐力，毅力和勇气。这个13公里的超级大道包含超过25个特色斯巴达障碍物，通过更加坚固和更加崎岖的地形。 3、2合1挑战赛 在同一天同时参加超级赛和竞速赛，并节省一些现金。通过获得竞速赛和超级赛奖牌，你将成为Spartan Trifecta的三分之二！ 4、儿童挑战赛 斯巴达挑战赛都是为了让自己变得泥泞而且充满乐趣！赛事的使命是鼓励孩子们出去，活跃，享受自己。这就是为什么我们的斯巴达儿童比赛鼓励年轻的斯巴达人在非竞争，安全和支持的环境中拥有一大堆泥泞的乐趣来征服他们的目标！孩子们会跑步，平衡，走路，爬行，爬上充满乐趣的障碍课程，帮助他们了解成为斯巴达人的感受！比赛经过专门设计，适合所有年龄段和健身水平的孩子。 斯巴达儿童挑战赛是1-2公里纯净的泥泞快乐。所有障碍都是成人障碍物的微型版本，并包含巨大的充气滑梯等附加功能，让孩子在参赛过程中，享受赛事带来的最大快乐。 孩子们可以进入两个不同的类别。有3到8岁的Spartan Juniors（完成1节课程）和9-13岁（完成2圈）的Big Kids类别。 成年人可以选择跟随课程并帮助他们的孩子。父母也可以选择与孩子或观众一起跑步。 【参赛观感】 今天虽然又是一个炎热的酷暑，特别是挑战赛的过程中，选手们要走草地，过泥塘，翻越各种障碍，可以说比赛是对身体机能的一次极限挑战，也是对于意志品质的一次终极考验。只有克服了身体和意志的障碍，才能成为一名真正的斯巴达勇士。 很荣幸今天能作为志愿者，参加斯巴达挑战赛正赛。作为斯巴达竞赛的志愿者，虽然牺牲了周末的时间，但是能有机会感受到斯巴达赛及选手们冲天的参赛热情，并且能够参与到比赛中，让选手和和观众们拥有史诗般的体验，也算是一种难得而又珍贵的体验了。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.ozairs.com/tags/随笔/"}],"keywords":[]},{"title":"关于自己你需要知道的10件事","slug":"关于自己你需要知道的10件事-1","date":"2019-03-01T10:42:42.000Z","updated":"2019-03-01T10:45:18.793Z","comments":true,"path":"uncategorized/关于自己你需要知道的10件事-1/","link":"","permalink":"http://blog.ozairs.com/uncategorized/关于自己你需要知道的10件事-1/","excerpt":"","text":"我最近在INC发现了这篇文章，并且非常喜欢文中提到的挑战自己的方式，你是否问过自己以下这些棘手的问题。 无论我们的年龄，在生命的每个阶段，我们都应该花点时间进行评估，进行自我评估。我们应该知道我们是谁，理解我们想要什么。我们应该问自己一些棘手的问题，清楚地看到自己，并在必要时进行调整。这并不能保证成功，但它可以保证您对自己的生活方式感到满意。以下是我们应该始终能够对自己说的一些事情： \\1. 我遵从我内心的声音。即使有更轻松的选择，我也相信自己内心的声音能够引导我。我做了正确的事情，我忠于自己。 \\2. 我总是很积极。我把每一种情况视为祝福或教训。我一直保持着希望和乐观的态度。 \\3. 我很负责。我已经获得了信任，并对自己负责。我没有找借口，也没有责备别人。我是演出的明星，我很尊重我。 4.我很感激。我很感激我的生命。每个开门和关门，我都很感激。我很感激未来的希望。 \\5. 我选择原谅。我已经原谅了任何冤枉我的人。我原谅，因为我永远无法完全理解他们的处境，因为抱怨只会让我失望。 \\6. 我不留遗憾。好的，坏的，或者其他的，我永远不会后悔任何机会，即使结果很糟糕。我一直爱着，微笑，并尽我所能地生活，我永远不会后悔。 \\7. 我对自己诚实。我能够看着镜子里的脸，告诉他们真相。我是谁，我想成为谁，我喜欢什么，想要改变什么，我在哪里以及我想去哪里。这就是梦想成为现实的方式。 \\8. 我为自己感到骄傲。我为自己的成就感到自豪。大多数情况下，我为我这个人感到骄傲。最后，我会因为善良，诚实，勤奋，奉献和公平的人而被人们铭记。 \\9. 我不是一个轻言放弃的人。我不说，’我做不到’。我从不放弃，我从不放弃。我全力以赴。 \\10. 我还没完。只要我有气息，我就会继续生活，笑，给予，并尝试。如果只是一个裂缝，总会有一扇门打开。 俗话说“我们必须先学会爱自己”。给自己一个休息时间。改变你的想法，试着去做到最好。 【The Original Article】I recently came across this article in INC and loved the way it challenged you to consider whether you had asked yourself the tough questions. Regardless of our age, at each stage of life, we should take a moment to take stock, to do a self-evaluation. We should know who we are and understand what we want. We should ask ourselves the tough questions, see ourselves clearly, and make adjustments if necessary. This doesn’t guarantee success but it guarantees that you will feel good about how you are living your life. Here are some things we should always be able to say about ourselves: \\1. I have followed my heart. I have trusted my inner voice to lead me even when there were easier roads. I have done the ‘right’ thing. I have been true to myself. \\2. I have looked for the positive. I have treated every situation as a blessing or a lesson. I have kept hope and optimism on the forefront. \\3. I am responsible. I have taken credit and held myself accountable. I’ve made no excuses, nor blamed another. I am the star of my show, and I own up to me. \\4. I am grateful. I am grateful for the life I’ve been given. I’m grateful for every opened and closed door. I am grateful for the hope of more to come. \\5. I have forgiven. I have forgiven any and everyone who has wronged me. I forgive because I can never fully understand their situation and because holding a grudge only holds me back. \\6. I have no regrets. Good, bad, or otherwise, I will never regret any opportunity, even if it turned out badly. I have loved, laughed, and lived to the best of my ability, and I will never be sorry. \\7. I am honest with myself. I am able to look at the face in the mirror and tell them the truth. Who I am and who I want to be, what I love and what I want to change, where I am and where I want to go. This is how dreams become reality. \\8. I am proud of myself. I am proud of my accomplishments. Mostly, I am proud of the person I am. In the end, I will be remembered for the kind, honest, hard-working, giving, and fair person that I am. \\9. I am not a quitter. I do not say, ‘I can’t’. I never give up, and I never give in. I give my all to every endeavour. \\10. I am not finished. As long as I have breath, I will continue to live and laugh and give, and try. There is always a door that is open if only just a crack. As the old saying goes, “we must first love ourselves”. Give yourself a break. Change what you, and be the best you can be.","categories":[],"tags":[{"name":"励志","slug":"励志","permalink":"http://blog.ozairs.com/tags/励志/"}],"keywords":[]},{"title":"澳洲日记：班吉尔广场（Bunji Place)一览","slug":"澳洲日记：班吉尔广场（Bunji-Place-一览","date":"2019-02-23T23:19:33.000Z","updated":"2019-03-08T23:51:02.905Z","comments":true,"path":"旅行/澳洲日记：班吉尔广场（Bunji-Place-一览/","link":"","permalink":"http://blog.ozairs.com/旅行/澳洲日记：班吉尔广场（Bunji-Place-一览/","excerpt":"","text":"班吉尔广场（Bunjil Place）位于东墨尔本的凯西市，是一处新建的大型公共文化娱乐建筑，类似于中国大陆的“文化宫”。2017年10月29日，班吉尔广场正式对外开放。2019年2月14日，我第一次遇见班吉尔广场，趁着清晨游客较少的时段，比较仔细地欣赏了一番，感触颇多。 班吉尔广场的正面，“远看”似乎并不十分“起眼”，——这是澳洲很多公共建筑的共同特征，需要“近观”，才能发现它的“宏伟”与“壮丽”。 班吉尔广场的背面，比较内敛、含蓄的蓝灰色，闪烁着淡淡的蓝宝石般的光辉。### 班吉尔广场的正门，12米高大的透明玻璃幕墙，显示出一种坦诚开放、包容的姿态，欢迎来自四面八方的人们；向两翼竭力伸展的网状木质构架，给人一种展翅欲飞、努力向上的振奋。### 事实上，班吉尔广场之所以称为“Bunjil”，就是因为它的造型像征着澳洲土著的神鹰“Bunjil”，“Bunjil”被认为是澳洲土著的祖先之一，其原型是澳洲体型最大的猛禽“楔形尾鹰”。### 从正门高大的玻璃幕墙内，向外观看班吉尔广场的露天剧场，气势宏大，视野开阔，赏心悦目。班吉尔广场室内共三层，这是贯通一二三层的主大厅，两根巨大的网状艺术支柱支撑起整座屋顶，——如果说“Bunjil Place”象征着一只展翅欲飞的“神鹰”，那么这两根巨大的支柱就是“神鹰”的双腿。大厅底层有访客中心接待处、图书馆接待处与入口、剧院售票处与入口、表演中心接待处与入口，以及通向二三楼的旋转式楼梯，场面宏大，手机只能拍出其中很一小部分。### 从另一个角度看班吉尔广场主大厅的内部，画面左边是两根网状艺术支柱之一，右边是剧院售票处与入口，正前方是访客中心接待处（太远了，看不太清楚）。时间是2月14日星期天早上九点半，班吉尔广场刚刚开门，游客不多。### 班吉尔广场主大厅天花板仰视，全部网状木质结构，朴实、明快、简谐、对称。### 位于班吉尔广场底层，具有800个观众席的现代风格剧场，据说音响效果达到世界一流水准。### 墨尔本号称“艺术之都”，戏院、剧场特多，班吉尔广场剧院似乎主要面对的是儿童与青少年观众，11月19日星期天上演的是儿童剧《舞蹈学校（School of Dance）》。### 班吉尔广场还有一个艺术画廊，这也是“艺术之都”墨尔本的特色，几乎可以肯定地说，在墨尔本，凡有博物馆、图书馆的地方必有艺术画廊，美术馆就更不必待言了。### 艺术画廊举行的“班吉尔广场建筑艺术”的画展。 凯西市图书馆入口处的接待大厅。班吉尔广场的主要功能之一就是公共图书馆，大约三分之一的空间（包括一二三层）为凯西市图书馆所有，占地面积是旧凯西市图书馆的两倍还多，凯西市图书馆也因此更名为“班吉尔图书馆”。澳洲具有众多的大大小小的图书馆，所有的公共图书馆均免费向公众开放，是澳洲的文化特色之一；澳洲人重视阅读、喜爱阅读，从“班吉尔图书馆”可见一斑。### 从图书馆二楼俯瞰一楼接待大厅。### 图书馆一楼除了接待大厅，还开辟了若干不同类型的小型阅览室。 图书馆二楼大厅，包括一个开放式的多功能演讲厅，以及一排排摆满各种书籍的书架、一个个桌椅齐全、采光优良的阅览室。见微知著，图书馆内的书架都不高，书籍触手可及，也体现了图书馆处处为读者着想的理念。图书馆二楼的多功能演讲厅，座位的设计十分有趣，与通往三楼的楼梯浑然一体，左侧有一个两米来宽的人行通道，才是真正的楼梯。### 从图书馆三楼俯瞰二楼阅览室，各部分既相互连通又相对独立，加上明亮温馨的柔光，给读者营造出安静舒适的阅读空间。### 图书馆三楼的阅览室，空间的划分又有自己不同的特色，但总体上仍保持了各部分既相互连通又相对独立的风格，读者能够快速穿梭游走其间，查找图书资料十分方便，同时又保证了阅览室内潜心阅读的人尽可能不受干扰。身临其境，不知不觉就会被无形中“如饥似渴”的阅读氛围所感染。### 从图书馆二楼阅览室眺望班吉尔广场外部环境，草地青青、绿树环绕，原有的水上运动中心（游泳馆）、儿童游乐场与新建的班吉尔广场浑然一体，对面的WestField购物中心则与班吉尔广场遥遥相望。### 本文一开头便说“班吉尔广场”是大型公共文化娱乐建筑，类似于中国大陆的“文化宫”。但中国大陆的“文化宫”，“文化”二字名不符实，说是“文化”实则“娱乐”，称之为“娱乐宫”更加贴切，而且商业气息越来越浓。澳洲墨尔本的这座“班吉尔广场”，堪称真正意义上的“文化宫”，集图书、戏剧、音乐、美术于一身，为凯西市市民提供了一个文化与娱乐活动的场所；无论外观还是内涵，“班吉尔广场”处处都体现出了浓厚的“文化”精神。","categories":[{"name":"旅行","slug":"旅行","permalink":"http://blog.ozairs.com/categories/旅行/"}],"tags":[{"name":"澳洲","slug":"澳洲","permalink":"http://blog.ozairs.com/tags/澳洲/"}],"keywords":[{"name":"旅行","slug":"旅行","permalink":"http://blog.ozairs.com/categories/旅行/"}]},{"title":"Why do I need a cover letter","slug":"Why-do-I-need-a-cover-letter","date":"2019-02-23T12:03:18.000Z","updated":"2019-02-23T12:04:19.345Z","comments":true,"path":"uncategorized/Why-do-I-need-a-cover-letter/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Why-do-I-need-a-cover-letter/","excerpt":"","text":"If you have ever read one of the job ads I’ve posted, you would have seen my request for a cover letter. After reading some of the responses to that request, I’m sure the initial thought might have been, “Why the do I need a cover letter?” There’s no doubt I have read a bucket load of cover letters. Those that I have read which are poor far outweigh those that are good. It’s like comparing the sheer size of Jupiter to the Forest Moon of Endor; small and non-existent. Many of you, I am sure, wonder why you should bother at all. I tend to agree if the purpose of your cover letter is to be general and vague. Believe it or not, there have been times when I have called a candidate on the strength of their cover letter, alone. So, what makes one cover letter stand out over another in my opinion? Before I get to that, I want to share an experience in my career that has led to my opinion and writing this blog post. Before establishing my recruitment business, I worked in IT as a BDM for over a decade. In that time, I worked on countless proposals for my customers. It was always a collaborative process. My job was to get the frame of the document and the requirements clear. I would engage experts to provide the technical content of our solution. I would speak to relevant internal teams and third parties around our commercial model. Once I had all the information I needed, there was only one thing left to do. I needed to write my executive summary. I read a great book many years ago called Persuasive Business Proposals – Writing to Win More Customers, Clients, and Contracts by Tom Sant. On page 138, the chapter headed Executive Summary, the first line sets the theme of that chapter; The executive summary is the single most important part of your proposal. This line and the entire chapter changed how I wrote proposals forever. It resulted in me progressing to more shortlists and winning more deals. I even had a customer once ask me to write an executive summary to explain a proposal I hadn’t even written. The very premise of an executive summary in a business proposal got me thinking how similar one is, or should be, to a cover letter. If you are selling yourself to an employer, should you treat your resume as a business proposal? If so, why are you not introducing your solution (you) to the hiring manager’s problem with an effective executive summary? Tom goes on to say; the executive summary is the only part that’s likely to be read by everybody involved in making the decision. In fact, it’s the only part of your proposal that some decision makers will read at all. Now, I know in a recruitment process that’s unlikely to happen. Your resume will get read at some point, but there are some significant parallels to draw here. If a stakeholder can progress a proposal based on an executive summary, your cover letter can make a big impact too. I remember the old way I used to write a proposal and the way my customer would read them. I’d articulate my understanding of the problem and the outcome they were aiming to achieve. I’d relate their situation to the broader market. Our solution would then follow and the technical justification to support my claim. All important stuff. There would be pages and pages of diagrams, tables, jargon and blah blah blah. They’d read page after page until they found one of the most important things they were looking for to see if the discussion was worth continuing. The price. It was one of the most critical pieces of the puzzle, and yet I had it hidden in the shadows of my document. It’s no wonder people read my proposals like a Herald Sun reading sports enthusiast, from back to front. The first time I put my pricing in the executive summary was a real test of nerves. I was shitting myself. “What if they reject us before even looking at our solution?” However, that didn’t happen. The most important information was at the front. Our understanding of the problem, the key themes of our solution to address it and the price. The rest of the business proposal became the supporting documentation. What I found was it gave us more air time with our customer than we had before. It demonstrated a level of confidence in our solution. I found that more customers wanted to get me in to discuss the detail of the solution. A cover letter that addresses your customer, in the same way, will show the same confidence. It will demonstrate that you understand the role and why, in short, you are the right person for the job. An executive summary always exists as a part of the business proposal document. You want to make sure it’s the first thing your customer reads. I think cover letters should be the same. Not a separate document, but the first page of your resume. If you have two documents, your cover letter is less likely to be read after the resume has been opened first. Usually, recruiters will only attach one document with a candidate in their databases. For future roles, it’s beneficial to have everything in the same document. A cover letter in the resume will offer another page of content to where keywords can be found. Over my time, I have read countless cover letters that read like the narrative of a novel. Usually, they are one or two pages, densely populated with words. At first glance, they seem like a fair investment of time to read. However, for a cover letter, such a style doesn’t address the time-poor nature of your reader. Make your cover letter one page, the first thing someone sees. Be specific. Use dot points and have them well spaced (one and a half spaces works well for me) so they are easy to read. When you find a job advertisement you want to apply for, focus on the requirements section. Ask yourself, “what are the three critical things I think these guys are looking for?” Those lines will be explicit in the skill or experience they’re after. This is what you should prioritise and address in your cover letter. Don’t bother with the general requirements as you’ll only respond with general statements. These are the requirements like ‘excellent communication skills’ or ‘works well in a team.’ These things you can demonstrate in an interview. A good cover letter cuts specific words or phrases out of the advertisement. They do this, so it couldn’t be any clearer what they are trying to address. It’s a risk leaving it to chance that your audience will be able to interpret your resume in the way you want. This is where you should help them out. Point directly to the experience or skill. Say, “there, that’s where I did it!” And point to it from your cover letter. Being able to highlight what you think is important will help a recruiter find what they are looking for. However, if anything, it will help you qualify if, in fact, you are right for the job. The role of a recruitment consultant is not easy. Many of us are working on ten, twenty, even more positions at a given time. If you consider putting forward three or four candidates per role, that’s a lot to manage. We coordinate client briefings, write advertisements and drive proactive campaigns. We accept applications, conduct phone screenings and send out rejection emails. We organise interviews, build shortlists, lock in candidates to meet with clients. We help with salary negotiations, references and sending out offers. And all the time, keep our bosses off our backs maintaining weekly KPI’s. It ain’t easy, and we’re often left feeling like a panting sheepdog at the end of each day. We receive hundreds of applications per role. With limited minutes in the day, the trick, as a recruiter, is to find what you need as quickly as possible. You want to find what you need, pick up the phone and progress the candidate to the next stage. It’s like a game of Crash Bandicoot; every requirement you meet grants you another few seconds of reading time. However, offer a passage of boring fluff, and you go backwards. And if you do make it to the end of the level, that’s when you get the call from a recruiter. They are ringing to have an in-depth discussion with you about your application. There is no doubt that applying for a job through an advertisement is one of the hardest things to do. How do you stand out through words on a page? With so many lousy cover letters out there, I believe this is where you can answer that question. In the process, you will save the recruiter time trying to find what they’re looking for in your resume. If you think of it like this: the executive summary, your cover letter, is the map to the island of your resume. Be bold and tell a hiring manager exactly where to find what they are looking for. Tell them why you are right for the job, and maybe, you’ll be that next candidate who stands out from the crowd.","categories":[],"tags":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/tags/求职/"}],"keywords":[]},{"title":"Are Australia’s ‘secondary’ cities still a bargain, or have they run their race?","slug":"Are-Australia’s-‘secondary’-cities-still-a-bargain-or-have-they-run-their-race","date":"2019-02-21T00:21:58.000Z","updated":"2019-02-21T00:39:45.031Z","comments":true,"path":"uncategorized/Are-Australia’s-‘secondary’-cities-still-a-bargain-or-have-they-run-their-race/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Are-Australia’s-‘secondary’-cities-still-a-bargain-or-have-they-run-their-race/","excerpt":"","text":"Australia’s capital cities may be coming off the boil, but what of their metropolitan siblings? Secondary cities such as Geelong, Newcastle and Launceston have been on a run, proving more affordable options for buyers after prices shot up in the closest major capital city. But with prices in some capitals declining – most notably in Sydney and Melbourne – some secondary cities now don’t look quite as good value as they did a year or two ago. The outlook for prices in major regional cities Newcastle, Wollongong, Gold Coast, Sunshine Coast, Geelong and Launceston is analysed below. Secondary cities boomed after major cities became too expensiveWhen capital city prices become too expensive for first-home buyers and investors, aspiring capital city home buyers often look to nearby regional cities as a cheaper alternative. These secondary cities are often close enough to a major capital that people can commute to the capital city for work. Price growth in major cities and secondary cities generally track pretty closely together, but sometimes with a delay of around a year. For some cities, the major city in some city-pairs can lead turning points in the price growth of the secondary city. Sydneysiders consider Newcastle and Wollongong, Melburnians often look to Geelong, and Launceston, Tasmania’s second-largest city, is considered after Hobart. In Queensland, the typical house in Brisbane is cheaper than in the Gold Coast and the Sunshine Coast, but these coastal cities are both within commuting distance to Brisbane and are obvious alternatives to Queensland’s capital. Property prices in Wollongong, Newcastle and Geelong began rising a year or two after Sydney and Melbourne property prices began taking off around 2013. Launceston house prices have increased significantly since 2017, a couple of years after Hobart’s price boom started in 2015. While price growth has been more subdued up north, Sunshine Coast and Gold Coast house prices have increased by more than those in Brisbane. Notes: Capital city house prices are Australian Property Monitor city regions and are a stratified median price. Secondary cities are ABS Significant Urban Areas and are a raw median price. Most secondary cities have experienced stronger house price growth than their nearest capital cityMedian house price, December quarter 2015 2016 2017 2018 Per cent change,**2015-2018** Sydney $1,015,559 $1,131,882 $1,180,024 $1,062,619 5% Wollongong $585,000 $665,000 $718,000 $705,000 21% Newcastle $453,000 $495,000 $535,000 $558,000 23% Melbourne $718,853 $811,393 $909,463 $833,321 16% Geelong $435,000 $465,000 $518,000 $557,500 28% Hobart $347,841 $377,316 $440,970 $479,685 38% Launceston $285,000 $285,000 $310,000 $344,000 21% Brisbane $517,843 $546,984 $566,602 $566,058 9% Gold Coast $545,000 $590,000 $620,000 $622,500 14% Sunshine Coast $540,000 $560,000 $615,000 $620,000 15% What’s in store for secondary cities house prices?Several indicators are used to predict price growth in secondary cities in the coming years. The first method is comparing the ratio of the median price in a capital city with the secondary city’s median house price. The higher the capital city/secondary city price ratio, the more expensive the capital is compared to the secondary city (for example, a ratio of 2 indicates a typical house in the capital city is twice as expensive as the secondary city). If a capital city/secondary city price ratio is below average, then this may indicate the secondary city is overvalued, suggesting the secondary city may see weaker price growth in the near future (and vice versa). Buyer interest in an area – using changes in the number of views per listing from Domain’s website and apps, a leading indicator of future price growth – is also analysed. The economic outlook and job prospects in secondary cities, including the interconnectedness of the secondary city with the closest capital city, are also considered. Sydney-WollongongWhile Wollongong’s economy is performing well, its prices are likely to stagnate or fall in the year ahead. The main reason is that the Sydney/Wollongong price ratio has fallen just below the 2010-2018 average and is back close to the level over the 2003-2013 period, where the median house price in Sydney prices was approximately 50 per cent higher than in Wollongong (see graph below). This fall in the price ratio was due to Sydney house prices falling by more than Wollongong house prices over the past two years. While prices are likely to remain fairly stagnant over the next one to two years, Wollongong’s improving job market and growing links to Sydney should provide support to Wollongong property prices in the medium term. Wollongong has seen strong jobs growth in the past couple of years, with the unemployment rate for the Wollongong LGA falling from almost 7 per cent in 2016 to 4.5 per cent in 2018. Wollongong is also a growing commuter town: in 2016, more than 21,000 people commuted from Wollongong to Sydney for work (the second largest regional city to capital city commuting pair, behind the Gold Coast to Brisbane). Wollongong and Illawarra residents may also benefit from the construction of the Badgerys Creek airport, which will be just over an hour’s drive from Wollongong, although construction is not expected to finish until 2026. Sydney-NewcastleNewcastle is likely to see weak price growth or modest price falls in the next year or two. The Sydney/Newcastle price ratio has fallen below the 2010-2018 average as prices have grown slowly in Newcastle over the past year, but fell by 10 per cent in Sydney. This indicates Newcastle houses may be becoming overvalued compared to Sydney. Buyer interest in Newcastle also appears to be waning. Domain’s views-per-listing measure for Newcastle fell by 2 per cent over 2018 as there were fewer buyers or they began looking elsewhere. Another reason property price growth in Newcastle might be subdued is that there is no clear jobs boom on the horizon in the region. Newcastle’s unemployment rate has hovered around 6 per cent over the past couple of years, which is above Sydney’s unemployment rate of 4 per cent. Melbourne-GeelongThe Melbourne/Geelong house price ratio fell significantly over 2018 as house prices increased in Geelong and fell in Melbourne. The Melbourne/Geelong price ratio now sits at 1.5, meaning a typical house in Melbourne is 50 per cent more expensive than a typical Geelong house. The ratio is now below the 2010-2018 average. With Melbourne house prices forecast to continue falling in 2019, Geelong’s relative affordability will decline further, so this may also see prices in Geelong stagnate or fall modestly. The Geelong market is already losing momentum, with house price growth slowing in Geelong over 2018 and Domain’s views-per-listing measure for Geelong falling at the end of 2018. While the analysis of the Melbourne/Geelong price ratio suggests Geelong prices may fall, there are some promising signs for Geelong’s economy. Some sectors are seeing jobs growth, particularly government jobs, and the city is on the rebound after the end of car manufacturing in 2016. Geelong’s unemployment rate has hovered around 6 per cent since 2016, but a very low unemployment rate in Melbourne of 4 per cent (down from 6 per cent over the past year) may help push Geelong’s unemployment rate lower. Geelong is increasingly interconnected with Melbourne, which should see the Geelong property market become further tied to the Melbourne market. There are a number of transport infrastructure projects planned, or underway, that should improve travel times between Geelong and Melbourne, including the West Gate tunnel project and planned improvements to the Geelong-Melbourne rail service. These projects – combined with strong population growth and lots of homebuilding in Geelong and surrounding towns – mean the number of commuters from Geelong to Melbourne will likely increase from the 15,000 commuters in 2016. Hobart-LauncestonAn above-average Hobart/Launceston price ratio, increasing buyer interest and brighter economic prospects all indicate that Launceston may see further price growth over the next one to two years. Price growth in Launceston, Tasmania’s second-largest city, is closely correlated with price growth in Hobart. As Hobart’s prices boomed over the past few years – house prices have increased by more than 40 per cent since early 2015 – Launceston has become relatively cheaper. The Hobart/Launceston price ratio has increased, with a typical house in Hobart now 40 per cent more expensive than a typical Launceston house, up from a 20 per cent difference a few years ago. But Launceston prices have also grown strongly since 2017, resulting in the price ratio stabilising, with the relative affordability of Launceston likely to encourage some investors and migrants to buy in Launceston instead of Hobart. There is also growing buyer interest in Launceston. Views per listing in Launceston increased by about 40 per cent over 2018. Launceston’s economic prospects are also improving. Unemployment recently fell to its lowest level in more than seven years, although it remains elevated at 6.8 per cent. Launceston is the subject of a City Deal partnership between federal, state and local governments to boost the Launceston economy. The annual MONA-FOMA festival has been moved from Hobart to Launceston, so Launceston may benefit from some of the “MONA-effect” that has boosted Hobart’s economy. A weaker Australian dollar should continue to support Tasmania’s economy by boosting tourist numbers to Tasmania, as well as making Tasmania’s exports cheaper for overseas buyers. Unlike other city-pairs considered in this article, few people travel between Launceston and Hobart for work (only 275 people commuted from Launceston to Hobart in 2016). Brisbane-Gold Coast and Brisbane-Sunshine CoastModerate price growth in the Gold Coast and the Sunshine Coast compared to slower price growth in Brisbane over the past two years has made a house in Brisbane relatively cheap compared to the coastal cities. The Brisbane/Gold Coast and Brisbane/Sunshine Coast price ratios have fallen and now sit below the 2010-2018 average, suggesting the coastal cities are slightly overvalued. Because the smaller Queensland cities have a higher median price than Brisbane, the Brisbane/Gold Coast and Brisbane/Sunshine Coast price ratios are below 1, meaning a typical Brisbane house is about 10 per cent cheaper than in the Gold Coast and the Sunshine Coast. South-east Queensland is highly interconnected. More than 30,000 people commuted from the Gold Coast to Brisbane for work in 2016, the biggest city pair in Australia, while 8400 people commuted from the Sunshine Coast to Brisbane. Job prospects have been better in the Gold Coast than in the other cities. The Gold Coast’s unemployment rate has fallen from 5.5 per cent in late 2016 to 4.3 per cent at the end of 2018, whereas the unemployment rate hovered around 6 per cent in Brisbane in 2018 and increased to 6.5 per cent in 2018 in the Sunshine Coast. The price ratios suggest Gold Coast and Sunshine Coast house prices may grow more slowly than Brisbane in 2019. But the Domain views-per-listing measure for the Gold Coast and the Sunshine Coast increased in the second half of 2018, and job prospects look better in the Gold Coast, suggesting there is scope for further price growth for both secondary cities. The outlookSecondary cities are closely tied to the performance of their closest capital. Over the next few years, as jobs continue to concentrate in Australia’s major cities, secondary cities will likely become even more closely linked to their nearest capital city. The outlook for some capital cities is for further falls in 2019 before prices bottom-out later in the year, so the likelihood is secondary cities will see prices stagnate or fall in 2019, although Launceston looks to be an exception.","categories":[],"tags":[{"name":"Property","slug":"Property","permalink":"http://blog.ozairs.com/tags/Property/"}],"keywords":[]},{"title":"10 Most Popular DevOps Interview Questions and Answers","slug":"10-Most-Popular-DevOps-Interview-Questions-and-Answers","date":"2019-02-20T08:28:55.000Z","updated":"2019-02-20T08:31:15.366Z","comments":true,"path":"uncategorized/10-Most-Popular-DevOps-Interview-Questions-and-Answers/","link":"","permalink":"http://blog.ozairs.com/uncategorized/10-Most-Popular-DevOps-Interview-Questions-and-Answers/","excerpt":"","text":"Until recently, development engineers often worked in isolation, restricting their knowledge and skill sets to coding and testing, while operations engineers would focus on delivery and infrastructure configuration jobs, with minimal knowledge about software development. However, with the fast-paced growth of the IT domain and technology advancements, the traditional approach of most IT companies has seen a paradigm shift. The culture of DevOps, although in its infancy, acts as the perfect bridge between IT development and operations and has become a popular methodology for software development in recent years. An article entitled, “The DevOps Hiring Boom” claims that as many as 80 percent of Fortune 1000 organizations are expected to adopt DevOps by 2019. A survey conducted by Indeed.comshows that the average annual salary of a DevOps engineer in the U.S. is approximately $123,439. If you’ve started cross-training to prepare for development and operations roles in the IT industry, you know it’s a challenging field that will take some real preparation to break into. Here are some of the most common DevOps interview questions and answers that can help you while you prepare for DevOps roles in the industry. Want to become certified DevOps Practitioner? Q1. What do you know about DevOps? A1. Your answer must be simple and straightforward. Begin by explaining the growing importance of DevOps in the IT industry. Discuss how such an approach aims to synergize the efforts of the development and operations teams to accelerate the delivery of software products, with a minimal failure rate. Include how DevOps is a value-added practice, where development and operations engineers join hands throughout the product or service lifecycle, right from the design stage to the point of deployment. Q2. Why has DevOps gained prominence over the last few years? A2. Before talking about the growing popularity of DevOps, discuss the current industry scenario. Begin with some examples of how big players such as Netflix and Facebook are investing in DevOps to automate and accelerate application deployment and how this has helped them grow their business. Using Facebook as an example, you would point to Facebook’s continuous deployment and code ownership models and how these have helped it scale up but ensure quality of experience at the same time. Hundreds of lines of code are implemented without affecting the quality, stability, and security. Your next use case should be Netflix. This streaming and on-demand video company, follows similar practices with fully automated processes and systems. Mention the user base of these two organizations: Facebook has 2 billion users while Netflix streams online content to more than 100 millions users worldwide. These are great examples of how DevOps can help organizations to ensure higher success rates for releases, reduce lead time between bug fixes, streamline and continuous delivery through automation, and an overall reduction in manpower costs. Q3. Which are some of the most popular DevOps tools? Do you have experience working with any of these tools? A3. The more popular DevOps tools include: ​ a. Selenium ​ b. Puppet ​ c. Chef ​ d. Git ​ e. Jenkins ​ f. Ansible ​ g. Docker Want to master all these DevOps tools? Thoroughly describe any tools that you are confident about, what it’s abilities are and why you prefer using it. For example, if you have expertise in Git, you would tell the interviewer that Git is a distributed Version Control System (VCS) tool that allows the user to track file changes and revert to specific changes when required. Discuss how Git’s distributed architecture gives it an added edge where developers make changes locally, and can have the entire project history on their local Git repositories, which can be later shared with other team members. Now that you have mentioned VCS, be ready for the next obvious question. Q4. What is version control and why should VCS be used? A4. Define version control and talk about how this system records any changes made to one or more files and saves them in a centralized repository. VCS tools will help you recall previous versions and perform the following: Go through the changes made over a period of time and check what works versus what doesn’t. Revert specific files or specific projects back to an older version. Examine issues or errors that have occurred due to a particular change. Using VCS gives developers the flexibility to simultaneously work on a particular file and all modifications can be logically combined later. Q5. Is there a difference between Agile and DevOps? If yes, please explain. A5. As a DevOps engineer, interview questions like this are quite expected. Start by describing the obvious overlap between DevOps and Agile. Although implementation of DevOps is always in sync with Agile methodologies, there is a clear difference between the two. The principles of Agile are associated to seamless production or development of a piece of software. On the other hand, DevOps deals with development, followed by deployment of the software, ensuring faster turnaround time, minimum errors, and reliability. If you are preparing for senior DevOps roles, prepare for these specific Chef DevOps interview questions. Q6. Why are configuration management processes and tools important? A6. Talk about multiple software builds, releases, revisions, and versions for each software or testware that is being developed. Move on to explain the need for storing and maintaining data, keeping track of development builds and simplified troubleshooting. Don’t forget to mention the key CM tools that can be used to achieve these objectives. Talk about how tools like Puppet, Ansible, and Chef help in automating software deployment and configuration on several servers. Q7. How is Chef used as a CM tool? A7. Chef is considered to be one of the preferred industry-wide CM tools. Facebook migrated its infrastructure and backend IT to the Chef platform, for example. Explain how Chef helps you to avoid delays by automating processes. The scripts are written in Ruby. It can integrate with cloud-based platforms and configure new systems. It provides many libraries for infrastructure development that can later be deployed within a software. Thanks to its centralized management system, one Chef server is enough to be used as the center for deploying various policies. Q8. How would you explain the concept of “infrastructure as code” (IaC)? A8. It is a good idea to talk about IaC as a concept, which is sometimes referred to as a programmable infrastructure, where infrastructure is perceived in the same way as any other code. Describe how the traditional approach to managing infrastructure is taking a back seat and how manual configurations, obsolete tools, and custom scripts are becoming less reliable. Next, accentuate the benefits of IaC and how changes to IT infrastructure can be implemented in a faster, safer and easier manner using IaC. Include the other benefits of IaC like applying regular unit testing and integration testing to infrastructure configurations, and maintaining up-to-date infrastructure documentation. If you have completed a certification on Amazon Web Services (AWS), and are interviewing for niche roles such as AWS-certified DevOps engineer, here are some AWS DevOps interview questions that you must be prepared for: Q9. What is the role of AWS in DevOps? A9. When asked this question in an interview, get straight to the point by explaining that AWS is a cloud-based service provided by Amazon that ensures scalability through unlimited computing power and storage. AWS empowers IT enterprises to develop and deliver sophisticated products and deploy applications on the cloud. Some of its key services include Amazon CloudFront, Amazon SimpleDB, Amazon Relational Database Service, and Amazon Elastic Computer Cloud. Discuss the various cloud platforms and emphasize any big data projects that you have handled in the past using cloud infrastructure. Q10. How is IaC implemented using AWS? A10. Start by talking about the age-old mechanisms of writing commands onto script files and testing them in a separate environment before deployment and how this approach is being replaced by IaC. Similar to the codes written for other services, with the help of AWS, IaC allows developers to write, test, and maintain infrastructure entities in a descriptive manner, using formats such as JSON or YAML. This enables easier development and faster deployment of infrastructure changes. As a DevOps engineer, an in-depth knowledge of processes, tools, and relevant technology are essential. You must also have a holistic understanding of the products, services, and systems in place. If your answers matched the answers we’ve provided above, you’re in great shape for future DevOps interviews. Good luck! If you’re looking for answers to specific DevOps interview questions that aren’t addressed here, ask them in the comments below. Our DevOps experts will help you craft the perfect answer.","categories":[],"tags":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/tags/求职/"}],"keywords":[]},{"title":"比尔盖茨夫妇发布2019年度公开信 分享9大意外","slug":"比尔盖茨夫妇发布2019年度公开信-分享9大意外","date":"2019-02-13T12:47:09.000Z","updated":"2019-02-13T12:49:13.236Z","comments":true,"path":"uncategorized/比尔盖茨夫妇发布2019年度公开信-分享9大意外/","link":"","permalink":"http://blog.ozairs.com/uncategorized/比尔盖茨夫妇发布2019年度公开信-分享9大意外/","excerpt":"","text":"比尔盖茨的微博账号上发布了和《比尔和梅琳达·盖茨：我们的2019年度公开信》内容，他们在信中分享了9件让他们意外的事情，希望能借此鼓舞大众。 [TechWeb]盖茨夫妇首先回顾到，“二十五年前，我们读到的一篇文章中提到，贫困国家每年有数十万儿童死于腹泻。这个出乎我们意料的数字，促使我们确立了盖茨基金会的理念。” 他们表示，“在今年的公开信里，我们希望和大家分享一路走来的另外九大意外。有些让人忧虑，有些给人启迪，但无一不激励我们采取行动。我们希望大家也能获得同样的鼓舞，并付诸行动。只有这样，世界才能变得更好。” 1。 非洲是最年轻的大陆 全球老龄化趋势仍在持续，但非洲的年龄（几乎）没变。非洲人口的年龄中位数只有18岁，北美则是35岁。未来几十年，非洲的年轻人数量将一直保持上升。 盖茨夫妇认为，恰当的投资无疑将释放非洲的巨大潜力。非洲年轻人决定了整个大陆，乃至全世界的未来。 2。家庭基因检测既能帮助发现“连环手”，又能预防早产 3。今后四十年，全世界每个月都将新建一个纽约市 随着城市人口在未来几十年的持续增长，全球建筑体量到2060年预计将会翻倍，相当于从现在开始每月新建一个纽约市。这需要大量钢铁水泥。我们需要想办法在不加剧气候变化的前提下实现这一切。 4。 数据也存在性别歧视 比尔盖茨谈到，“我每天花大量时间研究健康和发展方面的数据。关于妇女和女童的数据如此之少，让我始料未及。我想主要原因在于，我们人为地将某些问题划分为“女性问题”和其它问题，而女性问题通常得不到深入研究。这将妨碍人类整体的进步。” 文章还谈到，“数据会催生更好的决策和政策，帮助我们制定目标、评估进展，也让倡导和问责成为可能。” 5。 跟青少年学习愤怒管理 越来越多的研究表明，如果能对年轻人进行干预，辅导他们控制冲动，也许能帮他们更安全地应对这些情况（言语不合，暴力相向，后果是非死即伤），从而留在学校，远离麻烦。这就是Becoming a Man（成为一个男人，缩写BAM）这样的项目所做的事。 6。全球的也是民族的 本国利益至上并不意味着对其他国家置之不理。事实证明，我们恰恰应该反其道而行之。 7。厕所还是一百年前的老样子 全球迄今还有20多亿人用不上卫生的厕所。他们的粪便未经处理就进入环境，每天导致近800名儿童死亡。引进发达国家的卫生设施行不通，因为配套的下水道系统建设成本过高，而且需要大量的水资源。 8。 课本正在变得过时 9。 在贫困女性手中，手机的作用能发挥到最大 盖茨夫妇还表示，对未来依旧乐观，“其中一个原因是我们深信创新的力量。但更重要的是，我们亲眼看到，对于我们在年信中谈及的每一个挑战，都有很多人在奉献着自己的智慧、资源甚至生命。” 盖茨夫妇最后表示，“我们把今年的年度公开信献给我们亲爱的朋友、微软（106.89， 1.64， 1.56%）联合创始人、去年十月罹患癌症去世的保罗-艾伦……每当Jimi Hendrix的音乐响起，我们都会想起他。”","categories":[],"tags":[{"name":"Bill Gates","slug":"Bill-Gates","permalink":"http://blog.ozairs.com/tags/Bill-Gates/"}],"keywords":[]},{"title":"关于Raid0,Raid1,Raid5,Raid10的总结","slug":"关于Raid0-Raid1-Raid5-Raid10的总结","date":"2019-02-13T11:46:34.000Z","updated":"2019-02-13T11:50:42.714Z","comments":true,"path":"Jobs/关于Raid0-Raid1-Raid5-Raid10的总结/","link":"","permalink":"http://blog.ozairs.com/Jobs/关于Raid0-Raid1-Raid5-Raid10的总结/","excerpt":"","text":"RAID0 定义： RAID 0又称为Stripe或Striping，它代表了所有RAID级别中最高的存储性能。RAID 0提高存储性能的原理是把连续的数据分散到多个磁盘上存取，这样，系统有数据请求就可以被多个磁盘并行的执行，每个磁盘执行属于它自己的那部分数据请求。这种数据上的并行操作可以充分利用总线的带宽，显著提高磁盘整体存取性能。 工作原理： 系统向三个磁盘组成的逻辑硬盘（RAID0 磁盘组）发出的I/O数据请求被转化为3项操作，其中的每一项操作都对应于一块物理硬盘。通过建立RAID 0，原先顺序的数据请求被分散到所有的三块硬盘中同时执行。从理论上讲，三块硬盘的并行操作使同一时间内磁盘读写速度提升了3倍。 但由于总线带宽等多种因素的影响，实际的提升速率肯定会低于理论值，但是，大量数据并行传输与串行传输比较，提速效果显著显然毋庸置疑。 优缺点： 读写性能是所有RAID级别中最高的。 RAID 0的缺点是不提供数据冗余，因此一旦用户数据损坏，损坏的数据将无法得到恢复。RAID0运行时只要其中任一块硬盘出现问题就会导致整个数据的故障。一般不建议企业用户单独使用。 总结： 磁盘空间使用率：100%，故成本最低。 读性能：N*单块磁盘的读性能 写性能：N*单块磁盘的写性能 冗余：无，任何一块磁盘损坏都将导致数据不可用。 RAID1 定义： RAID 1通过磁盘数据镜像实现数据冗余，在成对的独立磁盘上产生互为备份的数据。当原始数据繁忙时，可直接从镜像拷贝中读取数据，因此RAID 1可以提高读取性能。RAID 1是磁盘阵列中单位成本最高的，但提供了很高的数据安全性和可用性。当一个磁盘失效时，系统可以自动切换到镜像磁盘上读写，而不需要重组失效的数据。 工作原理： RAID1是将一个两块硬盘所构成RAID磁盘阵列，其容量仅等于一块硬盘的容量，因为另一块只是当作数据“镜像”。RAID1磁盘阵列显然是最可靠的一种阵列，因为它总是保持一份完整的数据备份。它的性能自然没有RAID0磁盘阵列那样好，但其数据读取确实较单一硬盘来的快，因为数据会从两块硬盘中较快的一块中读出。RAID1磁盘阵列的写入速度通常较慢，因为数据得分别写入两块硬盘中并做比较。RAID1磁盘阵列一般支持“热交换”，就是说阵列中硬盘的移除或替换可以在系统运行时进行，无须中断退出系统。RAID1磁盘阵列是十分安全的，不过也是较贵一种RAID磁盘阵列解决方案，因为两块硬盘仅能提供一块硬盘的容量。RAID1磁盘阵列主要用在数据安全性很高，而且要求能够快速恢复被破坏的数据的场合。 在这里，需要注意的是，读只能在一块磁盘上进行，并不会进行并行读取，性能取决于硬盘中较快的一块。写的话通常比单块磁盘要慢，虽然是并行写，即对两块磁盘的写入是同时进行的，但因为要比较两块硬盘中的数据，所以性能比单块磁盘慢。 优缺点： RAID1通过硬盘数据镜像实现数据的冗余，保护数据安全，在两块盘上产生互为备份的数据，当原始数据繁忙时，可直接从镜像备份中读取数据，因此RAID1可以提供读取性能。RAID1是硬盘中单位成本最高的，但提供了很高的数据安全性和可用性，当一个硬盘失效时，系统可以自动切换到镜像硬盘上读/写，并且不需要重组失效的数据。 总结： 磁盘空间使用率：50%，故成本最高。 读性能：只能在一个磁盘上读取，取决于磁盘中较快的那块盘 写性能：两块磁盘都要写入，虽然是并行写入，但因为要比对，故性能单块磁盘慢。 冗余：只要系统中任何一对镜像盘中有一块磁盘可以使用，甚至可以在一半数量的硬盘出现问题时系统都可以正常运行。 RAID 5 定义： RAID 5是RAID 0和RAID 1的折中方案。RAID 5具有和RAID0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID5的磁盘空间利用率要比RAID 1高，存储成本相对较低，是目前运用较多的一种解决方案。 工作原理： RAID5把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上，其中任意N-1块磁盘上都存储完整的数据，也就是说有相当于一块磁盘容量的空间用于存储奇偶校验信息。因此当RAID5的一个磁盘发生损坏后，不会影响数据的完整性，从而保证了数据安全。当损坏的磁盘被替换后，RAID还会自动利用剩下奇偶校验信息去重建此磁盘上的数据，来保持RAID5的高可靠性。 做raid 5阵列所有磁盘容量必须一样大，当容量不同时，会以最小的容量为准。 最好硬盘转速一样，否则会影响性能，而且可用空间=磁盘数n-1，Raid 5 没有独立的奇偶校验盘，所有校验信息分散放在所有磁盘上， 只占用一个磁盘的容量。 总结： 磁盘空间利用率：(N-1)/N，即只浪费一块磁盘用于奇偶校验。 读性能：(n-1)*单块磁盘的读性能，接近RAID0的读性能。 写性能：比单块磁盘的写性能要差（这点不是很明白，不是可以并行写入么？） 冗余：只允许一块磁盘损坏。 RAID10 定义： RAID10也被称为镜象阵列条带。象RAID0一样，数据跨磁盘抽取；象RAID1一样，每个磁盘都有一个镜象磁盘, 所以RAID 10的另一种会说法是 RAID 0+1。RAID10提供100%的数据冗余，支持更大的卷尺寸，但价格也相对较高。对大多数只要求具有冗余度而不必考虑价格的应用来说，RAID10提供最好的性能。使用RAID10，可以获得更好的可靠性，因为即使两个物理驱动器发生故障（每个阵列中一个），数据仍然可以得到保护。RAID10需要4 + 2*N 个磁盘驱动器（N &gt;=0)， 而且只能使用其中一半(或更小, 如果磁盘大小不一)的磁盘用量, 例如 4 个 250G 的硬盘使用RAID10 阵列， 实际容量是 500G。 实现原理： Raid10其实结构非常简单，首先创建2个独立的Raid1，然后将这两个独立的Raid1组成一个Raid0，当往这个逻辑Raid中写数据时，数据被有序的写入两个Raid1中。磁盘1和磁盘2组成一个Raid1，磁盘3和磁盘4又组成另外一个Raid1;这两个Raid1组成了一个新的Raid0。如写在硬盘1上的数据1、3、5、7，写在硬盘2中则为数据1、3、5、7，硬盘中的数据为0、2、4、6，硬盘4中的数据则为0、2、4、6，因此数据在这四个硬盘上组合成Raid10，且具有raid0和raid1两者的特性。虽然Raid10方案造成了50%的磁盘浪费，但是它提供了200%的速度和单磁盘损坏的数据安全性，并且当同时损坏的磁盘不在同一Raid1中，就能保证数据安全性。假如磁盘中的某一块盘坏了，整个逻辑磁盘仍能正常工作的。当我们需要恢复RAID10中损坏的磁盘时，只需要更换新的硬盘，按照RAID10的工作原理来进行数据恢复，恢复数据过程中系统仍能正常工作。原先的数据会同步恢复到更换的硬盘中。 总结： 磁盘空间利用率：50%。 读性能：N/2*单块硬盘的读性能 写性能：N/2*单块硬盘的写性能 冗余：只要一对镜像盘中有一块磁盘可以使用就没问题。","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Raid Storage","slug":"Raid-Storage","permalink":"http://blog.ozairs.com/tags/Raid-Storage/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"An In-Depth Guide to the Differences Between SAN and NAS","slug":"An-In-Depth-Guide-to-the-Differences-Between-SAN-and-NAS","date":"2019-02-13T11:29:13.000Z","updated":"2019-02-13T11:53:19.228Z","comments":true,"path":"Jobs/An-In-Depth-Guide-to-the-Differences-Between-SAN-and-NAS/","link":"","permalink":"http://blog.ozairs.com/Jobs/An-In-Depth-Guide-to-the-Differences-Between-SAN-and-NAS/","excerpt":"","text":"Storage area networks (SANs) and network attached storage (NAS) both provide networked storage solutions. A NAS is a single storage device that operates on data files, while a SAN is a local network of multiple devices. A NAS unit includes a dedicated hardware device that connects to a local area network, usually through an Ethernet connection. This NAS server authenticates clients and manages file operations in much the same manner as traditional file servers, through well-established network protocols. To reduce the costs that occur with traditional file servers, NAS devices generally run an embedded operating system on simplified hardware and lack peripherals like a monitoror keyboard and are instead managed through a browser tool. A SAN commonly utilizes Fibre Channel interconnects and connects a set of storage devices that are able to share data with one another. Important NAS and SAN BenefitsThe administrator of a home or small business network can connect one NAS device to a local area network. The device itself is a network node, much like computers and other TCP/IP devices, all of which maintain their own IP address and can effectively communicate with other networked devices. Given that the network attached storage device is attached to the network, all the other devices on that same network have easy access to it (given that proper permissions are set up). Because of their centralized nature, NAS devices offer an easy way for multiple users to access the same data, which is important in situations where users are collaborating on projects or utilizing the same company standards. Using a software program provided with the NAS hardware, a network administrator can set up automatic or manual backups and file copies between the NAS and all the other connected devices. Therefore, a NAS device is also useful for the opposite reason: to offload local data to the network storage device’s much larger storage container. This is useful not only to ensure that users do not lose data, since the NAS can be backed up on a regular schedule regardless of the end-user’s ability to back up, but also to give other network devices a place to keep large files, especially large files that are often shared among other network users. Without a NAS, users have to find another (often slower) means to send data to other devices on the network, like over email or physically with flash drives. The NAS holds many gigabytes or terabytes of data, and administrators can add additional storage capacity to their network by installing additional NAS devices, although each NAS operates independently. Administrators of large enterprise networks may require many terabytes of centralized file storage or extremely high-speed file transfer operations. While installing an army of many NAS devices is not a practical option, administrators can instead install a SAN containing a high-performance disk array to provide the needed scalability and performance. However, SANs are not always physical. You can also create virtual SANs (VSANs) that are defined by a software program. Virtual SANs are easier to manage and offer better scalability since they’re hardware independent and controlled entirely by easy-to-change software. SAN/NAS ConvergenceAs internet technologies like TCP/IP and Ethernet proliferate worldwide, some SAN products are making the transition from Fibre Channel to the same IP-based approach NAS uses. Also, with the rapid improvements in disk storage technology, today’s NAS devices now offer capacities and performance that once were only possible with SAN. These two industry factors have led to a partial convergence of NAS and SAN approaches to network storage, effectively creating high-speed, high-capacity, centrally located network devices. When SAN and NAS are joined together into one device in this way, it’s sometimes referred to as “unified SAN,” and it’s often the case that the device is a NAS device that simply utilizes the same technology behind SAN.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Storage","slug":"Storage","permalink":"http://blog.ozairs.com/tags/Storage/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"AWS面试经验分享","slug":"AWS面试经验分享","date":"2019-02-12T10:40:02.000Z","updated":"2019-02-12T10:48:04.314Z","comments":true,"path":"求职/AWS面试经验分享/","link":"","permalink":"http://blog.ozairs.com/求职/AWS面试经验分享/","excerpt":"","text":"AWS的全名是Amazon Web Services，也就是亚马逊旗下的子公司，专门做云计算，业务遍及全球近200个国家，也是云计算行业的领头羊（有兴趣可以看看这个链接）。依照AWS Senior VP Andy Jassy的话来讲是：“We are building the fastest growing technology business on earth.”我于2014年6月拿到此公司offer，在香港和台湾从事对客户或潜伏客户的培训工作，隶属于亚太区的培训与认证部门（APAC Training &amp; Certification）。这篇文章回顾了我面试及头半年的工作，和一些个人的感想。基于公司政策要求，其中不触及面试具体细节、工作具体内容（包括人名），产品介绍及评论。 “云计算”是个有趣的名词，由于现在这个环境下，普通大众想听不到它都难，但多数却完全不知道究竟是甚么。其实狭义且不严格地理解云计算，就是把计算资源像我们生活中水、电、气这类基础设施1样，按需供应计费，提供相对统1的标准或接口给其他厂商（生态圈）或终究客户使用。如果不明白计算资源怎样能像水电1样供应，可以联想1下平时使用的电脑，你在意的其实不是它的CPU内存硬盘网络等计算资源（简单统称方便理解），你在意的是输入的内容能得到你所需要的输出，不论这个输出是字符、图片、视频、音频、游戏画面、其他交互内容等等。那末“云计算”这里说的其实就是将你不在意的那些东西（CPU内存硬盘网络）和你在意的输入输出（比如键盘鼠标、显示器）分离，用户只具有基本的输入输出和网络连接服务，其他的全部放到远端。用户需要就启动使用并付费，不需要就像水电1样关掉。这是其中1个重点：资源分离。分离才方便做其他事情，具体好处这里就不说了。另外还需提及的是，对平时使用的电脑，不论你用还是不用，只要你买回来那末你已为其计算资源付费终了了，这样是否是很划算呢？你1年用1天和用360天，为计算资源付一样的费用，这其实其实不公道。个人使用还行，但企业就很不划算了，这就是按需分配计算资源的必要性，为了公道的利用及分配资源。 这篇文章不是教学文章，所以只是帮助不懂的朋友粗浅了解1下甚么是“云计算”。其实云计算还分好几类，上面提到的只是说基础设施层面的服务。其他层面的举个例子：想一想你手机上的App，它们也是云计算的1部份。由于他们也是你根据你的需求下载得手机上为你提供服务。所以云计算可以认为是Web Service，即通过网络为客户提供服务，这些服务源自于硬件与软件的组合或结合。我的工作就是介绍亚马逊的云计算服务给客户，让他们理解并学会使用亚马逊的云计算产品。我只负责香港和台湾，大陆培训业务与我无关，所以香港台湾的朋友如果要参加AWS的培训，多半会看到我（Michael Chen）。目前我所负责的区域就我1个人在做培训，也是香港台湾地区的第1个培训师。目前培训过的客户大小公司（世界500强到初创企业）都有，具体就不说了。 面试经历 面试 是1个有趣（折腾且漫长）的进程。由于我并没有主动申请这个职位，也不知道有这个职位在招聘，也没有猎头来找我（Amazon不通过猎头觅人）。当时（2013年）我还在联科团体工作，对AWS的职位只是偷偷想过，但种种缘由未有任何行动。直到： 2013年5月28日，AWS的Z在LinkedIn上和我联系，问我是不是有兴趣做“Ecosystem Solutions Architect”（以后简称SA）。我其实不认识Z，但看到这个消息确切很惊讶，1是没想到会有AWS的人通过LinkedIn和我联系，2是觉得自己的资格还不够，有这个机会却极可能抓不住。我坦诚告知Z说，我看了职位介绍，觉得自己不合适，但还是很愿意与他交换，问他是不是还希望继续。Z答应了，我却很忐忑。 2013年6月24日，与Z终究见面，才发现他只说英语（我进AWS后发现他也能说广东话，不过基本不说）。他觉得我还行，然后需要再与其他同事评估，给了简历。我当时我觉得不合适SA，但培训比较合适，但从他和公司的角度，最需要的还是SA，我接受了他的建议。 2013年7月15日，如我所料，内部评估结果觉得我不适合做SA。Z说可以推荐我去做培训这个职位。 2013年8月6日，向Z推荐L做SA，不过Z觉得不适合，问A（AWS亚太区培训认证主管）是不是和我联系，我回复还未联系。这位L后来进了Facebook，题外话就不多说了。 2013年8月22日，与Z分享Gartner IaaS魔力象限报告。Gartner是全球知名的IT咨询机构，它的这个报告系列在IT界有很好的公信力。报告说AWS全球领先，计算资源超过其他14位竞争对手总和的5倍。英文原文是：It is the overwhelming market share leader, with more than five times the cloud IaaS compute capacity in use than the aggregate total of the other 14 providers in this Magic Quadrant.（全文链接：Magic Quadrant for Cloud Infrastructure as a Service） 2013年10月2日，发邮件给Z国庆祝愿。 2013年11月18日，我在联科团体获升职，与Z分享。Z恭喜后又问我是不是还有兴趣加入AWS，他会再次帮我争取拿到培训的面试机会。大约过了34天，HR给我电话，顺利过关。 2013年12月6日，经过若干次与A约面试时间，终究与其电话面试，英语吞吞吐吐地过关，还需要看看粤语及技术方面。 2013年12月17日，技术兼粤语面试，粤语没问题，但好几个技术问题不会，以为应聘就此结束。回到家，内心非常难受。还是写了邮件与Z报告了情况。过了1段时间，得到继续面试的消息，我没想到居然还有机会。其间下班后在家狂看Glassdoor，学习AWS。 2014年1月30日，经过若干次来回讨论面试时间，从1月中旬最后定到了1月30日（除夕）。非常辛苦的1对1面试，1共5个小时不中断，有香港台湾的主管、亚太区培训认证主管、高级培训师、销售等好几个人车轮战，软技能和硬技能（AWS相干技术）、培训表达（英文与粤语）等都有触及，问得非常得仔细。面试犯了1些小错，整体顺利。 2014年2月3日，Bar Raiser（简单理解就是提高面试门坎的人）面试。其中有几个NoSQL的技术问题，都没有回答得很好。其他问题应当回答正确。当时感觉非常挫败，觉得最后1轮失败，很是惋惜。 2014年2月11日，讨论后结果是positive！我被录取了。 2014年2月14日，情人节签约。 2014年6月11日，经过非常麻烦的签证办理手续，终究开始上班。 从2013年5月28日到2014年6月11日，全部进程几近是1整年。从上面的描写中你或许能感遭到我当时经历如此漫长的煎熬与纠结吧，他人都在开心过年的时候，我在纠结 面试 及结果，好在终究成功了。另外，这全部进程中还有1些其他的事情： 2014年5月5日至2014年6月9日，陪老婆生孩子坐月子等各种生育相干事情。 2014年3月23日，推荐M应聘Business Development职位，2014年4月17日，M顺利闯关成功。 工作经历 工作经历用1句话就说完了：6月入职飞新加坡，7月飞曼谷，8月飞台北和西雅图，9月飞悉尼，10月再次飞台北，11月飞拉斯维加斯为AWS re:Invent大会帮忙，12月回武汉办理大陆户口注销事宜，这也是为了以后能更方便地去台湾商务旅行。看着飞很多，其实多半时间都在香港，出差1般是1周左右。具体内容就不说了，有几点值得提1下： 第1次培训是在台北，也是试讲，要被评估，若不合格还要重新再试讲评估。第1次用全英语讲课长达4天，这4天说的英语比我310多年说的都多，而且这几天平均每天睡4个钟头。好在最后1切顺利。但努力空间很大，需要认真学习和练习。在我提交完培训报告后，同事和老板都回邮件，说实话，挺给我信心的：“Great start Michael, the first one I am sure will always be the hardest to get through. But you are learning from the master in D too. Well done and good report.”“AWESOME report full of a lot of great information about our customers, their needs and provides AWS with the information required to help them further from a product/services and adoption perspective all the way back to training.” 以后在香港用英文培训，台北用普通话培训。每次培训完后，客户都要评分，每次写报告看分数都心跳加速，真是压力山东大学。今年我的整体分数在4.44（满分5分）。这个分数不算高，但就我个人而言，我觉得是客观的分数。 记得2014年3月听D在香港用英语对着4百来人做公然演讲培训时，1位AWS同事过来拍拍我肩膀，半开玩笑地说，明年此时就是你来演讲了哦！我想这么快啊！我能行吗？很难想象1年后我就可以面对几百人用英语演讲，我非常怀疑我有这个实力并且能做得如D那样好。结果入职不到半年，10月就在台北演讲，11月就在香港演讲，最后评价都还不错（台北4.5+，香港4.1+，这里不做与同事的横向比较）。回头来想一想，有些时候，你不能不需要1些压力来逼迫你提高，以做到自己都不敢想象的事情。 我1直觉得很难的AWS Solution Architect认证，居然也顺利通过。对那些在企业工作很多年的人来讲，这个认证其实其实不难。但我在企业才工作3年半，之前10年的工作都在两个大学里教书做科研，这其中的难度和跨度，对我是很大的（这里只是对我个人而言，不适用于其他人）。 百姓网的CEO王建硕曾在其博客里说过他“所看到的伟大的公司，或成功的生意人，发现他们有1种惊人的类似的地方，总结出来就是：对贡献有豪情，对回报有信心。”贡献的是为了兴趣，而不是为了回报。如果做事1定是为了某种回报，那末这件事情会很难坚持久长。这个观点丁香园的冯大辉也转载在其微信公众号的文章中：“只有对贡献有豪情，不在意回报的时候，你才能坚持做1件事情，就像伟大的公司有1个贡献的理念，才可以持久地保持豪情，在获得巨大的成功以后，接着日复1日地寻觅更大的贡献。”这类理念与豪情是对回报有信心的来源。 我算不上成功，算不上勤奋，乃至算不上坚持。真正了解我的人知道这是实话，比如我老婆肯定知道上面这句话不是谦虚:) 你看这个博客的更新频率都愈来愈低，说忙是理由也是借口。在信息碎片化的今天，能坚持写博客的人貌似不多，还能坚持定阅浏览博客的人也不多，我周围几个90后同事乃至已很少用Facebook而用Instagram。我说了上面这么多乱78糟的话，是为了让自己重新再检讨1下，继续坚持下去。我已草拟了2015年每天需要完成的事情，包括这个博客和健身。固然整体安排还是以工作为主，不会把写博客放到重要的事情列表上，但保持每周1篇的更新频率是应当的，除非出差或其他不可抗因素没法更新。我欠下的游记都差不多足数了，呵呵。 写博客纯属不写不舒服斯基。想一想博客能带给我甚么回报呢？金钱的回报基本没有，倒是帮很多人拿到了1些学校和公司的offer，解决了1些人在旅游和其他方面的问题。真实的咨询公司我没进去，倒做起了虚拟咨询，有趣。","categories":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/categories/求职/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://blog.ozairs.com/tags/AWS/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"http://blog.ozairs.com/categories/求职/"}]},{"title":"详解澳洲房屋物业费计算方式","slug":"How-to-calculate-the-property-rate-in-Australia","date":"2019-02-07T06:23:32.000Z","updated":"2019-02-07T09:34:08.331Z","comments":true,"path":"uncategorized/How-to-calculate-the-property-rate-in-Australia/","link":"","permalink":"http://blog.ozairs.com/uncategorized/How-to-calculate-the-property-rate-in-Australia/","excerpt":"","text":"每年，墨尔本市政府会计算您房屋的费率，以资助当地社区的建设，维护和服务。 关于房屋的费率的计算方式如下： 将房屋的财产价值乘以市政府为社区项目和服务提供资金所需的“美元汇率” 增加收到的任何废物服务的成本 加征防火税 减去您有资格获得的任何优惠 房屋物业费计算举例 确定您房屋的资本改善价值（CIV）为400,000美元。 确定’美元汇率’为0.00244201。 将400,000乘以0.00244201，基本利率为976.80美元。 增加您收到的任何废物服务和消防税的成本。 减去您有资格获得的任何让步。 如何进行房屋评估市政府每年都会按照维多利亚州政府法律，对当地的房产进行评估。实际操作过程中，会使用合格的估价师根据以下因素评估您的房产： 最近在该地区的销售 它的位置 土地的质量和位置 建筑物的大小，年龄和状况 如果您对不同意房屋估价如果您不同意您的房产估价，可以和当地市政府联系： 市政府评估团队成员可以： 更详细地解释我们如何评估您的财产 听取并理解您的反对意见 建议您可以采取哪些进一步措施 如何计算美元汇率通过以下方式计算出美元汇率： 计算提供所有计划和服务所需的费率收入总额 将此金额除以当地房产总价值 这个数字是通过市政府每年的预算流程和每年的变化来确定的。","categories":[],"tags":[{"name":"Property","slug":"Property","permalink":"http://blog.ozairs.com/tags/Property/"}],"keywords":[]},{"title":"Git从入门到熟练使用","slug":"Git从入门到熟练使用","date":"2019-02-06T06:41:25.000Z","updated":"2019-02-06T09:50:08.384Z","comments":true,"path":"Web开发/Git从入门到熟练使用/","link":"","permalink":"http://blog.ozairs.com/Web开发/Git从入门到熟练使用/","excerpt":"","text":"Git 基础基本原理 客户端并不是只提取最新版本的文件快照，而是把代码仓库完整的镜像下来。这样一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。每一次的克隆操作，实际上都是一次对代码仓库的完整备份。 Git的优势直接记录快照 Git 更像是把数据看作是对小型文件系统的一组快照。 每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。 为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 快照流。 如图，在version2中的 B 即是因为 File B 没有改变，所以直接存储了一个指向 FileB 的链接。只有修改了的文件才会产生一个新的文件，覆盖原来的文件。 几乎所有操作都在本地执行 在 Git 中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。因为你在本地磁盘上就有项目的完整历史，所以大部分操作看起来瞬间完成。 Git保证完整性 Git 中所有数据在存储前都计算校验和，然后以校验和来引用。Git 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。Git 数据库中保存的信息都是以文件内容的哈希值来确定的，而不是文件名。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。 Git一般只添加数据 你执行的 Git 操作，几乎只往 Git 数据库中增加数据。 很难让 Git 执行任何不可逆操作，或者让它以任何方式清除数据。 同别的 VCS 一样，未提交更新时有可能丢失或弄乱修改的内容；但是一旦你提交快照到 Git 中，就难以再丢失数据，特别是如果你定期的推送数据库到其它仓库的话。这个特性使得我们可以尽情的尝试对Git进行操作而不用害怕把它改坏了，只需要回滚即可。 需要注意的重点三种状态 已提交 committed ：数据已经保存在本地 Git 仓库 已修改 modified ： 修改了文件，但是还没保存在仓库中 已暂存 staged ： 对一个已修改的文件的当前版本做了标记 工作目录，暂存区域及Git仓库.png 三个区域 工作目录 Working Directory ：对项目的某个版本独立提取出来的内容，这些从Git仓库的压缩数据库提取出来的文件，放在磁盘上供你使用或修改。 暂存区域 Staging Area ：是一个文件，保存了下次将提交的文件列表，是待提交文件的暂存区域。一般在Git仓库的目录中，有时也被称为索引。 Git仓库：用来保存项目的元数据和对象数据库的地方。是Git中最重要的部分，从其他计算机克隆仓库时拷贝的就是这里的数据 基本的Git工作流程 在工作目录中修改文件 暂存文件，将文件的快照存储在暂存区域 提交更新，找到暂存区域的位置，将快照永久性存储到Git仓库目录 提交状态：如果Git目录中保存着特定版本的文件，就属于已提交状态。 暂存状态：如果做了修改并且已经放入暂存区域，就属于暂存状态。 已修改状态：如果自上次取出后，做了修改但是还没有存在暂存区域，就是已修改状态。 基本的Git操作流程基础设置 首先最基础的是需要配置用户信息 12$ git config --global user.name &quot;lanya&quot;$ git config --global user.email shenglanya@corp.netease.com 关于 config 的种类 1234567Config file location# global 表示配置全局信息，配置之后无论你在该系统上做任何事情，Git都会使用这些信息。 --global use global config file --system use system config file --local use repository config file -f, --file &lt;file&gt; use given config file --blob &lt;blob-id&gt; read config from given blob object 接着需要检查你的配置信息，使用 $ git config --list指令检查全部配置信息,结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051core.excludesfile=~/.gitignorecore.legacyheaders=falsecore.quotepath=falsemergetool.keepbackup=truepush.default=simplecolor.ui=autocolor.interactive=autorepack.usedeltabaseoffset=truealias.s=statusalias.a=!git add . &amp;&amp; git statusalias.au=!git add -u . &amp;&amp; git statusalias.aa=!git add . &amp;&amp; git add -u . &amp;&amp; git statusalias.c=commitalias.cm=commit -malias.ca=commit --amendalias.ac=!git add . &amp;&amp; git commitalias.acm=!git add . &amp;&amp; git commit -malias.l=log --graph --all --pretty=format:&apos;%C(yellow)%h%C(cyan)%d%Creset %s %C(white)- %an, %ar%Creset&apos;alias.ll=log --stat --abbrev-commitalias.lg=log --color --graph --pretty=format:&apos;%C(bold white)%h%Creset -%C(bold green)%d%Creset %s %C(bold green)(%cr)%Creset %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit --date=relativealias.llg=log --color --graph --pretty=format:&apos;%C(bold white)%H %d%Creset%n%s%n%+b%C(bold blue)%an &lt;%ae&gt;%Creset %C(bold green)%cr (%ci)&apos; --abbrev-commitalias.d=diffalias.master=checkout masteralias.spull=svn rebasealias.spush=svn dcommitalias.alias=!git config --list | grep &apos;alias\\.&apos; | sed &apos;s/alias\\.\\([^=]*\\)=\\(.*\\)/\\1\\ =&gt; \\2/&apos; | sortinclude.path=~/.gitcincludeinclude.path=.githubconfiginclude.path=.gitcredentialdiff.exif.textconv=exifcredential.helper=osxkeychaincore.excludesfile=/Users/shenglanya/.gitignore_globaldifftool.sourcetree.cmd=opendiff &quot;$LOCAL&quot; &quot;$REMOTE&quot;difftool.sourcetree.path=mergetool.sourcetree.cmd=/Applications/Sourcetree.app/Contents/Resources/opendiff-w.sh &quot;$LOCAL&quot; &quot;$REMOTE&quot; -ancestor &quot;$BASE&quot; -merge &quot;$MERGED&quot;mergetool.sourcetree.trustexitcode=trueuser.name=shenglanyauser.email=shenglanya@corp.netease.comcommit.template=/Users/shenglanya/.stCommitMsgcore.repositoryformatversion=0core.filemode=truecore.bare=falsecore.logallrefupdates=truecore.ignorecase=truecore.precomposeunicode=trueremote.origin.url=https://git.ms.netease.com/netease-precious-metals-client/ios-client.gitremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*branch.essential.remote=originbranch.essential.merge=refs/heads/essentialbranch.r_4.4.remote=originbranch.r_4.4.merge=refs/heads/r_4.4 使用 $ git config &lt;key&gt;来检查某一项配置信息 12$ git config user.nameshenglanya 查阅帮助手册方法 以下方法均可找到 Git 命令手册 123$ git help &lt;verb&gt;$ git &lt;verb&gt; --help$ man git-&lt;verb&gt; 获取Git仓库方法一：在现有目录中初始化仓库（创建一个新的自己的仓库） git init该命令将创建一个名为 .git的子目录，这个子目录含有你在初始化的Git仓库中所有的必须文件，这些文件是Git仓库的骨干。但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。 如果你是在一个已经存在文件的文件夹（而不是空文件夹）中初始化 Git 仓库来进行版本控制的话，你应该开始跟踪这些文件并提交。 你可通过 git add命令来实现对指定文件的跟踪，然后执行 git commit提交： 123$ git add *.c$ git add LICENSE$ git commit -m &apos;initial project version&apos; 具体操作流程 12345678910111213141516# 首先$ git initInitialized empty Git repository in /Users/shenglanya/Desktop/.git/#然后使用 ls -a 可查看隐藏文件，发现存在名为 .git 的子目录$ ls -a. .DS_Store .localized.. .git pic# 接着进入子目录,发现此目录中包含你初始化仓库中所有的必须文件，这些文件是 Git 仓库的骨干$ cd .git$ lsHEAD config hooks objectsbranches description info refs# 接着需要跟踪项目里的文件，需要注意的是，当创建一个新的项目里的文件时，它默认是未被跟踪的，所以此时我们需要手动的将它添加到版本控制中，也就是被跟踪 方法二：克隆现有仓库（clone别人的） 如果你想获得一份已经存在了的 Git 仓库的拷贝，比如说，你想为某个开源项目贡献自己的一份力，这时就要用到 git clone命令。Git 克隆的是该 Git 仓库服务器上的几乎所有数据，而不是仅仅复制完成你的工作所需要文件。 当你执行 git clone命令的时候，默认配置下远程 Git 仓库中的每一个文件的每一个版本都将被拉取下来。 1$ git clone https://github.com/libgit2/libgit2 Git 支持多种数据传输协议。 上面的例子使用的是 https://协议，不过你也可以使用 git://协议或者使用 SSH 传输协议，比如 user@server:path/to/repo.git。 记录每次更新到仓库 你工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。 检查当前文件状态 要查看哪些文件处于什么状态，可以用 git status命令。 如果在克隆仓库后立即使用此命令，会看到类似这样的输出： 123$ git statusOn branch masternothing to commit, working directory clean 这说明你现在的工作目录相当干净。表示所有已跟踪文件在上次提交后都未被更改过。 此外，上面的信息还表明，当前目录下没有出现任何处于未跟踪状态的新文件，否则 Git 会在这里列出来。 最后，该命令还显示了当前所在分支，并告诉你这个分支同远程服务器上对应的分支没有偏离。 现在，分支名是 “master”,这是默认的分支名。 如果你在当前已经有仓库管理的项目中添加了一个文件，名字叫做 README 。然后使用 git status命令，你会发现会出现： 123456789$ echo &apos;My Project&apos; &gt; README$ git statusOn branch masterUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) READMEnothing added to commit but untracked files present (use &quot;git add&quot; to track) 表示 README 还未被跟踪，表示 Git 之前的提交中没有这些文件。Git也不会自动跟踪它，这使得你不必担心将生成的二进制文件或者其他不想被包含的文件包含进来。若你想跟踪它，则需要明明白白的告诉它你想跟踪这个文件，使用 git add指令。 跟踪新文件 使用 git add可以跟踪新文件。所以可以使用 git add README, 然后再运行 git status会看到 12345678910111213141516171819202122232425262728293031$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/工作目录，暂存区域及Git仓库.pngUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) pic/实习学习笔记.md# 使用 git add 后$ git add pic/实习学习笔记.md$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/实习学习笔记.md new file: pic/工作目录，暂存区域及Git仓库.png 只要在 Changes to be committed这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。 你可能会想起之前我们使用 git init后就运行了 git add (files)命令，开始跟踪当前目录下的文件。 git add命令使用文件或目录的路径作为参数；如果参数是目录的路径，该命令将递归地跟踪该目录下的所有文件。 关于 git add指令还有别的作用： 用于追踪新文件 用于将已跟踪的文件放入暂存区 用于合并时把有冲突的文件标记为已解决 暂存已修改文件 修改已被跟踪的文件。比如说修改了一个名为 实习学习笔记.md 的文件，然后运行 git status 1234567891011121314151617181920212223242526272829303132333435$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/实习学习笔记.md new file: pic/工作目录，暂存区域及Git仓库.png# 说明已跟踪文件内容发生了变化，但是还未放入暂存区。如果想暂存这次更新，需要使用 git add 指令。 git add 指令是一个多功能命令：可以用它来跟踪新文件，或者把已经跟踪的文件放到暂存区中，还能用于合并时把有冲突的文件标记为已解决状态等。Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: pic/实习学习笔记.md # 使用 git add 指令将其添加到暂存区$ git add pic/实习学习笔记.md$ git statusOn branch masterNo commits yetChanges to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: pic/git存储项目虽时间改变的快照.png new file: pic/lifecycle.png new file: pic/实习学习笔记.md new file: pic/工作目录，暂存区域及Git仓库.png 需要注意的是，当已经使用了 git add指令暂存的版本又经过修改之后，需在再重新使用 git add指令将最新的修改放入暂存区，否则此时暂存区里只有上一次修改的内容。 提交文件到仓库 使用 git commit指令可以使得暂存在暂存区的文件被提交到仓库中去。 1234567$ git commit[master (root-commit) 2713657] 第一次的修改提交 4 files changed, 22 insertions(+) create mode 100644 pic/git存储项目虽时间改变的快照.png create mode 100644 pic/lifecycle.png create mode 100644 pic/实习学习笔记.md create mode 100644 pic/工作目录，暂存区域及Git仓库.png 基本的 Git 操作指令git status 命令概述 使用 git status时，实际上可以使用更为方便的指令来达到更为紧凑的格式输出。比如使用 git status -s 123456789101112131415161718$ git status -s# M 靠右的 M 表示修改过的文件并且还未被放入暂存区 M README # MM 靠左的 M 表示该文件被修改后放入了暂存区，靠右的表示修改过的文件并且还未被放入暂存区，所以 Rakefile 文件被修改过后放入了暂存区，但是之后又进行了修改，还未将最后一次修改放入暂存区MM Rakefile# A 表示新添加到暂存区的文件A lib/git.rb# M 靠左的 M 表示该文件被修改后放入了暂存区M lib/simplegit.rb# ?? 表示还未被跟踪?? LICENSE.txt # 所以此时暂存区中的文件有 Rakefile, lib/git.rb, lib/simplegit.rb git diff 命令概述 git diff可以说是 git status的具体版本，git status只能查看修改了哪些文件，而 git diff能够具体到该文件的某一部分。通常有以下两个用法 当前做的更新哪些还没有暂存？ 首先修改 pic/实习学习笔记.md 文件，然后使用 git status 指令 123456789$ git statusOn branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: pic/实习学习笔记.md # 表示该文件修改后还没有暂存 此时使用 git diff可以查看当前未暂存文件更新了哪些部分 12345678$ git diffdiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex 2b4e07b..a50f1a2 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。+* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵 此时就可以查看未暂存文件修改的部分了。 有哪些更新已经暂存起来了准备好了下次提交？ 可以使用 git diff --staged指令查看，首先需要使用 git add指令将刚刚修改的文件加入暂存区 123456789$ git add pic/实习学习笔记.mdshenglanyadeMacBook-Pro:desktop shenglanya$ git diff --stageddiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex 2b4e07b..a50f1a2 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。+* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵 当我们将文件暂存后继续编辑时，使用 git status指令查看如下： 1234567891011121314$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: pic/实习学习笔记.mdChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: pic/实习学习笔记.md# 该文件同时出现在了暂存区和修改部分。 现在运行 git diff查看暂存前后的变化 12345678git diffdiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex a50f1a2..2b4e07b 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵+* 有额外时间的话，需要将之前没读完的书继续读下去。 再使用 git diff --staged查看变化 12345678$ git diff --stageddiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdindex 2b4e07b..a50f1a2 100644--- a/pic/实习学习笔记.md+++ b/pic/实习学习笔记.md@@ -14,7 +14,7 @@-* 有额外时间的话，需要将之前没读完的书继续读下去。+* 有额外时间的话，需要将之前没读完的书继续读下去。呵呵呵 表示这个指令查看的是暂存区中文件的修改。 git commit 命令概述 当使用 git commit命令提交暂存区域的文件时，一定要确认是否还有什么修改过或新建的文件还未放入暂存区，否则一旦提交，这些文件或修改都会只留在本地磁盘，不会加入版本控制中。所以每次提交前都需要执行 git status命令来查看是否都暂存起来了 可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行 1234567$ git commit -m &quot;Story 182: Fix benchmarks for speed&quot;# 表示当前在 master 分支上提交的，本次提交的完整 SHA-1 校验和是 463dc4f[master 463dc4f] Story 182: Fix benchmarks for speed 2 files changed, 2 insertions(+) create mode 100644 README 注意：提交的是放在暂存区的快照，任何还未暂存的仍然保持已修改状态，可以在下次提交时再纳入版本管理。每一次提交都是对项目的一次快照，以后可以回到这个状态或进行比较。 使用 git commit -a可以跳过暂存这一步骤，git 会自动把所有已经跟踪过的文件暂存起来并且提交，即跳过 git add步骤。 git rm 命令概述 要从 Git 中移除某个文件，就必须从已经跟踪的文件清单中删除，然后提交。 删除有两种方式 第一种是简单的从暂存区中删除。但是文件还在被跟踪着。 第二种是直接在未暂存区域中移除文件，表示直接将文件移除版本控制中。不再跟踪。 下面来演示一下，首先对工作区域中的文件删除,使用 rm pic/实习学习笔记.md 123456789101112$ rm pic/实习学习笔记.md$ git statusOn branch masterChanges not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) deleted: pic/实习学习笔记.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)# 此时将文件从暂存区域中删除，但是文件还在被追踪 然后再将文件从跟踪中删除，这里两种指令 $ git rm pic/实习学习笔记.md和 $ git add pic/实习学习笔记.md都能达到同样效果。 1234567$ git add pic/实习学习笔记.md$ git statusOn branch masterChanges to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) deleted: pic/实习学习笔记.md 需要注意的是，如果删除文件之前文件修改过并且已经放入了暂存区域，则必须使用强制删除选项-f才能将其删除。主要是为了防止误删。 当我们想要将文件从 Git 仓库中删除但是却想让他仍在我们的工作区域中时，（即保存在本地磁盘并且不被 Git 跟踪），为了达到这一目的，使用 --cached选项。 1234$ git rm --cached pic/git存储项目虽时间改变的快照.pngrm &apos;pic/git存储项目虽时间改变的快照.png&apos;# 执行完此命令后，pic/git存储项目虽时间改变的快照.png 文件还在本地磁盘上，并没有被删除。 git mv 命令概述 Git 并不显式的跟踪文件移动操作。所以如果 Git 重命名某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 当我们想在 Git 中对文件进行改名可以使用 git mv a b方式来操作 123456$ git mv pic/实习学习笔记.md pic/note.md$ git diff --stageddiff --git a/pic/实习学习笔记.md b/pic/note.mdsimilarity index 100%rename from pic/实习学习笔记.mdrename to pic/note.md git mv等价于 123$ mv pic/实习学习笔记.md pic/note.md$ git rm pic/实习学习笔记.md$ git add pic/note.md 忽略文件 我们有时会有些文件不需要 Git 来进行管理，也不希望他们总是出现在未跟踪列表中，所以此时，我们可以创建一个名为 .gitignore 的文件，并在其中列出要忽略掉文件模式。 123456789101112# 先创建此忽略文件并向其中添加需要忽略的文件$ vi .gitignore# 查看此文件$ cat .gitignore.localized# 表示忽略所有以 .o 或 .a 结尾的文件*.[oa]# 表示忽略所有以波浪符（~）结尾的文件*~ 一些规范如下 所有空行或者以 ＃开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。glob 即是指 shell 简化了的正则表达式。 其中 * 可以匹配 0 ~ n 个字符 ？ 只能匹配一个字符 [0-9]表示匹配所有 0 到 9 的数字 表示匹配任意中间目录 比如 `a//z`可以匹配 a/z, a/b/z, a/b/c/z 等 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 git stash 命令概述 当我们已经在一个分支上修改文件后，如果必须要切换到其他分支展开其他的工作，而当前分支的工作还没有完成，此时我们需要使用 $ git stash或 $ git stash save命令将当前分支上的工作暂存到栈上，这时你的工作目录就干净了，就可以切换到其他分支工作，等工作完成后，再切换回原来的分支，可以使用 $ git stash apply将你刚刚的储藏重新应用。如果想查看你当前一共有多少个储藏，可以使用 $ git stash list来查看。如果你并不想应用最新的分支，而是想应用某一个早些时间的分支，你可以使用 $ git stash apply stash@{1}，其中最后一个括号内的数字为你某一次提交到工作栈上的暂存记录。如果你不指定 apply 的参数，git 将认为你想要应用最近一次的储藏。 当我们返回原本的分支后，使用 $ git stash apply指令恢复了工作栈中暂存的数据，但是如果当你提交这个分支之前，已经在暂存区缓存了一部分工作内容，并且使用 stash 保存了工作状态，此时当你恢复工作栈中的数据后，实际上暂存区中的内容将会被移出暂存区，而被放在了工作目录中修改的部分，你需要手动将它再放回暂存区，否则可以使用 $ git stash apply --index来尝试重新将暂存区的文件恢复到暂存区中。当你把这个修改放入暂存区后，实际上堆栈上还有这个修改的记录，此时你可以使用 $ git stash drop stash@{1}来从栈中移除它，或者直接使用 $ git stash pop来应用储藏栈这样它就会自动从储藏栈上消失了。 $ git stash --keep-index指令的作用在于告诉 Git 不要储藏任何你通过 git add 命令已经暂存的东西，也就是说比如你现在已经修改了一部分工作目录中的内容，并且还有一部分已经被你暂存了下来。此时你暂时不想继续改工作目录中的内容了，可是你也不想将它暂存到暂存区，此时可以使用这个指令将它暂存到工作栈上。 12345678910$ git status -sM index.html M lib/simplegit.rb$ git stash --keep-indexSaved working directory and index state WIP on master: 1b65b17 added the index fileHEAD is now at 1b65b17 added the index file$ git status -sM index.html $ git stash -u可以储藏还未跟踪的文件到工作栈 $ git stash branch如果使用 stash 储藏了一些工作，然后继续在储藏的分支上工作，在重新应用 stash 储藏的文件工作时可能会有问题。 如果应用尝试修改刚刚储藏的修改的文件，也就是两次同时修改了一个文件，你会得到一个合并冲突并不得不解决它。 如果想要一个轻松的方式来再次测试储藏的改动，可以运行 git stash branch创建一个新分支，检出储藏工作时所在的提交，重新在那应用工作，然后在应用成功后扔掉储藏 1234567891011121314$ git stash branch testchangesSwitched to a new branch &quot;testchanges&quot;# On branch testchanges# Changes to be committed:# (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)## modified: index.html## Changed but not updated:# (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)## modified: lib/simplegit.rb#Dropped refs/stash@&#123;0&#125; (f0dfc4d5dc332d1cee34a634182e168c4efc3359) $ git stash -all可以移除工作目录中所有未跟踪的文件并且存储在工作栈上，相应的一个不怎么安全的方法是 $ git clean直接清除了内容，无法追溯回。不过可以使用 git clean命令去除冗余文件或者清理工作目录。 使用git clean -f -d命令来移除工作目录中所有未追踪的文件以及空的子目录。 -f意味着 强制或 “确定移除”。在使用 $ git clean之前，我们可以先使用 $ git clean -d -n来看一下这样做的后果是什么，也就是有什么文件会被移除。 git log 命令概述 在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 此时便需要 git log命令。默认不加其他参数时， git log惠安提交时间列出所有更新。 123456789101112131415161718$ git logcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add piccommit ec50914561593b769a98ff468de6697a6d964cbdAuthor: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:33:36 2018 +0800 xiugaicommit a7372097ab8f063e17beca6fa8f82a15bb11c5e3Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:20:05 2018 +0800 提交 常用选项 -p,用来显示每次提交的内容差异，可以加上 -2 来仅仅显示最近两次提交 12345678910111213141516171819202122$ git log -pcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add picdiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differcommit ec50914561593b769a98ff468de6697a6d964cbdAuthor: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:33:36 2018 +0800 xiugaidiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngdeleted file mode 100644index 1036a42..0000000Binary files a/pic/git存储项目虽时间改变的快照.png and /dev/null differ --stat选项可以看到每次提交的简略统计信息 1234567891011121314151617181920212223$ git log --statcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add pic pic/git存储项目虽时间改变的快照.png | Bin 0 -&gt; 20722 bytes 1 file changed, 0 insertions(+), 0 deletions(-)commit ec50914561593b769a98ff468de6697a6d964cbdAuthor: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:33:36 2018 +0800 xiugai pic/git存储项目虽时间改变的快照.png | Bin 20722 -&gt; 0 bytes pic/实习学习笔记.md | 22 ++++++++++++++++++++++ 2 files changed, 22 insertions(+)commit a7372097ab8f063e17beca6fa8f82a15bb11c5e3Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:20:05 2018 +0800 常用选项 --pretty可以指定使用不同于默认格式的方式展示提交信息。比如 oneline将每个提交放在一行显示，查看到提交数很大时非常有用。另外还有 short`full`等。 12345$ git log --pretty=onelinefb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master) add picec50914561593b769a98ff468de6697a6d964cbd xiugaia7372097ab8f063e17beca6fa8f82a15bb11c5e3 提交2713657f264a3a019580dc3a489d303fade5dc5c 第一次的修改提交 format选项可以定制要显示的记录格式。这样的输出对后期提取分析格外有用。 12345$git log --pretty=format:&quot;%h - %an, %ar : s&quot;fb40f7a - shenglanya, 60 minutes ago : add picec50914 - shenglanya, 61 minutes ago : xiugaia737209 - shenglanya, 74 minutes ago : 提交2713657 - shenglanya, 3 hours ago : 第一次的修改提交 常用选项以及其代表意义 12345678910111213141516选项 说明%H 提交对象（commit）的完整哈希字串%h 提交对象的简短哈希字串%T 树对象（tree）的完整哈希字串%t 树对象的简短哈希字串%P 父对象（parent）的完整哈希字串%p 父对象的简短哈希字串%an 作者（author）的名字%ae 作者的电子邮件地址%ad 作者修订日期（可以用 --date= 选项定制格式）%ar 作者修订日期，按多久以前的方式显示%cn 提交者（committer）的名字%ce 提交者的电子邮件地址%cd 提交日期%cr 提交日期，按多久以前的方式显示%s 提交说明 选项 --graph可以形象的展示分支，合并历史 123456789101112131415161718$ git log --pretty --graph* commit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master)| Author: shenglanya &lt;shenglanya@corp.netease.com&gt;| Date: Wed Mar 7 11:34:54 2018 +0800| | add pic| * commit ec50914561593b769a98ff468de6697a6d964cbd| Author: shenglanya &lt;shenglanya@corp.netease.com&gt;| Date: Wed Mar 7 11:33:36 2018 +0800| | xiugai| * commit a7372097ab8f063e17beca6fa8f82a15bb11c5e3| Author: shenglanya &lt;shenglanya@corp.netease.com&gt;| Date: Wed Mar 7 11:20:05 2018 +0800| | 提交 git log 的常用选项 12345678910选项 说明-p 按补丁格式显示每个更新之间的差异。--stat 显示每次更新的文件修改统计信息。--shortstat 只显示 --stat 中最后的行数修改添加移除统计。--name-only 仅在提交信息后显示已修改的文件清单。--name-status 显示新增、修改、删除的文件清单。--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。--graph 显示 ASCII 图形表示的分支合并历史。--pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。 限制 git log输出的选项 12345678选项 说明-(n) 仅显示最近的 n 条提交--since, --after仅显示指定时间之后的提交。--until, --before仅显示指定时间之前的提交。--author 仅显示指定作者相关的提交。--committer 仅显示指定提交者相关的提交。--grep 仅显示含指定关键字的提交-S 仅显示添加或移除了某个关键字的提交 撤销操作指令 重新提交：有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend选项的提交命令尝试重新提交：$ git commit --amend这个命令将暂存区中的文件提交，如果自从上次提交以来还未做任何修改，则快照保持不变，你修改的只有提交信息。例如你提交后发现忘记了暂存某些需要的修改，可以像下面这样操作： 12345$ git commit -m &apos;initial commit&apos;$ git add forgotten_file$ git commit --amend# 最终只会有一个提交，第二次提交将代替第一次提交的结果 取消暂存的文件：可以使用 git reset HEAD yourfile来进行取消暂存区域内文件的暂存操作。 撤销对文件的修改：如果你不想保存对文件的修改，如何方便的将其还原成上次提交的样子？使用 $ gitcheckout -- pic/实习学习笔记.md撤销之前所做的修改。 Git 远程仓库的使用 查看远程仓库: 使用 git remote命令可以列出你指定的每个远程服务器的简写。如果已经克隆了自己的仓库，那么至少能看到 origin 123$ cd ios-client$ git remoteorigin 可以指定参数 -v 可以查看你的读写权限 123$ git remote -vorigin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (fetch)origin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (push) 添加远程仓库： 运行 git remote add &lt;shortname&gt; &lt;url&gt;添加一个新的远程 Git 仓库 12345678$ git remoteorigin$ git remote add test https://github.com/lanyasheng/NTAlgorithm.git$ git remote -vorigin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (fetch)origin https://git.ms.netease.com/netease-precious-metals-client/ios-client.git (push)test https://github.com/lanyasheng/NTAlgorithm.git (fetch)test https://github.com/lanyasheng/NTAlgorithm.git (push) 现在就可以使用 test 来代替整个 URL ，例如使用 git fetch test来拉取远端 Git 仓库中有但你没有的信息。 12345678$ git fetch testwarning: no common commitsremote: Counting objects: 84, done.remote: Total 84 (delta 0), reused 0 (delta 0), pack-reused 83Unpacking objects: 100% (84/84), done.From https://github.com/lanyasheng/NTAlgorithm * [new branch] develop -&gt; test/develop * [new branch] master -&gt; test/master 现在可以在本地访问 test/master 分支了，实际上对应远端的 master 分支。 从仓库中抓取: git fetch会访问远端仓库，从中拉取所有你没有的信息。执行完后，你会拥有该仓库的所有分支引用可以用来随时合并和查看。当使用了 git clone命令克隆一个远端仓库时，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。git fetch origin会抓取克隆（或上一次抓取）后新推送的所有工作。 必须注意 git fetch命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 当准备好时你必须手动将其合并入你的工作。 从仓库上拉取: git pull可以用来自动的抓取然后合并远程分支到当前分支，前提是你有一个分支设置为跟踪一个远程的分支。所以 git pull == git fetch + git merge。默认情况下， git clone会自动设置本地的 master 分支跟踪远程仓库的 master 分支，运行 git pull通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。 推送到远程分支：git push [remote-name][branch-name]指令可以将你的项目推送到服务器。例如当你想将 master 推到 origin 时，可以使用 $ git push origin master只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送 查看远程仓库: 如果想查看一个远程仓库的更多信息，可以使用 $ git remote show test 123456789101112131415$ git remote show test* remote test Fetch URL: https://github.com/lanyasheng/NTAlgorithm.git Push URL: https://github.com/lanyasheng/NTAlgorithm.git HEAD branch: master Remote branches: develop tracked master tracked Local branches configured for &apos;git pull&apos;: develop merges with remote develop master merges with remote master Local refs configured for &apos;git push&apos;: develop pushes to develop (local out of date) master pushes to master (local out of date) 这个命令列出了当你在特定的分支上执行 git push会自动地推送到哪一个远程分支。 它也同样地列出了哪些远程分支不在你的本地，哪些远程分支已经从服务器上移除了，还有当你执行 git pull时哪些分支会自动合并 远程仓库的移除与命名：运行 git remote rename &lt;shortname&gt; &lt;url&gt;重命名远程仓库 1234$ git remote rename test testNea$ git remoteorigintestNea 移除远程仓库: 123$ git remote rm testNea$ git remoteorigin Git 标签创建标签 轻量标签 — 就像一个不会改变的分支，只是一个特定提交的引用，创建轻量标签只需要提供版本号即可。git tag v1.4-1w 123456789101112$ git tag v1.4-1w$ git showcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master, tag: v1.4-1w, tag: v1.3)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add picdiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differ 附注标签 — 一个存储在 Git 数据库中的一个完整对象，他们可以被校验。其中包含打标签者的名字，电子邮件地址、日期时间，标签信息。并且可以使用 GNU Privacy Guard （GPG）签名与验证。可以使用$ git tag -a v1.3这样就给当前版本打上了 v1.3 标签。也可以使用 $ git tag -a v1.3 -m &#39;my version 1.3&#39;这样就直接标备注了。 git show可以查看标签信息与对应的提交信息 123456789101112$ git tag -a v1.3$ git showcommit fb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master, tag: v1.3)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 11:34:54 2018 +0800 add picdiff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differ 后期打标签 也可以对过去提交打标签。例如提交历史如下 123456$ git log --pretty=onelinefb40f7a259de8ec2f2edbada6f85aa855f4a6585 (HEAD -&gt; master, tag: v1.4-1w, tag: v1.3) add picec50914561593b769a98ff468de6697a6d964cbd xiugaia7372097ab8f063e17beca6fa8f82a15bb11c5e3 提交20c944dba3f056aef30aada88d0a452e8faffcbc hehe2713657f264a3a019580dc3a489d303fade5dc5c 第一次的修改提交 可以使用 $ git tag -a v1.2 2713657表示对该校验和的版本打上标签。 123456789101112131415161718192021222324252627$ git tagv1.2v1.3v1.4-1w$ git show v1.2tag v1.2Tagger: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 15:00:31 2018 +0800对之前的打标签`commit 2713657f264a3a019580dc3a489d303fade5dc5c (tag: v1.2)Author: shenglanya &lt;shenglanya@corp.netease.com&gt;Date: Wed Mar 7 09:41:21 2018 +0800 第一次的修改提交diff --git a/pic/git存储项目虽时间改变的快照.png b/pic/git存储项目虽时间改变的快照.pngnew file mode 100644index 0000000..1036a42Binary files /dev/null and b/pic/git存储项目虽时间改变的快照.png differdiff --git a/pic/lifecycle.png b/pic/lifecycle.pngnew file mode 100644index 0000000..922b02cBinary files /dev/null and b/pic/lifecycle.png differdiff --git a/pic/实习学习笔记.md b/pic/实习学习笔记.mdnew file mode 100644 Git 分支分支简介简介 Git 保存到不是文件的变化或差异，而是一系列不同时刻的文件快照。当提交时，Git 会保存一个提交的对象。该提交对象会包含一个指向暂存内容快照的指针，还会包含作者姓名和邮箱，提交时输入的信息以及指向他的父对象的指针。首次提交产生的提交对象没有父对象，普通提交操作产生的提交对象有一个父对象，而由多个分支合并产生的提交对象有多个父对象。 我们假设现在有一个工作目录，里面包含了三个将要被暂存和提交的文件。 暂存操作会为每一个文件计算校验和然后会把当前版本的文件快照保存到 Git 仓库中，最终将校验和加入到暂存区域等待提交： 创建分支 Git 创建新分支的本质就是创建一个可以移动的新的指针。比如创建一个 testing 分支。$ git branch testing这会在当前所提交的对象上创建一个指针，此时如图： two-branches.png 如何判断 Git 当前在哪一个分支？此时就要依靠 HEAD 指针。该指针指向当前所在的本地分支。如图 此时 HEAD 指针指向 master 指针，也就是实际上 HEAD 指针指向的时当前所在的本地分支。在本例中，我们仍在 master 分支上，因为 git branch命令仅仅是创建了一个新分支，并没有切换到它上面。可以使用以下命令来查看各个分支当前所指的对象 123456$ git log --oneline --decorate5a5f9fe (HEAD -&gt; master) renamefb40f7a (tag: v1.4-1w, tag: v1.3, testing) add picec50914 xiugaia737209 提交2713657 (tag: v1.2) 第一次的修改提交 可以看到，当前 HEAD 和 master 分支均指向 5a5f9fe 开头的对象 分支切换 使用 git checkout命令可以切换分支 1234567$ git checkout testingSwitched to branch &apos;testing&apos;$ git log --oneline --decoratefb40f7a (HEAD -&gt; testing, tag: v1.4-1w, tag: v1.3) add picec50914 xiugaia737209 提交2713657 (tag: v1.2) 第一次的修改提交 可以看到，此时 HEAD 指针指向了 testing 指针，表示当前的本地分支切换为 testing 分支。然后在 testing 分支上进行一些操作 12345678910111213$ git commit -a -m &apos;made a change on tesing&apos;[testing 844332b] made a change on tesing 3 files changed, 1 insertion(+) create mode 100644 pic/head-to-master.png create mode 100644 pic/test.md create mode 100644 pic/two-branches.png$ git log --oneline --decorate844332b (HEAD -&gt; testing) made a change on tesingfb40f7a (tag: v1.4-1w, tag: v1.3) add picec50914 xiugaia737209 提交20c944d hehe2713657 (tag: v1.2) 第一次的修改提交 此时可以发现 HEAD 指针指向 testing 指针指向了新提交的文件。[图片上传失败…(image-dde0a4-1520604809580)] 此时再切换到 master 分支看一下 12345678$ git checkout masterSwitched to branch &apos;master&apos;$ git log --oneline --decorate5a5f9fe (HEAD -&gt; master) renamefb40f7a (tag: v1.4-1w, tag: v1.3) add picec50914 xiugaia737209 提交2713657 (tag: v1.2) 第一次的修改提交 可以发现此时 master 分支还指向刚刚它指向的位置，也就是[图片上传失败…(image-85e5da-1520604809580)] git checkout master一共做了两件事： 使 HEAD 指向 master 分支 将工作目录恢复成 master 分支所指向的快照内容，也就是忽略 testing 分支所做的修改。 若我们此时再对 master 分支上的文件上进行修改，就会产生分叉。因为你刚创建了一个新分支，并且切换过去进行了一些工作，然后后切换回了 master 分支进行了一些额外的工作。上述改动针对的是不同分支，你可以在不同分支之间来回切换并在某一时刻将他们合并。 项目分叉历史 可以使用 git log命令查看分叉历史。运行 git log --oneline --decorate --graph —all，他会输出你的提交历史各个分支的指向以及项目的分支分叉情况。 12345678910$ git log --oneline --decorate --graph --all* b551643 (HEAD -&gt; master) made a change on master* 5a5f9fe rename| * 844332b (testing) made a change on tesing|/ * fb40f7a (tag: v1.4-1w, tag: v1.3) add pic* ec50914 xiugai* a737209 提交* 20c944d hehe* 2713657 (tag: v1.2) 第一次的修改提交 由于 Git 的分支实际上只是包含所指对象的校验和，创建一个新分支仅仅相当于往一个文件中写入 41 个字节。 分支操作分支的新建与合并 具体实例总结在此文章中 分支的新建与合并 需要注意的地方： 首先当你想直接从当前分支创建并切换到新分支时，可以使用 $ git checkout -b yourname来进行操作，这个命令等价于 $ git branch yourname + $ git checkout yourname 当你在新分支上工作时，突然需要切换到之前开始分叉的 master 分支并且需要在 master 分支上开一个新的分支进行工作，则首先需要暂存你在 yourname 分支上还未进行暂存的修改，然后将其提交到仓库。否则可能会跟你即将检出的分支产生冲突。 当你在 master 分支上开了一个新分支并且已经解决完问题后，可以将 master 和 hotfix 进行合并，使用 1$ git checkout master, $ git merge hotfix 进行合并。 - 快进 （Fast forward）：在合并时，如果当前的 master 分支是你要合并分支的直接上游，则 Git 会直接将 master 指针向前推进到 hotfix 上面。然后就可以将 hotfix 进行删除。 使用 `$ git branch -d hotfix` - 合并提交：而如果 master 不是你要合并分支的直接上游，比如此时 master 分支已经指向了原本 hotfix 指向的位置，则将它与 yourname 分支合并起来会比较麻烦。由于此时 master 分支已经更新了，如果我们需要它新的内容可以将 master 合并到 yourname 上，如果不需要可以直接等 yourname 分支任务完成后，将其合并到 master 上面。如果我们想将 yourname 合并到 master 上，首先会记录他们两个指针所指向的最后一个快照，然后记录他们共同的祖先快照，最后将三方合并的结果做一个新的快照并且自动创建一个新的提交指向它。合并后可以删除 yourname 分支。 遇到冲突的分之合并：可以直接使用 git status状态来查看具体是哪个文件产生了冲突，然后直接打开该文件删除乱码部分和不需要的部分。 分支管理(git branch 命令) $ git branch命令不仅可以创建或删除分支，当不加参数时，其作用为可以查看当前分支 123$ git branch* master testing 其中 * 表示当前分支 $ git branch -v可以查看每个分支的最后一次提交 123$ git branch -v* master b551643 made a change on master testing 844332b made a change on tesing $ git branch --merged可以查看哪些分支已经合并到当前分支上，同理 $ git branch --no-merged 1234$ git branch --merged* master$ git branch --no-merged testing $ git branch -d yourname可以用来删除已经合并的分支，如果是未合并的分支则会报错。 分支开发工作流程 长期分支（最常用） 如只在 master 上保留稳定的代码，有可能仅仅是已经发布的代码。还有一些其他的分支如 develop 和 next 平行分支用来进行后续开发，一旦在在这些分支上达到了稳定，再将他们合并到 master 分支上。这样在确保这些已完成的特性分支能够通过所有的测试，并且不会引入 bug 后再将他们合并到 master 上等待下一次发布。 特性分支 特性分支被用来实现单一特性或相关工作，一旦工作完成它就会被删除。这项技术可以使你快速的进行上下文切换。当你做这么多操作时，这些分支要确保存于本地，而不会与服务器进行交互。 远程分支 远程引用是指对远程仓库的引用，包括分支标签等。他们是你不能移动的本地引用，当你做任何网络通信操作时，他们会自动移动。远程跟踪分支像是你上次连接到远程仓库时，那些分支所处状态的书签。他们的命名格式为 (remote)/(branch) 。如果你想要看你最后一次与远程 origin 分支通信时 master 分支的状态，则可以查看 origin / master 分支。你与同事合作解决一个问题并且他们推送了一个 iss53分支，你可能有自己的本地 iss53分支；但是在服务器上的分支会指向 origin/iss53的提交。 当与远端仓库共同工作时，如果你不抓取fetch远端 orgin/master ，则它将会一直指向在你上次 fetch 的那个文件。此时即使你本地的 master 已经指向很远的地方了，远端的 orgin/master 还依旧指向你上次 fetch 的那个位置。直到你下一次 fetch。 需要注意的问题 当我们使用分支合并时，要确定是谁合并到谁：当我们需要使用其他分支的内容时，可以把其他分支合并到我们的分支上。但是当我们在开发时，有时可能是从 master 或 develop 分支上拉取的工作分支，此时如果 master 或 develop 分支有更新并且我们需要用到，可以将 master 或 develop 分支拉取到我们的分支。否则，则应该等开发完毕后，将我们的分支合并到 master 或 develop 分支上。当开发完毕后，首先需要检出 master 分支，然后将工作分支合并到 master 上即可。 $ git checkout master $ git merge workBranch。合并完成后，可以将工作分支删除。$ git branch -d workBranch，需要注意的是，当我们删除的分支还包含未提交的内容，分支删除会失效。强制删除可以使用 -D 当 merge 出现冲突时，我们可以先 $ git status来查看是哪里出现了问题，然后 cd 进入该文件，直接将冲突部分删除即可解决问题。合并完成后再次执行 $ git status来查看问题是否解决。若问题解决，即可提交。 当已经使用了 git add指令暂存的版本又经过修改之后，需在再重新使用 git add指令将最新的修改放入暂存区，否则此时暂存区里只有上一次修改的内容 $ git commit指令仅仅是将暂存区内的文件快照提交到本地仓库中，想要推送到远程仓库则还需要 push 操作，在 push 操作之前我们需要先 $ git fetch操作将远程仓库的需要合并的文件抓取到本地，然后进行合并，合并完成后使用 $ git status指令进行查看，没问题后再推送到远端。这里其实也可以使用 $ git pull来拉取远端分支的快照，但是这容易产生冲突，若产生冲突则可以找到产生冲突的文件，修改冲突部分再重新提交。提交完成后若想删掉远端工作分支，则可以使用 $ git push origin --delete指令。 当我们想删除本地暂存区中的内容，可以使用$ git rm --cache 文件名指令，当我们想删除工作区的某个文件可以使用 $ git rm -f。 当我们想要删除错误提交到本地仓库的 commit $ git reset --soft 版本库ID仅仅撤销已经提交的版本库，不会修改暂存区和工作区 $ git reset --mixed 版本库ID仅仅撤销提交到版本库和暂存区的内容，不会修改工作区的内容 $ git reset --hard 版本库ID将工作区，暂存区，和版本库记录恢复到指定版本。 $ git stash branch如果使用 stash 储藏了一些工作，然后继续在储藏的分支上工作，在重新应用 stash 储藏的文件工作时可能会有问题。 如果应用尝试修改刚刚储藏的修改的文件，也就是两次同时修改了一个文件，你会得到一个合并冲突并不得不解决它。 如果想要一个轻松的方式来再次测试储藏的改动，可以运行 git stash branch创建一个新分支，检出储藏工作时所在的提交，重新在那应用工作，然后在应用成功后自动扔掉储藏。 可以使用 $ git stash -all来清除工作目录中所有冗余的未被跟踪的文件，并且他们会被存储在工作栈上，当你想要恢复时也可以使用 $ git stash apply恢复使用。 当在本地新创建一个分支时，需要先 push 到远端仓库，远端仓库才会有这个分支，否则会报错 123456789101112131415161718192021222324252627282930error: the requested upstream branch &apos;origin/f_tradeReverse&apos; does not existhint:hint: If you are planning on basing your work on an upstreamhint: branch that already exists at the remote, you may need tohint: run &quot;git fetch&quot; to retrieve it.hint:hint: If you are planning to push out a new local branch thathint: will track its remote counterpart, you may want to usehint: &quot;git push -u&quot; to set the upstream config as you push.$ git fetch$ git statusOn branch f_tradeReversenothing to commit, working tree clean$ git pushfatal: The current branch f_tradeReverse has no upstream branch.To push the current branch and set the remote as upstream, use git push --set-upstream origin f_tradeReverse$ git push --set-upstream origin f_tradeReverseUsername for &apos;https://git.ms.netease.com&apos;: shenglanyaPassword for &apos;https://shenglanya@git.ms.netease.com&apos;:Total 0 (delta 0), reused 0 (delta 0)remote:remote: Create merge request for f_tradeReverse:remote: https://git.ms.netease.com/preciousmetals/LDPMTrade/merge_requests/new?merge_request%5Bsource_branch%5D=f_tradeReverseremote:To https://git.ms.netease.com/preciousmetals/LDPMTrade.git * [new branch] f_tradeReverse -&gt; f_tradeReverseBranch &apos;f_tradeReverse&apos; set up to track remote branch &apos;f_tradeReverse&apos; from &apos;origin&apos;. git 拉取远程分支并且创建本地分支 $ git checkout -b 本地分支名x origin/远程分支名x 如果写错名字，重命名远程为dev1。思路：删除远程分支、重命名本地分支、重新提交一个远程分支 1、git push –delete origin dev——删除远程分支 2、git branch -m dev dev1——重命名本地分支为dev1 3、git push origin dev1——重新推送远端仓库分支名称为dev1 如何删除本地的文件的修改？ 如果是删除已经暂存的文件，则直接使用 $ git reset HEAD 文件名 如果是要删除未暂存的文件，使用 $ git checkout --文件名这样会使得这个文件去掉所有还未暂存的修改 如果删除未跟踪的文件，使用 $ git clean -df 删除不想要的修改 $ git stash &amp;&amp; $ git stash clear 删除本地分支 $ git branch -D BranchName 删除远端分支 删除本地的远端分支 $ git branch -r -D origin/BranchName 删除远端服务器的分支 $ git push origin -d BranchName 打 tag 在本地打 tag ：$ git tag 4.20.1 将 tag 推送到远端 ： $ git push origin :4.20.1 查看远端分支 $ git branch -r 从远端拉取分支 $ git checkout -b x origin/x 总结 本次 Git 基础学习总结到现在就告一段落，文章由于时间，精力和自己本身能力原因并未能够完整的写完，留到日后的学习工作中当有时间和精力，以及对 Git 的使用更加了解后，将继续完善。","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://blog.ozairs.com/tags/Git/"}],"keywords":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}]},{"title":"How to network like a pro at social events","slug":"How-to-network-like-a-pro-at-social-events","date":"2019-02-05T02:45:31.000Z","updated":"2019-02-05T05:47:46.560Z","comments":true,"path":"Jobs/How-to-network-like-a-pro-at-social-events/","link":"","permalink":"http://blog.ozairs.com/Jobs/How-to-network-like-a-pro-at-social-events/","excerpt":"","text":"With the Christmas party season just around the corner, now is the time to brush up on your networking skills. Your friends and family can help you network and help in your job search, but you never know who you might meet at a BBQ, Christmas drinks, or extended family get-together. You don’t want to miss out on the perfect opportunity to land your next job. Here’s our top tips on how to network like a pro at social events. Accept invitationsThis might sound obvious, but if you don’t get out there, you won’t meet people. Networking can be a numbers game. The more people you meet, the more chances you have of meeting someone who can help you find a new job. So say yes, yes, yes to those invitations! Introduce yourselfEveryone has contacts – don’t forget to introduce yourself to everyone you meet. To feel more confident, it helps to have an introduction and some ice-breaker questions ready to go. It doesn’t have to be a formal party for you to use these, any gathering where there are a group of people is the prime opportunity to connect. You could be at a game of backyard cricket, watching your kids play sport, or just enjoying a BBQ with mates. While it’s great to introduce yourself to everyone you meet, this doesn’t mean hassling everyone at a party to give you a job. Networking is about building relationships – these may or may not lead a job offer but they can have many other benefits. Be conversational and genuinely interested in what other people have to say. Avoid constantly talking about yourself and don’t just talk about how badly you need a job. Dress to impressIf you are looking to professionally network at Christmas parties, it is important to dress well. You want people to remember you for the right reasons. If you dress well, ask questions, listen well and speak confidently to people you meet, you will leave a good impression. If you’re chatting to someone and the conversation veers towards your career, make sure you have your elevator pitch ready to go. Remember, if you are using social events to network to find a job, you need to act professionally at all times. Don’t go heavy on the alcohol and act like you would at a formal networking event. Take notes about the people you meetTake notes of people who you think could be a good contact or who offer you help. Get their LinkedIn contact details, business card or email address. Jot down something about your conversation as it will help jog your memory later. Follow upMake sure you follow up with anyone you connect with. Integrity is a key attribute people look for when networking or hiring. If you say you’re going to contact someone, do it. Otherwise, you’ll undo all the hard work you did when you first met the person. Follow up with an email, LinkedIn message or phone call. Stay positiveIf you’ve been looking for work for awhile, it can be hard to remain positive. Being social might be the last thing you feel like doing, but going to different events can be a surprising way to meet people and build professional networks. Networking can also be a fun way to boost your job search, and beats sitting in front of the computer all day.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Australia","slug":"Australia","permalink":"http://blog.ozairs.com/tags/Australia/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"Top 10 job interview questions and how to answer them","slug":"Top-10-job-interview-questions-and-how-to-answer-them","date":"2019-02-05T02:27:07.000Z","updated":"2019-02-05T06:37:13.726Z","comments":true,"path":"Jobs/Top-10-job-interview-questions-and-how-to-answer-them/","link":"","permalink":"http://blog.ozairs.com/Jobs/Top-10-job-interview-questions-and-how-to-answer-them/","excerpt":"","text":"Top 10 job interview questions and how to answer themIf you’ve got an interview coming up there’s a good chance you’ll be asked at least one of these top 10 job interview questions. Don’t get nervous, we’ve got you covered. How to answer the top 10 job interview questionsThe key to a successful job interview to think about what an employer might ask you, and prepare some answers. Here’s some good and bad examples of how to answer the top 10 job interview questions. 1. Tell me about yourselfEmployers ask this to see how you’ll fit in. They already have a copy of your resume, so you don’t need to go over everything on it. Give a quick summary of your key qualities, skills, experience and goals. Some people call this an elevator pitch. Good: “I am passionate about giving customers excellent services and experiences. My background is in hotels and restaurants, where I learnt the power of hard work and enthusiasm. I want to shift my focus and take on opportunities in tourism management.” Bad: Don’t tell your interviewer what you did on the weekend or your favourite TV show (unless it’s actually relevant to the job). 2. What are your strengths?This is a great opportunity to sell yourself, but you need to give examples. Good: “I’m a great project manager. In my last job as a chef my role expanded to ordering food for the kitchen. As a result, the kitchen no longer ran out of food before the end of a shift and customer numbers increased by 30 per cent.” Bad: Don’t give an answer that you can’t back up. Anyone can say they’re hard working. You need to explain how and why. 3. What are your weaknesses?Don’t be afraid of this question. The ability to identify a weakness is actually a strength! But, you need to say what you have done or plan to do to fix any weakness. Good: “I don’t have experience using spreadsheets in the workplace. But I asked a friend to show me the basics, and I am doing a course online to learn more.” Bad: Don’t say you don’t have any weaknesses. It will make you sound like you lack self-awareness. “I work too hard” won’t cut it either. Bonus tip: Don’t list a weakness that is a key part of the job you’re interviewing for. Don’t say you can’t spell if you’re trying to get a job as a writer. Don’t say you are bad at talking to people if you’re trying to get a sales job. 4. Why do you want to work here?An employer wants to know if you’re really interested in the job or if you just want a paycheck. Do some research on the company. Talk about the products or services they sell and why you like them. Good: “I know you recently won an award for your new recyclable coffee cups. I’m passionate about the environment and I want to work for a company that reflects my values.” Bad: Don’t say that you just want a job. 5. Why should we hire you?Employers want to know why you’re a perfect fit for the job. Tell them how hiring you will help solve their problems. If you’ve done your research you can work out what these problems are. Good: You found out the company has opened five new stores in your city, and is hiring a lot of new staff. Tell them you were responsible for training new staff in your last job and have skills in this area. Bad: Don’t just say you’d be an asset to the team. Explain why. 5. What has been your biggest achievement at work?Talk about an achievement you’re proud of that relates to the job. Use examples from study or your personal life if you don’t have a work one. Good: If the job ad you responded to said you need to be a hard worker; you might say: “At my old job at a fast food restaurant I got an award for serving the most customers in a month.” Bad: Don’t say that you don’t have any achievements! 6. What has been your biggest obstacle or problem at work and how have you overcome it?Use an example that relates to the job you’re going for. Good: A customer at the record store you worked at was not happy the store had sold out of a new album and was threatening to buy it online. You solved it by asking the manager to order extra copies, and suggested that in future the manager could order extra stock of the store’s top five releases. Bad: Don’t say that you’ve never had an obstacle. Everybody has. 7. Where do you see yourself in five years?Employers want to know how the job lines up with your ambitions and values, and whether you’re likely to stick around or leave after a few months. If you’re not sure what the future holds, that’s OK – you can say the position will help you decide. Good: For a sales position, you could say, “Within two years I would like to be seen as an expert in customer management and have increased my average monthly sales by 50 per cent.” Bad: Don’t say that you don’t know. And don’t go in the other direction and something unrealistic like you want to be company CEO. 8. Why do you want to leave your current job / Why did you leave your last job?Regardless of the actual reason you left, NEVER badmouth your last employer. Think of a way to be diplomatic about why you left. Good: “My company was cutting back and my position changed in a way that didn’t match my goals” or “I’m looking for a new challenge and to grow my career”. Bad: “The hours were terrible, they didn’t pay me enough, I hated it.” 9. What are your salary expectations?Most jobs will specify a salary range in the advertisement. If you’re feeling bold, aim for the top! But note that it’s generally not a good idea to discuss salary at the first interview, unless the employer raises it first. Good: “Your ad said the salary range for this job was between $45,000 and $55,000. Based on my experience and qualifications I expect a salary at the top end of your range.” An employer might want a specific answer. Do your research and find out what other people get paid to do the job. Bad: Don’t ask for a salary that’s too high (you might price yourself out of the job) or too low (you need to be able to buy groceries every week!) 10. Do you have any questions?This is a great opportunity to impress an employer. An interview is a two-way street and a good chance to see if you like the organisation, too. Think of a few questions beforehand, and try to come up with a question based on something said during the interview also. Good: You’re being interviewed for a job at a bike hire shop. When you checked out the store’s website you noticed the page to hire bikes was broken. Ask if this is being repaired or improved. Bad: Don’t say that you don’t have any questions. You won’t seem interested in the job.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Australia","slug":"Australia","permalink":"http://blog.ozairs.com/tags/Australia/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"Tips to help you get a job","slug":"Tips-to-help-you-get-a-job","date":"2019-02-05T02:02:59.000Z","updated":"2019-02-05T05:08:13.456Z","comments":true,"path":"Jobs/Tips-to-help-you-get-a-job/","link":"","permalink":"http://blog.ozairs.com/Jobs/Tips-to-help-you-get-a-job/","excerpt":"","text":"It’s New Year’s Day 2019, it’s 38 degrees and I am lying in the river with some of my best friends talking about what lies ahead for 2019. Janet, who’s a bit of a procrastinator, says “This is the year of 100 for me. I am going to swim 100 kilometres this year. I am going to clean all the clutter from my apartment in the first 100 days. I’m going to save an extra $100 a month.” Janet took things she thought were insurmountable and broke them into simple goals. She didn’t make general New Year resolutions like getting fit, losing weight, cleaning up her house. Janet made her goals clear. She broke them down into things she could do and show she had done. It got us all talking about goals and how to achieve them. Just like The White Stripes song Little Acorns, it’s important to break down your goals into bite-size chunks. Like a squirrel putting away acorns for the winter, you do it one acorn at a time. How to get a job in 2019?The first thing to do is break down your job search into bite-size chunks and set goals to achieve them. Here’s some job search tips to get you going. 1. Freshen up your resumeStart the year with a fresh resume. Make sure it’s up to date and includes any voluntary work you’ve been doing over the break. Don’t forget any holiday casual work. It’s also time to rewrite your About Me section. There’s some great tips on jobactive.gov.au if you need some examples. Why not create a range of different resumes for different jobs? Create 5 resumes in 5 days. 2. Make a list of businesses to cold callOne-in-three jobs aren’t advertised at all. The best way to get your foot in the door is to cold call places you’d like to work in your suburb or town. Take a walk this week and spot the places you’d like to work. Make a list of 10 places and contact them all in 10 days. You could have a job before the end of January! There’s some great tips on youtube.com/jobactivejobsto build your confidence to cold call places. 3. Pick a job that’s ripe for youIt’s peak fruit picking season, that means lots of fruit and vegetable picking jobs right across Australia. You could have a job in less than 5 days with harvest work. If you have never considered it, you could have regular work right now. Remember, picking fruit is a great stepping stone to a great job. It shows other employers you’re reliable and a hard worker. Just hit the Search button on this page to see all the fruit and vegie jobs – or read more about it. You could apply for a harvest job today and be picking next week! 4. Find out where the most jobs areSome industries are booming. Australia is going through an infrastructure boom. New schools are going up. New roads being built. There’s a new railway line being built inland. The health industry is also going crazy with enormous demand for carers. One of the best ways to get a job is to apply for jobs in industries that are going gangbusters. The Labour Market Information Portal may sound boring but it will tell you where the best places are to get a job. Take a look at the Industry Employment Projections Report and pick 5 industries to focus your job search on.","categories":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}],"tags":[{"name":"Australia","slug":"Australia","permalink":"http://blog.ozairs.com/tags/Australia/"}],"keywords":[{"name":"Jobs","slug":"Jobs","permalink":"http://blog.ozairs.com/categories/Jobs/"}]},{"title":"HEXO主题配置","slug":"HEXO主题配置","date":"2019-02-03T02:54:06.000Z","updated":"2019-02-03T06:22:56.520Z","comments":true,"path":"Web开发/HEXO主题配置/","link":"","permalink":"http://blog.ozairs.com/Web开发/HEXO主题配置/","excerpt":"","text":"您可以在 _config.yml 中修改大部分的配置。 网站 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 author 您的名字 language 网站使用的语言 timezone 网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。 其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。 网址 参数 描述 默认值 url 网址 root 网站根目录 permalink 文章的 永久链接 格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 网站存放在子目录 如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url设为 http://yoursite.com/blog 并把 root 设为 /blog/。 目录 参数 描述 默认值 source_dir 资源文件夹，这个文件夹用来存放内容。 source public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public tag_dir 标签文件夹 tags archive_dir 归档文件夹 archives category_dir 分类文件夹 categories code_dir Include code 文件夹 downloads/code i18n_dir 国际化（i18n）文件夹 :lang skip_render 跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。 提示 如果您刚刚开始接触Hexo，通常没有必要修改这一部分的值。 文章 参数 描述 默认值 new_post_name 新文章的文件名称 :title.md default_layout 预设布局 post auto_spacing 在中文和英文之间加入空格 false titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置 相对地址 默认情况下，Hexo生成的超链接都是绝对地址。例如，如果您的网站域名为example.com,您有一篇文章名为hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。 分类 &amp; 标签 参数 描述 默认值 default_category 默认分类 uncategorized category_map 分类别名 tag_map 标签别名 日期 / 时间格式Hexo 使用 Moment.js 来解析和显示时间。 参数 描述 默认值 date_format 日期格式 YYYY-MM-DD time_format 时间格式 H:mm:ss 分页 参数 描述 默认值 per_page 每页显示的文章量 (0 = 关闭分页功能) 10 pagination_dir 分页目录 page 扩展 参数 描述 theme 当前主题名称。值为false时禁用主题 deploy 部署部分的设置","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://blog.ozairs.com/tags/Hexo/"}],"keywords":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}]},{"title":"MacOS安装使用Node.js","slug":"MacOS安装使用Node-js","date":"2019-02-02T10:43:45.000Z","updated":"2019-02-02T13:46:32.849Z","comments":true,"path":"Web开发/MacOS安装使用Node-js/","link":"","permalink":"http://blog.ozairs.com/Web开发/MacOS安装使用Node-js/","excerpt":"","text":"\\1. 到官网https://nodejs.org/zh-cn/download/下载，选择Macintosh Installer, 如下： \\2. 按预设的下一步，Node.js版本为v6.10.0, NPM版本为v3.10.10 \\3. 过程可能要输入用户密码 \\4. 安装成功如下： \\5. 用终端验证是否成功安装, 输入 node -v \\6. console.log(1+2), 得到结果3 \\7. 我Mac的Eclipse不支援EcmaScript 6, 例如 let 等ES6的关键子在Eclipse都验证不过去。 大概Google下了，找到一个JavaScript支援很不错的IDE，网址如下： https://www.jetbrains.com/webstorm/ 下载完，create一个工程，然后新增一个JavaScript文件： \\8. 将hello_weekend配置为Node.js来debug \\9. Node interpreter设置为Node.js的安装路径 \\10. Script如下： 123456789101112/** * Created by prolink on 17/3/19. */var http = require(&apos;http&apos;);var server = http.createServer(function (req, res) &#123; res.writeHead(200); res.end(&apos;Hello World&apos;);&#125;);server.listen(8088); \\11. 这个http返回Hello World，并在该行鼠标左键点击设置断点 \\12. debug该文件 \\13. 成功启动之后看到Console有相关的资讯 \\14. Chrome浏览器输入 http://localhost:8088/， 可以看到已经命中断点 ，在Console中可以改变变量的值，例如在这里不返回Hello World了，改成返回Hello Weekend，如下图，输入完之后按回车，可以看到true \\15. 看看浏览器得到的就是刚才debug时候重设的值 \\16. 如果仅仅做到这步，WebStorm还不支援ECMAScript 6，打开 Preferences -&gt; Languages &amp; Franeworks -&gt; JavaScript, 如下图将预设的ECMAScript 5.1改为ECMAScript 6 \\17. ES6毕竟是2015年才发布的，形容性并不好，为了让您编写的ES6的程式码可以有更好的相容性，可以用Babel file watcher来监视并自动转码ES5. 12prolinkdeMacBook-Pro:milo_demo prolink$ sudo npm install -g babel-cliprolinkdeMacBook-Pro:milo_demo prolink$ cd /Users/prolink/WebstormProjects/milo_demo 按上一步进入工程目录之后，安装babel-preset-env, 参考 https://babeljs.io/docs/plugins/preset-env/ 1sudo npm install babel-preset-env --save-dev \\18. 打开 Preferences -&gt; Tools -&gt; File Watchers, 添加Bable, 如下： 如果安装一切顺利，当您编辑JS文件时候，会自动在工程目录中同步编译到dist目录中。","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}],"tags":[{"name":"Node.js","slug":"Node-js","permalink":"http://blog.ozairs.com/tags/Node-js/"}],"keywords":[{"name":"Web开发","slug":"Web开发","permalink":"http://blog.ozairs.com/categories/Web开发/"}]},{"title":"澳洲高考制度简介(HSC/VCE/ATAR/UAC/VTAC)","slug":"澳洲高考制度简介-HSC-VCE-ATAR-UAC-VTAC","date":"2019-02-02T07:29:32.000Z","updated":"2019-02-02T10:36:06.811Z","comments":true,"path":"求学/澳洲高考制度简介-HSC-VCE-ATAR-UAC-VTAC/","link":"","permalink":"http://blog.ozairs.com/求学/澳洲高考制度简介-HSC-VCE-ATAR-UAC-VTAC/","excerpt":"","text":"在澳洲, 国际学生和本地学生一样，在完成各州规定的高中课程后，在12年级(高三），所有的学生都必须参加州政府组织的毕业考试，通过考试的学生便获得各州颁发的高中毕业证书。 澳洲高考是在每年的10月份。 澳洲高中对学生学业的评分标准非常灵活，平时成绩占很大比例，中学生必须认真对待平时的每一次考试和作业。这样的学业考评标准不仅让学生打下扎实的基础，同时也避免了一次考试定终身的不合理现象。 各州高中毕业考试名称 新南威尔士州(NSW)：高中毕业证书(HSC)（Higher School Certificate） 澳大利亚首都地区(ACT)：ACT12年级证书（ACT Year 12 Certificate) 维多利亚州(VIC)： 维多利亚州高中毕业证书(VCE)（Victorian Certificate of Education) 北部地区(NT)： 北部地区教育证书(NTCE)（Northern territory Certificate of Education) 昆士兰州(QLD)： 高中毕业证书（Senior Certificate) 南澳大利亚州(SA)： 南澳大利亚州高中毕业证书(SACE)（South Australian Certificate of Education) 塔斯马尼亚州(TAS)： 塔斯马尼亚州高中毕业证书(TCE)（Tasmanian Certificate of Education) 西澳大利亚州(WA)： 西澳大利亚州高中毕业证书（WA Certificate of Education） 虽然称呼不同，但是性质都相当于中国的高考。 各州高中考试&amp;平时成绩比例划分和中国不同的是，高考成绩并不是决定高中毕业生升学的唯一标准，通常，这一成绩只占总成绩的一部分，另一部分成绩来自于学生的平时成绩，主要是11年级和12年级的成绩。 各州高考评分比例 地区 / 平时成绩 / 州会考 新州 / 50% / 50% 维州 / 30% / 70% 南澳州 / 50% / 50% 昆士兰州 / 100% / 0% 首都地区 / 100% / 0% 塔斯马尼亚州 / 100% / 0% 以维多利亚州高中毕业的VCE考试为例 VCE是澳大利亚维多利亚州的高中毕业考试，全称Victoria Certificate of Education。这是颁发给顺利完成维多利亚州大学预科课程(高中)学生的毕业证书。维多利亚州高考课程评估当局(VCAA)对学生考试成绩进行审核和评估，合格者颁发VCE 证书。 VCE课程在十一年级和十二年级开设，相当于中国的高二和高三年级，但可以用三年完成，也可以提前一年申请学习，它的课程设置既有我们熟知的数学(根据难易程度分设多种数学课程)、历史、劳技、外语、生物、地理、物理、政治、体育、信息技术等课程，更多的是国内高中未开设的如经济、会计、设计技术、食物科技、心理、环境科学、文学、戏剧、健康和人类发展等更多的适合学生多种兴趣发展的课程，为完成VCE课程，学生必须通过四单元的英语(共有4种选择，English ESL, English, English Languague, English Literature，从简单到难，可以同时选择English和English Literature) 和另外任意5门学科。除英语外VCE并没有任何必修科目。 课程概况 VCE目前共有129门学科供学生选择，但是大多数学校开设的课程为40~60门左右。如果没有足够的学生选择一门课程学校出于经济和课表安排考虑是不会提供该门学科。VCE学科从英语、数学、科学、人文、体育、外语都包括，学生可以选择多达40门的外语。英语如前文所讲提供4种选择。英语第二语言English ESL是为照顾移民和海外留学生提供, 需要资格鉴定(Qualification of Second Languague Status, 条件是在英语国家里学习时间不能超过5年, 一般学校会帮助留学生完成)。英语(English或English Mainstream)是最多人学习的, 有75%的学生选择. English Languague稍难, English Literature是最难的英语课程。如果学生有兴趣的话可以选择English ESL/English加English Literature. 数学也提供3种选择, 最基本的General Mathematics B - Furthur Mathematics主要是基本的实用性数学; 稍难的主要讲述微积分的4单元Mathematics Methods是大学商科, 科学和工程学入学必修; 最难的高级微积分的GeneralMathematics A - Specialist Mathematics是大学精算学, 工程学入学必修课, 学习SpecialistMathematics的同时必须学习Mathematics Methods. 学生可以选择2门数学, 这也是中国留学生通常的选择。 VCE评分 VCE评分由维多利亚州高考课程评估当局VCAA管理. 学生只要学习完成英语和任意4门VCE课程并且拿到满意(Satisfactory)就可以拿到VCE证书. 如果学生希望接受大学教育则需要更加繁琐的评分。 VCE评分系统 VCE是一个使用标准分的系统，每门科目学习分数(Study Score)满分是50分，平均分是30。50%的学生会拿到30以上的分数，最好的8%拿到40分以上，最好的2%拿到45分以上(6%拿到40-45分)。 为了照顾各个学科有难易程度，学习人数和有效范围，VCE有一个加减分系统(Scaling)，目的是确保25的英语难易度和25分的其他课程难易度是一样的。拿数学为例，最难的Specialist Mathematics下学生的最终分数(Score after Scaling)会比学习分数高10分左右(通常说这门课加10分)，Specialist Mathematics和拉丁语是仅有的两门最终分数满分是55的学科(高级中文第二语言满分是53分)。简单一点的Methematics Methods是加5分，而最简单的FurthurMathematics是减5分。3种中文都是加分课程。有效范围也是加分影响之一，例如物理和化学的难度系数是一样的，但是由于医科全部要求化学而科学和工程都是化学物理任选，所以化学的有效范围高于物理, 化学通常加分比物理高1分。小语种和学习人数很少的学科都是加5分。所有学科如果拿到50分的学习分数(Perfect Study Score，通过在最终考试中考满分拿到)都是不减分的，Specialist Mathematics、拉丁语和高级中文第二语言会分别加到55，55，53。 在加减分评估之后学生会拿到至少5个VCE分数。通常情况下英语和其他3门最高分数的科目算作主4门(Primary 4)，其他的科目算作加分科目(Incremental Subjects)。虽然VCE并不限制学生学习数量，但是最多2门科目可以算进加分科目，系统会自动选取最高的两门。VCE总分是主4门的成绩之和加上加分科目成绩的10%。举个例子：若学生成绩为42、52、48、44、40、27、24、最低分24舍去, 总分是42+52+48+44+(40+27)*0.1=192.7。理论上VCE最高满分是223分(学习Specialist Mathemactis、拉丁语、中文第二语言、英语、Mathematics Methods和任意一门)。 在特殊情况主4门不会选择学生最高分数的科目。特殊情况是学生报考的大学需要特定VCE科目成绩, 则该VCE科目自动列入主4门. 例如如果报考医学，算分的时候无论化学和Specialist Maths多少分都会被计入主4门. 算出VCE总分之后需要比对学生成绩，算出ENTER(Equivalent National Tertiary EntranceRankings，标准国家大学入学排名)。分数在99.95-0.00之间，以0.05进位。每0.05大约有20个学生。如果拿到90.00的ENTER，说明此学生的VCE总分是最高的10%。99.95表明此学生是VCE最高的0.05%的学生。99.95的ENTER也被称作完美ENTER(Perfect ENTER Score)。低于30的分数都以低于30发表(Less than 30)，实际分数不予公布。 VCE的学习有校外考试(Final Exams)和校内考试(通常是School Assessed Coursework, SAC)。校外考试包括正式的学科考试和通常能力测试(General Achievment Test, GAT, 通常只有12年纪学生参加，如果11年纪学生学习了VCE 3/4单元课程也要参加)。通常能力测试主要用来评估学校之间的差距，不影响学生个人分数。校内考试通常由任课老师出题，如果有多名任课老师则一起合作出题或一人出题确保公平。虽然校内考试和校外考试都计入总分，校内考试主要用来排名，校外考试则确定分数。例如一个班级，在校外考试考出48、46、44的成绩。学生甲在校外考试和校内考试都是第一名，他会拿到48的学习分数。学生乙在校外考试第2名，校内考试第3名，学生丙在校外考试第3名，校内考试第2名。如果该学科的校外考试和校内考试比重一样的话学生乙和学生丙都是第二名，拿到45的平均分。如果该学科侧重校外考试的话学生乙拿到46分，学生丙拿到44分。 VCE是享有盛誉的高中文凭，澳大利亚其它州和海外的学校都认可该成绩，(IB课程只是少数人选修)。维多利亚州的VCE学生人数占所有高中在校学生的99.5%。 总结： 在澳大利亚，除了昆士兰州以外，考试成绩通常为百分等级 Percentile Ranking, 满分为100，中间间隔0.05。各州对于成绩排名的称呼也不同，虽然叫法不一样，但反映的学生水平是相同的。 澳大利亚高考是由各州举行。 考分进行加权计算，得出每个考生的全国通用分数，称为ATAR，是各大学的录取标准。ATAR是Australian Tertiary Admission Rank 其实就是学生最后的“高考成绩”，各个大学所谓的分数线就是指学生的ATAR分。","categories":[{"name":"求学","slug":"求学","permalink":"http://blog.ozairs.com/categories/求学/"}],"tags":[{"name":"高考","slug":"高考","permalink":"http://blog.ozairs.com/tags/高考/"}],"keywords":[{"name":"求学","slug":"求学","permalink":"http://blog.ozairs.com/categories/求学/"}]},{"title":"谁来拯救你，我的ATAR！","slug":"谁来拯救你，我的ATAR！","date":"2019-02-02T06:31:26.000Z","updated":"2019-02-02T09:40:15.023Z","comments":true,"path":"求学/谁来拯救你，我的ATAR！/","link":"","permalink":"http://blog.ozairs.com/求学/谁来拯救你，我的ATAR！/","excerpt":"","text":"“在澳洲读高中，上大学是不是so easy？？？” 其实国内许多人都认为，在国外无论是读高中还是上大学都“很轻松”。 有的人说神马高中放学早，功课少，数学很简单；又有人说，国外大学宽进严出，留学生随便混混都能上名校——俨然勾勒出一幅在充斥着自由与民主气息的土地上接受教育，不时地和当地人进行思维与文化冲撞的安然画面…… However, 留学生们学习有多辛苦你造吗？ 澳洲高中才不会只用Exam衡量学生呢！ 因为除了所谓的“期中”“期末”Exam——还有quiz，test，essay，paper，assignment，individual project，group project，presentation，lab，report, attendance！每天背着又沉又重的书包上下学，忙的时候4点下课写作业自习至凌晨！负担多到爆有木有！另外对于Year11的学生，部分科目的平时成绩还会记入HSC成绩，这让他们哪里还敢随便浪。 最重要的是——** 好的HSC成绩不代表一定有好的ATAR分数， 你知道你的ATAR成绩对你上大学有多重要么？ 怎么才能考上好大学？ATAR成绩是关键！对于澳洲的高中生来说，不存在高考一次定生死。看的是你的ATAR成绩！ ATAR评分体系 ATAR全称是Australian Tertiary Admission Rank 其实就是学生最后的“高考成绩”，各个大学所谓的分数线就是指学生的ATAR分。澳大利亚高考是由各州各自举行，除了昆士兰州以外，考试成绩通常为百分等级，满分为99.95，以每0.05%为单位来划分。举个栗子，如果你的ATAR 80分，那就说明你的成绩超过了今年所有考生中的80%。 ATAR成绩 虽然各州对于高考叫法不一（比如新州的考试叫HSC，在维州就是VCE），但反映的学生水平是相同的。根据考试成绩和平时成绩进行加权计算后，得出每个考生的全国通用分数，即为ATAR成绩，也就是各大学的录取标准！ 以新州为例，ATAR是由平时成绩（11年级最后一学期&amp;12年级全年在校考试成绩）和最后HSC成绩组成。成绩公布后，登陆UAC系统就可以查出你的ATAR辣~ UAC系统: http://www.uac.edu.au/atar/ 都清楚ATAR是什么了吧？ 现在就来看看怎么按ATAR分选大学吧！ 主要大学&amp;专业ATAR要求","categories":[{"name":"求学","slug":"求学","permalink":"http://blog.ozairs.com/categories/求学/"}],"tags":[{"name":"澳洲","slug":"澳洲","permalink":"http://blog.ozairs.com/tags/澳洲/"}],"keywords":[{"name":"求学","slug":"求学","permalink":"http://blog.ozairs.com/categories/求学/"}]},{"title":"马特达蒙麻省理工2016毕业演讲","slug":"马特达蒙麻省理工2016毕业演讲","date":"2019-02-01T08:09:09.000Z","updated":"2019-02-01T11:17:12.355Z","comments":true,"path":"演讲/马特达蒙麻省理工2016毕业演讲/","link":"","permalink":"http://blog.ozairs.com/演讲/马特达蒙麻省理工2016毕业演讲/","excerpt":"","text":"导语：98年凭借《心灵捕手》斩获影帝，07年被《人物》杂志评为“全球最性感男人”，同年成为第2343位留名好莱坞星光大道的明星……不过谁能想到这位有着非凡成就、实打实的演技派，甚至没有正儿八经的从大学毕业？！麻省理工学院（MIT）今年请到了马达，来为2016的毕业生做一场演讲，而马达牌鸡汤告诉他们——失败是走向成功的最好盔甲！ I don’t even have a college degree. I just didn’t graduate from Harvard. I got pretty close, but I started to get movie roles and didn’t finish all my courses. So you can imagine how excited I was when President Reif called to invite me to speak at the MIT commencement. 我都没个大学文凭，我就是没从哈佛毕业。差点就毕业了，但我开始接触电影开始演戏，并没有完成所有的课程。所以，你可以想象，莱夫校长邀请我到麻省理工毕业典礼上讲话我有多激动。 My brother Kyle and I, and my friend Ben Affleck never really amounted to much.One of the scenes in Good Will Hunting was based on something that actually happened to my brother. Kyle was visiting a physicist we knew at MIT, and he was walking down the Infinite Corridor. He saw those blackboards that line the halls. So my brother, who’s an artist, picked up some chalk and wrote an incredibly elaborate, totally fake, version of an equation. It was so cool and so completely insane that no one erased it for months. This is true. 我和我的兄弟卡尔、还有我的朋友本·阿弗莱克都没有太了不得。《心灵捕手》其中一幕就是根据我兄弟的真人真事拍的。卡尔当时在麻绳理工访问一名我们认识的物理学家，他一路沿着无尽长廊走，看到了大厅连成行的黑板。于是乎，我的兄弟卡尔这位艺术家，拾起粉笔，精心写下了完全凭空杜撰的方程。写得相当酷炫、几近疯狂，好几个月都没人擦去。这是真的，确有其事。 But like I said, we later made a movie here. Which did not go unnoticed on campus. In fact I’d like to read you some actual lines, some selected passages, from the review of Good Will Huntingin the MIT school paper. 如我所说，后来我们在那儿拍了电影，在校园里并没有引起注意。实际上，我想读几句台词给你们听，读些麻省理工校报上《心灵捕手》影评选段给你们听。 You’re working on some crazy stuff in these buildings. I’ll tell you one that’s been on my mind: Simulation Theory. There’s a philosopher named Nick Bostrom at Oxford, and he’s postulated that if there’s a truly advanced form of intelligence out there in the universe, then it’s probably advanced enough to run simulations of entire worlds — maybe trillions of them — maybe even our own. 你们在学校大楼里研究些厉害的事物。我告诉你们我在想些什么：模拟理论。牛津大学尼克·博斯特罗姆曾假定，如果宇宙真有一种先进的智能在，或许可以先进到模拟所有世界，也许有数百万个世界在，也许甚至模拟我们自己的世界。 The basic idea is that we could be living in a massive simulation run by a far smarter civilization, a giant computer game, and we don’t even know it. What if this—all of this—is a simulation? 基本想法就是我们可能生活在超级大型的模拟中，由比我们聪慧得多的文明或者巨型电脑游戏控制着，而我们却不自知。如果这一切真的是模拟呢？ But then again: what if it isn’t a simulation? Either way, what we do matters. What we do affects the outcome. MIT, you’ve got to go out and do really interesting things. Important things. Inventive things. Because this world … real or imagined … this world has some problems we need you to drop everything and solve. 当然，如果这一切又不是模拟呢？无论怎样，我们的所为会影响结果。麻省理工的学生，你们要走出去，做真正有意思的事情、重要的事情、有创造力的事情。因为这个世界，无论真实也好，想象也罢，都会有些问题需要你放下一切去解决。 But before you step out into our big, troubled world, I want to pass along a piece of advice that Bill Clinton offered me a little over a decade ago. What he said was “turn toward the problems you see.”Turn toward the problems you see. Engage with them. Walk right up to them, look them in the eye. In my experience, there’s just no substitute for actually going and seeing things. 你们就要踏入这个纷繁的大世界，我想给你们一句赠言，这是比尔·克林顿十多年前给我的建议。他说“去面对你看到的问题。”去关注你看到的问题，参与其中，径直走过去，直视问题。以我个人的经验，没有什么可以取代真正去面对、去看事物了。 When I was a teenager, Mom thought it was important for us to see the world outside of Boston. I think it was that same impulse that took my brother and me to Zambia in 2006, as part of the ONE Campaign — the organization to fight poverty and preventable disease in the developing world. On that trip, in a small community, I met a girl and walked with her to a nearby bore well where she could get clean water. 我十几岁的时候，我妈妈觉得带我们走出波士顿看看很重要，我觉得，我和我兄弟2006年成为ONE运动的一份子，走进赞比亚也是出于同样的动力。ONE运动这一组织力求在发展中国家战胜贫穷、预防疾病。那次旅途中，在一个小型社区里，我遇见了一个女孩，和她一起去附近的一个钻井汲取干净的水源。 And water goes hand-in-hand with sanitation. And getting out in the world and meeting people like this little girl is what put me on the path to starting Water.org. You see some tough things out there. But you also see life- changing joy. And it all changes you. 水和卫生息息相关。走出去到世界上，正是遇见小女孩这样的人让我走上了开启Water.org之路。你会看到世上的困难，但你也看到改变世界的快乐。这一切都改变着你。 There was a refugee crisis back in ’09 that I read about in an amazing article in the New York Times. People were streaming across the border of Zimbabwe to a little town in northern South Africa called Messina. I was working in South Africa, so I went up to Messina to see for myself what was going on. Human beings will take your breath away. They will teach you a lot… but you have to engage. There’s a lot of trouble out there, MIT. But there’s a lot of beauty, too. I hope you see both. 2009年曾有难民危机，我曾在《纽约时报》读到一篇精彩的文章。人们涌向津巴布韦边境，前往南非北部一个叫摩西那的小镇。我当时在南非工作，所以我亲自就去摩西那看看究竟。人会使你屏息震惊、会教你很多，但你一定要融入。麻省理工的学子们，那里困难重重，但也充满美好，我希望你们两者都能看到。 The point is to try to eliminate your blind spots — the things that keep us from grasping the bigger picture. But looking at the world as it is, and engaging with it, is the first step toward finding our blind spots. There’s a few more things I hope you’ll keep in mind. 关键是，要努力去除你的盲点、那些阻止我们看到全貌的事物。但看到事物的原貌，融入其中，还只是我们找到盲点的第一步。还有其它事情我希望你们牢记。 First, you’re going to fail sometimes, and that’s a good thing. Not having an answer isn’t embarrassing. It’s an opportunity. Don’t be afraid to ask questions. 第一，你有时候会失败，这是好事情。没有答案并不难堪，这是机会，所以不要害怕提问。 The second thing is that you’ve got to keep listening. Even outside your work, there are ways to keep challenging yourself. Listen to online lectures. I love what President Obama said at Howard University’s commencement last month: he said,“Democracy requires compromise, even when you are 100 percent right.” 第二是你要保持聆听。即便是工作之外，也有方法可以挑战自我。去听网上的讲座。我喜欢奥巴马上个月在霍华德大学毕业典礼说的话，“民主需要妥协，即便你百分百正确。” The third and last thought I want to leave you with is that not every problem has a high-tech solution. We need to be just as innovative in public policy. 第三、也是最后我想寄予你们的，不是所有的问题都有高科的解决方案。我们的国家政策需要有所创新。 So, graduates, let me ask you this in closing: What do you want to be a part of? What’s the problem you’ll try to solve? Whatever your answer, it’s not going to be easy. 所以，毕业生们，让我问你们一个问题以此作结。你想成为什么的一份子？你想解决什么问题？无论你的回答为何，都不会是轻而易举。 Here you are alive at a time when science and technology may not hold all the answers, but are indispensable to any solution. 你们所处的时代，科学和技术或许不能解决一切，但所有的解决方案都离不开科技。 So I hope you’ll turn toward the problem of your choosing … Because you must. I hope you’ll drop everything … Because you must And I hope you’ll solve it. Because you must. Your game begins: now. Congratulations and thanks very much! 所以，我希望你们正视你们的选择问题，因为你们必须如此。我希望你们可以放下一切，因为你们必须如此。我希望你们可以解决这个问题，因为你们必须如此。你们的竞赛，现在开始。祝贺你们！非常感谢。","categories":[{"name":"演讲","slug":"演讲","permalink":"http://blog.ozairs.com/categories/演讲/"}],"tags":[{"name":"Matt Damon","slug":"Matt-Damon","permalink":"http://blog.ozairs.com/tags/Matt-Damon/"}],"keywords":[{"name":"演讲","slug":"演讲","permalink":"http://blog.ozairs.com/categories/演讲/"}]},{"title":"【转载】Bill Gates：What I learned at work this year","slug":"What-I-learned-at-work-this-year","date":"2019-01-31T23:16:54.000Z","updated":"2019-02-01T02:20:18.106Z","comments":true,"path":"uncategorized/What-I-learned-at-work-this-year/","link":"","permalink":"http://blog.ozairs.com/uncategorized/What-I-learned-at-work-this-year/","excerpt":"","text":"Every Christmas when I was a kid, my parents would send out a card with an update on what the family was up to. Dad’s law firm is growing, Mom’s volunteer work is going strong, the girls are doing well in school, Bill is a handful. Some people think it is corny, but I like the tradition. These days, at the end of each year, I still enjoy taking stock of my work and personal life. What was I excited about? What could I have done better? I thought I would share a few of these thoughts as 2018 concludes. One thing that occurs to me is that the questions I am asking myself at age 63 are very different from the ones I would have asked when I was in my 20s. Back then, an end-of-year assessment would amount to just one question: Is Microsoft software making the personal-computing dream come true? Today of course I still assess the quality of my work. But I also ask myself a whole other set of questions about my life. Did I devote enough time to my family? Did I learn enough new things? Did I develop new friendships and deepen old ones? These would have been laughable to me when I was 25, but as I get older, they are much more meaningful. Melinda has helped broaden my thinking on this point. So has Warren Buffett, who says his measure of success is, “Do the people you care about love you back?” I think that is about as good a metric as you will find. It may sound grand, but I think the world is slowly going through a similar transition to a broader understanding of well-being. For most of human history, we have been focused on living longer by fighting disease and trying to grow enough food for everyone. As a result, life spans have gone up dramatically. Technology has played a key role in that through vaccines, medicines, and improved sanitation. We still need a lot of innovation to solve problems like malaria or obesity, but we are also going to be focusing more on improving the quality of life. I think this will be the thrust of many big breakthroughs of the future. For example, software will be able to notice when you’re feeling down, connect you with your friends, give you personalized tips for sleeping and eating better, and help you use your time more efficiently. There are not the same clear measures of these things as there are for diseases, and there may never be. But there is nascent work in this field and I think it is going to accelerate. As I look back on the year, I am also thinking about the specific areas I work on. Some of this is done through our foundation but a lot of it (such as my work on energy and Alzheimer’s work) is not. What connects it all is my belief that innovation can save lives and improve everyone’s well-being. A lot of people underestimate just how much innovation will make life better. Here are a few updates on what’s going well and what isn’t with innovation in some areas where I work. Alzheimer’s disease I saw two positive trends in Alzheimer’s research in 2018. I saw two positive trends in Alzheimer’s research in 2018. One is that researchers focused on a new set of ideas about how to stop Alzheimer’s. The first generation of theories, which dominated the field for years, emphasized two proteins called amyloid and tau. These proteins cause plaques and tangles in the brain, clogging up and killing brain cells. The idea was to stop the plaques and tangles from forming. I hope these approaches pay off, but we have not seen much evidence that they will. In the past year, researchers have doubled down on a second generation of hypotheses. One theory is that a patient’s brain cells break down because their energy producers (called mitochondria) wear out. Another is that brain cells break down because part of the immune system gets overactivated and attacks them. This is a great example of how improving our understanding of biology will reduce both medical costs and human suffering. The other trend this year is that the Alzheimer’s community focused on getting more and better access to data. We’re working with researchers to make it easier for them to share information from their studies broadly so that we can better understand questions like how the disease progresses. Over the past few years, the U.S. government has dramatically stepped up funding for Alzheimer’s research, from $400 million a year to over $2 billion a year. There is also a big push to create better diagnostics. The only problem where I don’t yet see a clear path forward yet is how to develop more efficient ways to recruit patients for clinical trials. Without a simple and reliable diagnostic for Alzheimer’s, it’s hard to find eligible people early enough in the disease’s progression who can participate in trials. It can take years to enroll enough patients. If we could find a way to pre-screen participants, we could start new trials more quickly. But there is so much momentum in other areas—scientific tools, better diagnostics, improved access to data—that as long as we can solve the recruitment problem, I am confident that we will make substantial progress in the next decade or two. Polio I thought we would be closer to eradicating polio today than we are. I thought we would be closer to eradicating polio today than we are. Unfortunately, there were more cases in 2018 than in 2017 (29 versus 22). I underestimated how hard it would be to vaccinate children in places where there’s political violence and war. Families move around to escape fighting, which makes it hard to keep track of children and make sure they get all the doses of the vaccine. Or sewage systems get destroyed, allowing the virus to spread as children come into contact with an infected person’s excrement. This is a key reason why Afghanistan and Pakistan have never been free of polio—in fact they are the only two countries that have never been free of polio. I spend a lot of time on polio, part of it talking to the funders to make sure they continue their commitment even though eradication is taking longer than any of us would like. I remind them of the huge benefits of success, and the risk that the disease will return in a big way if we don’t finish the job. I also remind them what a difference innovation is making. We’re now able to test sewage samples to track the virus and find the source before an outbreak starts. And the global health community is finding creative ways to work in war zones, having stopped outbreaks in Syria and Somalia in recent years. Finally, I am hopeful about a new oral vaccine being tested in Belgium and Panama. The results should be out in 2019, and if this one proves effective, it would overcome some of the problems with previous oral vaccines when they’re used in places where few children are immunized. The new vaccine could be in use as soon as 2020. Despite all the challenges, I am still optimistic that we can eradicate polio soon. EnergyGlobal emissions of greenhouse gases went up in 2018. For me, that just reinforces the fact that the only way to prevent the worst climate-change scenarios is to get some breakthroughs in clean energy. Some people think we have all the tools we need, and that driving down the cost of renewables like solar and wind solves the problem. I am glad to see solar and wind getting cheaper and we should be deploying them wherever it makes sense. But solar and wind are intermittent sources of energy, and we are unlikely to have super-cheap batteries anytime soon that would allow us to store sufficient energy for when the sun isn’t shining or the wind isn’t blowing. Besides, electricity accounts for only 25% of all emissions. We need to solve the other 75% too. This year Breakthrough Energy Ventures, the clean-energy investment fund I’m involved with, announced the first companies we’re putting money into. You can see the list at http://www.b-t.energy/ventures/our-investment-portfolio/. We are looking at all the major drivers of climate change. The companies we chose are run by brilliant people and show a lot of promise for taking innovative clean-energy ideas out of the lab and getting them to market. Next year I will speak out more about how the U.S. needs to regain its leading role in nuclear power research. (This is unrelated to my work with the foundation.) Nuclear is ideal for dealing with climate change, because it is the only carbon-free, scalable energy source that’s available 24 hours a day. The problems with today’s reactors, such as the risk of accidents, can be solved through innovation. The United States is uniquely suited to create these advances with its world-class scientists, entrepreneurs, and investment capital. Unfortunately, America is no longer the global leader on nuclear energy that it was 50 years ago. Unfortunately, America is no longer the global leader on nuclear energy that it was 50 years ago. To regain this position, it will need to commit new funding, update regulations, and show investors that it’s serious. There are several promising ideas in advanced nuclear that should be explored if we get over these obstacles. TerraPower, the company I started 10 years ago, uses an approach called a traveling wave reactor that is safe, prevents proliferation, and produces very little waste. We had hoped to build a pilot project in China, but recent policy changes here in the U.S. have made that unlikely. We may be able to build it in the United States if the funding and regulatory changes that I mentioned earlier happen. The world needs to be working on lots of solutions to stop climate change. Advanced nuclear is one, and I hope to persuade U.S. leaders to get into the game. The next epidemicIn 1918, the Spanish flu killed 50 million people worldwide. It still ranks as one of the deadliest natural disasters ever. I had hoped that hitting the 100th anniversary of this epidemic would spark a lot of discussion about whether we’re ready for the next global epidemic. Unfortunately, it didn’t, and we still are not ready. People rightly worry about dangers like terrorism and climate change (and, more remotely, an asteroid hitting the Earth). But if anything is going to kill tens of millions of people in a short time, it will probably be a global epidemic. And the disease would most likely be a form of the flu, because the flu virus spreads easily through the air. Today a flu as contagious and lethal as the 1918 one would kill nearly 33 million people in just six months. I have been studying this for several years. To be prepared, we need a plan for national governments to work together. We need to think through how to handle quarantines, make sure supply chains will reach affected areas, decide how to involve the military, and so on. There was not much progress on these questions in 2018. There has been progress toward a vaccine that would protect you from every strain of the flu. The good news is that there has been progress toward a vaccine that would protect you from every strain of the flu. This year I visited the U.S. National Institutes of Health in Maryland and got an update from some of the people leading this work. The challenges of making a universal flu vaccine are fascinating. All strains of the virus have certain structures in common. If you’ve never been exposed to the flu, it’s possible to make a vaccine that teaches your immune system to look for those structures and attack them. But once you’ve had the flu, your body obsesses over the strain that got you sick. That makes it really hard to get your immune system to look for the common structures. So it is clear how we could make a universal vaccine that would protect anyone (such as the very young) who has never been exposed to the flu before. But for anyone who has already had the virus, it is a lot harder. The problem is a long way from being solved, but new research money is coming in and more scientists are working on it. To make the most of these scientific efforts (some of which our foundation is funding), the world needs to develop a global system for monitoring and responding to epidemics. That is a political matter that requires international cooperation among government leaders. This issue deserves a lot more focus. Gene editingGene editing made the news in November when a Chinese scientist announced that he had altered the genes of two baby girls when they were embryos. What is unprecedented about his work is that he edited their germline cells, meaning the changes will be passed down to their children. (The other, less controversial type of gene editing involves somatic cells, which aren’t inherited by future generations.) I agree with those who say this scientist went too far. But something good can come from his work if it encourages more people to learn and talk about gene editing. This might be the most important public debate we haven’t been having widely enough. The ethical questions are enormous. Gene editing is generating a ton of optimism for treating and curing diseases, including some that our foundation works on (though we fund work on altering crops and insects, not humans). But the technology could make inequity worse, especially if it is available only for wealthy people. I am surprised that these issues haven’t generated more attention from the general public. Today, artificial intelligence is the subject of vigorous debate. Gene editing deserves at least as much of the spotlight as AI. I encourage you to read up on it whenever you have a chance. Keep an eye out for articles in your news feed. If you are willing to read a whole book, The Gene by Siddhartha Mukherjee is very well done. This story is one to follow, because big breakthroughs—some good, some worrisome—are coming. Looking aheadAlthough I have never been one for New Year’s resolutions, I have always been committed to setting clear goals and making plans to achieve them. As I get older, these two things look more and more like the same exercise. So I am making a resolution for 2019. I am committing to learn and think about two key areas where technology has the potential to make an enormous impact on the quality of our lives, but also raises complex ethical and social considerations. One is the balance between privacy and innovation. How can we use data to gain insights into education (like which schools do the best job of teaching low-income students) or health (like which doctors provide the best care for a reasonable price) while protecting people’s privacy? The other is the use of technology in education. How much can software improve students’ learning? For years we have been hearing overheated claims about the huge impact that technology would have on education. People have been right to be skeptical. But I think things are finally coming together in a way that will deliver on the promises. I will be posting updates on these and other issues here on LinkedIn and on my blog, the Gates Notes. In the meantime, Melinda and I are working on our next Annual Letter. The theme is a surprise, though it is safe to say we’ll be sharing some positive trends that make us optimistic about the future. We’ll send the letter out in February. I hope you have a happy and healthy start to 2019.","categories":[],"tags":[{"name":"Review","slug":"Review","permalink":"http://blog.ozairs.com/tags/Review/"}],"keywords":[]},{"title":"【转载】Ray Dalio：Looking Back on the Last 40 Years of Reforms in China","slug":"Looking-Back-on-the-Last-40-Years-of-Reforms-in-China","date":"2019-01-31T23:03:31.000Z","updated":"2019-02-01T02:11:03.995Z","comments":true,"path":"uncategorized/Looking-Back-on-the-Last-40-Years-of-Reforms-in-China/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Looking-Back-on-the-Last-40-Years-of-Reforms-in-China/","excerpt":"","text":"As the end of 2018 marks the 40th anniversary of Deng Xiaoping and China’s other leaders opening up and reforming China and since this is also a time of greater questioning of China’s economic future, it is a good time to reflect on how China’s last 40 years have gone and why. The table below shows just a few representative statistics. These results speak for themselves. To have such rates of improvements in so many areas and for so many people has made it the greatest economic miracle ever. Clearly whatever they did worked great. So, what was behind these accomplishments and will they continue? Since I have been fortunate to have experienced 34 years of this 40 years in an up close and intimate way, and since I study what makes countries succeed and fail, I have some experiences and thoughts to share This is a retrospective look at China. A more comprehensive report about the current state of the economy and what is likely to come will follow shortly. From what I have seen, I believe that the very impressive results that the Chinese leadership and the Chinese people produced came about primarily because of the powerful combination of a) China’s opening up and reforming following an extended period of isolation that led to a fast catching up (especially in the coastal regions of China) with the advanced developed world, and b) the power of the Chinese culture and it’ related ways of operating. My first exposure to this came in 1984 when China was just opening. I was invited by CITIC (which was the only “window company,” which means the only company that was allowed to freely deal with the outside world) to teach them how the world financial markets work. I immediately got a taste for the culture and could see that China was undeveloped for different reasons than other underdeveloped countries. In China’s case, the people and culture were highly developed and suffered from isolation from the advances that occurred in the rest of the world (whereas in most other developed countries the reverse was the case). As an example of how undeveloped China was at the time because of lack of contact with the outside world, I gave senior people $10 calculators which they then thought were miraculous. To give you an idea of the rate of progress since then, some of those people are now overseeing the development of some of the most cutting-edge technologies in the world. Back in 1984, I saw that there was nothing about the Chinese people that prevented them from being as successful as those in the developed world, and I knew that China was opening its door, I could imagine the essence of the big changes that would occur. Because the closed door was a barrier that led to two different economic levels to exist between China and the developed world, the removal of that barrier would naturally equalize their economic levels like unconstrained water naturally seeks the same level. I remember being on the 10th floor of CITIC’s “Chocolate Building,” giving a lecture and pointing out the window to the two-story hutongs (poor neighborhoods) and telling my audience that it would not be long before the hutongs would be gone and skyscrapers would be there in their place. They didn’t believe me and told me “you don’t know China,” and I told them they did not know the power of the economic arbitrages that would happen as a result of opening up. That opening was the biggest force behind the high rates of improvement that we saw over the last 40 years. While the opening up created a great natural opportunity, the Chinese made the most of it. They did that by making and implementing reforms that were driven by uniquely Chinese cultural influences. These reforms freed up the Chinese people to realize their potential. When I first came to China, in addition to seeing that it was undeveloped because of its isolation, I saw that it was underdeveloped because it was run by an old-style communist system that provided little incentives or efficiencies. For example, people couldn’t choose their own careers and jobs, there were no private businesses allowed, government businesses (i.e., all business) were inefficiently run, and there were little or no incentives for working hard and doing a good job. In the years that followed, I saw numerous excellent and rapid reforms change all that. Even more important than my getting to see the particular reforms that they made, I got to see how they make reforms – I.e., how they come up with numerous big reform ideas, plan them out, get behind them, and then get them done. The demonstrated ability of the Chinese to go from visualizations to actualizations is quite amazing. For example, in 1989 I was introduced by my CITIC friend and contact Wang Li to a group of seven good people (which she was one of) who were appointed by nine companies at the request of the visionary reformer Wang Qishan to create an organization (the Stock Exchange Executive Council) to set up the first financial markets in China. China was still very poor, so their office was in a dingy hotel and they lacked adequate funding. Still they had what mattered most—i.e., a clear mission to create big changes, smart people of good character, open-mindedness to allow rapid learning and determination to achieve their goals. Over the decades that followed, I saw how they and many others built the Chinese financial markets to become among the largest in the world, and I got to participate in small ways, which has been one of the great joys of my life. Through all this I gained a love and respect for the Chinese people, the Chinese culture, and their rapid rates of improvements that these forces brought about. . As an extension of these sentiments in 1995, I had my 11-year-old son Matt live with an extraordinary and humble Chinese woman, Madame Gu, and go to a poor local school (Shi Jia Hu Tong Xiao Xue). All schools in China, like most everything else, were poor then. Though this school was poor (e.g., there wasn’t heat until late November so students wore their coats in classes), I saw how they had smart and caring educators who provided the children with an excellent, complete education that included character development. While Matt’s lifestyle was poor (e.g., he couldn’t take hot showers because the old apartment building he lived in only had hot water two days a week) he was superbly educated, loved, and better developed than in our rich Greenwich community. The experience changed his life forever and led him to set up a foundation to help Chinese orphans that he ran for 12 years that brought him and me into many more experiences with Chinese people and Chinese culture in China. Through experiences like these and by getting to know some of the Chinese leaders, I learned a lot more about the Chinese culture, about how it operates today and about how it evolved over thousands of years —-from notions of how family members and others should behave with each other, through Confucian thinking, through Neo-Confucian thinking, through various dynasties and with the lessons these events provided about how leaders should lead and how followers should follow. These values and ways of operating are what I’m referring to when I refer to the Chinese culture, which I saw manifested over and over. I For example, I could see how that Chinese culture connected Lee Kuan Yew and Deng Xiaoping so that they together could explore how China could have a “socialist market economy with Chinese characteristics.” Though I’m no expert on Chinese culture and its way of operating, I do believe that I have some sense of it that might be helpful to those who haven’t had such exposures to it. Most importantly, if you haven’t spent time in China, you need to get any stereotypes you might have out of your mind because it’s not how it was. This is not your father’s communism. It is “socialism with Chinese characteristics” that has been significantly and very effectively reformed, which has made it much more vital, creative, and economically free. Before I share more of my thinking about this, I’d like to pass along Xi Jinping’s far more important observations about the last 40 years of reforms and what to expect in the future. It is worthwhile reading for those who want to understand his perspective, which is most important. President Xi refers a lot to “Chinese characteristics,” though he doesn’t define them. While what defines Chinese culture would be better described by Chinese who are more knowledgeable than I am, I will refer you to the book Chinese Characteristics (here) – an American observer writing about Chinese culture in the late 1800s, some of which I think resonates today (though I’ll note that don’t agree with everything in the book, some of which is very outdated). Still, I will inadequately describe what I think Chinese culture most fundamentally is. As I’m not a Chinese scholar so that my comments are made solely on the basis of my contacts and my limited research, please take what I’m saying with a grain of salt. From my experiences and from what I am told by Chinese who should know, I believe Chinese leadership seeks to run the country the way they believe a good family should be run, from the top down, maintaining high standards of behavior, putting the collective interest ahead of any individual interest, with each member knowing their place and having filial respect for those in the hierarchy so the system works in an orderly way. One of China’s leaders who explained this concept to me told that the word “country” consists of two characters, state and family, which influences how they view their role in looking after their state/family. One might say that the Chinese government is paternal. For example, it regulates what types of video games are watched by children and how many hours a day they play them. As a broad generalization, when the interest of the country (like the family) is at odds with the interest of the individual, the interest of the country (like the interest of the family) should be favored over the interest of the individual. Individuals are parts of a greater machine. As a result of this perspective, the system seeks to develop, promote and reward good character and good citizenship. For example it gives people a social credit score that rates the quality of their citizenship. And each person is expected to view themselves as parts of the greater whole. This management from the top down includes visualizing what China 5, 10 and 20 years in the future should be like and then making and managing detailed multiyear plans to build out that vision, with the goal being to make China as great as it can be. China is run more like a giant company with many subsidiaries, some within the government’s direct control and some within its indirect control. Over those 40 years, the economic system was reformed to allow much more market-oriented and freer pursuit of self-interest as long that pursuit is pursed with good citizenship (including respect for the ruling system and its rules),. That included having growth of the private sector and private property. So what we have seen over the last 40 years is China making many big, practical reforms around a traditional Chinese way of operating. As Xi said in a recent speech, “we will reform the things that should be reformed and not reform the things that shouldn’t be reformed,” referring to having big changes while maintaining the traditional Chinese style governance system. While Chinese culture has been evolving, it has at its most fundamental level been operating in similar ways for many hundreds or even thousands of years and the results of operating that way are knowable in an approximate way. I have recently been researching the rise and fall of reserve currencies, which led me to study the rises and declines of the world’s most powerful countries. That led my research team and me to put together the following indices of the relative powers of leading countries since 1500. These indices are a combination of six sub-indices that measure six different types of power: 1) innovation &amp; competitiveness, 2) domestic output, 3) share of world trade, 4) financial-center size and power, 5) military strength, and 6) reserve-currency status—and they show when different countries reached their peaks relative to the rest of the world. As shown, China was either the number one or number two most powerful country from 1500 to at around1800 when it went into relative decline that continued until around 40 years ago when the opening up and reforming led to the previously described strong ascent to being the second-most powerful country in the world and on the path to being the most powerful one. I believe that excellent performance was largely the result of China’s powerful culture and its reforms. The chart below shows each of the six measures of Chinese strength going back to 900. The next chart shows our overall index going back to the year 900. As you can see, China has been a very successful country through the millennia except for the more recent 150 years or so (for reasons I won’t delve into now). Given that impressive track record and how deeply imbued the culture behind it is, we shouldn’t expect China’s most fundamental ways of operating to change much. As a result, while trade deals can be made, attempts to change “Chinese characteristics”,—most importantly to change the top-down government management of most/all aspects of the system pursuit of making China as great as it can be—won’t work. While considerable attention is now being paid to the trade war, what is more important is that China and the US are in a competition of cultural approaches, with the US approach being more opposite than similar to the Chinese approach Most fundamentally, the US is a country in which individuals, individualism, and individual property rights are perceived to be of paramount importance it is directed from the bottom up (e.g., through “one man, one vote” democracies that empower people to choose their leaders), being revolutionary is considered a good thing, and conflict is valued more than harmony. Rather than respecting top down control most American have a strong preference to keep government from interfering with their most individual choices. Character development is a personal or family issue, not a government issue (which leaves it largely neglected in areas with broken families, especially if they’re poor). Rather than there being a long-term top down vision for the country and a plan to achieve that vision, in the capitalist and democratic system such directions are more bottom up determined based on commercial and popularity considerations. I’m not saying which system is better. Each culture/system has its pros and cons that I’m not going to get into now. I believe that the important thing to know are that while there will be trade wars and trade truces they aren’t the most important things. The most important things are that 1) China has a culture and system that has worked well for it for a long time so it shouldn’t be expected to change much, 2) the U.S. has the same, 3) these systems (and those of other countries) will be both competing and cooperating, and how well they do that will be an important influence on global conditions, 4) how well each system works in practice will have a far greater influence on where each country stands in the future than the terms of the deals that they strike with each other, so each would do well to examine its own weaknesses and come up with reforms to rectify them, and 5) there is a lot to respect about the Chinese culture and approach that led to its remarkable accomplishments, 6) we would do well to learn from each other, cooperate and compete to bring each other up rather than to tear each other down, and 7) China is a place we need to continue to evolve with and invest in.","categories":[],"tags":[{"name":"Review","slug":"Review","permalink":"http://blog.ozairs.com/tags/Review/"}],"keywords":[]},{"title":"澳洲必备保健品","slug":"澳洲必备保健品","date":"2019-01-29T00:50:18.000Z","updated":"2019-01-29T03:57:33.673Z","comments":true,"path":"uncategorized/澳洲必备保健品/","link":"","permalink":"http://blog.ozairs.com/uncategorized/澳洲必备保健品/","excerpt":"","text":"前段时间去了澳洲玩，去之前做了一堆功课，最终买了这几款必备的保健品，因为本身是过敏体质，食用过后感觉有明显改善，因此用自己的方式画出来分享给大家。🌟 no. 1 ♡ 玫瑰果丸💘- 美白 价格比日本pola要实在很多，一瓶一百多软妹币，其实我本身白皮，但是我在澳洲上学的朋友她原来很黑的一个人，这次找她玩，我发现她竟然比我还要白很多！问了之后才知道她一直在食用这个，并且去海边也没有轻易晒黑，所以！必须入手！ no. 2 ♡ 葡萄籽 💘- 抗衰老 20多岁的老阿姨必须入手啊，感觉女生过了20岁以后真的老的很快，黑眼圈，暗沉，熬了一夜，第二天脸色就很差，所以很希望它能救救我，就入手了。 no. 3 ♡ 葡萄籽 💘- 护肝片 身为设计师，每天爆肝赶图无话可说，虽然不赶图时候也不早睡……但是因为晚上11点到1点是肝脏排毒时间，如果不睡的话就会积累很多毒素，所以一般这个点还没睡的话，我就会食用两颗辅助排毒，来缓解自己的心里负担，另外抽烟喝酒也可食用帮助排毒 no. 4 ♡ 胶原蛋白💘- 抗衰老 同样20多岁的老阿姨，感觉需要必入的东西，胶原蛋白火的有两款，一款液体，一款固体，功能差不多，我个人比较倾向于固体的，固体易携带，也不容易变质，不会那么麻烦，周围很多朋友因为液体放冰箱忘记食用最后变质，感觉很浪费 no. 5 ♡ 成人益生菌 💘- 抗过敏 我是过敏体质，所以专门做功课入了这一款，我过敏是因为免疫力差，这一款含多种益生菌，提高免疫力 no. 6 ♡ 膳食纤维粉💘- 减肥 看张韶涵有推荐，后来有个视频印象深刻，把这个和一杯油放在一起混合之后，水油会变分离，感觉排油很厉害，所以我如果是大吃大喝一顿或者吃夜宵的话，就会冲一杯缓解罪恶感，第二天会排出去 no. 7 ♡ 素颜丸💘- 修复肌肤 这个貌似很多人推荐，据说有改善肌肤，然后素颜也可以很美，我晚上睡前食用，会感觉睡的比较踏实，应该这个也有一方便原因吧，据说对女性也很有好吃，需要在食用一段时间看 no. 8 ♡ 睡眠片💘- 睡眠 有时候压力大晚上想事情会失眠，这个不含褪黑素，所以放心食用。 说实话澳洲保健品真的有用，女生不仅要注重外在修饰，内调更重要，用自己喜欢的方式做的第一次分享，画了好多图，码了好多字，喜欢的话请给我点赞打☎️（下一篇会更有动力，感恩💕） @小红叔 @薯队长 澳洲保健品 我的护肤日常 插画 日常美容保健品 美白必吃保健品 我的护肤日常 肌肤过敏如何急救 健身吃什么 懒人护肤法 健身吃什么 肌肤过敏如何急救 学生党护肤推荐","categories":[],"tags":[{"name":"澳洲","slug":"澳洲","permalink":"http://blog.ozairs.com/tags/澳洲/"}],"keywords":[]},{"title":"澳洲Ego QV儿童保湿霜","slug":"澳洲Ego-QV儿童保湿霜","date":"2019-01-28T11:07:18.000Z","updated":"2019-02-01T06:57:34.317Z","comments":true,"path":"澳洲代购/澳洲Ego-QV儿童保湿霜/","link":"","permalink":"http://blog.ozairs.com/澳洲代购/澳洲Ego-QV儿童保湿霜/","excerpt":"","text":"澳洲Ego QV婴儿、儿童保湿霜 澳洲QV的产品 几乎零差评 真心是高端却平价。 这么一大罐250克呢 从脸到脚都可以擦 成人有时候皮肤过敏啥的也能用哦 澳洲Ego QV婴儿、儿童保湿霜，这个牌子在澳洲家喻户晓 📢 在澳洲各大药房 👷 均有出售 ❕ 所有产品都不含香料，色素，羊毛脂和丙二醇，适合所有肌肤，特别是干燥及敏感肌肤。 国内已经进入秋天💨给宝宝用适合秋冬的面霜吧[愉快]特别适合给极度干燥，轻微湿疹，肌肤敏感的儿童使用。","categories":[{"name":"澳洲代购","slug":"澳洲代购","permalink":"http://blog.ozairs.com/categories/澳洲代购/"}],"tags":[{"name":"Baby","slug":"Baby","permalink":"http://blog.ozairs.com/tags/Baby/"}],"keywords":[{"name":"澳洲代购","slug":"澳洲代购","permalink":"http://blog.ozairs.com/categories/澳洲代购/"}]},{"title":"818澳洲那些超热门的婴幼儿营养品","slug":"818澳洲那些超热门的婴幼儿营养品","date":"2019-01-27T23:39:34.000Z","updated":"2019-01-28T02:49:47.140Z","comments":true,"path":"uncategorized/818澳洲那些超热门的婴幼儿营养品/","link":"","permalink":"http://blog.ozairs.com/uncategorized/818澳洲那些超热门的婴幼儿营养品/","excerpt":"","text":"​ 澳洲地广人稀，自然环境非常的优越，物产丰富，空气纯净，环境无污染，保证了本地产品独特的天然性，无论是内服还是外用产品，对宝宝们都是百分百安全的！ 澳洲除了婴儿奶粉外，保健品，护肤品，常用药，也非常出名，宝宝从怀胎十月的妈妈肚子里面来到这个美丽世界，少了子宫的保护，宝宝需要有强壮的身体才能茁壮成长，锌、钙、DHA等是孩子成长必需的微量元素，帮助妈妈保护和增强宝宝的免疫力、促进食欲、维护宝宝健康，呵护宝宝健康成长。下面为大家818澳洲那些超热门的婴幼儿、儿童产品，都是很值得推荐给宝妈们的！ 一、 Ostelin婴幼儿维生素D滴剂 【产品介绍】 Ostelin是澳洲唯一一家只生产钙和维D的品牌（除了钙及维D外不生产任何其他产品)，也是澳洲补钙和维D产品的首选，绝对专业中的专业。补钙，维生素D的摄入显得尤为重要。如果宝宝们体内缺少维他命D，无论我们补充多少的钙质也不能够被很好的吸收。草莓口味维生素D滴剂，让宝宝更容易接受。内含一刻度滴管，方便使用。 【产品功效】 1、提高肌体对钙、磷的吸收，使血浆钙和血浆磷的水平达到饱和程度。 2、促进生长和骨骼钙化，促进牙齿健全； 3、通过肠壁增加磷的吸收，并通过肾小管增加磷的再吸收； 4、维持血液中柠檬酸盐的正常水平； 【剂量及使用方法】 感冒时期：每天1.0ml，随餐服用或随医嘱 日常保健：每天0.5ml，随餐服用或随医嘱 开封后建议40天内服用完，可直接滴入宝宝口内或滴在一小勺牛奶、果汁中。（使用前先摇匀，每天剂量不可超过1.0ml） 【适用人群】 0-12岁儿童 二、Ostelin儿童VD+钙咀嚼片 【产品介绍】 说到儿童补钙产品怎么能不提Ostelin，它家的Ostelin儿童钙+VD可是深受妈妈们的喜爱，人称“恐龙钙”是也，绝对是孩子补钙好帮手！比（澳洲）市场上其他儿童维生素补充营养品含有更多的维生素D和钙 ，所含钙为儿童每日所需的钙摄入量，堪称“钙片中的爱马仕”，不含人造色素及香料 ，非常美味的梅子味咀嚼片。 【产品功效】 1、促进骨骼钙化和生长。 2、预防宝宝患佝偻病。 3、提高机体对钙的吸收。 4、增强和稳固牙齿、骨骼，预防和缓解缺钙引起的腰酸、腿痛、腿脚抽筋。 【剂量及使用方法】 2岁-8岁：每日嚼咀2片 9岁-13岁：每日嚼咀3片或遵医嘱服用 【适用人群】 1、年龄在2-13岁的儿童。 2、由于饮食的限制，如过敏或挑食的饮食，造成的膳食钙的摄入量不足。 3、日光照射有限区域的儿童。 4、 正处于非常快速的成长期的儿童。 三、Life Space婴幼儿益生菌粉 【产品介绍】 Life Space 是一家专门生产各类高端益生菌产品的澳洲本土公司，针对不同人群，特别量身定制了益生菌产品，包括婴幼儿，儿童，老人，孕妇，成人等，它被澳洲多本母婴杂志评选为澳洲最佳的母婴益生菌产品。Life space益生菌采用冻干粉技术保证了益生菌的存活率，并且无需冷藏储存，外出携带也非常方便。它属于复合型益生菌，蕴含十几种不同品种的天然益生菌群，从而满足人体的不同需求。 【产品功效】 有效增强抵抗力，调理肠道，保持身体机能健康 【适用人群】 1、免疫力较低，容易感冒发烧咳嗽的婴幼儿 2、患有湿疹、过敏性体质的婴幼儿 3、容易腹泻、拉肚子、便秘的婴幼儿 4、服用抗生素的婴幼儿 【剂量及使用方法】 6-18个月宝宝：每天1-2克 18-36个月宝宝：每天2克 （产品内附1克量勺），或遵医嘱 开启后三个月内用完，效果最佳，可混入牛奶、果汁及食物当中。 四、Bio island婴幼儿天然液体乳钙 【产品介绍】 Bioisland 是澳洲婴幼儿营养补充剂销量排名第一的婴幼儿营养品品牌，Bioisland乳钙是直接从牛奶中提取出来的纯天然活性高乳蛋白钙，在体内不需要太多胃酸参与，即可分离呈现离子状态，进而被人体直接吸收利用，迅速调节血钙平衡，消化吸收的过程中，不会给宝宝肠胃带来负担，不会出现气胀、浮肿、便秘，特别适合胃酸不足的婴幼儿补充。 【产品功效】 促进宝宝骨骼和牙齿生长，预防佝偻病和骨质疏松。 【剂量及使用方法】 0~6个月婴儿：每天1粒 7个月~12个月：每天1-2粒 1~3岁儿童：每天2-3粒 可以挤入牛奶或者果汁中服用。服用起来也特别方便，把小鱼的尾巴拧掉，把液体乳钙挤入宝宝嘴里就可以了。 五、Bio island顶级深海鳕鱼鱼油 【产品介绍】 鱼油的主要有益成分是Omega-3，是不饱和脂肪酸DHA、EPA，主要作用是益智。鱼肝油主要有益成分是对视力有好处的维生素A以及能促进钙吸收的维生素D，鱼油是脂肪酸，对大脑发育好，鱼肝油是脂溶性维生素，对眼睛和骨骼好。这款产品兼具鱼油和鱼肝油，补脑护眼，一粒搞定。 【产品功效】 促进钙吸收，有助宝宝大脑和视力、骨骼发育 【剂量及使用方法】 0~6个月婴儿：每天1粒 7个月~12个月：每天1-2粒 1~3岁儿童：每天2粒 可以挤入牛奶或者果汁中服用。服用起来也特别方便，把小鱼的尾巴拧掉，把鱼油挤入宝宝嘴里就可以了。 六、Bio island海藻油DHA 【产品介绍】 藻油DHA是从藻类中提炼的，因为具体原料藻类的品种以及提炼工艺的不同，有的藻油DHA中含有少量EPA，有的不含有EPA。给宝宝选择要选不含有EPA的藻油DHA。给宝宝选DHA不看来源，要看EPA含量，不论鱼油还是藻油，选EPA含量低的。 DHA是宝宝成长中的脑黄金，孕妇哺育中的好宝贝。奶粉中的DHA很容易氧化掉，建议应单独补充DHA。 【产品功效】 促进视网膜光感细胞的成熟,增进大脑细胞的发育 【剂量及使用方法】 0~6个月婴儿：每天1粒 7个月~6岁儿童：每天1粒 可以挤入牛奶或者果汁中服用。服用起来也特别方便，把小鱼的尾巴拧掉，把藻油挤入宝宝嘴里就可以了。 七、Bio island补锌咀嚼片 【产品介绍】 锌是人体不可缺少的微量元素，是几十种金属酶的组成部分，对蛋白质的合成、生长因子的产生和分泌等环节有重要作用，可促进宝宝的生长发育，增强创伤组织的再生能力，维持味觉与食欲，参与维生素A的代谢，增强免疫功能。 【产品功效】 1、提高儿童食欲，帮助儿童维持正常味觉，嗅觉功能 2、增强儿童肌体免疫力 3、参与儿童体内多种酶的合成与代谢，促进生长发育 4、参与儿童体内维生素A的代谢和生理功能 5、保护皮肤黏膜的正常发育 【剂量及使用方法】 1-8岁儿童：每天嚼咀1片或遵医嘱 9-12岁儿童：每天嚼咀2片或遵医嘱 八、Swisse儿童复合维生素 【产品介绍】 本产品是Swisse专为两岁以上的儿童设计的专用维生素，不仅可以为儿童提供每日所需的多种维生素、矿物质及抗氧化元素，还能减少宝宝因偏食，挑食所导致的营养不良，帮助骨骼的生长，使宝宝健康成长和发育。而且内含的西洋参能有效维持儿童身体的能量水平，荨草和玫瑰果则能增强儿童的免疫力。 【产品功效】 1、抵御伤风感冒袭击 2、缓解降低患感冒的时间长度及程度 3、帮助孩子增强抗体与健康 【剂量及使用方法】 2岁-4岁儿童：每日嚼咀1片 4岁-12岁儿童：每日嚼咀2片 随餐或餐后立即服用，或遵医嘱 九、Nature’s way 儿童三色鱼油 【产品介绍】 澳洲儿童营养专家研配，含有丰富的DHA及EPA以及omega 3，DHA有助大脑及身体发展，EPA有助调节血脂，维持血管正常。omega 3脂肪酸来自优质含脂量较高的鱼，是提升儿童记忆力、学习能力、行为控制力不可或缺的营养成份。 【产品功效】 1、强健脑力，提高记忆和学习能力。 2、保护眼睛，预防和改善近视。 3、促进胎儿、婴儿、儿童的大脑发育，增长智力。 4、补充大脑营养、提高大脑灵敏度、增强思维能力、提高记忆。 【剂量及使用方法】 6个月~5岁的儿童：每天1粒，或遵医嘱 5岁以上的儿童：每天1~2粒，或遵医嘱 年龄小的宝宝可以拧开或剪开胶囊尾部，挤入宝宝口中或加到食物里 — End — 话说，无论给宝贝选择什么样的营养补充品，您首先要保证的都是孩子的均！衡！饮！食！而且不要盲目跟风，要有针对性地根据宝宝年龄、身体状况进行选择，缺什么补什么，适合宝宝的才是最好的！","categories":[],"tags":[{"name":"Baby","slug":"Baby","permalink":"http://blog.ozairs.com/tags/Baby/"}],"keywords":[]},{"title":"Hello World","slug":"hello-world","date":"2019-01-27T04:05:03.506Z","updated":"2019-01-27T04:53:20.343Z","comments":true,"path":"uncategorized/hello-world/","link":"","permalink":"http://blog.ozairs.com/uncategorized/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[],"keywords":[]},{"title":"How To Buy A Car In Australia","slug":"How-To-Buy-A-Car-In-Australia","date":"2019-01-27T03:24:57.000Z","updated":"2019-01-27T06:36:59.756Z","comments":true,"path":"uncategorized/How-To-Buy-A-Car-In-Australia/","link":"","permalink":"http://blog.ozairs.com/uncategorized/How-To-Buy-A-Car-In-Australia/","excerpt":"","text":"导读：绝大部分的留学生买车主要是为了方便上下学和日常的打工，甚至有一小部分学生喜欢开车出去旅游，澳洲又是开车特别舒服的国家(路宽人少风景美)，基于这些需求，选择一辆质量好，节油，价格实惠的汽车是大部分学…… 1、如何选购汽车的品牌 绝大部分的留学生买车主要是为了方便上下学和日常的打工，甚至有一小部分学生喜欢开车出去旅游，澳洲又是开车特别舒服的国家(路宽人少风景美)，基于这些需求，选择一辆质量好，节油，价格实惠的汽车是大部分学生的第一选择。 其实澳洲本土来说，丰田汽车是保有量最大的品牌，其次是马自达。在中国随处可见的大众汽车，在澳洲几乎很难见得到。原因是丰田的车维修起来，成本低，时间短，而且又节油。有个朋友买了奥迪A4，不小心撞了前保险杠，拿去维修，等了半年才修好······因为德国的配件需要从德国空运，价格不仅贵了两三倍，时间也要等很久。 划重点：如果不是非常喜欢德系车，建议在澳洲购买日系车，使用更加方便 2、去哪里买车呢? 如果是买新车的话，建议就去当地的4S店，这一点跟中国差不多，多逛几家4S店，多了解一些价格，然后砍到合理的价格就入手。这里需要搞清楚的就是，你看中的这款车是不是最新款，有些“不良商家”喜欢把16年的车说成是17年款，实际上你掏了一样的钱却买了旧款的车子。具体的汽车配置可以上汽车品牌官网查看，也可以上Carsales(澳洲最大的车辆交易网站，可以通过这个网站来查看车子的内外功能配置) 如果是买二手车的话，购买渠道就很多了，有私人二手车(Private)、二手车行(Dealer)、拍卖行(Auctions)这三种主流购买渠道。刚刚我们推荐的Carsales这个网站，很多人会在上面发布卖车信息(发布信息网站是要收费的)，私人二手车和Dealer二手车都可以在这个上面找到，以下图举例： 除了Carsales还有Gumtree，Gumtree类似于我们国内的赶集网，58同城这种，发布信息都是免费的，所以导致信息真假和质量层次不齐，我们在这里就不推荐学生去这个网站搜索，Carsales已经可以满足大部分要求了(我们绝对没有收广告费!!工作室太小，Carsales也不认得我们o(╥﹏╥)o) Auctions主要拍卖的是政府的车，公里数比较高，车况一般，而且不能试车，国际驾照不能在拍卖行买车，所以我们就不多做介绍了。 3、如何判断这车可不可以买？ 先说二手车行(Dealer)的车，二手车行也分大小，一般价位在5000澳币以内的车只有小车行卖，要求门槛也比较低，车况不一定很好。卖5000-10000澳币的车行在规模上会相对大一些，但是没达到4S店的规模。经手的车辆在性能上和可靠性上一般可以维持12个月的中上水准。1W以上的车大部分都是在连锁Dealer上卖了，例如国内的4S店，价格虽然偏贵，但是车况是很不错的。第一类车行肯定是不推荐的，因为价格本来就便宜，车行还要分一笔钱，可想而知那车品质也好不到哪里去。第二类车行呢可以考虑，不过也要对比价格和提供的服务，比如有些车行不提供完善的保修服务，这种情况就得看你能不能接受了。第三类车行肯定是强烈推荐的，但是呢也分好坏，据我朋友说他见过最好的是墨尔本东部某起亚4s店，提供5年全车部件的保修，还包括卖车时候的蒸汽清洁和全新轮胎。 接下来是私人二手车了，一般先在网上找到自己喜欢的二手车，然后约车主出来看车，一般建议约学校附近或者住宅区附近，千万别太偏僻了，女孩子家最好多找几个人陪同。如果有朋友懂车，那是最好的，让他陪你一起去看。 4、接下来的步骤非常重要 01、挑选好自己喜欢的车之后，根据车辆的Registration Number上MyRTA(RTA 是Roads &amp; Traffic Authority的简称)的网站花费25刀查阅该车辆的历史纪录，重点查看其有无重大事故发生(Written-Off)，以及车主记录——“前任”越少越好。 02、检查车辆的保养记录(Service Logbook)，查看车辆是否按期保养。 03、记得查看和拍照保存车主的身份证和车子的Rego(汽车上路缴的路费单)，检查名字是否一致，同时记下相关信息，方便以后查询。 04、二手车的牌照，在汽车转手时也需要从卖主转到卖主。卖主需要在交易完成时在Rego单背面签字，并尽快填写车辆过户表(Vehicle Registration Transfer Form)给买主，让其交到RTA完成车主转移。 05、过户要求带上驾照、驾照翻译件和护照(或学生卡)和地址的信件去路局进行过户。过户的时候购买价格可议根据自己需求而填写成交金额，因为过户费需要缴纳成交金额的百分比，所以成交金额填写的越高需要贡献给政府的税金也就越高。 06、由于RWC(去过户的时候强制要求的一张证明，差不多就是车辆的体检单，有效期为1个月，大部分汽车维修店可以做RWC证明)有效期仅为一个月，建议完成购买之后尽快去过户;如果买的是Dealer的车，一般都是Drive Away服务，就是交钱立马开走。如果是私人二手车，就得找维修店去做。 07、买完车之后记得一定要买汽车保险，不同的保险公司报价也不一样，可以多咨询多比较。澳洲的保险公司一般以RACV(不同州结尾不同)、AAMI、Allianz这三家公司为主。网上可以搜到不同的险种和价格，如果确定要买的话，直接打电话说你要买就好了，保险当时就生效。","categories":[],"tags":[{"name":"Car","slug":"Car","permalink":"http://blog.ozairs.com/tags/Car/"}],"keywords":[]},{"title":"Serverless Overview","slug":"Serverless-Overview","date":"2019-01-26T10:58:05.000Z","updated":"2019-01-27T04:53:20.340Z","comments":true,"path":"uncategorized/Serverless-Overview/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Serverless-Overview/","excerpt":"","text":"今年有人提出了2018年微服务将疯狂至死，可见微服务的争论从未停止过。在这我将自己对微服务的理解整理了一下，希望对大家有所帮助。 1.什么是微服务 1）一组小的服务（大小没有特别的标准，只要同一团队的工程师理解服务的标识一致即可）2）独立的进程（java的tomcat，nodejs等）3）轻量级的通信（不是soap，是http协议）4）基于业务能力（类似用户服务，商品服务等等）5）独立部署（迭代速度快）6）无集中式管理（无须统一技术栈，可以根据不同的服务或者团队进行灵活选择）ps：微服务的先行者Netflix公司，开源了一些好的微服务框架，后续会有介绍。 怎么权衡微服务的利于弊 利：强模块边界 。（模块化的演化过程：类–&gt;组件/类库（sdk）–&gt;服务(service)，方式越来越灵活）可独立部署。技术多样性。弊：分布式复杂性。最终一致性。（各个服务的团队，数据也是分散式治理，会出现不一致的问题）运维复杂性。测试复杂性。 企业在什么时候考虑引入微服务 从生产力和系统的复杂性这两个方面来看。公司一开始的时候，业务复杂性不高，这时候是验证商业模式的时候，业务简单，用单体服务反而生产力很高。随着公司的发展，业务复杂性慢慢提高，这时候就可以采用微服务来提升生产力了。至于这个转化的点，需要团队的架构师来进行各方面衡量，就个人经验而言，团队发展到百人以上，采用微服务就很有必要了。有些架构师是具有微服务架构能力，所以设计系统时就直接设计成了微服务，而不是通过单服务慢慢演化发展成微服务。在这里我并不推荐这种做法，因为一开始对业务领域并不是很了解，并且业务模式还没有得到验证，这时候上微服务风险比较高，很有可能失败。所以建议大家在单服务的应用成熟时，并且对业务领域比较熟悉的时候，如果发现单服务无法适应业务发展时，再考虑微服务的设计和架构。4.微服务的组织架构 如上图左边，传统的企业中，团队是按职能划分的。开发一个项目时，会从不同的职能团队找人进行开发，开发完成后，再各自回到自己的职能团队，这种模式实践证明，效率还是比较低的。如上图右边，围绕每个业务线或产品，按服务划分团队。团队成员从架构到运维，形成一个完整的闭环。一直围绕在产品周围，进行不断的迭代。不会像传统的团队一样离开。这样开发效率会比较高。至于这种团队的规模，建议按照亚马逊的两个披萨原则，大概10人左右比较好。5：怎么理解中台战略和微服务 中台战略的由来：马云2015年去欧洲的一家公司supersell参观，发现这个公司的创新能力非常强，团队的规模很小，但是开发效率很高。他们就是采用中台战略。马云感触很深，回国后就在集团内部推出了中台战略。 简单的理解就是把传统的前后台体系中的后台进行了细分。阿里巴巴提出了大中台小前台的战略。就是强化业务和技术中台，把前端的应用变得更小更灵活。当中台越强大，能力就越强，越能更好的快速响应前台的业务需求。打个比喻，就是土壤越肥沃，越适合生长不同的生物，打造好的生态系统。6：服务分层 每个公司的服务分层都不相同，有的公司服务没有分层，有的怎分层很多。目前业界没有统一的标准。下面推荐一个比较容易理解的两层结构。 1：基础服务： 比如一个电商网站，商品服务和订单服务就属于基础服务（核心领域服务）。缓存服务，监控服务，消息队列等也属于基础服务（公共服务）2：聚合服务 ：例如网关服务就算一种聚合服务（适配服务）。这是一种逻辑划分，不是物理划分，实际设计的东西很多很复杂。7：微服务的技术架构体系 下图是一个成型的互联网微服务的架构体系： 1：接入层 负载均衡作用，运维团队负责2：网关层 反向路由，安全验证，限流等3：业务服务层 基础服务和领域服务4：支撑服务层5：平台服务6：基础设施层 运维团队负责。（或者阿里云）8：微服务的服务发现的三种方式 第一种：如下图所示，传统的服务发现（大部分公司的做法）。服务上线后，通知运维，申请域名，配置路由。调用方通过dns域名解析，经过负载均衡路由，进行服务访问。缺点： LB的单点风险，服务穿透LB，性能也不是太好 第二种：也叫客户端发现方式。如下图所示。通过服务注册的方式，服务提供者先注册服务。消费者通过注册中心获取相应服务。并且把LB的功能移动到了消费者的进程内，消费者根据自身路由去获取相应服务。优点是，没有了LB单点问题，也没有了LB的中间一跳，性能也比较好。但是这种方式有一个非常明显的缺点就是具有非常强的耦合性。针对不同的语言，每个服务的客户端都得实现一套服务发现的功能。 第三种：也叫服务端发现方式，如下图所示。和第二种很相似。但是LB功能独立进程单独部署，所以解决了客户端多语言开发的问题。唯一的缺点就是运维成比较高，每个节点都得部署一个LB的代理，例如nginx。 9.微服务网关 网关就好比一个公司的门卫。屏蔽内部细节，统一对外服务接口。 下图是一个网关所处位置的示例图。 10：Netflix Zuul网关介绍 核心就是一个servlet，通过filter机制实现的。主要分为三类过滤器：前置过滤器，过滤器和后置过滤器。主要特色是，这些过滤器可以动态插拔，就是如果需要增加减少过滤器，可以不用重启，直接生效。原理就是：通过一个db维护过滤器（上图蓝色部分），如果增加过滤器，就将新过滤器编译完成后push到db中，有线程会定期扫描db，发现新的过滤器后，会上传到网关的相应文件目录下，并通知过滤器loader进行加载相应的过滤器。 整个网关调用的流程上图从左变http Request开始经过三类过滤器，最终到最右边的Http Response，这就是Zull网关的整个调用流程。11：微服务的路由发现体系 整个微服务的路由发现体系，一般由服务注册中心和网关两部分组成。以NetFlix为例子，Eureka和Zull这两个组件支撑了netFlix整个的路由发现体系。如下图所示，首先外部请求发送到网关，网关去服务注册中心获取相应的服务，进行调用。其次内部服务间的调用，也通过服务注册中心进行的 12.微服务配置中心 目前大部分公司都是把配置写到配置文件中，遇到修改配置的情况，成本很高。并且没有修改配置的记录，出问题很难追溯。配置中心就接解决了以上的问题。可配置内容：数据库连接，业务参数等等 配置中心就是一个web服务，配置人员通过后台页面修改配置，各个服务就会得到新的配置参数。实现方式主要有两种，一种是push，另一种是pull。两张方式各有优缺点。push实时性较好，但是遇到网络抖动，会丢失消息。pull不会丢失消息但是实时性差一些。大家可以同时两种方式使用，实现一个比较好的效果。如下图所示，这是一个国内知名互联网公司的配置中心架构图。 开源地址：http://github.com/ctripcorp/appollo13：RPC遇到了REST 内部一些核心服务，性能要求比较高的可以采用RPC，对外服务的一般可以采用rest。14：服务框架和治理 微服务很多的时候，就需要有治理了。一个好的微服务框架一般分为以下14个部分。如下图所示。这就是开篇所说的，微服务涉及的东西很多，有些初创公司和业务不成熟的产品是不太适合的，成本比较高。目前国内比较好的微服务框架就是阿里巴巴的DUBBO了,国外的就是spring cloud,大家可以去研究一下. 15：监控体系 监控是微服务治理的重要环节。一般分为以下四层。如下图所示。 监控的内容分为五个部分：日志监控，Metrics监控（服务调用情况），调用链监控，告警系统和健康检查。日志监控，国内常用的就是ELK+KAFKA来实现。健康检查和Metrics，像spring boot会自带。Nagios也是一个很好的开源监控框架。16:Trace调用链监控 调用链监控是用来追踪微服务之前依赖的路径和问题定位。例如阿里的鹰眼系统。主要原理就是子节点会记录父节点的id信息。 下图是目前比较流行的调用链监控框架。 17：微服务的限流熔断 假设服务A依赖服务B和服务C，而B服务和C服务有可能继续依赖其他的服务，继续下去会使得调用链路过长。如果在A的链路上某个或几个被调用的子服务不可用或延迟较高，则会导致调用A服务的请求被堵住，堵住的请求会消耗占用掉系统的线程、io等资源，当该类请求越来越多，占用的计算机资源越来越多的时候，会导致系统瓶颈出现，造成其他的请求同样不可用，最终导致业务系统崩溃。一般情况对于服务依赖的保护主要有两种方式：熔断和限流。目前最流行的就是Hystrix的熔断框架。下图是Hystrix的断路器原理图： 限流方式可以采用zuul的API限流方法。18.Docker 容器部署技术&amp;持续交付流水线 随着微服务的流行，容器技术也相应的被大家重视起来。容器技术主要解决了以下两个问题：1：环境一致性问题。例如java的jar/war包部署会依赖于环境的问题（操着系统的版本，jdk版本问题）。2：镜像部署问题。例如java，rubby，nodejs等等的发布系统是不一样的，每个环境都得很麻烦的部署一遍，采用docker镜像，就屏蔽了这类问题。下图是Docker容器部署的一个完整过程。 更重要的是，拥有如此多服务的集群环境迁移、复制也非常轻松，只需选择好各服务对应的Docker服务镜像、配置好相互之间访问地址就能很快搭建出一份完全一样的新集群。19.容器调度和发布体系 目前基于容器的调度平台有Kubernetes，mesos，omega。下图是mesos的一个简单架构示意图。 下图是一个完整的容器发布体系 在此我向大家推荐一个架构学习交流群。交流学习群号：478030634 里面会分享一些资深架构师录制的视频录像：有Spring，MyBatis，Netty源码分析，高并发、高性能、分布式、微服务架构的原理，JVM性能优化、分布式架构等这些成为架构师必备的知识体系。还能领取免费的学习资源，目前受益良多 大家觉得文章对你还是有一点点帮助的，大家可以点击下方二维码进行关注。 《Java烂猪皮》 公众号聊的不仅仅是Java技术知识，还有面试等干货，后期还有大量架构干货。大家一起关注吧！关注烂猪皮，你会了解的更多…………..","categories":[],"tags":[{"name":"Serverless","slug":"Serverless","permalink":"http://blog.ozairs.com/tags/Serverless/"}],"keywords":[]},{"title":"Use-of-Terraform","slug":"Terraform使用","date":"2019-01-12T23:49:25.000Z","updated":"2019-01-27T04:53:20.344Z","comments":true,"path":"uncategorized/Terraform使用/","link":"","permalink":"http://blog.ozairs.com/uncategorized/Terraform使用/","excerpt":"","text":"Terraform 是一个 IT 基础架构自动化编排工具，它的口号是 “Write, Plan, and create Infrastructure as Code”, 基础架构即代码。具体的说就是可以用代码来管理维护 IT 资源，比如针对 AWS，我们可以用它创建，修改，删除 S3 Bucket, Lambda, EC2 实例，Kinesis， VPC 等各种资源。并且在真正运行之前可以看到执行计划(即干运行-dryrun)。由于状态保存到文件中，因此能够离线方式查看资源情况 – 当然，前提是不要在 Terraform 之外对资源进行修改。 Terraform 配置的状态除了能够保存在本地文件中，也可以保存到 Consul, S3, azure, http, swift 等处。 Terraform 是一个高度可扩展的工具，通过 Provider 来支持新的基础架构，AWS 不过为目前官方内建 68 个 Providers 中的一个。其他能用 Terraform 的地方有 Alicloud(阿里云, 实名制备案才能用), Google Cloud, Heroku, Kubernetes, Microsoft Azure, MySQL, RabbitMQ, Docker 等等。愿意的话可以写自己的 Provider, 如搞个 Kafka 的话，用来管理 Topic 等的创建，维护工作。 Terraform 之前我们对 AWS 的操作用的是 awscli, 或 Serverless。awscli 什么都能做，但它是无状态的，必须明确用不同的命令来创建，修改和删除。Serverless 不是用来管理基础架构的，用它创建 Lambda 时创建资源都是很麻烦的事。AWS 提供的 CloudFormation 才是与 Terraform 较类似的工具，但是看到用法就头疼。 下面从最简单例子开始，看看怎么用 Terraform 创建，删改，修改 S3 Bucket。本地系统为 Mac OS。 \\1. Terraform 安装 brew install terraform 安装后 shell 命令就是 terraform, 常用的是 terraform init, terraform plan, terraform apply \\2. 创建配置文件 像 git 一样，每个 Terraform 项目需要自己单独的目录空间，所以我们创建一个 terraform-learning 目录 mkdir terraform-learning cd terraform-learning 该目录下的所有 .tf 文件都会被 Terraform 加载，在初始化 Terraform 工作空间之前必须至少要有一个 .tf 文件。我们这里建立文件 main.tf, 内容如下 Terraform 配置的语法是该公司 HashiCorp 独创的 HCL(HashiCorp configuration language), 它可以兼容 JSON 格式。 上面 tf 文件在 Vim 中的语法加亮是安装的 hashivim/vim-terraform 插件。 我们写好了 *.tf 文件后可以调用 terraform fmt 对配置文件进行格式化，它比较喜欢被 Java 弃用的等号对齐的格式。 \\3. 配置文件介绍 从正式跨入 terraform 命令正题之前先来大概的介绍一下上面那个 main.tf 文件。 1) provider “aws” 部分，它指定选用什么 provider, 以及验证信息。aws 既允许指定 access_key 和 secret_key provider “aws” { ​ region = “us-east-1” ​ access_key = “your-access-key-here” ​ secret_key = “your-secret-key-here” } 也能够指定证书文件中的 profile provider “aws” { ​ region = “us-east-1” ​ shared_credentials_file = “~/.aws/credentials” //不指定的话，默认值是 “~/.aws/credentials” ​ profile = “yanbin” //不指定的话，默认值是 “default” } 如果是使用 shared_credentials_file 中的 profile, 请确定您以预先生成好的 credentials 文件及有效的 profile。 更多关于 AWS Provider 的配置请参考 https://www.terraform.io/docs/providers/aws/index.html 2) resource “aws_s3_bucket” “s3_bucket” 部分 这只是我们今天举的一个小例子，点击链接 aws_s3_bucket 查看 S3 Bucket 所有的配置项。Terraform 能够管理的所有 AWS 资源也能从前面那个链接中看到。 如果 bucket yanbin-test-bucket 不存在的话，运行 terraform apply 将会创建它，否则试图更新该 bucket。此例子只指定了 bucket 的 acl 和 tag 信息。terraform destroy 用来删除已存在的 bucket。 注意：terraform 配置文件中只指定要管理的资源对象，并不关心操作资源的行为–创建，修改，删除操作。操作行为与 Terraform 的状态有关系，无则创建，有则修改，更名会拆分为除旧立新两个操作，terraform destroy 用于显式删除资源。后面实例操作时会讲到。 注：resource “aws_s3_bucket” “s3_bucket” { 中，resource 后第一个是 type, 即资源名，第二个参是 name。其实 “s3_bucket” 在这里没什么用，只是一个描述或助记符而已。(2017-08-28): 更正一下，在作为变量引用的时候就要用到它，例如在后面要为 Lambda 创建一个 S3 Event 的 Trigger, 就要写成 event_source_arn = “${aws_s3_bucket.s3_bucket.arn}”, 引用时不需要知道实际的名称。 \\4. 初始化工作目录 在初始化 Terraform 工作目录之前， 其他命令如 apply, plan 多是不可用的，提示需要初始化工作目录，命令是 terraform init 它要做的事情像是 git init 加上 npm install，执行完了 terraform init 之后会在当前目录中生成 .terraform 目录，并依照 *.tf 文件中的配置下载相应的插件。 \\5. 执行 Terraform 管理命令 有了前面的准备之后，终于可以开始运行 Terraform 的管理命令了。Terraform 在正式执行之前提供了预览执行计划的机会，让我们清楚的了解将要做什么 terraform plan 由此计划还能知道关于 aws_s3_bucket 有些什么配置项，比如配置中可以加上 acceleration_status = “Enabled” terraform apply 这样便在 AWS 上创建了一个 S3 bucket “yanbin-test-bucket”, 同时会在当前目录中生成一个状态文件 terraform.tfstate, 它是一个标准的 JSON 文件。这个文件对 Terraform 来说很重要，它会影响 terraform plan 的决策，虽然不会影响到实际的执行效果。我们可以把它存到远端，如 S3 或 Consul。terraform state [list|mv|pull|push|rm|show] 用来操作状态文件。 此时什么也不改，再次执行 terraform plan, 会显示没什么要做的 aws_s3_bucket.s3_bucket: Refreshing state… (ID: yanbin-test-bucket) No changes. Infrastructure is up-to-date. 如果对 main.tf 作点小改，改个 tag 属性，再次 terraform plan ~ aws_s3_bucket.s3_bucket tags.Name: “Created by Terraform” =&gt; “sCreated by Terraform” Plan: 0 to add, 1 to change, 0 to destroy. 为什么说 terraform plan 是基于状态文件 terraform.tfstate 作出的呢？我们可以删除这个状态文件，然后执行 terraform plan 看看 + aws_s3_bucket.s3_bucket ​ ….. ​ bucket: “yanbin-test-bucket” ​ …… ​ tags.Environment: “QA” ​ …… Plan: 1 to add, 0 to change, 0 to destroy. Terraform 由于缺乏 terraform.tfstate 对比，所以认为是要添加一个 bucket, 但是实际执行 terraform apply 时，连接到远端 AWS, 发现该 bucket 已存在就只是进行更新。terraform apply 总能给出正确的操作结果。同理如果状态文件中说有那个 bucket, terraform plan 会说是更新，但 AWS 没有那个 bucket，实际执行 terraform apply 也会进行添加的。 资源更名 如果把 main.tf 中的 bucket = “yanbin-test-bucket” 改成 bucket = “yanbin-test-bucket-rename” 即欲为 bucket 更名，用 terraform plan 看下计划 实际上 terraform apply 也是先删除旧的，再创建新的。Terraform 像 git 一样用不同颜色和 +/- 号来显示变动操作 最后是 terraform destroy 命令，把 *.tf 文件中配置的所有资源从 AWS 上清理掉。 关于 Terraform 工作目录中文件命名 Terraform 运行时会读取工作目录中所有的 .tf, .tfvars 文件，所以我们不必把所有的东西都写在单个文件中去，应按职责分列在不同的文件中，例如： provider.tf – provider 配置 terraform.tfvars – 配置 provider 要用到的变量 varable.tf – 通用变量 resource.tf – 资源定义 data.tf – 包文件定义 output.tf – 输出 以此篇最简单的入门出发，以后可以深入了解 Lambda, Lambda 触发器，及 API Gateway, EC2 实例怎么用 Terraform 来管理，也知晓了资源的可用属性应该到哪里去查。 一个小提示：在执行像 terraform plan 或 terraform apply 等命令的时候，可以按下 ctrl + c 让控制台输出详细的日志信息。","categories":[],"tags":[{"name":"Cloud","slug":"Cloud","permalink":"http://blog.ozairs.com/tags/Cloud/"}],"keywords":[]},{"title":"djy","slug":"djy","date":"2019-01-12T03:30:18.000Z","updated":"2019-01-27T04:53:20.338Z","comments":true,"path":"uncategorized/djy/","link":"","permalink":"http://blog.ozairs.com/uncategorized/djy/","excerpt":"","text":"Hello world. This is my first blog.","categories":[],"tags":[],"keywords":[]}]}