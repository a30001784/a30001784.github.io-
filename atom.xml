<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>带你走进美丽的墨尔本</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.ozairs.com/"/>
  <updated>2020-02-02T09:13:45.881Z</updated>
  <id>http://blog.ozairs.com/</id>
  
  <author>
    <name>Mark Wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何选择合适的实例</title>
    <link href="http://blog.ozairs.com/Security/%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%AE%9E%E4%BE%8B/"/>
    <id>http://blog.ozairs.com/Security/如何选择合适的实例/</id>
    <published>2020-02-02T09:09:19.000Z</published>
    <updated>2020-02-02T09:13:45.881Z</updated>
    
    <content type="html"><![CDATA[<p>原文链接：<a href="https://mark-41.gitbook.io/-1/" target="_blank" rel="noopener"><a href="https://mark-41.gitbook.io/-1/" target="_blank" rel="noopener">https://mark-41.gitbook.io/-1/</a></a></p><p>【概述】</p><p>正确调整实例大小是使实例类型和大小与您的工作负载性能和容量要求相匹配的过程，并且成本要尽可能低。 这也是查看已部署实例并确定在不损害容量或其他要求的情况下消除或缩减规模的机会的过程，从而降低了成本。</p><p>正确调整大小是优化AWS成本的关键机制，但组织在首次迁移到AWS云时通常会忽略它。 他们举起并改变了他们的环境，并期望稍后再调整大小。 速度和性能通常要优先于成本，这会导致实例过大并浪费大量未使用的资源。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原文链接：&lt;a href=&quot;https://mark-41.gitbook.io/-1/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;a href=&quot;https://mark-41.gitbook.io/-1/&quot; target=&quot;_blank&quot; rel
      
    
    </summary>
    
      <category term="Security" scheme="http://blog.ozairs.com/categories/Security/"/>
    
    
      <category term="Security" scheme="http://blog.ozairs.com/tags/Security/"/>
    
  </entry>
  
  <entry>
    <title>AWS云安全介绍</title>
    <link href="http://blog.ozairs.com/Security/AWS%E4%BA%91%E5%AE%89%E5%85%A8%E4%BB%8B%E7%BB%8D/"/>
    <id>http://blog.ozairs.com/Security/AWS云安全介绍/</id>
    <published>2020-02-01T11:22:16.000Z</published>
    <updated>2020-02-01T11:29:27.706Z</updated>
    
    <content type="html"><![CDATA[<p>这是AWS官方提供的关于AWS云安全的介绍文档，具体链接参见：<a href="https://156709406.gitbook.io/aws-1/" target="_blank" rel="noopener">https://156709406.gitbook.io/aws-1/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是AWS官方提供的关于AWS云安全的介绍文档，具体链接参见：&lt;a href=&quot;https://156709406.gitbook.io/aws-1/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://156709406.gitbook.io/
      
    
    </summary>
    
      <category term="Security" scheme="http://blog.ozairs.com/categories/Security/"/>
    
    
      <category term="Security" scheme="http://blog.ozairs.com/tags/Security/"/>
    
  </entry>
  
  <entry>
    <title>Why We Moved to Apache Pulsar</title>
    <link href="http://blog.ozairs.com/Apache/Why-We-Moved-to-Apache-Pulsar/"/>
    <id>http://blog.ozairs.com/Apache/Why-We-Moved-to-Apache-Pulsar/</id>
    <published>2019-10-25T11:35:44.000Z</published>
    <updated>2019-10-25T11:59:34.248Z</updated>
    
    <content type="html"><![CDATA[<p>Nowadays, we may need to interact with millions of consumers every day through the retailers we serve. <strong>Consumers</strong> rely on us for timely reminders and updates on their accounts, on the state of their orders and packages, and on the status of their returns. On the other hand, <strong>our business customers</strong> — hundreds of the biggest retailers and brands in the world — rely on us for flexibility to configure Narvar’s product for the needs of their consumers. </p><p>Our platform helps retailers and brands by processing data and events to ensure timely and accurate communication with their customers. To handle that, we built our platform using a variety of messaging and processing technologies over time, from Kafka to Amazon SQS, Kinesis Streams to Kinesis Firehose, RabbitMQ to AWS Lambda. Many of these systems were native to AWS and easy to adopt and get up and running. These systems worked well and they served our needs…for a while.</p><p><img src="/Apache/Why-We-Moved-to-Apache-Pulsar/1.png" alt=""></p><h2 id="Our-Challenges"><a href="#Our-Challenges" class="headerlink" title="Our Challenges"></a>Our Challenges</h2><p>As the company grew and <strong>new business use cases</strong> began to emerge, we found these systems didn’t quite work as well as needed to address the new and expanded requirements of those use cases. As we grew our customer base it became clear it was not easy to process events in configurable ways that scaled accordingly. As we saw more applications needing to consume events, it required spinning up new services that entailed maintenance overhead or using expensive Amazon Lambdas. For other business cases that emerged, we saw that Kinesis Firehose did not provide the flexibility needed to output data in the form and structure that was required. As we saw a growing number of use cases that required strong in-order guarantees and topic scalability, it became clear that many of the solutions we were using were not suited for those new challenges.</p><p><img src="/Apache/Why-We-Moved-to-Apache-Pulsar/2.png" alt=""></p><p>In addition to these challenges from emerging business use cases, we also saw <strong>challenges of scale</strong>. As our traffic grew, it became apparent that the growing amount of DevOps and developer support required to maintain and scale these systems was unsustainable. Many of them were not containerized, making infrastructure configuration and management burdensome, and required frequent manual intervention. </p><p>Systems like Kafka — while reliable, popular and open source — had significant maintenance overhead as we scaled. For example, increasing throughput required increasing partitions, tuning consumers, and required a large amount of manual intervention by developers and DevOps. At the same time, solutions like Kinesis Streams and Kinesis Firehose were not cloud-agnostic, making it hard to decouple the choice of cloud solutions from functionality and making it difficult to leverage technologies in other clouds, and to support customers who needed to run in other clouds.</p><p>Faced with the challenges of these emerging business cases and the hassles that we were encountering as we scaled, we decided to move to Apache Pulsar.</p><h2 id="Why-Apache-Pulsar"><a href="#Why-Apache-Pulsar" class="headerlink" title="Why Apache Pulsar"></a>Why Apache Pulsar</h2><p>Like Kafka, Pulsar was reliable, cloud-agnostic and open-sourced. Unlike Kafka, Pulsar entailed very little maintenance overhead and scaled with minimal manual intervention. Pulsar was containerized and built on Kubernetes (ie. is ‘cloud native’) from the outset, and while it had multiple complex components within, it was easy to spin up and scale with the help of the Streamlio team. Version upgrades were easy to apply to a given cluster without much incurred downtime. Streamlio provided us with system monitoring dashboards (based on Grafana) making it easy to monitor out of the box.</p><p>In addition to being scalable and much more maintainable, Pulsar came with differentiating features that made several of our business use cases possible. For example, we gained access to Pulsar Functions, which helped us scale up the number of things we did with the consumed events while eliminating the need for expensive Lambda functions or standing up additional services. Stronger support for in-order guarantees within a topic enabled several more business use cases.</p><p><img src="/Apache/Why-We-Moved-to-Apache-Pulsar/3.png" alt=""></p><p>Finally, Pulsar provided a broad set of features and functionalities all in one system, thus eliminating the need for many of the point solutions we had been using. It eliminated the need for multiple messaging technologies — Kafka for pub/sub and RabbitMQ and Amazon SQS for queueing. Also, we no longer required Kinesis Streams for processing nor Kinesis Firehose to load streaming data into data stores. Moving from this list of technologies to Pulsar helped us reduce cost and complexity as well as make it easier to support other cloud infrastructure providers. Narvar has been using Pulsar live in production for close to a year now and it has proven to be a very reliable workhorse.</p><p>【译文】</p><p>现今，我们正日益面临着每天需要通过服务的零售商与数百万消费者互动的情形。<strong>消费者</strong>依赖我们的及时提醒和更新其帐户，订单和包裹的状态以及退货的状态。另一方面，<strong>我们的商业客户</strong>-世界上数百个最大的零售商和品牌- 依靠我们来灵活地配置产品以满足其消费者的需求。 </p><p>我们的平台通过处理数据和事件来帮助零售商和品牌，以确保与他们的客户及时，准确地沟通。为了解决这个问题，我们随着时间的推移使用了各种消息传递和处理技术来构建平台，从Kafka到Amazon SQS，从Kinesis Streams到Kinesis Firehose，从RabbitMQ到AWS Lambda。这些系统中的许多系统是AWS固有的，易于采用，启动和运行。这些系统运行良好，可以在一段时间内满足我们的需求。</p><h2 id="我们的挑战"><a href="#我们的挑战" class="headerlink" title="我们的挑战"></a>我们的挑战</h2><p>但是，随着公司的发展和<strong>新业务用例的发展</strong>，我们发现这些系统不能很好地满足那些用例的新需求和扩展需求。随着我们扩大客户群，很明显，想要使用可扩展的方式配置事件并不容易。随着我们看到更多需要消耗事件的应用程序，它需要分解新的服务，这需要维护费用或使用昂贵的Amazon Lambda。对于出现的其他业务案例，我们看到Kinesis Firehose没有提供以所需形式和结构输出数据所需的灵活性。随着我们看到越来越多的用例需要强大的有序保证能力和主题可伸缩性，很明显，我们使用的许多解决方案都不适合这些新挑战。</p><p>除了新兴业务用例带来的这些挑战之外，我们还需要应对快速增长的业务规模所带来的挑战。随着流量的增长，很明显，维持和扩展这些系统所需的DevOps和开发人员支持的增长是不可持续的。其中许多没有进行容器化，使得基础结构配置和管理负担沉重，需要频繁的手动干预。 </p><p>像Kafka这样的系统虽然可靠，流行且开源，但维护费用却很大。例如，增加吞吐量需要增加分区，调整使用者，并需要开发人员和DevOps进行大量手动干预。同时，诸如Kinesis Streams和Kinesis Firehose之类的解决方案都与云密切相关，这使得很难将云解决方案的选择与功能脱钩，并且难以利用其他云的技术，难以为需要在除AWS以外其他云上运行服务的客户提供技术支持。。</p><p>面对这些新兴业务案例的挑战以及在扩展过程中遇到的麻烦，我们决定迁移到Apache Pulsar。</p><h2 id="为什么选择Apache-Pulsar"><a href="#为什么选择Apache-Pulsar" class="headerlink" title="为什么选择Apache Pulsar"></a>为什么选择Apache Pulsar</h2><p>像Kafka一样，Pulsar是可靠的，支持多种云平台，并且是开源的。与Kafka不同，Pulsar的维护费用非常少，并且只需很少的人工干预即可扩展。Pulsar从一开始就被容器化并构建在Kubernetes上（即“云原生”），尽管其中包含多个复杂组件，但在Streamlio团队的帮助下很容易扩展和扩展。 版本升级很容易 应用于给定集群，而不会造成大量停机。Streamlio为我们提供了系统监视仪表板（基于Grafana），可轻松进行开箱即用的监视。</p><p>除了具有可扩展性和可维护性之外，Pulsar还具有与众不同的功能，这些功能使我们的多个业务用例成为可能。例如，我们获得了对Pulsar函数的访问权限，这有助于我们扩展已处理事件的处理数量，同时消除了对昂贵的Lambda函数或者启动的其他服务的需求。主题内部对于顺序保证的强大支持能力使更多的业务用例得以实现。</p><p>最终，Pulsar在一个系统中提供了广泛的特性和功能，从而消除了我们一直在使用的许多解决方案的需求。它消除了对多种消息传递技术的需求-用于发布/订阅和RabbitMQ的Kafka和用于队列的Amazon SQS。同样，我们不再需要Kinesis Streams进行处理，也不再需要Kinesis Firehose将流数据加载到数据存储中。将技术堆栈转移到Pulsar，不仅帮助我们降低了成本和复杂性，而且使得支撑其他云平台的工作变得更加轻松。我们在生产中使用Pulsar已有近一年的时间，事实证明它是非常可靠的主力。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Nowadays, we may need to interact with millions of consumers every day through the retailers we serve. &lt;strong&gt;Consumers&lt;/strong&gt; rely on
      
    
    </summary>
    
      <category term="Apache" scheme="http://blog.ozairs.com/categories/Apache/"/>
    
    
      <category term="Apache Pulsar" scheme="http://blog.ozairs.com/tags/Apache-Pulsar/"/>
    
  </entry>
  
  <entry>
    <title>什么是Kops?</title>
    <link href="http://blog.ozairs.com/Kubernetes/%E4%BB%80%E4%B9%88%E6%98%AFKops/"/>
    <id>http://blog.ozairs.com/Kubernetes/什么是Kops/</id>
    <published>2019-09-25T12:27:50.000Z</published>
    <updated>2019-09-25T12:36:53.182Z</updated>
    
    <content type="html"><![CDATA[<p>今天，我们将以我们最近对<a href="https://cloudacademy.com/blog/kubernetes-ecosystem-operations/" target="_blank" rel="noopener"><strong>Kubernetes生态系统的</strong></a>报道为基础，以更深入地讨论Kops。这篇文章是对我们<a href="https://cloudacademy.com/webinars/hands-kubernetes-part-1-38/" target="_blank" rel="noopener">今年</a>早些时候的<a href="https://cloudacademy.com/webinars/hands-kubernetes-part-1-38/" target="_blank" rel="noopener">Kubernetes网络研讨会</a>的补充，并且是在之前的文章中介绍的，这些文章涵盖了  <a href="https://cloudacademy.com/deploying-kubernetes-applications-with-helm/" target="_blank" rel="noopener">使用Helm部署应用程序</a>  以及使用Kops 创建和维护<a href="https://cloudacademy.com/blog/category/kubernetes/" target="_blank" rel="noopener">Kubernetes</a>集群。让我们首先解决一个基本问题：什么是Kops？</p><h2 id="什么是Kops？"><a href="#什么是Kops？" class="headerlink" title="什么是Kops？"></a>什么是Kops？</h2><p><a href="https://github.com/kubernetes/kops" target="_blank" rel="noopener">Kops是Kubernetes的官方项目，</a>用于管理生产级Kubernetes集群。Kops当前是将Kubernetes集群部署到Amazon Web Services的最佳工具。该项目将自己描述为集群的kubectl。</p><p><a href="https://github.com/kubernetes/kops" target="_blank" rel="noopener">(Kops is an official Kubernetes project</a> for managing production-grade Kubernetes clusters. Kops is currently the best tool to deploy Kubernetes clusters to Amazon Web Services. The project describes itself as kubectl for clusters.)</p><p>如果您熟悉kubectl，那么Kops会让您感到宾至如归。它具有创建集群，更新集群设置和应用更改的命令。Kops使用声明性配置，因此足够聪明，知道如何将基础结构更改应用于现有集群。它还支持集群操作任务，例如扩展节点或水平扩展集群。Kops可以在AWS上自动运行大部分Kubernetes。</p><p>在继续进行示例之前，让我们看一下它的主要功能：</p><ul><li>将群集部署到现有的虚拟私有云（VPC）或从头开始创建新的VPC</li><li>支持公共和私有拓扑</li><li>设置单个或多个主群集</li><li>可配置的堡垒机器，用于通过SSH访问单个群集节点</li><li>建立在状态同步模型上以实现空运行和自动幂等</li><li>直接基础架构操纵，或与CloudFormation和Terraform一起使用</li><li>滚动集群更新</li><li>通过创建多个实例组来支持异构集群</li></ul><p>请查看此  <a href="https://asciinema.org/a/97298" target="_blank" rel="noopener">简短的ASCII转换演示</a>  以获取更多信息。<br>现在，我们将解决一个常见的情况：创建一个集群并为您的用例进行配置。</p><h3 id="在AWS上创建第一个Kubernetes集群"><a href="#在AWS上创建第一个Kubernetes集群" class="headerlink" title="在AWS上创建第一个Kubernetes集群"></a>在AWS上创建第一个Kubernetes集群</h3><p>您需要配置IAM权限和的S3存储桶<code>KOPS_STATE_STORE</code>。KOPS_STATE_STORE是Kops管理的所有集群的真实来源。您需要适当的IAM权限，以便Kops可以代表您进行API调用。我不会在这篇文章中介绍它，但是您可以按照<a href="https://github.com/kubernetes/kops/blob/master/docs/aws.md" target="_blank" rel="noopener">此处</a>的<a href="https://github.com/kubernetes/kops/blob/master/docs/aws.md" target="_blank" rel="noopener">说明进行操作</a>。</p><p>您还需要配置DNS。Kops支持多种配置。每个都有自己的<a href="https://github.com/kubernetes/kops/blob/master/docs/aws.md" target="_blank" rel="noopener">设置说明</a>。具有现有HostedZone的AWS Route53是最简单的。<code>slashdeploy.com</code>在这些示例中，我们假设有一个现有的AWS Route53 HostedZone 。<br>Kops群集必须是有效的DNS名称。让我们创建<code>demo.slashdeploy.com</code>集群。Kops还将在<code>api.demo.slashdeploy.com</code>和处为Kubernetes API服务器创建DNS记录<code>bastion.demo.slashdeploy.com</code>。请记住，DNS名称可能只有这么长，因此请勿使用太长的基本群集名称。一切始于<code>kops create</code>。您可以将选项直接传递给命令或编写<a href="https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md" target="_blank" rel="noopener">集群规范文件</a>。在本练习中，我们将使用命令行选项。使用专用文件非常适合源代码控制和其他形式的配置管理。<code>kops create</code>接受很多选择。我们将从最简单的情况开始，仅提供所需的选项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kops create cluster \</span><br><span class="line">--yes \</span><br><span class="line">--zones=eu-west-1a,eu-west-1b,eu-west-1c \</span><br><span class="line">demo.slashdeploy.com</span><br></pre></td></tr></table></figure><p>有两个必需的值。<code>--zones</code>指出GCP区域/ AWS地区在何处创建基础架构。在此，指定了eu-west-1a，eu-west-1b，eu-west-1c。这指示Kops在每个eu-west-1可用区中创建基础结构。这很重要，因为Kops旨在创建高可用性生产集群。多个可用区通过防止一个可用区中的故障使群集更加可靠。</p><p>您还必须指定群集名称。<code>--yes</code>确认通常提示确认的操作。为新集群<code>kops create</code> 添加一个<code>kubectl</code>配置条目，因此您可以立即使用它。该命令是异步的。它会触发<strong>基础结构的创建</strong>，但不会完全阻止它。幸运的是，Kops包含用于验证集群的命令。您可以  <em>重新运行</em>此命令，直到成功为止。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kops validate demo.slashdeploy.com</span><br></pre></td></tr></table></figure><p>一切完成后，您应该会看到类似以下内容的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kops validate cluster demo.slashdeploy.com</span><br><span class="line">Validating cluster demo.slashdeploy.com</span><br><span class="line">INSTANCE GROUPS</span><br><span class="line">NAME                    ROLE    MACHINETYPE     MIN     MAX     SUBNETS</span><br><span class="line">master-eu-west-1a       Master  m3.medium       1       1       eu-west-1a</span><br><span class="line">master-eu-west-1b       Master  m3.medium       1       1       eu-west-1b</span><br><span class="line">master-eu-west-1c       Master  m3.medium       1       1       eu-west-1c</span><br><span class="line">nodes                   Node    t2.medium       2       2       eu-west-1a,eu-west-1b,eu-west-1c</span><br><span class="line">NODE STATUS</span><br><span class="line">NAME                                            ROLE    READY</span><br><span class="line">ip-172-20-120-240.eu-west-1.compute.internal    master  True</span><br><span class="line">ip-172-20-50-132.eu-west-1.compute.internal     master  True</span><br><span class="line">ip-172-20-66-106.eu-west-1.compute.internal     master  True</span><br><span class="line">ip-172-20-75-89.eu-west-1.compute.internal      node    True</span><br><span class="line">Your cluster demo.slashdeploy.com is ready</span><br></pre></td></tr></table></figure><p>现在，您可以运行任何<code>kubectl</code>命令，例如<code>kubectl get pods -n kube-system</code>。集群有点奇怪，因为它有三个主服务器，只有一个从服务。让我们更新节点实例组。</p><h3 id="修改集群基础架构"><a href="#修改集群基础架构" class="headerlink" title="修改集群基础架构"></a>修改集群基础架构</h3><p>记住，<code>kops</code>行为就像<code>kubectl</code>。这意味着您可以<code>kops edit</code>在编辑器中编辑配置文件。下一步是运行<code>kops update</code>。这将应用配置更改，但不会修改正在运行的基础结构。<code>kops rolling-update</code>管理更新或重新创建基础结构。</p><p>此过程适用于各种配置更改。首先<code>edit</code>，然后<code>update</code>，最后   <code>rolling-update</code>。让我们通过编辑节点实例组以增加辅助节点的数量来尝试一下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kops edit instancegroup nodes</span><br></pre></td></tr></table></figure><p>这将在编辑器中打开一个YAML文件。您将看到类似于以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kops/v1alpha2</span><br><span class="line">kind: InstanceGroup</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: &quot;2017-04-05T15:33:52Z&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kops.k8s.io/cluster: demo.slashdeploy.com</span><br><span class="line">  name: nodes</span><br><span class="line">spec:</span><br><span class="line">  image: kope.io/k8s-1.5-debian-jessie-amd64-hvm-ebs-2017-01-09</span><br><span class="line">  machineType: t2.medium</span><br><span class="line">  maxSize: 1</span><br><span class="line">  minSize: 1</span><br><span class="line">  role: Node</span><br><span class="line">  subnets:</span><br><span class="line">  - eu-west-1a</span><br><span class="line">  - eu-west-1b</span><br><span class="line">  - eu-west-1c</span><br></pre></td></tr></table></figure><p>我们需要做的就是替换<code>minSize</code> 并<code>maxSize</code> 使用适当的值。我将两个值都设置为<code>3</code> 并保存文件。这会将更新的文件写回到<code>KOPS_STATE_STORE</code>。现在，我们需要<code>update</code> 集群。同样，我们将提供<code>--yes</code> 确认更改。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kops update cluster --yes</span><br><span class="line">Using cluster from kubectl context: demo.slashdeploy.com</span><br><span class="line">I0422 07:34:58.458492   26834 executor.go:91] Tasks: 0 done / 114 total; 35 can run</span><br><span class="line">I0422 07:34:59.990241   26834 executor.go:91] Tasks: 35 done / 114 total; 26 can run</span><br><span class="line">I0422 07:35:01.211466   26834 executor.go:91] Tasks: 61 done / 114 total; 36 can run</span><br><span class="line">I0422 07:35:04.215344   26834 executor.go:91] Tasks: 97 done / 114 total; 10 can run</span><br><span class="line">I0422 07:35:04.845173   26834 dnsname.go:107] AliasTarget for &quot;api.demo.slashdeploy.com.&quot; is &quot;api-demo-1201911436.eu-west-1.elb.amazonaws.com.&quot;</span><br><span class="line">I0422 07:35:05.045363   26834 executor.go:91] Tasks: 107 done / 114 total; 7 can run</span><br><span class="line">I0422 07:35:05.438759   26834 executor.go:91] Tasks: 114 done / 114 total; 0 can run</span><br><span class="line">I0422 07:35:05.438811   26834 dns.go:140] Pre-creating DNS records</span><br><span class="line">I0422 07:35:06.707548   26834 update_cluster.go:204] Exporting kubecfg for cluster</span><br><span class="line">Wrote config for demo.slashdeploy.com to &quot;/home/ubuntu/.kube/config&quot;</span><br><span class="line">Kops has set your kubectl context to demo.slashdeploy.com</span><br><span class="line">Cluster changes have been applied to the cloud.</span><br><span class="line">Changes may require instances to restart: kops rolling-update cluster</span><br></pre></td></tr></table></figure><p>最后，应用<code>rolling-update</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kops rolling-update cluster --yes</span><br><span class="line">Using cluster from kubectl context: demo.slashdeploy.com</span><br><span class="line">NAME                    STATUS  NEEDUPDATE      READY   MIN     MAX     NODES</span><br><span class="line">bastions                Ready   0               1       1       1       0</span><br><span class="line">master-eu-west-1a       Ready   0               1       1       1       1</span><br><span class="line">master-eu-west-1b       Ready   0               1       1       1       1</span><br><span class="line">master-eu-west-1c       Ready   0               1       1       1       1</span><br><span class="line">nodes                   Ready   0               3       3       3       3</span><br><span class="line">No rolling-update required</span><br></pre></td></tr></table></figure><p>有点奇怪 Kops说，不需要滚动更新。这是正确的，因为我们仅更改了<code>nodes</code> 自动伸缩组中的最小实例数和最大实例数。这不需要对现有基础架构进行任何更改。AWS仅触发两个实例的创建。<br>让我们进行另一项需要更改基础结构的更改。想象一下，现有的t2 <code>.medium</code> 实例没有削减它。我们需要扩大规模以满足工作量要求。为此，我们需要更改实例类型。同样的<code>edit</code>，<code>update</code>和<code>rolling-update</code> 流程适用于此处。让我们升级到<code>m4.large</code>。重复练习，将t2替换为<code>.medium</code> ，<code>m4.large</code> 然后应用<code>rolling-update</code>。现在，Kops杀死每个节点以触发创建最新节点。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ kops rolling-update cluster --yes</span><br><span class="line">Using cluster from kubectl context: demo.slashdeploy.com</span><br><span class="line">NAME                    STATUS          NEEDUPDATE      READY   MIN     MAX     NODES</span><br><span class="line">bastions                Ready           0               1       1       1       0</span><br><span class="line">master-eu-west-1a       Ready           0               1       1       1       1</span><br><span class="line">master-eu-west-1b       Ready           0               1       1       1       1</span><br><span class="line">master-eu-west-1c       Ready           0               1       1       1       1</span><br><span class="line">nodes                   NeedsUpdate     3               0       3       3       3</span><br><span class="line">I0422 07:42:31.615734     659 rollingupdate_cluster.go:281] Stopping instance &quot;i-038cbac0aeaca24d4&quot; in AWS ASG &quot;nodes.demo.slashdeploy.com&quot;</span><br><span class="line">I0422 07:44:31.920426     659 rollingupdate_cluster.go:281] Stopping instance &quot;i-046fe9866a3b51fe6&quot; in AWS ASG &quot;nodes.demo.slashdeploy.com&quot;</span><br><span class="line">I0422 07:46:33.539412     659 rollingupdate_cluster.go:281] Stopping instance &quot;i-07f924becaa46d2ab&quot; in AWS ASG &quot;n</span><br></pre></td></tr></table></figure><p>注意！当前版本（&lt;= 1.6）尚未执行真正的滚动更新。将会发生停机。<a href="https://github.com/kubernetes/kops/issues/37" target="_blank" rel="noopener">问题＃37</a>我们实现了一项新功能，该功能可以耗尽并验证节点。此功能是实验性的，您可以通过设置使用新功能<code>export KOPS_FEATURE_FLAGS=&quot;+DrainAndValidateRollingUpdate&quot;</code>。此问题应在将来的版本中修复。</p><p>此过程适用于基础结构和配置（例如<code>kubelet</code> 标志或API服务器标志）。该<a href="https://github.com/kubernetes/kops/tree/master/docs" target="_blank" rel="noopener">文档</a>涵盖以下特定情况：</p><ul><li><a href="https://github.com/kubernetes/kops/blob/master/docs/instance_groups.md#changing-the-root-volume-size-or-type" target="_blank" rel="noopener">更改根卷大小</a></li><li><a href="https://github.com/kubernetes/kops/blob/master/docs/instance_groups.md#converting-an-instance-group-to-use-spot-instances" target="_blank" rel="noopener">使用竞价型实例</a></li><li><a href="https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md#kubelet" target="_blank" rel="noopener">配置kubelet标志</a></li><li><a href="https://github.com/kubernetes/kops/blob/master/docs/cluster_spec.md#runtimeconfig" target="_blank" rel="noopener">配置api服务器标志</a></li></ul><p>与往常一样，您可以参考<a href="https://github.com/kubernetes/kops/tree/master/docs" target="_blank" rel="noopener">文档</a>以获取完整信息。</p><h3 id="自定义集群基础架构"><a href="#自定义集群基础架构" class="headerlink" title="自定义集群基础架构"></a>自定义集群基础架构</h3><p>我们的示例涵盖了最简单的情况，但这并不适用于所有情况。让我们逐步了解可用的不同选项  <code>kops create cluster</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">$ kops create cluster --help</span><br><span class="line">Creates a k8s cluster.</span><br><span class="line">Usage:</span><br><span class="line">  kops create cluster [flags]</span><br><span class="line">Flags:</span><br><span class="line">      --admin-access stringSlice             Restrict access to admin endpoints (SSH, HTTPS) to this CIDR.  If not set, access will not be restricted by IP. (default [0.0.0.0/0])</span><br><span class="line">      --associate-public-ip                  Specify --associate-public-ip=[true|false] to enable/disable association of public IP for master ASG and nodes. Default is &apos;true&apos;.</span><br><span class="line">      --bastion                              Pass the --bastion flag to enable a bastion instance group. Only applies to private topology.</span><br><span class="line">      --channel string                       Channel for default versions and configuration to use (default &quot;stable&quot;)</span><br><span class="line">      --cloud string                         Cloud provider to use - gce, aws</span><br><span class="line">      --dns string                           DNS hosted zone to use: public|private. Default is &apos;public&apos;. (default &quot;Public&quot;)</span><br><span class="line">      --dns-zone string                      DNS hosted zone to use (defaults to longest matching zone)</span><br><span class="line">      --image string                         Image to use</span><br><span class="line">      --kubernetes-version string            Version of kubernetes to run (defaults to version in channel)</span><br><span class="line">      --master-count int32                   Set the number of masters.  Defaults to one master per master-zone</span><br><span class="line">      --master-security-groups stringSlice   Add precreated additional security groups to masters.</span><br><span class="line">      --master-size string                   Set instance size for masters</span><br><span class="line">      --master-zones stringSlice             Zones in which to run masters (must be an odd number)</span><br><span class="line">      --model string                         Models to apply (separate multiple models with commas) (default &quot;config,proto,cloudup&quot;)</span><br><span class="line">      --network-cidr string                  Set to override the default network CIDR</span><br><span class="line">      --networking string                    Networking mode to use.  kubenet (default), classic, external, cni, kopeio-vxlan, weave, calico. (default &quot;kubenet&quot;)</span><br><span class="line">      --node-count int32                     Set the number of nodes</span><br><span class="line">      --node-security-groups stringSlice     Add precreated additional security groups to nodes.</span><br><span class="line">      --node-size string                     Set instance size for nodes</span><br><span class="line">      --out string                           Path to write any local output</span><br><span class="line">      --project string                       Project to use (must be set on GCE)</span><br><span class="line">      --ssh-public-key string                SSH public key to use (default &quot;~/.ssh/id_rsa.pub&quot;)</span><br><span class="line">      --target string                        Target - direct, terraform (default &quot;direct&quot;)</span><br><span class="line">  -t, --topology string                      Controls network topology for the cluster. public|private. Default is &apos;public&apos;. (default &quot;public&quot;)</span><br><span class="line">      --vpc string                           Set to use a shared VPC</span><br><span class="line">      --yes                                  Specify --yes to immediately create the cluster</span><br><span class="line">      --zones stringSlice                    Zones in which to run the cluster</span><br><span class="line">--vpc and --newtork-cidr can be used when deploying to an existing AWS VPC.</span><br><span class="line">--bastion generates a dedicated SSH jump host for SSH access to cluster instances. This is best used with --associate-public-ip=false.</span><br><span class="line">--master-zones specifies all of the zones where masters run. This is key for HA setups.</span><br><span class="line">--networking sets the default network. Note that your particular choice depends on your requirements and may work with the specified --topology.</span><br><span class="line">--topology is the internal networking state. I prefer --bastion --topology=private --associate-public-ip=false --networking=weave to keep the clusters inaccessible on the public internet.</span><br></pre></td></tr></table></figure><ul><li><code>--vpc</code> 并且<code>--newtork-cidr</code> 可以在部署到现有的AWS VPC时使用。</li><li><code>--bastion</code> 生成<a href="https://github.com/kubernetes/kops/blob/master/docs/bastion.md" target="_blank" rel="noopener">专用的SSH跳转服务器，</a>以SSH访问群集实例。最好与<code>--associate-public-ip=false.</code></li><li><code>--master-zones</code> 指定主服务器运行的所有区域。这是HA设置的关键。</li><li><code>--networking</code> 设置默认<a href="https://github.com/kubernetes/kops/blob/master/docs/networking.md" target="_blank" rel="noopener">网络</a>。请注意，您的特定选择取决于您的要求，并且可以与指定的<code>--topology.</code></li><li><code>--topology</code> 是内部联网状态。我更喜欢<code>--bastion --topology=private --associate-public-ip=false --networking=weave</code>使群集无法在公共互联网上访问。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天，我们将以我们最近对&lt;a href=&quot;https://cloudacademy.com/blog/kubernetes-ecosystem-operations/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;strong&gt;Kubernetes生态系
      
    
    </summary>
    
      <category term="Kubernetes" scheme="http://blog.ozairs.com/categories/Kubernetes/"/>
    
    
      <category term="Kops" scheme="http://blog.ozairs.com/tags/Kops/"/>
    
  </entry>
  
  <entry>
    <title>如何一次性通过AWS DevOps Professional认证考试！</title>
    <link href="http://blog.ozairs.com/uncategorized/%E5%A6%82%E4%BD%95%E4%B8%80%E6%AC%A1%E6%80%A7%E9%80%9A%E8%BF%87AWS-DevOps-Professional%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95%EF%BC%81/"/>
    <id>http://blog.ozairs.com/uncategorized/如何一次性通过AWS-DevOps-Professional认证考试！/</id>
    <published>2019-09-15T01:18:53.000Z</published>
    <updated>2019-09-15T01:24:56.878Z</updated>
    
    <content type="html"><![CDATA[<p>我最近有机会参加AWS DevOps专业认证考试，并在第一次尝试时设法清除它。我已经在第一次尝试时提供了清除AWS DevOps Professional认证考试所需的一些AWS服务的一些信息。</p><p>首先要了解考试中包含的各个领域及其在考试中的相关百分比，简要地从理论上了解了域中列出的所有服务，如果您没有任何实践所有这些服务的经验，那么您必须了解服务在理论上如何在各种情况下工作。</p><p>1）<strong>Code Commit</strong>：了解用户如何创建repo，使用SSH / HTTPS从相应的repo克隆并使用正确的IAM权限，确保用户不在没有他/她在正确的IAM组的情况下提交master分支，了解如何您可以使用正确的IAM策略限制该用户。</p><p>2）<strong>Code Build</strong>：首先在所需的Ec2实例中构建一个示例hello world应用程序，通过从源获取文件以及如何构建推送到任何所需目标的工件来了解代码构建的工作原理。创建自己的buildspec.yaml文件。</p><p>3）<strong>Code Deploy</strong>：了解与AWS代码部署相关的各种部署类型，如何根据应用程序要求和兼容性在不同场景中使用它们，不能强调这一点代码部署部署类型对于考试非常重要。创建自己的appspec.yaml文件。</p><p>4）<strong>Code Pipeline</strong>：了解CI / CD管道的工作原理，如何与上述三种服务集成并触发管道。有关最佳实践，请了解如何使用AWS警报机制添加批准阶段并向所需组触发警报，了解如何基于代码提交提交触发管道。</p><p>5）<strong>Elastic Beanstalk</strong>：非常非常……对于考试来说很重要，请确保掌握这项服务的知识，创建示例应用程序，了解Elastic Beanstalk提供的各种部署类型。熟悉eb cli和.ebextensions文件夹及其文件结构。获取有关eb基本和增强监控的知识。使用eb练习蓝色/绿色部署，获取有关金丝雀部署的知识。熟悉与eb相关的docker。</p><p>6）<strong>Lambda</strong>：深入了解如何创建lambda函数，如何创建不可变版本以及将流量路由到不同版本。了解Lambda Edge的云端缓存和源。</p><p>7）<strong>OpsWorks</strong>：非常非常……对于考试来说很重要，了解与opsworks相关的不同阶段，获得有关厨师及其文件夹结构的知识。获取有关opsworks生命周期事件的知识。练习如何使用OpsWorks图层创建多层体系结构。</p><p>8）<strong>Elastic Container Service</strong>：不要求如此深入，了解ECS的机制，其任务和服务，如何创建任务和服务，如何使用与ECS的私有注册表的docker镜像。</p><p>9）<strong>CloudFormation：</strong>非常非常……对于考试来说很重要，了解云形成的IN和OUT，无法描述与云形成有关的考试的重要性，你需要知道IN和OUT，练习用不同的语法创建模板功能可用，练习云形成帮助脚本。</p><p>10）<strong>CloudWatch</strong>：CloudWatch是一个很大的主题，可以通过事件，警报，指标和触发器尽可能多地了解。了解其他服务如何触发CloudWatch警报以及警报可以执行的操作，您可以与之关联的钩子，了解与云监视及其相关应用程序日志记录关联的一些示例用例和方案。</p><p><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html</a></p><p>11）<strong>VPC Flow logs</strong>：获取有关流日志概念的基本知识，并了解示例日志中关联的所有元素，例如，日志包含Vpc流日志的版本，accountID，interfaceID，sourceIP，目标地址等等，获取基本知识了解整个日志的外观。</p><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html</a></p><p>12）<strong>CloudTrail</strong>：了解云跟踪API日志如何帮助审核，谁可以查看日志，如何使用IAM策略限制日志，以及如何防止日志被篡改。</p><p>13）<strong>X Ray</strong>：只要知道这项服务是什么，如何使用这个X射线sdk识别app中的瓶颈。</p><p><a href="https://github.com/aws-samples/aws-xray-cloudwatch-event" target="_blank" rel="noopener">https://github.com/aws-samples/aws-xray-cloudwatch-event</a></p><p>14）<strong>Delegation Access</strong>：获取该服务如何工作的基本知识，如何存储其他帐户密钥以及如何使用此服务访问其他帐户，如何从一个帐户登录并切换到其他帐户，需要具备哪些权限这个角色。</p><p>15）<strong>AWS SAM</strong>：获取非常基础的知识。</p><p>16）<strong>EC2系 System Manager</strong>：非常非常重要……对于考试而言，您将在许多问题中获得与EC2 System Manager服务相关的概念，了解如何使用此系统管理器服务同时在多个实例上运行脚本，如何补丁服务器，如何添加本地服务器和EC2实例，如何使用标记区分它们并通过分组对其进行修补。</p><p>17）<strong>AWS License Manager，**</strong>Data Lifecycle Management, Secret Manager, AWS Catalog, AWS organizations, EC2 Auto recovery, Parameter Store**：了解这些服务如何工作，与使用这些服务相关的最佳实践是什么以及如何将它们集成在一起在所需的场景中，您不会对这些服务如何工作有疑问，而是如何在不同场景中使用它们。</p><p>18）<strong>DynamoDB</strong>：对于考试很重要，您将会遇到如何使用DynamoDB提高应用程序性能的问题，使用DynamoDB的最佳实践是什么，如何在高可用性和容错性下工作，了解DynamoDB流概念。了解什么是DynamoDB加速器，读取容量单位，写入容量单位，排序键和分区键。</p><p>19）<strong>RDS</strong>：需要深入了解RDS读取副本，RDS multiAZ和RDS快照。</p><p>20）<strong>Elastic Load Balancer，Route53，Auto Scaling Groups，EBS Volumes，S3</strong>：在您尝试DevOps专业考试之前，请确保您对这些服务有深入的了解，可以给您足够的压力，了解这些服务的IN和OUT，在您了解这些服务之前不要尝试此考试，因为它们是您将在许多问题中看到的基本AWS服务，这些服务就像先决条件。</p><p>21）<strong>AWS Kinesis</strong>：知道AWS Kinesis用于实时数据分析，这是您可以记住的关键词，知道Kinesis Data Analytics，Firehose，Streams和视频流如何工作以及如何用于处理和分析。</p><p>22）了解<strong>IAM Access advisor, AWS cost explorer, Trusted Advisor, GuardDuty, Inspector</strong>的基本知识**。这些服务在考试中并不多，但它们将作为选项出现。</p><p><strong>专业提示</strong>：为了更好地理解概念和服务，请观看acloudguru，linuxacademy视频教程，完成kplabs来自Udemy的AWS devops专业认证课程，从Whizlabs获得练习考试。主要的AWS DevOps专业认证考试包括一些技术复杂性，冗长的问题以及冗长的选项。由于大问题，很难集中精力直到最后。避免在任何给定问题上花费超时，根据问题中要求的服务进行关键字匹配。当您为任何给定问题选择正确的选项时，请确保考虑具有成本效益且包含最佳实践的选项。</p><p>祝好运！</p><p>希望你喜欢这篇文章，发现它很有帮助！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我最近有机会参加AWS DevOps专业认证考试，并在第一次尝试时设法清除它。我已经在第一次尝试时提供了清除AWS DevOps Professional认证考试所需的一些AWS服务的一些信息。&lt;/p&gt;
&lt;p&gt;首先要了解考试中包含的各个领域及其在考试中的相关百分比，简要地从
      
    
    </summary>
    
    
      <category term="AWS" scheme="http://blog.ozairs.com/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>How to pass Azure103: Miscrosoft Azure Administrator</title>
    <link href="http://blog.ozairs.com/Azure/How-to-pass-Azure103-Miscrosoft-Azure-Administrator/"/>
    <id>http://blog.ozairs.com/Azure/How-to-pass-Azure103-Miscrosoft-Azure-Administrator/</id>
    <published>2019-06-19T12:09:22.000Z</published>
    <updated>2019-06-19T12:16:45.662Z</updated>
    
    <content type="html"><![CDATA[<ol><li><h3 id="Manage-Azure-subscriptions-and-resources-15-20"><a href="#Manage-Azure-subscriptions-and-resources-15-20" class="headerlink" title="Manage Azure subscriptions and resources (15-20%)"></a>Manage Azure subscriptions and resources (15-20%)</h3><p>Manage Azure subscriptions</p><ul><li>assign administrator permissions</li><li>configure cost center quotas and tagging</li><li>configure Azure subscription policies at Azure subscription level</li></ul><p>Analyze resource utilization and consumption</p><ul><li>configure diagnostic settings on resources</li><li>create baseline for resources</li><li>create and rest alerts</li><li>analyze alerts across subscription</li><li>analyze metrics across subscription</li><li>create action groups</li><li>monitor for unused resources</li><li>monitor spend</li><li>report on spend</li><li>utilize Log Search query functions</li><li>view alerts in Log Analytics</li></ul><p>Manage resource groups</p><ul><li>use Azure policies for resource groups</li><li>configure resource locks</li><li>configure resource policies</li><li>identify auditing requirements</li><li>implement and set tagging on resource groups</li><li>move resources across resource groups</li><li>remove resource groups</li></ul><p>Managed role based access control (RBAC)</p><ul><li>create a custom role</li><li>configure access to Azure resources by assigning roles</li><li>configure management access to Azure, troubleshoot RBAC, implement RBAC policies, assign RBAC Roles</li></ul></li><li><h3 id="Implement-and-manage-storage-15-20"><a href="#Implement-and-manage-storage-15-20" class="headerlink" title="Implement and manage storage (15-20%)"></a>Implement and manage storage (15-20%)</h3><p>Create and configure storage accounts</p><ul><li>configure network access to the storage account</li><li>create and configure storage account</li><li>generate shared access signature</li><li>install and use Azure Storage Explorer</li><li>manage access keys</li><li>monitor activity log by using Log Analytics</li><li>implement Azure storage replication</li></ul><p>Import and export data to Azure</p><ul><li>create export from Azure job</li><li>create import into Azure job</li><li>Use Azure Data Box</li><li>configure and use Azure blob storage</li><li>configure Azure content delivery network (CDN) endpoints</li></ul><p>Configure Azure files</p><ul><li>create Azure file share</li><li>create Azure File Sync service</li><li>create Azure sync group</li><li>troubleshoot Azure File Sync</li></ul><p>Implement Azure backup</p><ul><li>configure and review backup reports</li><li>perform backup operation</li><li>create Recovery Services Vault</li><li>create and configure backup policy</li><li>perform a restore operation</li></ul></li><li><h3 id="Deploy-and-manage-virtual-machines-VMs-15-20"><a href="#Deploy-and-manage-virtual-machines-VMs-15-20" class="headerlink" title="Deploy and manage virtual machines (VMs) (15-20%)"></a>Deploy and manage virtual machines (VMs) (15-20%)</h3><p>Create and configure a VM for Windows and Linux</p><ul><li>configure high availability</li><li>configure monitoring, networking, storage, and virtual machine size</li><li>deploy and configure scale sets</li></ul><p>Automate deployment of VMs</p><ul><li>modify Azure Resource Manager (ARM) template</li><li>configure location of new VMs</li><li>configure VHD template</li><li>deploy from template</li><li>save a deployment as an ARM template</li><li>deploy Windows and Linux VMs</li></ul><p>Manage Azure VM</p><ul><li>add data discs</li><li>add network interfaces</li><li>automate configuration management by using PowerShell Desired State Configuration (DSC) and VM Agent by using custom script extensions</li><li>manage VM sizes; move VMs from one resource group to another</li><li>redeploy VMs</li></ul><p>Manage VM backups</p><ul><li>configure VM backup</li><li>define backup policies</li><li>implement backup policies</li><li>perform VM restore</li><li>Azure Site Recovery</li></ul></li><li><h3 id="Configure-and-manage-virtual-networks-30-35"><a href="#Configure-and-manage-virtual-networks-30-35" class="headerlink" title="Configure and manage virtual networks (30-35%)"></a>Configure and manage virtual networks (30-35%)</h3><p>Create connectivity between virtual networks</p><ul><li>create and configure VNET peering</li><li>create and configure VNET to VNET</li><li>verify virtual network connectivity</li><li>create virtual network gateway</li></ul><p>Implement and manage virtual networking</p><ul><li>configure private and public IP addresses, network routes, network interface, subnets, and virtual network</li></ul><p>Configure name resolution</p><ul><li>configure Azure DNS</li><li>configure custom DNS settings</li><li>configure private and public DNS zones</li></ul><p>Create and configure a Network Security Group (NSG)</p><ul><li>create security rules</li><li>associate NSG to a subnet or network interface</li><li>identify required ports</li><li>evaluate effective security rules</li></ul><p>Implement Azure load balancer</p><ul><li>configure internal load balancer, configure load balancing rules, configure public load balancer, troubleshoot load balancing</li></ul><p>Monitor and troubleshoot virtual networking</p><ul><li>monitor on-premises connectivity, use Network resource monitoring, use Network Watcher, troubleshoot external networking, troubleshoot virtual network connectivity</li></ul><p>Integrate on premises network with Azure virtual network</p><ul><li>create and configure Azure VPN Gateway, create and configure site to site VPN, configure Express Route, verify on premises connectivity, troubleshoot on premises connectivity with Azure</li></ul></li><li><h3 id="Manage-identities-15-20"><a href="#Manage-identities-15-20" class="headerlink" title="Manage identities (15-20%)"></a>Manage identities (15-20%)</h3><p>Manage Azure Active Directory (AD)</p><ul><li>add custom domains</li><li>Azure AD Join</li><li>configure self-service password reset</li><li>manage multiple directories</li></ul><p>Manage Azure AD objects (users, groups, and devices)</p><ul><li>create users and groups</li><li>manage user and group properties</li><li>manage device settings</li><li>perform bulk user updates</li><li>manage guest accounts</li></ul><p>Implement and manage hybrid identities</p><ul><li>install Azure AD Connect, including password hash and pass-through synchronization</li><li>use Azure AD Connect to configure federation with on-premises Active Directory Domain Services (AD DS)</li><li>manage Azure AD Connect</li><li>manage password sync and password writeback</li></ul><p>Implement multi-factor authentication (MFA)</p><ul><li>configure user accounts for MFA, enable MFA by using bulk update, configure fraud alerts, configure bypass options, configure Trusted IPs, configure verification methods</li></ul></li></ol><p>【翻译】</p><ol><li><p>###管理Azure订阅和资源（15-20％）</p><p>管理Azure订阅</p><ul><li>分配管理员权限</li><li>配置成本中心配额和标记</li><li>在Azure订阅级别配置Azure订阅策略</li></ul><p>分析资源利用率和消耗量</p><ul><li>配置资源的诊断设置</li><li>为资源创建基线</li><li>创建和休息警报</li><li>分析订阅中的警报</li><li>分析订阅中的指标</li><li>创建行动小组</li><li>监控未使用的资源</li><li>监控支出</li><li>报告支出</li><li>利用日志搜索查询功能</li><li>在Log Analytics中查看警报</li></ul><p>管理资源组</p><ul><li>对资源组使用Azure策略</li><li>配置资源锁</li><li>配置资源策略</li><li>确定审计要求</li><li>在资源组上实现和设置标记</li><li>跨资源组移动资源</li><li>删除资源组</li></ul><p>基于托管角色的访问控制（RBAC）</p><ul><li>创建自定义角色</li><li>通过分配角色配置对Azure资源的访问</li><li>配置对Azure的管理访问，对RBAC进行故障排除，实施RBAC策略，分配RBAC角色</li></ul></li><li><p>###实施和管理存储（15-20％）</p><p>创建和配置存储帐户</p><ul><li>配置对存储帐户的网络访问</li><li>创建和配置存储帐户</li><li>生成共享访问签名</li><li>安装和使用Azure Storage Explorer</li><li>管理访问密钥</li><li>使用Log Analytics监控活动日志</li><li>实施Azure存储复制</li></ul><p>将数据导入和导出到Azure</p><ul><li>从Azure作业创建导出</li><li>创建导入Azure作业</li><li>使用Azure数据框</li><li>配置和使用Azure blob存储</li><li>配置Azure内容传送网络（CDN）端点</li></ul><p>配置Azure文件</p><ul><li>创建Azure文件共享</li><li>创建Azure文件同步服务</li><li>创建Azure同步组</li><li>解决Azure文件同步问题</li></ul><p>实施Azure备份</p><ul><li>配置和查看备份报告</li><li>执行备份操作</li><li>创建Recovery Services Vault</li><li>创建和配置备份策略</li><li>执行还原操作</li></ul></li><li><p>###部署和管理虚拟机（VM）（15-20％）</p><p>为Windows和Linux创建和配置VM</p><ul><li>配置高可用性</li><li>配置监控，网络，存储和虚拟机大小</li><li>部署和配置规模集</li></ul><p>自动部署VM</p><ul><li>修改Azure资源管理器（ARM）模板</li><li>配置新VM的位置</li><li>配置VHD模板</li><li>从模板部署</li><li>将部署保存为ARM模板</li><li>部署Windows和Linux VM</li></ul><p>管理Azure VM</p><ul><li>添加数据光盘</li><li>添加网络接口</li><li>使用自定义脚本扩展，使用PowerShell所需状态配置（DSC）和VM代理自动执行配置管理</li><li>管理VM大小;将VM从一个资源组移动到另一个资源组</li><li>重新部署VM</li></ul><p>管理VM备份</p><ul><li>配置VM备份</li><li>定义备份策略</li><li>实施备份策略</li><li>执行VM还原</li><li>Azure Site Recovery</li></ul></li><li><p>###配置和管理虚拟网络（30-35％）</p><p>在虚拟网络之间建立连接</p><ul><li>创建和配置VNET对等</li><li>创建和配置VNET到VNET</li><li>验证虚拟网络连接</li><li>创建虚拟网络网关</li></ul><p>实施和管理虚拟网络</p><ul><li>配置私有和公共IP地址，网络路由，网络接口，子网和虚拟网络</li></ul><p>配置名称解析</p><ul><li>配置Azure DNS</li><li>配置自定义DNS设置</li><li>配置私有和公共DNS区域</li></ul><p>创建和配置网络安全组（NSG）</p><ul><li>创建安全规则</li><li>将NSG关联到子网或网络接口</li><li>确定所需的端口</li><li>评估有效的安全规则</li></ul><p>实施Azure负载均衡器</p><ul><li>配置内部负载均衡器，配置负载均衡规则，配置公共负载均衡器，解决负载均衡问题</li></ul><p>监控和排除虚拟网络故障</p><ul><li>监控本地连接，使用网络资源监控，使用网络监控程序，排除外部网络故障，排除虚拟网络连接故障</li></ul><p>使用Azure虚拟网络集成本地网络</p><ul><li>创建和配置Azure VPN网关，创建和配置站点到站点VPN，配置Express Route，验证内部连接，使用Azure进行内部连接故障排除</li></ul></li><li><p>###管理身份（15-20％）</p><p>管理Azure Active Directory（AD）</p><ul><li>添加自定义域名</li><li>Azure AD加入</li><li>配置自助密码重置</li><li>管理多个目录</li></ul><p>管理Azure AD对象（用户，组和设备）</p><ul><li>创建用户和组</li><li>管理用户和组属性</li><li>管理设备设置</li><li>执行批量用户更新</li><li>管理访客帐户</li></ul><p>实施和管理混合身份</p><ul><li>安装Azure AD Connect，包括密码哈希和传递同步</li><li>使用Azure AD Connect配置与本地Active Directory域服务（AD DS）的联合</li><li>管理Azure AD Connect</li><li>管理密码同步和密码回写</li></ul><p>实施多重身份验证（MFA）</p><ul><li>为MFA配置用户帐户，使用批量更新启用MFA，配置欺诈警报，配置旁路选项，配置可信IP，配置验证方法</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;h3 id=&quot;Manage-Azure-subscriptions-and-resources-15-20&quot;&gt;&lt;a href=&quot;#Manage-Azure-subscriptions-and-resources-15-20&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="Azure" scheme="http://blog.ozairs.com/categories/Azure/"/>
    
    
      <category term="Azure" scheme="http://blog.ozairs.com/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>通过Powershell 登陆Azure（Azure MoonCake为例）一般常见的有两种方式</title>
    <link href="http://blog.ozairs.com/Azure/%E9%80%9A%E8%BF%87Powershell-%E7%99%BB%E9%99%86Azure%EF%BC%88Azure-MoonCake%E4%B8%BA%E4%BE%8B%EF%BC%89%E4%B8%80%E8%88%AC%E5%B8%B8%E8%A7%81%E7%9A%84%E6%9C%89%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
    <id>http://blog.ozairs.com/Azure/通过Powershell-登陆Azure（Azure-MoonCake为例）一般常见的有两种方式/</id>
    <published>2019-06-19T12:03:16.000Z</published>
    <updated>2019-06-19T12:04:53.099Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-用户交互式登陆"><a href="#1-用户交互式登陆" class="headerlink" title="1. 用户交互式登陆"></a>1. 用户交互式登陆</h4><p>前提条件：有一个AAD account<br>此种登陆方式会弹出一个登陆框，让你输入一个.onmschina.cn的账号，然后根据选择的订阅操作相应的资源。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># set Azure Enviroment into China Mooncake.  </span><br><span class="line">$EnvironmentName =&quot;AzureChinaCloud&quot; </span><br><span class="line"> </span><br><span class="line"># Give your subcriptionID here.  </span><br><span class="line">$SubscriptionId=&quot;*********&quot; </span><br><span class="line"> </span><br><span class="line">##login  </span><br><span class="line">Login-AzureRmAccount -EnvironmentName &apos;AzureChinaCloud&apos; </span><br><span class="line">Set-AzureRmContext -SubscriptionId $SubscriptionId</span><br></pre></td></tr></table></figure><p>缺点：会弹出登陆框，让你输入账号密码进行登陆，不适合自动化场景。</p><blockquote><p>此处也能改成隐式登陆的。具体参考<a href="https://stackoverflow.com/questions/37249623/how-to-login-without-prompt" target="_blank" rel="noopener">https://stackoverflow.com/questions/37249623/how-to-login-without-prompt</a></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Read-Host &quot;Enter Password&quot; -AsSecureString | ConvertTo-SecureString `</span><br><span class="line">-AsPlainText -Force | ConvertFrom-SecureString | Out-File &quot;C:\Password.txt&quot;</span><br><span class="line"># The azure account here must not be a Live ID.</span><br><span class="line">$username = &quot;&lt;your Azure account&gt;&quot;</span><br><span class="line">$SecurePassword = Get-Content &quot;C:\Password.txt&quot; | ConvertTo-SecureString</span><br><span class="line">$cred = new-object -typename System.Management.Automation.PSCredential `</span><br><span class="line">     -argumentlist $username, $SecurePassword</span><br><span class="line"></span><br><span class="line">Login-AzureRmAccount -Credential $cred -EnvironmentName &apos;AzureChinaCloud&apos;</span><br></pre></td></tr></table></figure><h4 id="2-AAD-Service-Principal登陆-前提条件："><a href="#2-AAD-Service-Principal登陆-前提条件：" class="headerlink" title="2. AAD Service Principal登陆 前提条件："></a>2. AAD Service Principal登陆 前提条件：</h4><p>需要在Azure AD 中去<a href="https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-integrating-applications" target="_blank" rel="noopener">注册一个app（service principal）</a>，并拿到这个app的Appliaction和key。此处你需要为app添加相应的权限。<br>运行完，直接根据选定的订阅就能操作Azure 订阅资源了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># the AAD app applicationID  </span><br><span class="line">$ServicePrincipalApplicationId=&quot;9059226d-******&quot; </span><br><span class="line"> </span><br><span class="line"># AAD app key  </span><br><span class="line">$ServicePrincipalPassword=&quot;********************&quot; </span><br><span class="line"> </span><br><span class="line"># the AAD directory ID = tenantID  </span><br><span class="line">$TenantId= &quot;*********************&quot; </span><br><span class="line"> </span><br><span class="line"># set Azure to Mooncake  </span><br><span class="line">$EnvironmentName =&quot;AzureChinaCloud&quot; </span><br><span class="line">$SubscriptionId=&quot;*******************************&quot; </span><br><span class="line">$spPassword =  ConvertTo-SecureString $ServicePrincipalPassword -AsPlainText -Force</span><br><span class="line">  </span><br><span class="line">$AzureServicePrincipalCreds = New-Object System.Management.Automation.PSCredential ($ServicePrincipalApplicationId, $spPassword)  </span><br><span class="line">Add-AzureRmAccount -Credential $AzureServicePrincipalCreds -ServicePrincipal -TenantId $TenantId -Environment $EnvironmentName </span><br><span class="line">Set-AzureRmContext -SubscriptionId $SubscriptionId</span><br></pre></td></tr></table></figure><p>缺点：泄露AAD app 的applicationID 和key 会比较麻烦。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-用户交互式登陆&quot;&gt;&lt;a href=&quot;#1-用户交互式登陆&quot; class=&quot;headerlink&quot; title=&quot;1. 用户交互式登陆&quot;&gt;&lt;/a&gt;1. 用户交互式登陆&lt;/h4&gt;&lt;p&gt;前提条件：有一个AAD account&lt;br&gt;此种登陆方式会弹出一个登陆框，让你
      
    
    </summary>
    
      <category term="Azure" scheme="http://blog.ozairs.com/categories/Azure/"/>
    
    
      <category term="Azure" scheme="http://blog.ozairs.com/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>How-to-get-started-with-Minikube-on-Mac-OS</title>
    <link href="http://blog.ozairs.com/Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/"/>
    <id>http://blog.ozairs.com/Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/</id>
    <published>2019-05-05T07:13:54.000Z</published>
    <updated>2019-05-05T07:18:20.204Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目标："><a href="#目标：" class="headerlink" title="目标："></a>目标：</h2><p>本文介绍了如何在Mac OS上开始使用Minikube的详细步骤。</p><p>这是学习Kubernetes的一个很好的起点。</p><h2 id="操作环境："><a href="#操作环境：" class="headerlink" title="操作环境："></a>操作环境：</h2><p>Mac OS 10.14 </p><p>Minikube v0.30.0</p><h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><h3 id="1-先决条件"><a href="#1-先决条件" class="headerlink" title="1.先决条件"></a>1.先决条件</h3><p>在Mac上安装xcode：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`xcode-``select` `--``install`</span><br></pre></td></tr></table></figure><p>然后安装</p><p>Homebrew：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`/usr/bin/ruby` `-e ``&quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;`</span><br></pre></td></tr></table></figure><p>所以基本上Homebrew会将软件包安装到他们自己的目录中，然后将他们的文件符号链接到/ usr / local。</p><h3 id="2-安装Minikube"><a href="#2-安装Minikube" class="headerlink" title="2.安装Minikube"></a>2.安装Minikube</h3><p>使用Homebrew，我们可以在Mac上轻松安装Minikube：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`brew cask ``install` `minikube`</span><br></pre></td></tr></table></figure><h3 id="3-在VM中启动单个节点Kubernetes群集"><a href="#3-在VM中启动单个节点Kubernetes群集" class="headerlink" title="3.在VM中启动单个节点Kubernetes群集"></a>3.在VM中启动单个节点Kubernetes群集</h3><p>默认情况下，Minikube使用“virtualbox”作为VM驱动程序，您也可以将其更改为其他驱动程序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$ minikube start -h |``grep` `vm-driver``      ``--vm-driver string               VM driver is one of: [virtualbox vmwarefusion kvm xhyve hyperv hyperkit kvm2 none] (default ``&quot;virtualbox&quot;``)`</span><br></pre></td></tr></table></figure><p>现在启动VM中的单节点Kubernetes集群（默认内存大小为2G）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`minikube start`</span><br></pre></td></tr></table></figure><h3 id="4-启动Kubernetes-Web-Dashboard"><a href="#4-启动Kubernetes-Web-Dashboard" class="headerlink" title="4.启动Kubernetes Web Dashboard"></a>4.启动Kubernetes Web Dashboard</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`minikube dashboard`</span><br></pre></td></tr></table></figure><p>只有一个节点显示：</p><p><img src="/Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/1.png" alt=""></p><h3 id="5-将hello-world-Node-js应用程序部署到Minikube中"><a href="#5-将hello-world-Node-js应用程序部署到Minikube中" class="headerlink" title="5.将hello world Node.js应用程序部署到Minikube中"></a>5.将hello world Node.js应用程序部署到Minikube中</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`kubectl run hello-minikube --image=k8s.gcr.io``/echoserver``:1.4 --port=8080`</span><br></pre></td></tr></table></figure><p>显示在仪表板的“部署”中：</p><p><img src="/Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/2.png" alt=""></p><p>或者在CLI中显示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$ kubectl get deployments``NAME             DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE``hello-minikube   1         1         1            1           15m`</span><br></pre></td></tr></table></figure><h3 id="6-将部署公开为服务"><a href="#6-将部署公开为服务" class="headerlink" title="6.将部署公开为服务"></a>6.将部署公开为服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`kubectl expose deployment hello-minikube --``type``=NodePort`</span><br></pre></td></tr></table></figure><p>在仪表板中显示服务信息：</p><p><img src="/Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/3.png" alt=""></p><p>或者在CLI中显示服务信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$ kubectl get services hello-minikube``NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE``hello-minikube   NodePort   xxx.xxx.xxx.xxx &lt;none&gt;        8080:31978``/TCP`   `3m`</span><br></pre></td></tr></table></figure><h3 id="7-等待pod启动并运行"><a href="#7-等待pod启动并运行" class="headerlink" title="7.等待pod启动并运行"></a>7.等待pod启动并运行</h3><p>继续在命令下运行，直到pod的状态正在运行并准备就绪。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$  kubectl get pods``NAME                             READY   STATUS    RESTARTS   AGE``hello-minikube-6c47c66d8-gv7n2   1``/1`     `Running   0          31m`</span><br></pre></td></tr></table></figure><h3 id="8-访问服务"><a href="#8-访问服务" class="headerlink" title="8.访问服务"></a>8.访问服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`curl $(minikube service hello-minikube --url)`</span><br></pre></td></tr></table></figure><p>或直接转到浏览器中的网址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`$ minikube service hello-minikube --url``http:``//192``.168.99.100:31978`</span><br></pre></td></tr></table></figure><p><img src="/Kubernetes/How-to-get-started-with-Minikube-on-Mac-OS/4.png" alt=""></p><h3 id="9-关闭群集"><a href="#9-关闭群集" class="headerlink" title="9.关闭群集"></a>9.关闭群集</h3><p>删除服务（服务在此之后消失）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`kubectl delete service hello-minikube`</span><br></pre></td></tr></table></figure><p>删除部署（之后部署和pod都消失了）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`kubectl delete deployment hello-minikube`</span><br></pre></td></tr></table></figure><p>停止minikube集群：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`minikube stop`</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目标：&quot;&gt;&lt;a href=&quot;#目标：&quot; class=&quot;headerlink&quot; title=&quot;目标：&quot;&gt;&lt;/a&gt;目标：&lt;/h2&gt;&lt;p&gt;本文介绍了如何在Mac OS上开始使用Minikube的详细步骤。&lt;/p&gt;
&lt;p&gt;这是学习Kubernetes的一个很好的起点。&lt;/
      
    
    </summary>
    
      <category term="Kubernetes" scheme="http://blog.ozairs.com/categories/Kubernetes/"/>
    
    
      <category term="Minikube" scheme="http://blog.ozairs.com/tags/Minikube/"/>
    
  </entry>
  
  <entry>
    <title>深入探讨AKS和AAD</title>
    <link href="http://blog.ozairs.com/Cloud-Service/%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8AKS%E5%92%8CAAD/"/>
    <id>http://blog.ozairs.com/Cloud-Service/深入探讨AKS和AAD/</id>
    <published>2019-04-30T10:24:17.000Z</published>
    <updated>2019-04-30T10:30:47.610Z</updated>
    
    <content type="html"><![CDATA[<p>【译文】</p><p>本快速研讨将指导您使用AAD配置AKS以使用RBAC对用户进行身份验证。</p><p><img src="/Cloud-Service/深入探讨AKS和AAD/1.png" alt="img"></p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>开发团队成员需要访问Kubernetes集群以部署应用程序并配置集群。但是，并非所有成员都需要相同级别的访问权限。这甚至是最佳实践，或者必须授予成员不同的访问级别。例如，开发人员可以在自己的命名空间内获取，创建和删除部署。并且，Ops人员可以配置群集以添加或删除用户，扩展群集或升级它。这将保护k8s群集并降低不良操作的风险。</p><p>您需要安装Azure订阅，az和kubectl cli。</p><p>本研讨会将首先创建Azure AD客户端和服务器应用程序。然后我们将创建一个配置了AAD的AKS集群。我们将通过创建Role和RoleBinding k8s清单文件来完成。</p><h4 id="1-创建Azure-AD服务器和客户端应用程序"><a href="#1-创建Azure-AD服务器和客户端应用程序" class="headerlink" title="1.创建Azure AD服务器和客户端应用程序"></a>1.创建Azure AD服务器和客户端应用程序</h4><p>我们需要创建服务器和客户端应用程序，这些应用程序将用于通过AAD验证连接到AKS的用户。这意味着应首先在AAD中创建用户以访问群集。这是身份验证部分。对于授权部分，它将由第3节中的Role和RoleBinding k8s对象管理。</p><p>请按照此处链接（在创建群集部分之前）中描述的步骤创建客户端和服务器应用程序：<a href="https://docs.microsoft.com/en-us/azure/aks/aad-integration" target="_blank" rel="noopener">https</a>：<a href="https://docs.microsoft.com/en-us/azure/aks/aad-integration" target="_blank" rel="noopener">//docs.microsoft.com/en-us/azure/aks/aad-integration</a></p><p>最后，我们应该有AAD租户ID，客户端应用ID，服务器应用ID和服务器应用秘密。我们将使用这些来配置AKS与AAD。</p><h4 id="2-创建使用Azure-Active-Directory配置的AKS群集"><a href="#2-创建使用Azure-Active-Directory配置的AKS群集" class="headerlink" title="2.创建使用Azure Active Directory配置的AKS群集"></a>2.创建使用Azure Active Directory配置的AKS群集</h4><p>Azure使用资源组对与同一应用程序或服务相关的资源进行分组。Azure中的所有资源都必须位于资源组内，包括AKS。让我们从使用az命令行创建资源组开始。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ az group create -name aks- aad -rg -location westeurope</span><br></pre></td></tr></table></figure><blockquote><p>如果您有多个Azure订阅，则可以设置一个默认订阅，以便az命令始终指向它，方法是：</p></blockquote><blockquote><p><strong>az帐户设置“Your_Azure_Subscription_Id_Or_Name”</strong></p></blockquote><p>然后我们可以创建AKS集群。Kubernetes使用OpenId Connect（OIDC）对用户进行身份验证。并且，AKS可以配置为使用AAD作为OIDC的实现。az cli工具提供了在创建群集期间（但不是之后）进行此配置的选项。确保替换AAD中的值。这将需要大约5分钟才能运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ az aks create </span><br><span class="line">     -resource-group aks- aad- rg \ </span><br><span class="line">     -name aks-aad \ </span><br><span class="line">     -generate-ssh-keys \ </span><br><span class="line">     -aad-server-app-id cbb2efcb-9b3c-4441-b58f-9c6cca37 \ </span><br><span class="line">     -aad-server- app-secret VBnbw1gEhxtRVfKTv8dYD + MyraLF5jn = \ </span><br><span class="line">     -aad-client-app-id 4c2a05a5-7ed1-4a2c-b4aa-b78bc \ </span><br><span class="line">     -aad-tenant-id 72f988bf-0000-0000-0000-2d7cd011db47</span><br></pre></td></tr></table></figure><p>现在，来自AAD帐户的所有用户都可以向AKS群集进行身份验证。但是，他们不能做任何操作，因为他们还没有做任何事情的许可。我们需要通过Role和RoleBinding授予他们访问k8s资源的权限。在此之前，我们需要以管理员身份访问群集，以便分配角色。</p><h4 id="3-连接到AKS群集"><a href="#3-连接到AKS群集" class="headerlink" title="3.连接到AKS群集"></a><strong>3.连接到AKS群集</strong></h4><p>我们需要连接到AKS，以便作为管理员对新集群运行kubectl命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ az aks get-credentials \ </span><br><span class="line">     -resource-group aks- aad- rg \ </span><br><span class="line">     -name aks- </span><br><span class="line">     aad --admin将</span><br><span class="line"> “aks- aad -admin”合并为/Users/houssem/.kube/config中的当前上下文</span><br></pre></td></tr></table></figure><p>顺便说一下，所有命令的源代码都在这里：<a href="https://github.com/HoussemDellai/rbac-aks-aad" target="_blank" rel="noopener">github.com/HoussemDellai/rbac-aks-aad</a></p><h4 id="4-创建角色和RoleBinding"><a href="#4-创建角色和RoleBinding" class="headerlink" title="4.创建角色和RoleBinding"></a>4.创建角色和RoleBinding</h4><p>让我们创建一个角色，它将定义对某些资源的访问权限。例如，仅从pod中读取信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind： Role </span><br><span class="line">apiVersion： rbac.authorization.k8s.io/v1 </span><br><span class="line">metadata：</span><br><span class="line">  namespace：默认</span><br><span class="line">  名称： pod-reader </span><br><span class="line">规则：</span><br><span class="line">-  apiGroups： [“”]＃“”表示核心API组</span><br><span class="line">  资源： [“pods”] </span><br><span class="line">  动词： [“get”，“watch”，“list”]</span><br></pre></td></tr></table></figure><p>要将角色分配给用户，我们需要使用<a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/" target="_blank" rel="noopener">RoleBinding</a>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kind： RoleBinding </span><br><span class="line">apiVersion： rbac.authorization.k8s.io/v1 </span><br><span class="line">metadata：</span><br><span class="line">  name： read-pods </span><br><span class="line">  namespace：默认</span><br><span class="line">主题：</span><br><span class="line">-  kind：用户</span><br><span class="line">  名： “houssem.dellai@live.com”#Name是区分大小写的</span><br><span class="line">  apiGroup： rbac。 authorization.k8s.io </span><br><span class="line">roleRef：</span><br><span class="line">  kind：角色#this必须是Role或ClusterRole </span><br><span class="line">  名称： pod-reader＃必须匹配角色</span><br><span class="line">  apiGroup的名称： rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure><blockquote><p>我们可以使用Group而不是User来绑定AAD组中的所有用户。</p></blockquote><p>然后我们使用kubectl部署这两个文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f role.yaml</span><br><span class="line"> role.rbac.authorization.k8s.io/pod-reader created </span><br><span class="line">$ kubectl apply -f role-</span><br><span class="line"> binding.yaml rolebinding.rbac.authorization.k8s.io/read-pods created</span><br></pre></td></tr></table></figure><p>我们可以检查Role和RoleBinding是否已成功创建：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get roles</span><br><span class="line"> NAME AGE </span><br><span class="line">pod-reader 2m </span><br><span class="line">$ kubectl get rolebindings</span><br><span class="line"> NAME AGE </span><br><span class="line">read-pods 2m</span><br></pre></td></tr></table></figure><h4 id="5-测试对AKS的认证和授权"><a href="#5-测试对AKS的认证和授权" class="headerlink" title="5.测试对AKS的认证和授权"></a>5.测试对AKS的认证和授权</h4><p>现在一切都已配置好，我们将伪装成RoleBinding中使用的用户。我们将从另一台机器连接到AKS集群。这是使用登录Azure，而不是使用群集。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ az aks get-credentials \ </span><br><span class="line">     -resource-group aks- aad- rg \ </span><br><span class="line">     -name aks- </span><br><span class="line">aad将“aks-aad”合并为/Users/houssem/.kube/config中的当前上下文</span><br></pre></td></tr></table></figure><p>然后我们将尝试允许的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br></pre></td></tr></table></figure><p><img src="/Cloud-Service/深入探讨AKS和AAD/2.png" alt="img"></p><p>因为我们添加了身份验证，所以要求登录群集。我们将以RoleBinding中指定的用户身份登录。我们需要在指定的url地址中启动浏览器并使用给定的代码。</p><p>然后我们按继续。</p><blockquote><p>确保RoleBinding中使用的用户也存在于Azure AD中。</p></blockquote><p><img src="/Cloud-Service/深入探讨AKS和AAD/3.png" alt="img"></p><p>在这里，我们来到最令人兴奋的部分，即登录AKS集群！</p><p>我们可以使用用户的电子邮件和密码登录。</p><p><img src="/Cloud-Service/深入探讨AKS和AAD/4.png" alt="img"></p><p>此网页表示您已成功登录！</p><p>我们再次运行允许的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br></pre></td></tr></table></figure><p>如果我们尝试运行其中一个非允许的操作，那么它将失败！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get deploymentments</span><br></pre></td></tr></table></figure><p>如果我们尝试从所有命名空间中获取pod，那么也会失败。因为我们在Role中配置用户以仅从默认命名空间获取pod。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>我们已将用户配置为登录并访问特定的AKS资源。我们也可以为整个AAD组做这件事。</p><p>【原文】</p><p>This quick workshop will walk you through configuring AKS with AAD to use RBAC to authenticate users.</p><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>The development team members needs to access Kubernetes cluster to deploy apps and configure the cluster. But, not all members needs the same level of access rights. It is even a best practice or a must have to grant members different access levels. For example, developers can get, create and delete deployments inside their own namespace. And, Ops guys can configure the cluster to add or remove users, scale the cluster or upgrade it. This will secure the k8s cluster and reduce the risk of bad manipulations.</p><p>You will need an Azure subscription, az and kubectl cli installed.</p><p>This workshop will start by creating Azure AD client and server apps. Then we’ll create an AKS cluster configured with AAD. And we’ll finish by creating the Role and RoleBinding k8s manifest files.</p><h4 id="1-Create-Azure-AD-server-and-client-apps"><a href="#1-Create-Azure-AD-server-and-client-apps" class="headerlink" title="1. Create Azure AD server and client apps"></a>1. Create Azure AD server and client apps</h4><p>We need to create a server and client apps, those will be used to authenticate the users connecting to AKS through AAD. This means the user should be first created in AAD to have access to the cluster. This is the authentication part. For the authorisation part, it will be managed by Role and RoleBinding k8s objects in section 3.</p><p>Please follow the steps described in the link here (just before section Create Cluster) to create client and server apps: <a href="https://docs.microsoft.com/en-us/azure/aks/aad-integration" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/azure/aks/aad-integration</a></p><p>At the end, we should have the AAD tenant Id, client app Id, server app Id and server app secret. We’ll use those to configure AKS with AAD.</p><h4 id="2-Create-AKS-cluster-configured-with-Azure-Active-Directory"><a href="#2-Create-AKS-cluster-configured-with-Azure-Active-Directory" class="headerlink" title="2. Create AKS cluster configured with Azure Active Directory"></a>2. Create AKS cluster configured with Azure Active Directory</h4><p>Azure uses Resource Group to group resources related to the same application or service. All resources in Azure must live inside a resource group, including AKS. Let’s start by creating a resource group using the az command line.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ az group create -name aks-aad-rg -location westeurope</span><br></pre></td></tr></table></figure><blockquote><p>If you have multiple Azure subscriptions, you can set a default one so that az commands points always to it, by using:</p></blockquote><blockquote><p><strong>az account set “Your_Azure_Subscription_Id_Or_Name”</strong></p></blockquote><p>Then we can create the AKS cluster. Kubernetes uses OpenId Connect (OIDC) to authenticate users. And, AKS could be configured to use AAD as an implementation of OIDC. The az cli tool provide the options to make this configuration during (but not after) the creation of the cluster. Make sure to replace the values from your AAD. This will take about 5 minutes to run.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ az aks create </span><br><span class="line">     -resource-group aks-aad-rg \</span><br><span class="line">     -name aks-aad \</span><br><span class="line">     -generate-ssh-keys \</span><br><span class="line">     -aad-server-app-id cbb2efcb-9b3c-4441-b58f-9c6cca37 \</span><br><span class="line">     -aad-server-app-secret VBnbw1gEhxtRVfKTv8dYD+MyraLF5jn= \</span><br><span class="line">     -aad-client-app-id 4c2a05a5–7ed1–4a2c-b4aa-b78bc \</span><br><span class="line">     -aad-tenant-id 72f988bf-0000–0000–0000–2d7cd011db47</span><br></pre></td></tr></table></figure><p>Now, all users from the AAD account can authenticate to the AKS cluster. But, they can not do any operation as they don’t have yet any permission to do whatever. We need to grant them access to k8s resources through Role and RoleBinding. Before that, we need to access the cluster as admin, in order to assign the roles.</p><h4 id="3-Connect-to-AKS-cluster"><a href="#3-Connect-to-AKS-cluster" class="headerlink" title="3. Connect to AKS cluster"></a><strong>3. Connect to AKS cluster</strong></h4><p>We need to connect to AKS in order to run kubectl commands against the new cluster, as an admin.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ az aks get-credentials \</span><br><span class="line">     -resource-group aks-aad-rg \</span><br><span class="line">     -name aks-aad</span><br><span class="line">     --admin</span><br><span class="line">Merged &quot;aks-aad-admin&quot; as current context in /Users/houssem/.kube/config</span><br></pre></td></tr></table></figure><p>By the way, the source code for all the commands are here: <a href="https://github.com/HoussemDellai/rbac-aks-aad" target="_blank" rel="noopener">github.com/HoussemDellai/rbac-aks-aad</a></p><p>And this workshop is available as a video.</p><h4 id="4-Create-the-Role-and-RoleBinding"><a href="#4-Create-the-Role-and-RoleBinding" class="headerlink" title="4. Create the Role and RoleBinding"></a>4. Create the Role and RoleBinding</h4><p>Let’s create the Role which will define access to certain resources. For example, only reading information from pods.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  namespace: default</span><br><span class="line">  name: pod-reader</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [“”] # “” indicates the core API group</span><br><span class="line">  resources: [“pods”]</span><br><span class="line">  verbs: [“get”, “watch”, “list”]</span><br></pre></td></tr></table></figure><p>To assign the role to a user, we need to use <a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/" target="_blank" rel="noopener">RoleBinding</a>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: read-pods</span><br><span class="line">  namespace: default</span><br><span class="line">subjects:</span><br><span class="line">- kind: User</span><br><span class="line">  name: &quot;houssem.dellai@live.com&quot; # Name is case sensitive</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role #this must be Role or ClusterRole</span><br><span class="line">  name: pod-reader # must match the name of the Role</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure><blockquote><p>We can use a Group instead of User, to bind to all users within the AAD group.</p></blockquote><p>Then we deploy both files using kubectl:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f role.yaml</span><br><span class="line">role.rbac.authorization.k8s.io/pod-reader created</span><br><span class="line">$ kubectl apply -f role-binding.yaml</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/read-pods created</span><br></pre></td></tr></table></figure><p>We can check if the Role and RoleBinding were successfully created:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get roles</span><br><span class="line">NAME       AGE</span><br><span class="line">pod-reader 2m</span><br><span class="line">$ kubectl get rolebindings</span><br><span class="line">NAME        AGE</span><br><span class="line">read-pods   2m</span><br></pre></td></tr></table></figure><h4 id="5-Test-authentication-and-authorisation-to-AKS"><a href="#5-Test-authentication-and-authorisation-to-AKS" class="headerlink" title="5. Test authentication and authorisation to AKS"></a>5. Test authentication and authorisation to AKS</h4><p>Now that everything is configured, we will pretend to be the user used in RoleBinding. We’ll connect to the AKS cluster from another machine. This is using login to Azure, not to to the cluster.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ az aks get-credentials \</span><br><span class="line">     -resource-group aks-aad-rg \</span><br><span class="line">     -name aks-aad</span><br><span class="line">Merged &quot;aks-aad&quot; as current context in /Users/houssem/.kube/config</span><br></pre></td></tr></table></figure><p>Then we’ll try the allowed command:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line">To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code CL7DWV3P2 to authenticate.</span><br></pre></td></tr></table></figure><p>Because we added authentication, it is asking to login to the cluster. We’ll login as the user specified in RoleBinding. We need to launch the browser in the specified url address and use the given code.</p><p>Then we press continue.</p><p>And here we come to the most exciting part, the login to the AKS cluster!</p><p>We can login with the email and password for the user.</p><p>We run again the allowed command:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line">No resources found. # we didn&apos;t created a Pod yet !</span><br></pre></td></tr></table></figure><p>If we try to run one of the non allowed operations, then it will fail!</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get deployments</span><br><span class="line">Error from server (Forbidden): deployments.extensions is forbidden: User “f97fc9ba-ebda-439e-825a-..” cannot list deployments.extensions in the namespace “default”</span><br></pre></td></tr></table></figure><p>If we try to get the pods from all the namespaces, that will also fail. Because we configured the user in Role to get pods from only the default namespace.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces</span><br><span class="line">Error from server (Forbidden): pods is forbidden: User &quot;f97fc9ba-ebda-439e-825a-0e25801cb32c&quot; cannot list pods at the cluster scope</span><br></pre></td></tr></table></figure><h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>We have configured a user to login and get access to specific AKS resources. We could also do this for an entire AAD group.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;【译文】&lt;/p&gt;
&lt;p&gt;本快速研讨将指导您使用AAD配置AKS以使用RBAC对用户进行身份验证。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/Cloud-Service/深入探讨AKS和AAD/1.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="Cloud Service" scheme="http://blog.ozairs.com/categories/Cloud-Service/"/>
    
    
      <category term="GCP" scheme="http://blog.ozairs.com/tags/GCP/"/>
    
  </entry>
  
  <entry>
    <title>关于Google Professional Cloud Architect考试-GCP2019</title>
    <link href="http://blog.ozairs.com/Cloud-Service/%E5%85%B3%E4%BA%8EGoogle-Professional-Cloud-Architect%E8%80%83%E8%AF%95-GCP2019/"/>
    <id>http://blog.ozairs.com/Cloud-Service/关于Google-Professional-Cloud-Architect考试-GCP2019/</id>
    <published>2019-04-30T10:14:21.000Z</published>
    <updated>2019-04-30T10:22:15.309Z</updated>
    
    <content type="html"><![CDATA[<p>【译文】</p><p>这个月，我参加了<a href="https://cloud.google.com/certification/guides/professional-cloud-architect/" target="_blank" rel="noopener">专业云架构师</a>考试，我通过了，现在我已经通过了Google Cloud认证。因此，现在是时候反思认证，我喜欢什么，我不喜欢什么，或者对我来说如何通过这个认证之旅。如果您打算获得认证，也许您会在这里获得一些见解以做好准备。</p><h3 id="我喜欢这一认证的地方"><a href="#我喜欢这一认证的地方" class="headerlink" title="我喜欢这一认证的地方"></a><strong>我喜欢这一认证的地方</strong></h3><h4 id="1-认证中出现的都是场景题"><a href="#1-认证中出现的都是场景题" class="headerlink" title="1. 认证中出现的都是场景题"></a>1. 认证中出现的都是场景题</h4><p>我真正喜欢的专业云架构师认证（PCA）是它主要是基于场景的考试。这意味着对于几乎所有问题，都会描述业务问题，您的任务是找到解决问题的最佳解决方案。对于这些场景，谷歌记录了三个案例研究（<a href="https://cloud.google.com/certification/guides/cloud-architect/casestudy-mountkirkgames-rev2" target="_blank" rel="noopener">Mountkirk</a>，<a href="https://cloud.google.com/certification/guides/cloud-architect/casestudy-dress4win-rev2" target="_blank" rel="noopener">Dress4Win</a>和<a href="https://cloud.google.com/certification/guides/cloud-architect/casestudy-terramearth-rev2" target="_blank" rel="noopener">TerramEarth）</a>）。他们每个人都介绍了一个虚构的公司，他们的解决方案，他们的目标和挑战。强烈建议在考试前花时间研究这些文件，我也鼓励人们考虑每个案例研究的目标GCP架构。在考试中，案例研究存在大量问题（可能&gt; 20％）。但是，如果它们与案例研究没有直接关系，那么大多数其他问题也是基于情景的事件。</p><p>我非常喜欢这种基于场景的方法，因为它需要一些思考才能找到正确的答案。专业架构师认证不是考试补习。您不必认真地学习大量信息，并且在测试当天重新学习所学内容（然后在后一天忘记所有内容）。该认证需要一些实践和一些云背景。</p><h4 id="2-这是个关于架构师认证"><a href="#2-这是个关于架构师认证" class="headerlink" title="2. 这是个关于架构师认证"></a>2. 这是个关于架构师认证</h4><p>该认证的另一个有趣的方面是它要求您作为架构师思考。我的意思是，许多认证只需要您成为工具专家，了解很多产品功能。如果GCP产品和服务知识对于通过PCA测试很重要，我认为这还不够。许多问题要求您找到问题的解决方案，而不是向您询问产品功能。这种方法让我想起了架构师（2000年初的J2EE认证企业架构师）的旧Sun Microsystem认证，你不仅需要通过考试（多项选择题），还需要定义和记录架构，然后写一篇文章。</p><p>在PCA考试中，据我所知，绝大多数问题都是关于GCP能力以最好地解决特定挑战。您不会经常被问及具体的产品功能。您将在更广泛的背景下测试本机或混合云解决方案。如果您了解Compute Engine的所有信息，那对您有好处，但如果您对测试方法，持续交付，GDPR或PCI DSS一无所知，那么您就会被搞砸。请记住，对于某些问题，最佳答案并不总是包含Google产品的问题（谷歌对此表示赞赏）。与现实生活中一样，商业问题的最佳选择可能包括GCP服务，……或者不包括。也许开源解决方案可以更好地满足技术和业务需求。再次，作为一名架构师，而不是作为工具专家。</p><h4 id="3-认证覆盖范围很广"><a href="#3-认证覆盖范围很广" class="headerlink" title="3. 认证覆盖范围很广"></a>3. 认证覆盖范围很广</h4><p>Professional Architect认证的范围很广：IaaS，PaaS，SaaS，网络，存储，安全，测试，监控等。因此它涵盖了许多不同的云计算领域。</p><p>这意味着当您准备考试时，您很可能不得不触及您没有掌握的主题。我个人不得不走出我的舒适区域，了解有关网络和防火墙的更多信息。我不是在谈论GCP的具体情况，而是谈到我过去从未处理过的一些重要的网络概念。所以我学到了很多，而且由于认证的范围很广，我认为这是一个真正的机会，可以回顾你已经知道的东西，提高你的一些技能，并学习全新的东西。此外，我觉得我大多数都经过了重要的测试，而不是非常具体的产品细节。</p><h3 id="我不喜欢这个考试的地方"><a href="#我不喜欢这个考试的地方" class="headerlink" title="我不喜欢这个考试的地方"></a>我不喜欢这个考试的地方</h3><p>现在让我们来探讨认证中一些不太令人兴奋的方面。第一个与考试范围有关。</p><h4 id="认证范围太广"><a href="#认证范围太广" class="headerlink" title="认证范围太广"></a>认证范围太广</h4><p>如果认证是一个很好的学习机会，那么也存在被大量淹没的风险……很多信息。</p><p>请查看下面的图片，了解认证涵盖的内容（或使用<a href="https://raw.githubusercontent.com/gregsramblings/google-cloud-4-words/master/Poster-hires.png" target="_blank" rel="noopener">此链接</a>）。</p><p><img src="/Cloud-Service/关于Google-Professional-Cloud-Architect考试-GCP2019/1.png" alt="img"></p><p>如果您删除了PCA主题之外的内容（G Suite，移动设备，地图，其他资源。），则学习材料仍然很大。测试准备耗时并且需要真正的努力和承诺。</p><h4 id="有限的学习材料"><a href="#有限的学习材料" class="headerlink" title="有限的学习材料"></a>有限的学习材料</h4><p>因此，认证很难，因为它涵盖了所有产品。但我能理解这一点。PCA是经验丰富的云专业人员的高级认证。所以它必须非常广泛。但我真正不喜欢的PCA认证是缺乏相关的学习材料。</p><p>除GCP文档外，没有任何研究书籍或在线资料。Google似乎依赖Coursera或其他人进行自定进度的培训。在<a href="https://www.coursera.org/specializations/gcp-architecture?utm_source=googlecloud&amp;utm_medium=institutions&amp;utm_campaign=GoogleCloud_PCA_Architecting" target="_blank" rel="noopener">与谷歌云平台架构专业化</a>（Coursera）是很有趣的，但还不够。它没有适当地涵盖BigQuery。最近<a href="https://www.coursera.org/learn/preparing-cloud-professional-cloud-architect-exam?utm_source=googlecloud&amp;utm_medium=institutions&amp;utm_campaign=GoogleCloud_Cert_Prep_PCA" target="_blank" rel="noopener">准备Google Cloud Professional Cloud架构考试</a>与实际考试内容更加一致，但不会深入研究。据我所知，现有的Udemy课程并不相关。Google提供讲师指导的培训，因此这可能是接受Google专业人员培训的最佳方式。但这对我来说不是一个选择（需要自定进度的训练）。</p><p>幸运的是，<a href="https://www.qwiklabs.com/quests/47" target="_blank" rel="noopener">Qwiklabs对GCP架构的挑战</a>非常好，但它们不是免费的，并且它们没有附带的伴随学习材料。就个人而言，如果没有Qwiklabs，我绝不会通过测试，所以如果你能负担得起，我强烈推荐订阅。我认为GCP架构，Kubernetes和BigQuery Qwiklabs任务非常重要。如果您认为BigQuery超出了范围，因为它是更多的数据分析（这是Coursera培训有时会说的……），请三思而后行。您将有关于BigQuery的<em>多个</em>问题。</p><h4 id="没有官方通过分数"><a href="#没有官方通过分数" class="headerlink" title="没有官方通过分数"></a>没有官方通过分数</h4><p>据我所知，通过考试的最低分数不公开。这可能是80％左右，但我不认为谷歌正式就这一点进行沟通。坦率地说，我不确定我理解为什么。我认为这是谷歌更灵活的一种方式，可以动态改变成功因素。但由于没有及格分数，也没有考试成绩。这意味着考试的结果是二进制：通过或失败。如果失败（谷歌称之为“非熟练”），你不知道你是否错过了它或者你是否足够接近。如果你通过，也一样。在我所知道的其他认证中，您通常会按类别获得全局分数和分数。我认为这有助于更好地了解您需要改进的地方，以便真正完全熟练（无论您是否通过了考试）。</p><h4 id="还有一些棘手的测试问题"><a href="#还有一些棘手的测试问题" class="headerlink" title="还有一些棘手的测试问题"></a>还有一些棘手的测试问题</h4><p>我相信Professional Cloud Architect考试总体上是一个很好的考试。根据我与人们的一些交流，与2018年11月之前的情况相比，它似乎也有所改善。我无法分辨，因为我只接触过“2018年11月后”版本的考试。</p><p>但是在考试的这里和那里，仍然有一些可以避免的愚蠢问题。作为云架构师，不要测试我记住gcloud命令行的能力。在现实生活中，我总能通过简单的互联网搜索或使用gcloud帮助找到合适的语法。最重要的是，我不认为这是PCA考试中的一个问题，但是可以避免的轻微刺激。</p><p>关于认证的另一个棘手方面与Dress4Win案例研究有关。或者我应该说“ <strong>相关</strong>”因为它似乎已经解决了这个问题。我没有证据（如屏幕截图）但我很肯定Dress4Win技术环境直到最近才提到MySQL 5.8（事实上，至少到4月的第一周）。为什么这很重要？好吧，我不是MySQL专家，但似乎5.8版本不存在（5.7之后的版本是8.0）。所以这听起来像个伎俩。此外，Google Cloud SQL仅支持5.7版本。因此，任何与Dress4win MySQL可移植性相关的问题都会产生误导，因为如果不支持数据库版本，则无法利用Cloud SQL。但正如我所说，这已经修复，Dress4Win描述现在提到MySQL 5.7</p><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>我持有Sun Microsystems（Oracle），IBM，Open Group和Google等几家公司的认证。我的第一个认证是从2002年开始，作为Java开发人员（恕我直言，不是一个好的认证考试）。我也参与了认证考试的开发。如果您参加过IBM Cloud认证测试，您可能会遇到我创建的一些问题。我提到这一切的原因是因为我相信我的职业生涯中已经接触过大量的认证。根据我目前所看到的情况，我认为<em>Google Professional Cloud Architect</em>是我最喜欢的认证之一。这不仅是因为它测试了你解决业务问题的能力，还因为如果你想成功，它会迫使你练习很多。</p><p>当然，认证就是认证。它不会取代现场经验，也不能证明您是专业人士。认证只能证明你具有通过认证的能力。因此，对我来说，认证过程只是GCP激动人心的旅程的开始。</p><p>【原文】</p><p>This month, I took the <a href="https://cloud.google.com/certification/guides/professional-cloud-architect/" target="_blank" rel="noopener">Professional Cloud Architect</a> exam, I passed, and I am now Google Cloud Certified. So it is time to reflect on the certification, what I liked, what I did not like, or how it has been useful for me to go through this certification journey. And if you plan to get certified as well, maybe you will get some insights here to get better prepared.</p><h3 id="What-I-liked-about-the-exam"><a href="#What-I-liked-about-the-exam" class="headerlink" title="What I liked about the exam"></a><strong>What I liked about the exam</strong></h3><h4 id="Scenario-based"><a href="#Scenario-based" class="headerlink" title="Scenario-based"></a>Scenario-based</h4><p>What I really like about the Professional Cloud Architect certification (PCA) is that it is mostly a scenario-based exam. It means that for almost all questions, a business problem is described and your task is to find the best solution to address the problem. For those scenarios, Google has documented three Case Studies (<a href="https://cloud.google.com/certification/guides/cloud-architect/casestudy-mountkirkgames-rev2" target="_blank" rel="noopener">Mountkirk</a>, <a href="https://cloud.google.com/certification/guides/cloud-architect/casestudy-dress4win-rev2" target="_blank" rel="noopener">Dress4Win</a> and <a href="https://cloud.google.com/certification/guides/cloud-architect/casestudy-terramearth-rev2" target="_blank" rel="noopener">TerramEarth</a>). Each one of them introduces a fictitious company, their solution, their objectives and their challenges. It is strongly recommended to spend time studying these documents before the exam, and I would also encourage people to think about a target GCP architecture for each case study. In the exam, there is a significant amount of questions on the case studies (probably &gt;20%). But most other questions are also scenario-based event if they don’t directly relate to the case studies.</p><p>I like this scenario-based approach a lot as it requires some thinking to be able to identify the correct answer. The Professional Architect certification is not an exam cram. You don’t have to learn a huge amount of information by heart and regurgitate what you learned the day of the test (and then forget everything the day after). The certification requires some practice and some cloud background.</p><h4 id="A-certification-for-architects"><a href="#A-certification-for-architects" class="headerlink" title="A certification for architects"></a>A certification for architects</h4><p>Another interesting aspect of the certification is that it asks you to think as an architect. What I mean is that a lot of certifications just require you to be a tool specialist, to know a lot of product features. If GCP products and services knowledge is important to pass the PCA test, I think it is not sufficient. Many questions ask you to find a solution to a problem instead of asking you about product capabilities. This approach reminds me a bit of the old Sun Microsystem certification for architects (Certified Enterprise Architect for J2EE in early 2000) where you needed not only to pass an exam (multiple-choice questions) but also to define and document an architecture, and then write an essay.</p><p>In the PCA exam, as far as I can remember, a vast majority of the questions are about GCP capabilities to best address a given challenge. You will not often be asked about specific product features. You will be tested about native or hybrid cloud solutions in an broader context. If you know everything about Compute Engine, that’s good for you, but if you know nothing about testing approaches, continuous delivery, GDPR or PCI DSS, you’re are screwed. And keep in mind that for some questions, the best answer is not always the one that includes Google products (kudos to Google for this). As in real life, the best option to a business problem may include GCP services, … or not. Maybe an open source solution will better address technical and business requirements. Again, think as an architect, not as a tool specialist.</p><h4 id="Broad-certification"><a href="#Broad-certification" class="headerlink" title="Broad certification"></a>Broad certification</h4><p>The scope of the Professional Architect certification is broad: IaaS, PaaS, SaaS, Networking, Storage, Security, Testing, Monitoring, etc…. So it covers a lot of different cloud computing domains.</p><p>Which means that when you prepare for the exam, you will most likely have to touch upon topics that you’re not mastering. I personally had to go outside of my comfort zone and learn more about networking and firewalls. And I am not talking about GCP specificities here but about some important networking concepts I never had to deal with in the past. So I learned a lot, and because the scope of the certification is so wide, I think this is a real opportunity to review what you already know, to sharpen some of your skills, and to learn brand new stuff. Moreover, I feel I have mostly been tested on stuff that matters, not on very specific product details.</p><h3 id="What-I-did-not-like-about-the-exam"><a href="#What-I-did-not-like-about-the-exam" class="headerlink" title="What I did not like about the exam"></a>What I did not like about the exam</h3><p>So now let’s explore some less exciting aspects of the certification. The very first one is related to the scope of the exam.</p><h4 id="Broad-certification…-the-other-side-of-the-coin"><a href="#Broad-certification…-the-other-side-of-the-coin" class="headerlink" title="Broad certification…. the other side of the coin"></a>Broad certification…. the other side of the coin</h4><p>If the certification is a great opportunity to learn, there is also a risk of being overwhelmed by a lot… A LOT… of information.</p><p>Take a look at the picture below to get a sense of what the certification covers (or use <a href="https://raw.githubusercontent.com/gregsramblings/google-cloud-4-words/master/Poster-hires.png" target="_blank" rel="noopener">this link</a>).</p><p>If you remove stuff that is out of the PCA topics (G Suite, Mobile, Maps, Additional resources.), the study material is still huge. The test preparation is time consuming and requires real effort and commitment.</p><h4 id="Limited-study-material"><a href="#Limited-study-material" class="headerlink" title="Limited study material"></a>Limited study material</h4><p>So the certification is difficult because of all the products it covers. But I can understand that. The PCA is an advanced certification for experienced cloud professionals. So it has to be quite extensive. But what I really did not like about the PCA certification is the lack of relevant study material.</p><p>There is no study book or online material other than the GCP documentation. It seems that Google relies on Coursera or others for self-paced training. The <a href="https://www.coursera.org/specializations/gcp-architecture?utm_source=googlecloud&amp;utm_medium=institutions&amp;utm_campaign=GoogleCloud_PCA_Architecting" target="_blank" rel="noopener">Architecting with Google Cloud Platform Specialization</a> (Coursera) is quite interesting but not sufficient. And it does not properly cover BigQuery. The more recent <a href="https://www.coursera.org/learn/preparing-cloud-professional-cloud-architect-exam?utm_source=googlecloud&amp;utm_medium=institutions&amp;utm_campaign=GoogleCloud_Cert_Prep_PCA" target="_blank" rel="noopener">Preparing for the Google Cloud Professional Cloud Architect Exam</a> is more aligned with real exam content, but does not go deep dive. The existing Udemy courses are, according to me, not relevant. Google offers instructor-led training, so this is probably the best way to get trained by Google professional. But it was not an option for me (self-paced training was needed).</p><p>Fortunately, the <a href="https://www.qwiklabs.com/quests/47" target="_blank" rel="noopener">Qwiklabs Challenge on GCP Architecture</a> is very good, but they are not free and they don’t come with companion study material. Personally, I would never have passed the tests without Qwiklabs, so I strongly recommend a subscription if you can afford it. I think GCP architecture, Kubernetes and BigQuery Qwiklabs Quests are important. And if you believe BigQuery is out of scope because it is more data analytics (this is what the Coursera training is sometime saying…), think twice. You will have <em>multiple</em> questions on BigQuery.</p><h4 id="No-official-passing-score"><a href="#No-official-passing-score" class="headerlink" title="No official passing score"></a>No official passing score</h4><p>As far as I know, the minimum score to pass the exam is not public. It is probably something around 80% but I don’t think Google officially communicates on this. Frankly, I am not sure I understand why. I suppose it is a way for Google to be a bit more flexible and change success factors on the fly. But because there is no passing score, there is no exam score either. Which means that the result of the exam is binary: Passed or Failed. In case of failure (Google calls this “Non proficient”), you don’t know if you miserably missed it or if you were close enough. Same if you passed. In other certifications I am aware of, you usually get a global score and a score by category. I think this is useful to better understand where you need to improve in order to really become fully proficient (whether or not you passed the exam).</p><h4 id="Still-some-tricky-test-questions"><a href="#Still-some-tricky-test-questions" class="headerlink" title="Still some tricky test questions"></a>Still some tricky test questions</h4><p>I believe that Professional Cloud Architect exam is overall a good one. Based on some exchanges I had with people, it also seems it has improved compared to what it was before November 2018. I cannot really tell as I was only exposed to the “Post Nov 2018” version of the exam.</p><p>But here and there in the exam, there are still some silly questions that may be avoided. As a Cloud Architect, don’t test me on my ability to remember a gcloud command line. In real life, I can always find the proper syntax with a simple internet search or using gcloud help. Bottom line, I don’t think it is an issue in the PCA exam, but a minor irritant that could be avoided.</p><p>Another tricky aspect about the certification is related to the Dress4Win case study. Or I should say “<strong>was related</strong>” because it seems the issue has been solved quite recently. I don’t have proof (like a screen shot) but I am positive that Dress4Win technical environment was mentioning MySQL 5.8 until recently (in fact, until first week of April at least). Why is this important? Well, I am not a MySQL expert but it seems that the 5.8 version does not exist (the one after 5.7 is 8.0). So it sounded like a trick. Moreover, Google Cloud SQL only supports up to version 5.7. So any question related to Dress4win MySQL portability would have been misleading, as you cannot leverage Cloud SQL if the database version is not supported. But as I said, this has been fixed and Dress4Win description now mentions MySQL 5.7</p><h4 id="Summary…"><a href="#Summary…" class="headerlink" title="Summary…."></a>Summary….</h4><p>I hold certifications from a couple of entities such as Sun Microsystems (Oracle), IBM, the Open Group, and now Google. My first certification is from 2002, as a Java Developer (IMHO, not a good certification exam). I have also been involved in the development of certification exams. If you ever take IBM Cloud certification tests, you may get some questions that I created. The reason I am mentioning all this is because I believe I have been exposed to a significant amount of certifications in my career. And based on what I have seen so far, I really think that the <em>Google Professional Cloud Architect</em> is one of my favourite certifications. Not only because it tests you on you ability to solve business problems, but also because it forces you to practice a lot if you want to succeed.</p><p>Of course, a certification is just that…a certification. It does not replace field experience, and it does not prove that you are a professional. A certification is only as good as what you do with it. For me, the certification process was just the beginning of an exciting journey on GCP.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;【译文】&lt;/p&gt;
&lt;p&gt;这个月，我参加了&lt;a href=&quot;https://cloud.google.com/certification/guides/professional-cloud-architect/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
      
    
    </summary>
    
      <category term="Cloud Service" scheme="http://blog.ozairs.com/categories/Cloud-Service/"/>
    
    
      <category term="GCP" scheme="http://blog.ozairs.com/tags/GCP/"/>
    
  </entry>
  
  <entry>
    <title>使用GitBook编写文档书籍</title>
    <link href="http://blog.ozairs.com/gitbook/%E4%BD%BF%E7%94%A8GitBook%E7%BC%96%E5%86%99%E6%96%87%E6%A1%A3%E4%B9%A6%E7%B1%8D/"/>
    <id>http://blog.ozairs.com/gitbook/使用GitBook编写文档书籍/</id>
    <published>2019-04-28T12:54:43.000Z</published>
    <updated>2019-04-28T13:09:48.430Z</updated>
    
    <content type="html"><![CDATA[<p>GitBook 是一个基于 Node.js 的命令行工具，可使用 Github/Git 和 Markdown 来制作精美的电子书。GitBook支持输出以下几种文档格式：</p><p>静态站点：GitBook默认输出该种格式<br>PDF：需要安装gitbook-pdf依赖<br>eBook：需要安装ebook-convert<br>GitBook可以用来写书、API文档、公共文档，企业手册，论文，研究报告等。</p><p>一、GitBook安装<br>在安装之前，我们还需要配置一下 nodejs 插件安装的下载镜像地址。因为默认的镜像地址在国外，需要翻墙才可以访问，因此我们需要设置国内的镜像地址。这里使用阿里巴巴的镜像地址 <a href="http://registry.npm.taobao.org" target="_blank" rel="noopener">http://registry.npm.taobao.org</a> 。使用下面的命令，进行配置。</p><p>npm config set registry <a href="http://registry.npm.taobao.org" target="_blank" rel="noopener">http://registry.npm.taobao.org</a><br>1、NMP安装Gitbook</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install gitbook -g</span><br></pre></td></tr></table></figure><p>//安装命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g gitbook-cli</span><br></pre></td></tr></table></figure><p>//卸载命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall -g gitbook</span><br></pre></td></tr></table></figure><p>2、检验下是否安装成功</p><p>//显示gitbook以及gitbook-cli版本号</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitbook -V</span><br></pre></td></tr></table></figure><p>二、基本使用<br>Gitbook需要2个基本文件：</p><p>README.md</p><p>SUMMARY.md</p><p>README.md是关于你的书的介绍，而SUMMARY.md中则包含了书的目录。我们还可以添加“book.json（电子书配置文件）”、“GLOSSARY.md（书尾词汇表）”以及“封面图片”等，默认文件树中没有这些，需要自行添加。</p><ol><li>生成图书目录结构<br>创建一个目录test， 使用gitbook init命令就可以在目录下生产这两个文件。一个SUMMARY.md文件的格式大致如下，每一行对应一个相应的文件。</li></ol><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><ul><li><a href="README.md">Introduction</a></li><li><a href="chapter1/README.md">第一章</a><ul><li><a href="chapter1/seciont1.md">第一节</a></li><li><a href="chapter1/section2.md">第二节</a></li></ul></li><li><a href="chapter2/README.md">第二章</a><ul><li><a href="chapter2/seciont1.md">第一节</a></li><li><a href="chapter2/section2.md">第二节</a></li></ul></li><li><p><a href="end/README.md">结束</a></p><p>执行 gitbook init 会根据 SUMMARY.md 目录生成对应的文件夹和 md 文件，每一个 md 文件对应每一章节，每一章节的内容在对应的 md 文件里编辑，你可以使用本地支持Markdown语法的编辑器编辑，例如Markdown Pad。</p></li></ul><p>如果想要新增章节，可以在 SUMMARY.md 里面新增，然后执行 gitbook init 就会新增对应的 md 文件，原有文件不会变化；如果想要删除章节，在 SUMMARY.md 里面删除，然后执行 gitbook init 想要删除的 md 文件并不会删除，需要手动删除。</p><ol start="2"><li>生成图书<br>2.1 输出为静态网站<br>执行下面的命令</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitbook serve</span><br></pre></td></tr></table></figure><p>然后浏览器中输入 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a> 就可以预览生成的以网页形式组织的书籍。</p><p>这里你会发现，你在你的图书项目的目录中多了一个名为_book的文件目录，而这个目录中的文件，即是生成的静态网站内容。</p><p>使用build参数生成到指定目录</p><p>与直接预览生成的静态网站文件不一样的是，使用这个命令，你可以将内容输入到你所想要的目录中去：</p><p>$ mkdir /tmp/gitbook<br>​$</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitbook build --output=/tmp/gitbook</span><br></pre></td></tr></table></figure><p>文档写好以后，你可以把Gitbook源目录下面的所有文件都复制到你项目下(app_root/docs/api/gitbook_api_dir)。这样，你的项目就多了一份漂亮的文档。</p><p>　2.2 输出为PDF<br>输出为PDF文件，需要先使用NPM安装上gitbook pdf：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo npm install gitbook-pdf -g</span><br></pre></td></tr></table></figure><p>三、Gitbook的插件支持<br>新建book.json，可以做一些配置，比如标题，作者，指定readme文件，关闭分享链接等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;gitbook tutorial&quot;,</span><br><span class="line">  &quot;description&quot;: &quot;Webpack 是当下最热门的前端资源模块化管理和打包工具，本书大部分内容翻译自 Webpack 官网。&quot;,</span><br><span class="line">  &quot;structure&quot;: &#123;</span><br><span class="line">    &quot;readme&quot;: &quot;README.md&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;links&quot;: &#123;</span><br><span class="line">    &quot;gitbook&quot;: false,</span><br><span class="line">    &quot;sharing&quot;: &#123;</span><br><span class="line">      &quot;google&quot;: false,</span><br><span class="line">      &quot;facebook&quot;: false,</span><br><span class="line">      &quot;twitter&quot;: false,</span><br><span class="line">      &quot;all&quot;: false</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  &quot;plugins&quot;: [&quot;disqus&quot;,&quot;advanced-emoji&quot;],</span><br><span class="line">  &quot;pluginsConfig&quot;: &#123;</span><br><span class="line">    &quot;disqus&quot;: &#123;</span><br><span class="line">        &quot;shortName&quot;: &quot;gitbookuse&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gitbook install ./</span><br></pre></td></tr></table></figure><p>gitbook命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">gitbook init //初始化目录文件</span><br><span class="line">gitbook help //列出gitbook所有的命令</span><br><span class="line">gitbook --help //输出gitbook-cli的帮助信息</span><br><span class="line">gitbook build //生成静态网页</span><br><span class="line">gitbook serve //生成静态网页并运行服务器</span><br><span class="line">gitbook build --gitbook=2.0.1 //生成时指定gitbook的版本, 本地没有会先下载</span><br><span class="line">gitbook ls //列出本地所有的gitbook版本</span><br><span class="line">gitbook ls-remote //列出远程可用的gitbook版本</span><br><span class="line">gitbook fetch 标签/版本号 //安装对应的gitbook版本</span><br><span class="line">gitbook update //更新到gitbook的最新版本</span><br><span class="line">gitbook uninstall 2.0.1 //卸载对应的gitbook版本</span><br><span class="line">gitbook build --log=debug //指定log的级别</span><br><span class="line">gitbook builid --debug //输出错误信息</span><br></pre></td></tr></table></figure><p>四、托管到GitBook.com<br>1、注册 GitBook.com 账号</p><p>首先进入 GitBook.com 注册一个账号，并新建一个项目。在“Setting（设置）”页面获取到“Git URL（Git 链接）”，如下所示： </p><p>1、<a href="https://git.gitbook.com/charmingfst/mytest.git" target="_blank" rel="noopener">https://git.gitbook.com/charmingfst/mytest.git</a><br>2、使用Git上传电子书项目</p><p>在本地新建一个文件夹，并通过 Git 命令把刚才新建的远程项目抓取到本地，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir FirstBook</span><br><span class="line">cd FirstBook</span><br><span class="line">git init</span><br><span class="line">git pull https://git.gitbook.com/charmingfst/mytest.git</span><br></pre></td></tr></table></figure><p>然后把本地电子书项目“test”中的所有内容拷贝到刚才新建的文件夹中，如上面的“FirstBook”。然后使用 Git 命令把本地的项目上传到远程，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git add -A</span><br><span class="line">git commit -m &quot;提交说明&quot;</span><br><span class="line">git remote add gitbook https://git.gitbook.com/charmingfst/mytest.git</span><br><span class="line">git push -u gitbook master</span><br></pre></td></tr></table></figure><h2 id="git-push-命令中的-u-表示将本地-master-分支的上游分支设置为-github-master，下次直接使用git-push命令即可。"><a href="#git-push-命令中的-u-表示将本地-master-分支的上游分支设置为-github-master，下次直接使用git-push命令即可。" class="headerlink" title="git push 命令中的 -u 表示将本地 master 分支的上游分支设置为 github/master，下次直接使用git push命令即可。"></a>git push 命令中的 -u 表示将本地 master 分支的上游分支设置为 github/master，下次直接使用git push命令即可。</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;GitBook 是一个基于 Node.js 的命令行工具，可使用 Github/Git 和 Markdown 来制作精美的电子书。GitBook支持输出以下几种文档格式：&lt;/p&gt;
&lt;p&gt;静态站点：GitBook默认输出该种格式&lt;br&gt;PDF：需要安装gitbook-pdf依
      
    
    </summary>
    
      <category term="gitbook" scheme="http://blog.ozairs.com/categories/gitbook/"/>
    
    
      <category term="gitbook" scheme="http://blog.ozairs.com/tags/gitbook/"/>
    
  </entry>
  
  <entry>
    <title>100条你需要知道的英语俚语</title>
    <link href="http://blog.ozairs.com/English-Skills/100%E6%9D%A1%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E8%8B%B1%E8%AF%AD%E4%BF%9A%E8%AF%AD/"/>
    <id>http://blog.ozairs.com/English-Skills/100条你需要知道的英语俚语/</id>
    <published>2019-04-27T10:25:21.000Z</published>
    <updated>2019-04-27T10:30:28.275Z</updated>
    
    <content type="html"><![CDATA[<h2 id="100-Common-sayings-everyone-must-know"><a href="#100-Common-sayings-everyone-must-know" class="headerlink" title="100+ Common sayings everyone must know"></a>100+ Common sayings everyone must know</h2><p>\1. Curiosity Killed the Cat</p><p>\2. World is Your Oyster</p><p>\3. You Need Money to Make Money</p><p>\4. All good things come to those who wait</p><p>\5. If at first you don’t succeed, try, try again.</p><p>\6. Never put off till tomorrow what you can do today.</p><p>\7. Don’t cross the bridge until you come to it.</p><p>\8. Two heads are better than one.</p><p>\9. Paddle your own canoe.</p><p>\10. Save for a rainy day.</p><p>\11. Life is what we make it.</p><p>\12. Opposite attracts.</p><p>\13. Faint heart never won fair lady.</p><p>\14. The meek shall inherit the earth.</p><p>\15. With age comes wisdom.</p><p>\16. Two is company, three is a crowd.</p><p>\17. It’s better to be safe than sorry.</p><p>\18. Don’t look a gift horse in the mouth.</p><p>\19. Do unto others as you would have others do unto you.</p><p>\20. Hitch your wagon to a star.</p><p>\21. Many hands make light work.</p><p>\22. You’re never too old to learn.</p><p>\23. A word to the wise is sufficient.</p><p>\24. Don’t judge a book by its cover.</p><p>\25. The squeaking wheel gets the grease.</p><p>[<img src="/English-Skills/100条你需要知道的英语俚语/1.jpg" alt="Popular common sayings"></p><p>\26. A stitch in time saves nine</p><p>\27. Look before you leap.</p><p><strong>See Also:  Wise Sayings, Wisdom Sayings and Life</strong></p><p>\28. Haste makes waste.</p><p>\29. Fools rush in where angels fear to tread.</p><p>\30. Seek and ye shall find.</p><p>\31. The best things in life are free.</p><p>\32. The Apple Doesn’t Fall Far From the Tree</p><h2 id="More-Common-Sayings-–-Slangs"><a href="#More-Common-Sayings-–-Slangs" class="headerlink" title="More Common Sayings – Slangs"></a>More Common Sayings – Slangs</h2><p>\33. Root of the Problem</p><p>\34. Say Your Piece</p><p>\35. Screw the Pooch</p><p>\36. Shoot the Breeze</p><p>\37. Sit on the Fence</p><p>\38. Speak of the Devil</p><p>\39. Ace in the Hole</p><p>\40. Lose Your Marbles</p><p>\41. Luck of the Irish</p><p>\42. Make a Big To Do</p><p>\43. Make a Fuss</p><p>\44. Miss the Boat</p><p>\45. Off the Hook</p><p>\46. On the Ball</p><p>\47. Out of Sight, Out of Mind</p><p>\48. Out of the Picture</p><p>\49. Out of Touch</p><p>\50. Over the Hill</p><p>[<img src="/English-Skills/100条你需要知道的英语俚语/2.jpg" alt="Popular sayings 2">o</p><p>\51. Paint a Picture</p><p>\52. Perfect Stranger</p><p>\53. Piece of Cake</p><p>\54. Add Insult to Injury</p><p>\55. All Ears</p><p>\56. All Thumbs</p><p>\57. All Your Eggs in One Basket</p><p>\58. Axe to Grind</p><p>\59. Barking Up the Wrong Tree</p><p>\60. Basket Case</p><p><strong>See Also: Family Saying – Things To Say About Family</strong></p><p>\61. Beat Around the Bush</p><p>\62. Beck and Call</p><p>\63. Bend Over Backwards</p><p>\64. The Best of Both Worlds</p><p>\65. Bite Off More Than One Can Chew</p><p>\66. Bite the Bullet</p><p>\67. A Bitter Pill</p><p>\68. Bring Home the Bacon</p><p>\69. Burn the Midnight Oil</p><p>\70. Call It a Day</p><p>\71. Can’t Hold a Candle</p><p>\72. Caught Between Two Stools</p><p>\73. Chew the Fat</p><p>\74. Chickens Come Home to Roost</p><p>\75. Chip On His Shoulder</p><p>\76. Cold Shoulder</p><p>\77. Costs an Arm and a Leg</p><p>\78. Couch Potato</p><p>\79. Cut a Rug</p><p>\80. Cut Corners</p><p>\81. Cut the Cheese</p><p>\82. Cut the Mustard</p><p>\83. Cut to the Chase</p><p>\84. A Dime a Dozen</p><p>\85. Dodge a Bullet</p><p>\86. A Dog’s Breakfast</p><p>\87. Down for the Count</p><p>\88. High and Mighty</p><p>\89. Hit the Road</p><p>\90. Have a Blast</p><p>\91. Higher Than a Kite</p><p>\92. Honest to Goodness</p><p>\93. Hot and Bothered</p><p>\94. A Hot Potato</p><p>\95. If the Shoe Fits, Wear It</p><p>\96. In the Bag</p><p>\97. Jog Your Memory</p><p>\98. Joke Is On You</p><p>\99. Jump At the Chance</p><p>\100. Jump To Conclusion.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;100-Common-sayings-everyone-must-know&quot;&gt;&lt;a href=&quot;#100-Common-sayings-everyone-must-know&quot; class=&quot;headerlink&quot; title=&quot;100+ Common saying
      
    
    </summary>
    
      <category term="English Skills" scheme="http://blog.ozairs.com/categories/English-Skills/"/>
    
    
      <category term="Slang" scheme="http://blog.ozairs.com/tags/Slang/"/>
    
  </entry>
  
  <entry>
    <title>14种令人难以置信的提高英语口语的方法</title>
    <link href="http://blog.ozairs.com/English-Skills/14%E7%A7%8D%E4%BB%A4%E4%BA%BA%E9%9A%BE%E4%BB%A5%E7%BD%AE%E4%BF%A1%E7%9A%84%E6%8F%90%E9%AB%98%E8%8B%B1%E8%AF%AD%E5%8F%A3%E8%AF%AD%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://blog.ozairs.com/English-Skills/14种令人难以置信的提高英语口语的方法/</id>
    <published>2019-04-27T10:13:50.000Z</published>
    <updated>2019-04-27T10:16:34.064Z</updated>
    
    <content type="html"><![CDATA[<p><strong>我们都想知道如何提高英语口语。</strong></p><p>但是对于我们中的一些人来说，这是一个很大的障碍。</p><p>为了提高英语口语，最好的办法是<a href="https://www.fluentu.com/blog/english/english-speaking-online/" target="_blank" rel="noopener">与母语人士交谈</a>。<strong>但并非所有人都有这个选择！</strong></p><p>如果你不认识讲英语的人怎么办？如果你没有时间怎么办？如果你根本没有足够的信心与本地人一起练习怎么办？</p><p><strong>如何在没有其他人帮助的情况下练习英语口语  ？</strong></p><p>别担心。即使没有说话伴侣，您仍然可以<a href="https://www.fluentu.com/blog/english/english-speaking/" target="_blank" rel="noopener">提高英语</a>口语。</p><p>我们将解释如何。</p><p><strong>没有说话伙伴？没问题！</strong></p><h2 id="1-用英语思考"><a href="#1-用英语思考" class="headerlink" title="1.用英语思考"></a>1.用英语思考</h2><p>有时候讲英语的困难不是语言本身，而是你如何思考。</p><p>如果您用您的母语思考然后尝试说英语，您将始终必须在不同语言之间进行翻译。翻译不是一件容易的事！即使是<a href="https://www.fluentu.com/blog/youtube-language-learning/" target="_blank" rel="noopener">精通两种或多种语言的人</a>也难以在语言之间切换。</p><p><strong>解决方案是用英语思考。</strong></p><p>你可以随时随地做到这一点。当你想到你的一天，或者当你想要决定要点什么食物时，尝试使用英语。甚至尝试使用英语 - 英语词典来查找单词。这样你就不必使用母语和翻译单词。你会注意到，当你用英语思考时，你会更容易用英语说话。</p><h2 id="2-和自己说话"><a href="#2-和自己说话" class="headerlink" title="2.和自己说话"></a>2.和自己说话</h2><p>无论何时在家（或在其他地方独自一人），您都可以与自己喜欢的人一起提高英语口语：自己。</p><p>如果您已经在用英语思考，请尝试大声说出您的想法。大声<a href="https://www.fluentu.com/english/blog/easy-simple-english-books-read-beginners/" target="_blank" rel="noopener">读</a>出来。练习就是练习，即使你没有任何人可以纠正你的错误，只要大声说话就可以帮助你更好地说英语。</p><h2 id="3-使用镜子"><a href="#3-使用镜子" class="headerlink" title="3.使用镜子"></a>3.使用镜子</h2><p>每当你可以的时候，花几天时间站在镜子面前说话。选择一个主题，设置一个计时器两到三分钟，然后说话。</p><p>这个练习的目的是在你说话时注意你的嘴，脸和肢体语言。这也让你觉得你在和别人说话，所以你可以假装你<a href="https://www.fluentu.com/english/blog/simple-english-conversation-practice-online/" target="_blank" rel="noopener">和一个学习伙伴讨论过。</a></p><p>说说整整两三分钟。不要停止！如果你遇到一个你不知道的单词，试着以不同的方式表达你的想法。你总是可以在两到三分钟结束后查看如何说出这个单词。这肯定会帮助您找出您遇到问题的单词或句子。</p><h2 id="4-专注于英语流利，而不是语法"><a href="#4-专注于英语流利，而不是语法" class="headerlink" title="4.专注于英语流利，而不是语法"></a>4.专注于英语流利，而不是语法</h2><p>当你说英语时，你多久停一次？</p><p>你停的越多，你的声音就越不自信，你变得越不舒服。尝试上面的镜子练习，但挑战自己说话时不要停止或口吃（在你的话语之间停顿）整个时间。</p><p>这可能意味着你的句子在语法上不完美，那<em>没关系</em>！如果你专注于流利地说话而不是正确说话，你仍然会被理解，你会听起来更好。当您更好地学习它们时，您可以填写正确的语法和单词规则。</p><h2 id="5-试试英语绕口令"><a href="#5-试试英语绕口令" class="headerlink" title="5.试试英语绕口令"></a>5.试试英语绕口令</h2><p>绕口令是一系列很难说的话。一个例子是：“三十三个小偷认为他们在整个星期四激动了宝座。”试着这几次！这是不容易的。</p><p>像这样的文字游戏将帮助您找到适合您口腔和舌头的位置，甚至可以帮助您发音。你可以<a href="https://www.fluentu.com/blog/english/tongue-twisters-in-english/" target="_blank" rel="noopener">在这里</a>找到一个<a href="https://www.fluentu.com/blog/english/tongue-twisters-in-english/" target="_blank" rel="noopener">很好的绕口令</a>列表。</p><h2 id="6-倾听并重复"><a href="#6-倾听并重复" class="headerlink" title="6.倾听并重复"></a>6.倾听并重复</h2><p>你<a href="https://www.fluentu.com/english/blog/learn-english-esl-youtube/" target="_blank" rel="noopener">用英语</a><a href="https://www.fluentu.com/english/blog/learn-english-american-sitcoms/" target="_blank" rel="noopener">看电视节目</a>或<a href="https://www.fluentu.com/english/blog/learn-english-esl-youtube/" target="_blank" rel="noopener">YouTube视频吗？</a>用它们来提高你的流利程度。选择节目的一小部分并逐行重复。尝试匹配音调，速度甚至重音（如果可以）。如果你错过几句话没关系，重要的是继续说话。尝试听起来像节目中的母语人士。</p><p><strong>FluentU</strong>是练习聆听和重复的好方法。</p><p><a href="https://www.fluentu.com/english" target="_blank" rel="noopener"><strong>FluentU</strong>采用真实世界的视频，如音乐视频，电影预告片，新闻和鼓舞人心的演讲，并将其转化为个性化的语言学习课程</a>。</p><p>每当您在此处观看视频时，您都会在屏幕上看到所有语音消息。</p><p>这使得倾听和重复变得更加容易。当你想要挑战时，只需关闭字幕即可！</p><p>如果您看到一个您不知道的单词，请点击该单词以查看使用该单词的图像，定义，示例和其他视频。</p><p>例如，如果点击“带”这个词，那么你会看到：</p><p>FluentU可让您点按以查找任何单词。</p><p>您可以使用FluentU学习任何视频的词汇。向左或向右滑动以查看您正在学习的单词的更多示例。</p><p>FluentU可帮助您快速学习有用的问题和多个示例。<a href="https://www.fluentu.com/english/" target="_blank" rel="noopener">学到更多。</a></p><p>在FluentU，您可以决定学习方式。您可以自由选择哪些视频对<em>您的</em>个人 学习体验最有趣。</p><p>你听这个真正的英语越多，你就越能理解如何自然地说英语。</p><p><a href="https://www.fluentu.com/english/" target="_blank" rel="noopener">使用</a>  计算机或平板电脑<a href="https://www.fluentu.com/english/" target="_blank" rel="noopener">在网站上</a>开始  <a href="https://www.fluentu.com/english/" target="_blank" rel="noopener">使用FluentU</a>，或  <a href="https://itunes.apple.com/ca/app/fluentu-learn-language-videos!/id917892175?mt=8" target="_blank" rel="noopener">从iTunes商店</a>  或<a href="https://play.google.com/store/apps/details?id=com.fluentflix.fluentu&amp;hl=en_US" target="_blank" rel="noopener">Google Play商店</a><a href="https://itunes.apple.com/ca/app/fluentu-learn-language-videos!/id917892175?mt=8" target="_blank" rel="noopener">下载FluentU应用程序</a>。</p><h2 id="7-注意强调的声音"><a href="#7-注意强调的声音" class="headerlink" title="7.注意强调的声音"></a>7.注意强调的声音</h2><p>英语在单词和句子中使用<em>压力</em>。这意味着当你说英语时，你需要强调或强调某些单词和音节（声音）来赋予单词和句子不同的含义。</p><p>聆听<a href="http://esl.fis.edu/grammar/multi/stress.htm" target="_blank" rel="noopener">母语人士</a>说话时<a href="http://esl.fis.edu/grammar/multi/stress.htm" target="_blank" rel="noopener">强调的地方</a>。尝试以同样的方式重复它，以提高自己演讲中的英语压力。</p><p>这不仅可以帮助你说英语，甚至可以减少误解。有时将压力放在错误的音节上会完全改变这个词。例如，ADdress这个词与adDRESS这个词不同。ADdress指的是某人居住的物理位置，adDRESS意味着正式与一群人交谈。</p><p>学会听到差异！</p><h2 id="8-唱英文歌"><a href="#8-唱英文歌" class="headerlink" title="8.唱英文歌"></a>8.唱英文歌</h2><p>和<a href="https://www.fluentu.com/english/blog/learn-english-through-songs-music/" target="_blank" rel="noopener">你最喜欢的英文歌曲</a>一起<a href="https://www.fluentu.com/english/blog/learn-english-through-songs-music/" target="_blank" rel="noopener">唱歌</a>会让你变得更流畅。这是一种经过验证的<a href="https://kuscholarworks.ku.edu/bitstream/handle/1808/8026/Mori_ku_0099D_11582_DATA_1.pdf;sequence=1" target="_blank" rel="noopener">语言学习方法，它以科学为后盾</a>。</p><p>一旦你可以和<a href="https://www.youtube.com/watch?v=nfWlot6h_JM" target="_blank" rel="noopener">Taylor Swift</a>和<a href="https://www.youtube.com/watch?v=O1-4u9W-bns" target="_blank" rel="noopener">Jason Mraz</a>一起唱歌，你可以用更难的东西测试你的技能：说唱！</p><p>说唱是练习英语的好方法，因为这些单词通常像普通句子一样说。然而，说唱歌手使用更强的节奏和更快的速度。有些单词可能没有意义，但是如果你能跟上说唱歌手的话，那么你就可以开始流利了！</p><h2 id="9-用新词学习单词形式"><a href="#9-用新词学习单词形式" class="headerlink" title="9.用新词学习单词形式"></a>9.用新词学习单词形式</h2><p>在你张开嘴之前，有些练习。通过学习您学习的任何单词的不同形式，使说话更容易。你应该在<a href="https://www.fluentu.com/english/blog/english-vocabulary-football-soccer-esl/" target="_blank" rel="noopener">学习新词汇</a>时这样做。例如，如果您刚刚学习了<em>写</em>单词，您还应该学习其他一些形式，如  <em>写</em>和<em>写</em>。</p><p>知道在任何一种句子中使用单词的正确方法很重要。这种知识可以帮助你说话。你不必停下来想想不同的词 - 你会确切地知道你何时需要在讲话时使用这个词。</p><h2 id="10-学习短语，而不是单词"><a href="#10-学习短语，而不是单词" class="headerlink" title="10.学习短语，而不是单词"></a>10.学习短语，而不是单词</h2><p>提高英语水平的一个更好的想法是<a href="https://www.fluentu.com/english/blog/english-past-tense/" target="_blank" rel="noopener">学习单词短语，</a>而不仅仅是单词。</p><p>你可能正在使用正确的语法和词汇，但它仍然不是母语人士会说的。</p><p>例如，你可以说“你今天感觉如何？”但是母语人士可能会说“你在做什么？”或者“怎么了？”。当您说话时，短语和表达可以帮助您发出更自然的声音。</p><h2 id="11-学习你最常见的谚语"><a href="#11-学习你最常见的谚语" class="headerlink" title="11.学习你最常见的谚语"></a>11.学习你最常见的谚语</h2><p>花一些时间来真正注意你的母语怎么说。</p><p>你经常使用哪些单词和短语？</p><p><strong>了解如何用英语说出最常用的短语和单词。</strong>用英语了解它们将帮助您用英语和您的母语一样用英语说话。</p><h2 id="12-为特定情况做好准备"><a href="#12-为特定情况做好准备" class="headerlink" title="12.为特定情况做好准备"></a>12.为特定情况做好准备</h2><p>您是否因<a href="https://files.eric.ed.gov/fulltext/EJ1053934.pdf" target="_blank" rel="noopener">特定原因</a>学习英语口语？例如，您是否正在学习英语，以便在英语公司找到工作？在这种情况下，<a href="https://www.fluentu.com/english/blog/english-job-interview-questions/" target="_blank" rel="noopener">练习英语将帮助您在面试中。</a>你在学习英语，这样你就可以在美国交朋友吗？那你需要一种不同的英语。</p><p>在你去一个你必须说英语的地方之前，你可以练习你可能要说的话。如果你准备去餐厅，餐馆里的谈话听起来像什么？回答服务员可能会问你的问题。尝试谈论食物和菜单。</p><p>如果你做好准备，你会感到更自信！</p><h2 id="13-放松！"><a href="#13-放松！" class="headerlink" title="13.放松！"></a>13.放松！</h2><p>在学会流利说话时，你可以成为你最好的帮手或最大的敌人！我们知道这很难，但你应该尽量不要担心发言时的声音。放轻松！</p><p>如果你陷入困境或困惑，只需大口气然后重新开始。如果必须，请说慢一点。花些时间停下来思考你的下一句话。</p><p>尽情享受说英语会变得更加舒适。</p><h2 id="14-用英语讲述你的语言故事"><a href="#14-用英语讲述你的语言故事" class="headerlink" title="14.用英语讲述你的语言故事"></a>14.用英语讲述你的语言故事</h2><p>这是一种有趣的方式来测试你的英语口语的发展程度：选择一个你熟悉的故事并用英语讲述。</p><p>当你讲述你的故事时，记得用英语思考。专注于说流利而不是正确。对自己大声说出每一句话。</p><p>即使你没有人用英语交谈，你仍然可以<a href="https://www.fluentu.com/blog/english/improve-english-2/" target="_blank" rel="noopener">在自己的时间建立信心和掌握流利</a>。</p><p>在某些方面，练习口语  自己<em>更容易</em> ！现在你知道如何自己提高英语口语，并且应该有信心这样做！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;我们都想知道如何提高英语口语。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;但是对于我们中的一些人来说，这是一个很大的障碍。&lt;/p&gt;
&lt;p&gt;为了提高英语口语，最好的办法是&lt;a href=&quot;https://www.fluentu.com/blog/english/engl
      
    
    </summary>
    
      <category term="English Skills" scheme="http://blog.ozairs.com/categories/English-Skills/"/>
    
    
      <category term="Speaking" scheme="http://blog.ozairs.com/tags/Speaking/"/>
    
  </entry>
  
  <entry>
    <title>如何提升英语技能</title>
    <link href="http://blog.ozairs.com/uncategorized/%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E8%8B%B1%E8%AF%AD%E6%8A%80%E8%83%BD/"/>
    <id>http://blog.ozairs.com/uncategorized/如何提升英语技能/</id>
    <published>2019-04-27T10:12:32.000Z</published>
    <updated>2019-04-27T10:16:34.061Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>作为领导者，时间是您最有价值的资源</title>
    <link href="http://blog.ozairs.com/%E8%AF%84%E8%AE%BA/%E4%BD%9C%E4%B8%BA%E9%A2%86%E5%AF%BC%E8%80%85%EF%BC%8C%E6%97%B6%E9%97%B4%E6%98%AF%E6%82%A8%E6%9C%80%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E8%B5%84%E6%BA%90/"/>
    <id>http://blog.ozairs.com/评论/作为领导者，时间是您最有价值的资源/</id>
    <published>2019-04-27T06:25:34.000Z</published>
    <updated>2019-04-27T06:56:41.615Z</updated>
    
    <content type="html"><![CDATA[<p>【译文】</p><p>在亚马逊的面试过程中，最后我们会留出五分钟，由面试者进行提问。有些人询问他们将与之合作的团队，而其他人询问他们将使用的技术。</p><p>有时一位候选人说，“我听说亚马逊可能是一个非常难以工作的地方。有些人茁壮成长，有些人失败。为什么会这样，我怎么能避免加入失败者的行列呢？“</p><p>这是一个很好的问题。多年来，我在亚马逊多次听到很多次类似这样的问题：</p><blockquote><p>我几乎要疯了！我有14个直接报告和一个关键项目在同时进行，我的日历已完全占满。我可以取得任何进展的唯一方法是在我的团队回家后继续工作。我不确定我能忍受多久。</p></blockquote><p>我对受访者的通常回答如下：</p><blockquote><p>亚马逊有无数的工作。需要救火的工作永远不会减少。没有人会为你扼杀你的工作。如果你很难说不，或者很难确定工作的优先顺序的花，那么你一定会被工作所淹没。你会工作越来越多，直到你最终退出。另一方面，如果你的工作并不糟糕，而且你可以选择正确的事情去做，并对其他一切说不的话，那么你会喜欢上它。</p></blockquote><p>如果你把这个建议付诸实践的话，它将为你的余生带来诸多好处。你可以将“亚马逊”替换为任何其他公司、副业或甚至是你的个人生活。你的时间是你最宝贵的资源。你不能做得更多。你不能暂停它。你只能分配它。以下教你如何去分配时间： </p><h3 id="确定你最重要的任务"><a href="#确定你最重要的任务" class="headerlink" title="确定你最重要的任务"></a>确定你最重要的任务</h3><p>在我在亚马逊的职业生涯早期，我获准在一个紧迫的截止日期前为一个重要项目雇用五名额外的工程师。我在亚马逊的内部系统中开设了职位，并与一些人讨论了内部调动。我还开始编写项目计划，创建要开始工作的主要故事，并安排与我们的工程师进行设计审查会议。几个星期后，我和我的经理讨论过这个问题：</p><blockquote><p><strong>经理：</strong>招聘怎么样？如你所知，项目截止日期十分紧迫。</p></blockquote><blockquote><p><strong>我：</strong>这有点慢。我可能会填补一个职位。</p></blockquote><blockquote><p><strong>经理：</strong>你认为这是你最重要的任务吗？</p></blockquote><blockquote><p><strong>我：</strong>我尽可能多地花时间，但我的工作日历排的很满。我有这个关键项目，我现有的工作，以及一个非常大的团队。有很多事情要做，我会更加努力。</p></blockquote><blockquote><p><strong>经理：</strong>我认为你同意如果没有这五位工程师的话，你就无法完成项目。总会有很多事情发生。努力尝试不是一种解决问题的办法。如果你没有花费至少50％的时间在这上面，那么你的计划很有可能会失败。您需要每天花费至少四小时的时间来招聘。咖啡加上可能候选人，组织招聘会议，更新职位描述。没有这个你就不会成功。没有其他一切，你还有可能成功。</p></blockquote><p>那天我的经理教了我一堂非常有价值的课。我尝试去认真思考，那时那刻我必须做的重要的事情。但是我需要退后一步，评估我是否将时间分配到了我想去的地方。我很努力地低头拉车，但显然没有做到抬头看路。</p><p>我内化了我的经理说的话。我认识到我在整体上取得了进步，但并没有朝着我最重要的目的地迈进。我的工作主要集中在我的大部分工作上，但我需要将注意力集中在我最重要的工作上。</p><h3 id="意识到一切照旧都行不通"><a href="#意识到一切照旧都行不通" class="headerlink" title="意识到一切照旧都行不通"></a>意识到一切照旧都行不通</h3><p>几年前，我是一只非常忙碌的蜜蜂。我有多个团队，有数十名工程师和经理向我汇报。我有长期的项目规划，架构和设计讨论，每周几十次一对一的会议，广泛的组织会议，运营审查会议等等。我的日历总是每周预约至少40小时的会议，我每周至少工作50-60小时。我很开心，但似乎我在透支我的精力。</p><p>然后我被要求进行大规模的跨组织规划过程。我被清楚地告知，这将是我未来三个月的首要任务。在此期间，我预计每周至少花20个小时来完成这个规划过程。这个过程将有助于确定我们的组织明年将关注的重点，因此它可以利用数百名工程师。在亚马逊一如既往，我没有被剥夺任何我已经管理过的东西。我刚刚获得了这个重要的角色，并期望解决这个问题。</p><blockquote><p>选择性地选择一些东西，并去掉其他一切，只关注并处理你认为最重要的事情。</p></blockquote><p>我对这个职业机会感到非常兴奋，但似乎我每周还需要至少在多工作10-20小时。</p><p>我还记得那天晚上坐在办公室里喝啤酒（不要评判我），盯着被排的满满的日历。我开始寻找任何明显可切割的东西。我每周例行的一对一面谈拉升到2周一次。我盯着我的日历，最后，我认识到必须改作出一些重大的改变，否则日程表依然会排的满满当当。</p><h3 id="直面惨淡的人生"><a href="#直面惨淡的人生" class="headerlink" title="直面惨淡的人生"></a>直面惨淡的人生</h3><p>当我试图将事情从我们的生活中剔除时，我们经常会提出错误的问题。我们会问一些事情是否重要，或者我们是否重视。答案肯定很容易回答。相反，我们应该问这两个问题：</p><ul><li>“如果我精简掉这个，最糟糕的结果是什么？”</li><li>“从长远来看，这会让我想要去哪里吗？”</li></ul><p>想想如果你精简这个项目/工作/任务/会议你会遇到的痛苦。最糟糕的结果是什么？你能处理吗？同样重要的是，这个项目/工作/任务/会议是否与您最重要的长期目标相关？</p><p>那天晚上，我喝完了啤酒，我把我的日程表精简到不能再精简。我让我的一位经理参加了每周的运营会议，然后放弃了。我让我的一位高级工程师负责架构会议系列，然后放弃它。我让所有初级员工都参加两周一次的会议。我让几位员工直接向经理报告。我放弃了每周项目状态会议。我放弃了几个员工。</p><p>我每周开会15个小时。我能够轻松地将计划流程安排到我的日历中，同时减少每周的工作时间。</p><h3 id="检查结果和后果"><a href="#检查结果和后果" class="headerlink" title="检查结果和后果"></a><strong>检查结果和后果</strong></h3><p>当我完成计划过程时，我的日历突然变成了半空。这对于像我这样的职位来说非常罕见。我当然没有经历过。</p><p>首先，我完全删除了一些工作。这些会议很有用，但还不足以证明它们需要占用我或者其他人的时间。空闲时间给予无限的投资回报。</p><p>其次，我已经为我的经理和一些高级工程师委派了一些高可见和重要的工作。双方都取得了巨大的成功。我知道我该怎么开展我的工作。这不是具有成长性的工作，而仅仅只是在维持工作。我给了他人成长的机会，他们茁壮成长。新的所有者改变了一些流程并进行了改进。他们受到新机遇的挑战，对所有参与者来说都是令人兴奋的。</p><p>具有挑战性的工作才是具有成长性的工作，坚持这些领导职位，我一直试图在剥夺别人自己成长的机会。授权是一项双赢的工作。你有更多的时间，而其他人获得了宝贵的经验。</p><p>我预计一旦项目结束，我会可能会需要弥补短暂的痛苦。相反，我做了一个健康的切割，大多数变化是永久性的。我现在有时间重新评估对我和我的团队来说重要的是什么，从长远来看，我已经可以安排这项工作了。</p><h3 id="定期精简"><a href="#定期精简" class="headerlink" title="定期精简"></a>定期精简</h3><p>当您从日程表中精简某些内容时，通常会从重要性堆栈排名的底部选择一个项目。你说，“我每天需要30分钟完成这项任务，所以我会放弃这项任务。”它的投资回报率有限，因为你只是将一件物品交换成另一件物品。</p><p>相反，你需要最大程度精简你的日程表。切换你的工作流程，而不是从重要性堆栈排名的底部进行删减。选择性地选择一些东西，并删减掉其他一切。只处理你最重要的事情。</p><p>看看你正在做的每一件事。确定你是否需要每个人实现最重要的长期目标。如果没有，问问自己如果精简掉它的话，会带来多少痛苦。考虑将这段时间花在最高优先级上是否有意义。</p><p>你的首要任务几乎总是那些在你生活中发挥作用的东西，在这些东西上花费的时间才是最最宝贵的。</p><p>【原文】</p><p>During interviews at Amazon, we allow five minutes for questions at the end. Some people ask about the team they’ll be working with, while others inquire about the technology they’ll be using.</p><p>Occasionally a candidate says, “I’ve heard Amazon can be a really hard place to work. Some people thrive and some people fail. Why is that, and how can I avoid joining the ranks of those who fail?”</p><p>This is a great question. I have heard a variation of this statement at Amazon dozens of times over the years:</p><blockquote><p>I’m going to lose my mind! I have 14 direct reports and one critical project on fire, and my calendar is completely packed. The only way I can make any progress is by working after my team goes home. I’m not sure how much longer I can take it.</p></blockquote><p>My usual answer to the interviewee is this:</p><blockquote><p>Amazon has an infinite amount of work. The fire hose of work will never abate. No one will throttle your work for you. If you have a hard time saying no, or a hard time prioritizing your tasks, you are guaranteed to drown. You will work more and more hours until you eventually quit. On the other hand, if you aren’t terrible at your job, and you can pick the right things to work on and say no to everything else, you’ll love it here.</p></blockquote><p>If you put this advice into practice, it will pay dividends for the rest of your life. You can replace “Amazon” with any modern company, a side business, or even your personal life. Your time is your most valuable resource. You can’t make more. You can’t pause it. You can only allocate it. Here’s how.</p><h3 id="Identify-your-most-important-task"><a href="#Identify-your-most-important-task" class="headerlink" title="Identify your most important task"></a>Identify your most important task</h3><p>Early in my career at Amazon, I received approval to hire five additional engineers for an important project with a tight deadline. I opened the positions in Amazon’s internal system and talked to a few people about transferring. I also began writing up a project plan, creating the major stories to begin working on, and scheduling design review meetings with our engineers. I had a discussion with my manager a few weeks later, which went something like this:</p><blockquote><p><strong>Manager:</strong> How’s the hiring going? As you’re aware, you have a tight deadline.</p></blockquote><blockquote><p><strong>Me:</strong> It’s a bit slow. I might have one position filled.</p></blockquote><blockquote><p><strong>Manager:</strong> Are you treating this as your most important task?</p></blockquote><blockquote><p><strong>Me:</strong> I’m spending as much time on it as I can, but I have a pretty full calendar. I have this critical project, my existing work, and a pretty big team. There’s a lot going on. I’ll try harder.</p></blockquote><blockquote><p><strong>Manager:</strong> I assume you agree that you can’t finish the project without those five engineers. There will always be a lot going on. Trying harder is not a mechanism. If you’re not literally spending at least 50% of your time on this, you’re planning to fail. You need to spend at least four hours a day on hiring. Coffees with potential hires. Meetings with recruiting. Updating job descriptions. You can’t succeed without this. You can succeed without almost everything else.</p></blockquote><p>My manager taught me a very valuable lesson that day. I was looking one level deep at the seemingly important things I had to do right then and there. But I needed to take a step back and assess whether I was allocating my time to take me to where I wanted to go. I was pedaling my bike as hard as I could, but I wasn’t looking at the street signs.</p><p>I internalized what my manager said. I recognized I was making progress in general, but not toward my most important destination. I was broadly focused on the bulk of my work, but I needed to focus narrowly on my most important work.</p><h3 id="Realize-that-business-as-usual-won’t-work"><a href="#Realize-that-business-as-usual-won’t-work" class="headerlink" title="Realize that business as usual won’t work"></a>Realize that business as usual won’t work</h3><p>A number of years ago, I was a very busy bee. I had multiple teams, with dozens of engineers and managers reporting to me. I had long-term project planning, architecture and design discussions, a couple of dozen one-on-one meetings a week, broad organizational meetings, operation review meetings, and more. My calendar was always booked with at least 40 hours of meetings a week, and I tended to spend at least another 10 to 20 hours at work per week. I was having fun, but I was also burning the candle at both ends.</p><p>I was then asked to run a massive cross-organizational planning process. I was told very clearly that this would be my top priority for the next three months. During that time, I would be expected to spend at least 20 hours per week on this planning process. The process would help determine what our organization would focus on for the next year, so it had leverage over hundreds of engineers. As is always true at Amazon, I wasn’t being taken off anything I already managed. I was just offered this important role, and expected to solve the problem.</p><blockquote><p>Selectively pick a few things, and cut everything else. Work on only your most important things.</p></blockquote><p>I was excited for the career opportunity, but I also had to fit another 20 hours into my 50- to 60-hour workweek.</p><p>I can still remember sitting in my office that evening with a beer (don’t judge me), staring at my completely full calendar. I started by looking for anything obvious to cut. I switched one weekly one-on-one to biweekly. Then I stared at my calendar some more. Finally I recognized that something drastic had to change. Business as usual was not going to cut it.</p><h3 id="Cut-to-the-bone-and-measure-the-pain"><a href="#Cut-to-the-bone-and-measure-the-pain" class="headerlink" title="Cut to the bone and measure the pain"></a>Cut to the bone and measure the pain</h3><p>When trying to cut things out of our lives, we often ask the wrong questions. We ask whether something is important, or if we value it. It is far too easy to answer in the affirmative. Instead, we should ask these two questions:</p><ul><li>“What is the worst case result if I cut this?”</li><li>“Is this going to get me where I want to go in the long run?”</li></ul><p>Think of the pain you’ll experience if you cut this item/work/task/meeting. What is the worst result? Can you handle it? And, equally important, is this item/work/task/meeting related to your most important long-term goals?</p><p>That night I finished my beer and cut my schedule to the bone. I asked one of my managers to attend the weekly operations meeting, then dropped it. I asked one of my senior engineers to take charge of the architecture meeting series, then dropped it. I moved all junior employees to biweekly meetings. I moved a couple of direct employees to report to a manager. I dropped the weekly project status meeting. I dropped a couple of mentees—with apologies.</p><p>I was down to perhaps 15 hours of meetings a week. I was able to easily schedule the planning process into my calendar, and at the same time cut down my hours worked each week.</p><h3 id="Examine-results-and-aftermath"><a href="#Examine-results-and-aftermath" class="headerlink" title="Examine results and aftermath"></a><strong>Examine results and aftermath</strong></h3><p>When I completed the planning process, my calendar was suddenly half-empty. This was very rare for those in positions like mine. I had certainly never experienced it.</p><p>First, I had completely removed some work. These meetings were useful, but not enough to justify their time on my or anyone else’s calendar. Free time back gives an infinite return on investment.</p><p>Second, I had delegated some high visibility and critical work to my managers and a few senior engineers. It was a wild success for both parties. I was delegating work I knew how to do. This wasn’t growth work; it was maintenance. I gave people growth opportunities, and they thrived. The new owners changed some processes and made improvements. They were challenged by the new opportunities, and it was exciting for all involved.</p><p>Challenging work is growth work, and by holding on to those leadership positions I had been depriving someone else of their own opportunity to grow. Delegating is a gift with two recipients. You get more time, and someone else gains valuable experience.</p><p>I expected temporary pain that I would remedy once the project was over. Instead, I had made a healthy cut, and most of the changes were permanent. I now had the time to re-evaluate what was important to me and my group in the long run, and I could schedule that work instead.</p><h3 id="Make-regular-cuts"><a href="#Make-regular-cuts" class="headerlink" title="Make regular cuts"></a>Make regular cuts</h3><p>When you remove something from your schedule, you’re usually picking a single item from the bottom of your importance stack rank. You’re saying, “I need 30 minutes more per day, so I’ll drop this single 30-minute task.” It has limited return on investment, because you’re swapping one item for another.</p><p>Instead, make regular cuts to the bone with your schedule, your possessions, and the like. Instead of cutting from the bottom of your stack rank, switch your process. Selectively pick a few things, and cut everything else. Work on only your most important things.</p><p>Look at every single thing you’re doing. Determine whether you need each one to achieve your most important long-term goals. If not, ask yourself how much pain you’d feel if you cut it. Consider whether it makes sense to spend that time on your top priorities instead. Your top priorities are almost always the things that move the needle in your life, and time spent there is the most precious.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;【译文】&lt;/p&gt;
&lt;p&gt;在亚马逊的面试过程中，最后我们会留出五分钟，由面试者进行提问。有些人询问他们将与之合作的团队，而其他人询问他们将使用的技术。&lt;/p&gt;
&lt;p&gt;有时一位候选人说，“我听说亚马逊可能是一个非常难以工作的地方。有些人茁壮成长，有些人失败。为什么会这样，我怎么
      
    
    </summary>
    
      <category term="评论" scheme="http://blog.ozairs.com/categories/%E8%AF%84%E8%AE%BA/"/>
    
    
      <category term="时间" scheme="http://blog.ozairs.com/tags/%E6%97%B6%E9%97%B4/"/>
    
  </entry>
  
  <entry>
    <title>AWS的生产环境准备清单</title>
    <link href="http://blog.ozairs.com/DevOps/AWS%E7%9A%84%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%E6%B8%85%E5%8D%95/"/>
    <id>http://blog.ozairs.com/DevOps/AWS的生产环境准备清单/</id>
    <published>2019-04-25T10:26:39.000Z</published>
    <updated>2019-04-25T10:28:04.880Z</updated>
    
    <content type="html"><![CDATA[<p>你刚刚建立了你的惊人的新应用程序 它会改变<em>一切</em>。但首先，您需要将其部署到AWS。你究竟是怎么做到的？</p><p>事实证明，有很多步骤。事实上几百个。你可能错过了一些。例如：</p><ol><li>您是否记得加密所有应用程序机密，或者您是否在某处以纯文本形式存在数据库密码或API密钥？</li><li>您的数据库是否已备份？你怎么知道的？我的意思是，你真的试过从其中一个备份中恢复吗？</li><li>您团队中的每个开发人员是否共享一个到服务器SSH的EC2 KeyPair？如果其中一个开发者离开公司，你打算做什么？</li><li>您是否在EC2实例中使用IAM角色？您是否记得锁定EC2元数据端点以便只能<code>root</code>访问它？</li><li>您的实例是否在ASG中运行，启用了ELB运行状况检查，部署在多个AZ，私有子网中，受NACL保护？</li></ol><p>我敢打赌，至少有一些人在阅读上面的一些项目时感到畏缩。也许你对所有人都感到畏缩。你们中的一些人可能会觉得这样：</p><p>好吧，我们为您提供解决方案。在Gruntwork，我们通过全面的检查表帮助数百家公司在AWS上运行。今天，我们很高兴与大家分享清单：</p><p><a href="https://gruntwork.io/devops-checklist/?ref=prod-readiness-blog-post" target="_blank" rel="noopener"><strong>AWS的生产准备清单</strong></a></p><p>此核对表是您在AWS中部署安全，可扩展且高度可用的基础架构的最佳实践的指南。它涵盖了一系列主题，包括服务器端应用程序，客户端应用程序，持续集成，持续交付，架构，安全性，监控以及利用现代DevOps和云原生实践所需的一切。在您上线之前，请仔细检查每个项目，并确保您没有错过任何重要的内容！</p><p>哦，如果所有这些基础设施工作感觉有点压倒性，请记住道格拉斯亚当斯的话：不要恐慌。创建一个生产就绪的基础设施是很多工作，但我们已经为您提供了保障。清单中的所有内容都已<a href="https://gruntwork.io/infrastructure-as-code-library" target="_blank" rel="noopener">作为代码库</a>的Gruntwork <a href="https://gruntwork.io/infrastructure-as-code-library" target="_blank" rel="noopener">Infrastructure的</a>一部分，并且可作为<a href="https://gruntwork.io/reference-architecture" target="_blank" rel="noopener">参考体系结构的</a>一部分在1天内部署在您的AWS账户中。</p><p>因此，请开始使用<a href="https://gruntwork.io/devops-checklist/?ref=prod-readiness-blog-post" target="_blank" rel="noopener">清单</a>并让您的应用程序正常运行！</p><p><em>整个基础设施，定义为代码，大约需要一天。</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;你刚刚建立了你的惊人的新应用程序 它会改变&lt;em&gt;一切&lt;/em&gt;。但首先，您需要将其部署到AWS。你究竟是怎么做到的？&lt;/p&gt;
&lt;p&gt;事实证明，有很多步骤。事实上几百个。你可能错过了一些。例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;您是否记得加密所有应用程序机密，或者您是否在某处以纯
      
    
    </summary>
    
      <category term="DevOps" scheme="http://blog.ozairs.com/categories/DevOps/"/>
    
    
      <category term="AWS" scheme="http://blog.ozairs.com/tags/AWS/"/>
    
  </entry>
  
  <entry>
    <title>Gruntwork 2018年回顾</title>
    <link href="http://blog.ozairs.com/%E8%AF%84%E8%AE%BA/Gruntwork-2018%E5%B9%B4%E5%9B%9E%E9%A1%BE/"/>
    <id>http://blog.ozairs.com/评论/Gruntwork-2018年回顾/</id>
    <published>2019-04-25T10:19:35.000Z</published>
    <updated>2019-04-25T10:26:11.025Z</updated>
    
    <content type="html"><![CDATA[<p>在Gruntwork，我们在冬季关闭了几个星期，让每个人都回家，与家人共度时光，庆祝节日，放松，并花些时间思考。我发现这是暂停和思考这一年的好时机。</p><p>很容易迷失在细节中，为眼前的失败而感到到沮丧，并沉迷于没有完成的事情，所以你经常忘记环顾四周，看看你到底有多远。今年，我们开始在Gruntwork开始写一篇年度评论博客文章作为一种停止方式的传统，花一些时间欣赏去年发生的一切，并开始考虑明年。</p><h4 id="该团队于2018年"><a href="#该团队于2018年" class="headerlink" title="该团队于2018年"></a>该团队于2018年</h4><p>我们从2018年开始只有3人; 我们今年结束了9名全职员工和3名员工。作为一家<a href="https://blog.gruntwork.io/how-we-built-a-distributed-self-funded-family-friendly-profitable-startup-93635feb5ace" target="_blank" rel="noopener">100％的自助公司</a>，这是一个非凡的增长率。此外，无论他们在世界的哪个地方，包括英国，德国，芬兰，尼日利亚和整个美国，我们都通过雇用我们能找到的最有才能的人来充分利用成为<a href="https://blog.gruntwork.io/how-we-built-a-distributed-self-funded-family-friendly-profitable-startup-93635feb5ace" target="_blank" rel="noopener">100％分布式公司</a>的优势（有关所有详细信息，请参阅我们的<a href="https://gruntwork.io/about/" target="_blank" rel="noopener">关于页面 </a>这就是现代公司的样子：</p><p><img src="/评论/Gruntwork-2018年回顾/1.png" alt="img"></p><p>能够每天与这样的团队一起工作，我感到非常荣幸和非常幸运。该团队拥有丰富的经验，从初创公司到各行各业的财富500强公司，包括医疗保健，旅游，电信，基础设施管理，社交网络，FinTech，EdTech，零售，游戏等等。最重要的是，他们是善良，诚实，有趣的人。</p><h4 id="公司成立于2018年"><a href="#公司成立于2018年" class="headerlink" title="公司成立于2018年"></a>公司成立于2018年</h4><p>我们在2018年达到了一个重要的里程碑：<a href="https://blog.gruntwork.io/how-we-got-to-1-million-in-annual-recurring-revenue-with-0-in-fundraising-340ed2b4e158" target="_blank" rel="noopener">年度经常性收入100万美元（全年</a>总收入约160万美元）。我们以筹集资金0美元和债务0美元来实现这一里程碑，我们实现了盈利，为每个人支付了不错的薪水和奖金，并且增长迅速。</p><p>今年我们的用户群增长了近4倍，我们有幸与世界上一些最大的品牌合作。我们已经完成了所有这一切，只有2人的销售团队，Josh和我，Josh加紧处理大部分销售工作。</p><p>我为我们的营销方式感到特别自豪，这几乎完全包括制作高质量的内容 - 特别是博客文章，演讲和开源代码 - 向全世界讲述DevOps。以下是一些亮点：</p><ul><li><a href="https://blog.gruntwork.io/5-lessons-learned-from-writing-over-300-000-lines-of-infrastructure-code-36ba7fadeac1" target="_blank" rel="noopener">编写超过300,000行基础设施代码的5个经验教训</a></li><li><a href="https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799" target="_blank" rel="noopener">在命令行上对AWS进行身份验证的综合指南</a></li><li><a href="https://blog.gruntwork.io/the-production-readiness-checklist-for-aws-c5a3b5a3a8e5" target="_blank" rel="noopener">AWS的生产准备清单</a></li><li>我们还在2018年发布了一些开源项目，我将在下一节中讨论。</li></ul><h4 id="我们在2018年建造的"><a href="#我们在2018年建造的" class="headerlink" title="我们在2018年建造的"></a>我们在2018年建造的</h4><p>在2018年，我们写了很多代码。以下是一些亮点（您可以在我们的<a href="https://blog.gruntwork.io/tagged/gruntwork-newsletter" target="_blank" rel="noopener">月刊中</a>获得所有血腥细节）：</p><ul><li><strong>Gruntwork Houston：</strong>我们推出了<a href="https://blog.gruntwork.io/gruntwork-houston-a-fundamentally-better-devops-experience-is-now-in-beta-3a4603852db1" target="_blank" rel="noopener">Gruntwork Houston</a>的第一个版本！私有测试版提供了一种更好的方式来处理AWS上的身份验证，允许您使用现有的身份提供商（例如，ADFS，Google，Okta等）通过Web，命令行，VPN和SSH访问您的AWS账户。私有alpha提供了一个简单的Web界面，您的开发团队可以使用它来部署和管理基础架构，而在幕后，Web界面以及它如何管理基础架构完全由您的Ops团队定义和控制为代码。</li><li><strong>Kubernetes</strong>：我们在<a href="https://gruntwork.io/infrastructure-as-code-library/" target="_blank" rel="noopener">基础架构中</a>添加了一组模块<a href="https://gruntwork.io/infrastructure-as-code-library/" target="_blank" rel="noopener">作为代码库，</a>以使用EKS <a href="https://blog.gruntwork.io/gruntwork-newsletter-december-2018-17971f237bf1" target="_blank" rel="noopener">在AWS中部署和管理Kubernetes集群</a>。</li><li><strong>ELK堆栈</strong>：我们创建了一组模块，用于<a href="https://blog.gruntwork.io/gruntwork-newsletter-august-2018-4654d6064e65" target="_blank" rel="noopener">在AWS上运行您自己的Elasticsearch，Logstash和Kibana（ELK）集群</a>。</li><li><strong>InfluxDB企业版</strong>：我们与InfluxData团队合作，构建和开源一组模块，以<a href="https://blog.gruntwork.io/get-up-and-running-with-influxdb-enterprise-on-aws-ff4dc79f6305" target="_blank" rel="noopener">在AWS上运行InfluxDB企业</a>。</li><li><strong>Couchbase</strong>：我们与Couchbase团队合作，构建并开源了一组模块，以<a href="https://blog.gruntwork.io/get-couchbase-running-on-aws-in-5-minutes-732d3be36784" target="_blank" rel="noopener">在AWS上运行Couchbase和Sync Gateway</a>。</li><li><strong>Lambda + API网关</strong>：我们创建了一组模块，使您可以<a href="https://blog.gruntwork.io/gruntwork-newsletter-march-2018-37dbd051607c#c013" target="_blank" rel="noopener">使用AWS Lambda，API Gateway和Swagger构建无服务器的Web应用程序</a>。</li><li><strong>ECS改进</strong>：我们更新了ECS模块以支持<a href="https://blog.gruntwork.io/gruntwork-newsletter-may-2018-c0323ab4d5a4#3a01" target="_blank" rel="noopener">Fargate</a>，<a href="https://blog.gruntwork.io/gruntwork-newsletter-september-2018-29b646feba56#2590" target="_blank" rel="noopener">服务发现</a>，<a href="https://blog.gruntwork.io/gruntwork-newsletter-september-2018-29b646feba56#ae4f" target="_blank" rel="noopener">守护程序服务</a>和<a href="https://blog.gruntwork.io/gruntwork-newsletter-november-2018-256cf63ed123#42cc" target="_blank" rel="noopener">部署检查</a>。</li><li><strong>NLB</strong>：我们添加了模块来<a href="https://blog.gruntwork.io/gruntwork-newsletter-april-2018-1f90b51effe1#955f" target="_blank" rel="noopener">部署和管理亚马逊的网络负载均衡器（NLB）</a>。</li><li><strong>Terratest</strong>：我们<a href="https://blog.gruntwork.io/open-sourcing-terratest-a-swiss-army-knife-for-testing-infrastructure-code-5d883336fcd5" target="_blank" rel="noopener">开源Terratest</a>，我们用于测试基础设施代码的瑞士军刀，并对该库进行了大量改进，包括添加对<a href="https://blog.gruntwork.io/gruntwork-newsletter-september-2018-29b646feba56#aeaa" target="_blank" rel="noopener">Google Cloud</a>，<a href="https://blog.gruntwork.io/gruntwork-newsletter-december-2018-17971f237bf1#9596" target="_blank" rel="noopener">Kubernetes</a>，<a href="https://blog.gruntwork.io/gruntwork-newsletter-november-2018-256cf63ed123#2ea4" target="_blank" rel="noopener">日志解析</a>和<a href="https://blog.gruntwork.io/gruntwork-newsletter-september-2018-29b646feba56#aeaa" target="_blank" rel="noopener">日志文件收集的支持</a>。</li><li><strong>Terragrunt</strong>：我们做了很多的改进<a href="https://github.com/gruntwork-io/terragrunt" target="_blank" rel="noopener">Terragrunt</a>，我们的开源Terraform包装，包括增加支持<a href="https://blog.gruntwork.io/gruntwork-newsletter-october-2018-594decf5eb2e#f953" target="_blank" rel="noopener">的错误重试</a>，<a href="https://blog.gruntwork.io/gruntwork-newsletter-april-2018-1f90b51effe1#c045" target="_blank" rel="noopener">前/挂机后</a>，和许多改进的<a href="https://blog.gruntwork.io/gruntwork-newsletter-july-2018-7354835132f8#7681" target="_blank" rel="noopener">init命令和缓存</a>。</li><li><strong>cloud-nuke</strong>：<a href="https://blog.gruntwork.io/cloud-nuke-how-we-reduced-our-aws-bill-by-85-f3aced4e5876" target="_blank" rel="noopener">我们开源的cloud-nuke</a>是一个用于删除AWS账户中所有资源的CLI工具，我们用它来大大减少用于自动化测试的账户的AWS账单。</li><li><strong>bash-commons</strong>：<a href="https://blog.gruntwork.io/gruntwork-newsletter-may-2018-c0323ab4d5a4#784d" target="_blank" rel="noopener">我们开源bash-commons</a>，一组可重复使用的bash实用程序，包括文档和自动化测试。</li><li><strong>Redis</strong>：我们<a href="https://blog.gruntwork.io/gruntwork-newsletter-april-2018-1f90b51effe1" target="_blank" rel="noopener">重构了我们的Redis模块，</a>以使用最新的Terraform资源，并增加了对身份验证，加密和分片的支持。</li><li><strong>还有更多</strong>：我们对AWS和GCP的<a href="https://github.com/hashicorp/terraform-aws-consul/" target="_blank" rel="noopener">Consul</a>和<a href="https://github.com/hashicorp/terraform-aws-vault/" target="_blank" rel="noopener">Vault</a>模块进行了大量更新（增加了对Consul和Vault Enterprise，Auto Pilot，Auto Unseal和Auth方法的支持），更新了所有模块以与<a href="https://blog.gruntwork.io/gruntwork-newsletter-feburary-2018-891fa0e6cbd9" target="_blank" rel="noopener">Terraform 0.11配合使用</a>，添加了<a href="https://blog.gruntwork.io/gruntwork-newsletter-may-2018-c0323ab4d5a4#ce71" target="_blank" rel="noopener">ip-lockdown模块</a>可以在使用IAM角色时显着提高安全性，还有更多。</li></ul><h4 id="期待2019年"><a href="#期待2019年" class="headerlink" title="期待2019年"></a>期待2019年</h4><p>我们对明年非常兴奋。以下是我们所关注的内容：</p><ul><li><strong>Gruntwork Houston：</strong>休斯顿是2019年我们的首要任务，我们将尽可能地<strong>加大</strong>开发力度，因为我们相信它提供了一个从根本上更好的DevOps体验。最初，我们将继续与私人测试版和阿尔法客户一起测试休斯顿（如果您有兴趣，请发送电子邮件至<a href="mailto:info@gruntwork.io" target="_blank" rel="noopener">info@gruntwork.io</a>），但只要我们确定了用户体验，我们就会将休斯顿公之于众。给大家。</li><li><strong>Google Cloud和Azure：</strong> 2019年，我们将扩展Gruntwork <a href="https://gruntwork.io/infrastructure-as-code-library/" target="_blank" rel="noopener">Infrastructure作为代码库</a>，为Google Cloud和Azure提供一流的支持！今天，图书馆主要关注AWS，但在明年，我们可以在大约一天内将您的整个基础架构定义为任何（或所有！）主要公共云的代码！我们正在寻找与我们合作的公司，所以如果您有兴趣，请发送电子邮件至<a href="mailto:info@gruntwork.io" target="_blank" rel="noopener">info@gruntwork.io</a>！</li><li><strong>AWS：</strong>我们当然也将继续投资我们的AWS产品，包括改善使用Lambda和API Gateway构建无服务器应用程序的端到端体验，对CloudWatch监控，警报和日志聚合工具的主要更新，添加ECS集群调整大小/重新部署工具，更新所有模块以支持Amazon Linux 2和systemd，将Kafka模块更新为Kafka 2.x，改进ZooKeeper模块的运行状况检查等等。</li><li><strong>Kubernetes：</strong>我们将使用可重复使用的模块扩展我们的Kubernetes代码，用于定义和管理您的Kubernetes服务作为代码，一流（安全！）Helm / Tiller支持，以及<a href="https://gruntwork.io/reference-architecture/" target="_blank" rel="noopener">Gruntwork参考架构</a>中的一流支持。此外，我们将浏览现有的基于VM的模块<a href="https://gruntwork.io/infrastructure-as-code-library/" target="_blank" rel="noopener">库</a>，并开始添加在Kubernetes上运行的类似基于Docker的模块。这将允许公司使用Kubernetes定义和管理其大部分基础架构，使其基础架构更加一致，可在云之间移植，并且更易于测试。</li><li><strong>支持和维护：</strong>公司成为Gruntwork客户的主要原因是，我们不仅可以访问<a href="https://gruntwork.io/infrastructure-as-code-library/" target="_blank" rel="noopener">基础设施作为代码库</a>中的300,000多个经过实战检验的代码，还可以访问该库的持续支持和维护。我们将在2019年继续这样做，包括更新整个库以支持和利用<a href="https://www.hashicorp.com/blog/terraform-0-1-2-preview" target="_blank" rel="noopener">Terraform 0.12中</a>的所有更改，添加对新的最佳实践的支持，并修复我们发现的任何错误。</li><li><strong>战略计划：</strong>我们将扩展Gruntwork合作伙伴计划，使我们的客户更容易找到DevOps顾问和托管服务提供商，与熟悉Gruntwork代码的人员合作，并使我们的合作伙伴更轻松地使用和转售Gruntwork Infrastructure作为代码库作为自己产品的一部分。我们还将对<a href="https://gruntwork.io/" target="_blank" rel="noopener">Gruntwork网站</a>进行重大更改，包括提供试用期以及使订阅和用户管理完全自助服务和自动化。</li><li><strong>我们正在接受请求！</strong>在Gruntwork，我们没有在真空中提出我们的路线图，并在洞穴中消失了6个月来构建它。我们在Gruntwork建立的每一件事都是客户提出并付费的事情（看<a href="https://blog.gruntwork.io/how-we-built-a-distributed-self-funded-family-friendly-profitable-startup-93635feb5ace#d592" target="_blank" rel="noopener">我们如何引导公司</a>）。如果您希望我们在2019年建立一些不在列表中的东西，我们提供<a href="https://gruntwork.io/custom-module-development/" target="_blank" rel="noopener">定制模块开发</a>，请发送电子邮件至<a href="mailto:info@gruntwork.io" target="_blank" rel="noopener">info@gruntwork.io</a>告诉我们您的需求！</li></ul><p>2018年是地狱般的一年，预祝2019年一帆风顺！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在Gruntwork，我们在冬季关闭了几个星期，让每个人都回家，与家人共度时光，庆祝节日，放松，并花些时间思考。我发现这是暂停和思考这一年的好时机。&lt;/p&gt;
&lt;p&gt;很容易迷失在细节中，为眼前的失败而感到到沮丧，并沉迷于没有完成的事情，所以你经常忘记环顾四周，看看你到底有多远
      
    
    </summary>
    
      <category term="评论" scheme="http://blog.ozairs.com/categories/%E8%AF%84%E8%AE%BA/"/>
    
    
      <category term="DevOps" scheme="http://blog.ozairs.com/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>Azure服务之旅</title>
    <link href="http://blog.ozairs.com/Cloud-Service/Azure%E6%9C%8D%E5%8A%A1%E4%B9%8B%E6%97%85/"/>
    <id>http://blog.ozairs.com/Cloud-Service/Azure服务之旅/</id>
    <published>2019-04-22T09:56:57.000Z</published>
    <updated>2019-04-22T10:11:10.479Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Azure服务"><a href="#Azure服务" class="headerlink" title="Azure服务"></a>Azure服务</h2><p>以下是Azure中可用服务和功能的全景图。</p><p><img src="/Cloud-Service/Azure服务之旅/1.png" alt=""></p><p>让我们仔细看看最常用的类别：</p><ul><li>计算</li><li>联网</li><li>存储</li><li>移动</li><li><p>数据库</p></li><li><p>卷筒纸</p></li><li>物联网</li><li>大数据</li><li>人工智能</li><li>DevOps的</li></ul><h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><p>计算服务通常是公司迁移到Azure平台的主要原因之一。Azure为托管应用程序和服务提供了一系列选项。以下是Azure中计算服务的一些示例：</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Vitual Machines</td><td>Azure中托管的Windows或Linux虚拟机（VM）</td></tr><tr><td>Azure Vitual Machine Scale Sets</td><td>扩展Azure中托管的Windows或Linux VM</td></tr><tr><td>Azure Kubernetes Service</td><td>支持管理运行容器化服务的VM群集</td></tr><tr><td>Azure Service Fabric</td><td>分布式系统平台。在Azure或本地运行</td></tr><tr><td>Azure Batch</td><td>为并行和高性能计算应用程序提供托管服务</td></tr><tr><td>Azure Container Instances</td><td>在Azure上运行容器化应用程序而无需配置服务器或VM</td></tr><tr><td>Azure Functions</td><td>事件驱动的无服务器计算服务</td></tr></tbody></table><h3 id="联网"><a href="#联网" class="headerlink" title="联网"></a>联网</h3><p>链接计算资源和提供对应用程序的访问是Azure网络的关键功能。Azure中的网络功能包括一系列选项，用于将外部世界连接到全局Microsoft Azure数据中心中的服务和功能。</p><p>Azure网络设施具有以下功能：</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Virtual Network</td><td>将VM连接到传入的虚拟专用网络（VPN）连接</td></tr><tr><td>Azure Load Balancer</td><td>平衡到应用程序或服务端点的入站和出站连接</td></tr><tr><td>Azure Application Gateway</td><td>优化应用服务器场传输，同时提高应用安全性</td></tr><tr><td>Azure VPN Gateway</td><td>通过高性能VPN网关访问Azure虚拟网络</td></tr><tr><td>Azure DNS</td><td>提供超快的DNS响应和超高域可用性</td></tr><tr><td>Azure VPN Gateway</td><td>为全球客户提供高带宽内容</td></tr><tr><td>Azure DDoS Protection</td><td>保护Azure托管的应用程序免受分布式拒绝服务（DDOS）攻击</td></tr><tr><td>Azure Traffic Manager</td><td>分布全球Azure区域的网络流量</td></tr><tr><td>Azure ExpressRoute</td><td>通过高带宽专用安全连接连接到Azure</td></tr><tr><td>Azure Network Watcher</td><td>使用基于场景的分析监控和诊断网络问题</td></tr><tr><td>Azure Firewall</td><td>实现具有无限可扩展性的高安全性，高可用性防火墙</td></tr><tr><td>Azure Virtual WAN</td><td>创建统一的广域网（WAN），连接本地和远程站点</td></tr></tbody></table><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><p>Azure提供四种主要类型的存储服务。这些服务是：</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Blob Storage</td><td>用于非常大的对象的存储服务，例如视频文件或位图</td></tr><tr><td>Azure FIle Storage</td><td>您可以像文件服务器一样访问和管理的文件共享</td></tr><tr><td>Azure Queue Storage</td><td>用于在应用程序之间排队并可靠地传递消息的数据存储</td></tr><tr><td>Azure Table Storage</td><td>存储非结构化数据的NoSQL存储，独立于任何模式</td></tr></tbody></table><p>这些服务都有几个共同特征：</p><ul><li><strong>耐用</strong>且高度可用，具有冗余和复制功能。</li><li>通过自动加密和基于角色的访问控制来<strong>保护安全</strong>。</li><li><strong>可扩展</strong>，几乎无限存储。</li><li><strong>管理</strong>，处理维护和任何关键问题。</li><li><strong>可</strong>通过HTTP或HTTPS从世界上任何地方<strong>访问</strong>。</li></ul><h3 id="移动"><a href="#移动" class="headerlink" title="移动"></a>移动</h3><p>Azure使开发人员能够快速，轻松地为iOS，Android和Windows应用程序创建移动后端服务。过去需要花费时间并增加项目风险的功能（例如添加公司登录，然后连接到SAP，Oracle，SQL Server和SharePoint等本地资源）现在很容易包含在内。</p><p>该服务的其他功能包括：</p><ul><li>离线数据同步。</li><li>与本地数据的连接。</li><li>广播推送通知。</li><li>自动缩放以满足业务需求。</li></ul><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>Azure提供多种数据库服务来存储各种数据类型和卷。通过全球连接，这些数据可立即供用户使用。</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Cosmos DB</td><td>支持NoSQL选项的全局分布式数据库</td></tr><tr><td>Azure SQL Database</td><td>完全托管的关系数据库，具有自动扩展，集成智能和强大的安全性</td></tr><tr><td>Azure Database for MySQL</td><td>完全托管和可扩展的MySQL关系数据库，具有高可用性和安全性</td></tr><tr><td>Azure Database for PostgreSQL</td><td>完全托管和可扩展的PostgreSQL关系数据库，具有高可用性和安全性</td></tr><tr><td>SQL Server on VMs</td><td>在云中托管企业SQL Server应用程序</td></tr><tr><td>Azure SQL Data Warehouse</td><td>完全管理的数据仓库，无需额外费用即可在各种规模上实现完整的安全性</td></tr><tr><td>Azure Database Migration Service</td><td>无需更改应用程序代码即可将数据库迁移到云</td></tr><tr><td>Azure Redrest for Redis</td><td>缓存经常使用的静态数据以减少数据和应用程序延迟</td></tr><tr><td>Azure Database for MariaDB</td><td>完全托管且可扩展的MariaDB关系数据库，具有高可用性和安全性</td></tr></tbody></table><h3 id="Web"><a href="#Web" class="headerlink" title="Web"></a>Web</h3><p>拥有出色的网络体验对于当今的商业世界至关重要。Azure包括构建和托管Web应用程序以及基于HTTP的Web服务的一流支持。专注于Web托管的Azure服务包括：</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure App Service</td><td>快速创建功能强大的基于Web的云应用程序</td></tr><tr><td>Azure Notification Hubs</td><td>从任何后端向任何平台发送推送通知。</td></tr><tr><td>Azure API Management</td><td>安全且大规模地向开发人员，合作伙伴和员工发布API。</td></tr><tr><td>Azure Search</td><td>完全托管的搜索即服务。</td></tr><tr><td>Web Apps feature of Azure App Service</td><td>大规模创建和部署任务关键型Web应用程序。</td></tr><tr><td>Azure SignalR Service</td><td>轻松添加实时Web功能。</td></tr></tbody></table><h3 id="物联网"><a href="#物联网" class="headerlink" title="物联网"></a>物联网</h3><p>人们能够获得比以往更多的信息。它始于个人数字助理（PDA），然后演变为智能手机。现在有智能手表，智能恒温器，甚至智能冰箱。个人电脑曾经是常态。现在互联网允许任何在线能够访问有价值信息的项目。设备获取然后中继信息以进行数据分析的这种能力被称为物联网（IoT）。</p><p>有许多服务可以为Azure上的物联网提供协助和驱动端到端解决方案。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>IoT Central</td><td>全面管理的全球物联网软件即服务（SaaS）解决方案，可轻松连接，监控和管理您的物联网资产</td></tr><tr><td>Azure IoT Hub</td><td>消息中心，提供数百万个物联网设备之间的安全通信和监控</td></tr><tr><td>IoT Edge</td><td>将您的数据分析推送到您的IoT设备而不是云中，使他们能够更快地对状态变化做出反应。</td></tr></tbody></table><h3 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h3><p>数据有各种格式和大小。当我们谈论大数据时，我们指的是<em>大量</em>数据。来自天气系统，通信系统，基因组研究，成像平台和许多其他场景的数据会产生数百GB的数据。这些数据使得分析和制定决策变得困难。它往往是如此之大，以至于传统形式的处理和分析已不再合适。</p><p>已经开发了开源集群技术来处理这些大型数据集。Microsoft Azure支持广泛的技术和服务，以提供大数据和分析解决方案。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure SQL Datawarehouse</td><td>使用基于云的企业数据仓库（EDW）大规模运行分析，该数据仓库利用大规模并行处理（MPP）在数PB的数据中快速运行复杂查询</td></tr><tr><td>Azure HDInsight</td><td>使用云中的Hadoop集群托管集群处理大量数据</td></tr><tr><td>Azure Databricks（preview）</td><td>协作的基于Apache Spark的分析服务，可与Azure中的其他大数据服务集成。</td></tr></tbody></table><h3 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h3><p>在云计算的背景下，人工智能基于广泛的服务，其核心是机器学习。机器学习是一种数据科学技术，它允许计算机使用现有数据来预测未来的行为，结果和趋势。使用机器学习，计算机无需明确编程即可学习。</p><p>机器学习的预测或预测可以使应用和设备更加智能。例如，当您在线购物时，机器学习会根据您购买的产品帮助推荐您可能喜欢的其他产品。或者，当刷卡时，机器学习会将交易与交易数据库进行比较，并有助于检测欺诈行为。当您的机器人吸尘器吸尘房间时，机器学习可帮助它确定工作是否完成。</p><p>Azure中一些最常见的人工智能和机器学习服务类型是：</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure机Azure Machine Learning Service</td><td>基于云的环境，您可以使用它来开发，培训，测试，部署，管理和跟踪机器学习模型。它可以自动生成模型并为您自动调整模型。它将允许您开始在本地计算机上进行培训，然后扩展到云</td></tr><tr><td>Azure Machine Learning Studio</td><td>协作，拖放式可视化工作区，您可以使用预先构建的机器学习算法和数据处理模块构建，测试和部署机器学习解决方案</td></tr></tbody></table><p>一组密切相关的产品是<em>认知服务</em>。这些是您可以在应用程序中利用的预构建API，以解决复杂问题。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Vision</td><td>图像处理算法，可以智能识别，标题，索引和调节您的图片和视频。</td></tr><tr><td>Speech</td><td>将语音转换为文本，使用语音进行验证，或在应用中添加说话人识别。</td></tr><tr><td>Knowledge mapping</td><td>映射复杂的信息和数据，以解决智能推荐和语义搜索等任务。</td></tr><tr><td>Bing Search</td><td>将Bing搜索API添加到您的应用中，并利用单个API调用功能来梳理数十亿个网页，图片，视频和新闻。</td></tr><tr><td>Natural Language processing</td><td>允许您的应用使用预先构建的脚本处理自然语言，评估情绪并学习如何识别用户想要的内容。</td></tr></tbody></table><h3 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h3><p>DevOps（开发和运营）汇集了人员，流程和技术，自动化软件交付，为您的用户提供持续的价值。Azure DevOps Services允许您创建<em>构建</em>和<em>发布</em>为您的应用程序提供持续集成，交付和部署的管道。您可以集成存储库和应用程序测试，执行应用程序监视，以及使用构建工件。您还可以使用和积压项目进行跟踪，自动化基础架构部署以及集成一系列第三方工具和服务，例如Jenkins和Chef。所有这些功能以及更多功能都与Azure紧密集成，以便为您的应用程序提供一致，可重复的部署，从而提供简化的构建和发布流程。</p><p>Azure提供的一些主要DevOps服务是Azure DevOps Services和Azure DevTest Labs。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure DevOps</td><td>Azure DevOps Services（以前称为Visual Studio Team Services，或VSTS）提供开发协作工具，包括高性能管道，免费的私有Git存储库，可配置的看板，以及广泛的自动化和基于云的负载测试</td></tr><tr><td>Azure DevTest Labs</td><td>快速创建按需Windows和Linux环境，您可以使用它们直接从部署管道测试或演示应用程序</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Azure服务&quot;&gt;&lt;a href=&quot;#Azure服务&quot; class=&quot;headerlink&quot; title=&quot;Azure服务&quot;&gt;&lt;/a&gt;Azure服务&lt;/h2&gt;&lt;p&gt;以下是Azure中可用服务和功能的全景图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/Cloud-Serv
      
    
    </summary>
    
      <category term="Cloud Service" scheme="http://blog.ozairs.com/categories/Cloud-Service/"/>
    
    
      <category term="Azure" scheme="http://blog.ozairs.com/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>Azure实战应用</title>
    <link href="http://blog.ozairs.com/Cloud-Service/Azure%E5%AE%9E%E6%88%98%E5%BA%94%E7%94%A8/"/>
    <id>http://blog.ozairs.com/Cloud-Service/Azure实战应用/</id>
    <published>2019-04-22T06:21:53.000Z</published>
    <updated>2019-04-22T10:11:10.478Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Cloud Service" scheme="http://blog.ozairs.com/categories/Cloud-Service/"/>
    
    
      <category term="Azure" scheme="http://blog.ozairs.com/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>Azure Cosmos DB简介</title>
    <link href="http://blog.ozairs.com/Azure/Azure-Cosmos-DB%E7%AE%80%E4%BB%8B/"/>
    <id>http://blog.ozairs.com/Azure/Azure-Cosmos-DB简介/</id>
    <published>2019-04-22T03:58:55.000Z</published>
    <updated>2019-04-22T04:12:42.045Z</updated>
    
    <content type="html"><![CDATA[<p>Azure Cosmos DB 是由 Microsoft 提供的全球分布式多模型数据库。 只需单击一个按钮，即可通过 Azure Cosmos DB 跨任意数量的 Azure 地理区域弹性且独立地缩放吞吐量和存储。 它通过综合服务级别协议 (SLA) 提供吞吐量、延迟、可用性和一致性保证，这是其他数据库服务无法提供的。</p><p>Azure Cosmos DB 提供关系数据库和非关系数据库的最佳功能<br>下表比较了关系DB，非关系DB和Cosmos DB的关系</p><p>功能    关系 DB    非关系 (NoSQL) DB    Azure Cosmos DB<br>全球分布    否    否    统包式解决方案，目前在中国有 2 个区域，多宿主，全球超过30个区域<br>横向缩放    否    是    独立缩放存储和吞吐量<br>延迟保证    否    是    在 99% 的情况下，读取操作的延迟 &lt; 10 毫秒，写入操作的延迟 &lt; 15 毫秒<br>高可用性    否    是    始终可用，PACELC 权衡，自动和手动故障转移<br>数据模型 + API关系    关系+SQL    多模型+OSS API    多模型 + SQL + OSS API（即将推出更多）<br>SLA    是    否    有关延迟、吞吐量、一致性和可用性的综合 SLA<br>*PACELC 解释：<a href="https://en.wikipedia.org/wiki/PACELC_theorem#Database_PACELC_ratings" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/PACELC_theorem#Database_PACELC_ratings</a></p><p>*OSS:对象存储（Object Storage Service，简称OSS）</p><p>关键功能<br>作为一种全球分布式数据库服务，Azure Cosmos DB 提供以下功能，帮助构建可缩放的、具有高响应性的全球分布式应用程序：</p><p>统包式全球分布</p><p>应用程序在任何地方都可以即时提供给用户使用。 现在，数据也可以这样。</p><p>不必担心硬件以及添加节点、VM 或内核等问题。 只需点击一下，即可获得数据。</p><p>多个数据模型和用于访问及查询数据的常用 API</p><p>支持多个数据模型，包括键值、文档和列式数据模型。</p><p>用于 Node.js、Java、.NET、.NET Core、Python 和 MongoDB 的可扩展 API。</p><p>用于查询的 SQL。</p><p>在全球范围内按需求弹性缩放吞吐量和存储</p><p>以秒和分钟为时间粒度轻松缩放吞吐量，并可以随时对其进行更改。</p><p>透明且自动地缩放存储以满足现在和将来对大小的要求。</p><p>构建具有高响应性的任务关键型应用程序</p><p>在全球任意位置均可访问你的数据，99% 的情况下延迟仅为几毫秒。</p><p>确保“始终可用”可用性</p><p>在单个区域内可用性为 99.99%。</p><p>部署到任意数量的 Azure 区域可提高可用性。</p><p>模拟一个或多个区域的故障而保证不丢失任何数据。</p><p>编写全球分布式应用程序的正确方式</p><p>五个一致性模型提供类似于 SQL 的非常一致性到类似于 NoSQL 的最终一致性，以及介于两者之间的一致性。</p><p>退款保证</p><p>要么数据快速到达，要么退款。</p><p>有关可用性、延迟、吞吐量和一致性的服务级别协议。</p><p>无数据库架构/索引管理</p><p>无需担心将数据库架构和索引与应用程序架构保持同步的问题。 我们免架构。</p><p>拥有成本低廉</p><p>比非托管解决方案的成本效益高五到十倍。</p><p>比 DynamoDB 便宜三倍。</p><p>创建Comos DB<br>点击Azure CosomosDB，出现如下界面，点击ID ，选择API，API目前有三种选择：MongoDB、SQL (DocumentDB) 和表（键/值），这里创建了一个 SQL(DocumentDB)测试。</p><p><img src="/Azure/Azure-Cosmos-DB简介/1.png" alt=""></p><p>创建成功后，点击：数据资源管理器</p><p><img src="/Azure/Azure-Cosmos-DB简介/2.png" alt=""></p><p>点击New Collection，创建数据集 ，输入数据库ID ,数据集的ID ， 容量，吞吐量，这里创建了 每秒400个的吞吐量， 400ru/s的能力。</p><p>这里创建了2个数据集，结果如下：</p><p><img src="/Azure/Azure-Cosmos-DB简介/3.png" alt=""></p><p>可以看到配置了区域是北京和上海，如果使用国际版意味着可以创建超过30个区域的配置。这就是DBA的梦想啊！！！</p><p>也可以进行缩放配置，也就是说可以进行某个区域的性能进行调整。</p><p><img src="/Azure/Azure-Cosmos-DB简介/4.png" alt=""></p><p>浏览数据</p><p><img src="/Azure/Azure-Cosmos-DB简介/5.png" alt=""></p><p><img src="/Azure/Azure-Cosmos-DB简介/6.png" alt=""></p><p>应用使用数据</p><p>.Nets示例，如何使用程序读取</p><p><a href="https://docs.azure.cn/zh-cn/cosmos-db/documentdb-dotnet-samples" target="_blank" rel="noopener">https://docs.azure.cn/zh-cn/cosmos-db/documentdb-dotnet-samples</a></p><p>其他示例：</p><p><a href="https://docs.azure.cn/zh-cn/cosmos-db/documentdb-nodejs-samples" target="_blank" rel="noopener">https://docs.azure.cn/zh-cn/cosmos-db/documentdb-nodejs-samples</a></p><p><a href="https://docs.azure.cn/zh-cn/cosmos-db/documentdb-python-samples" target="_blank" rel="noopener">https://docs.azure.cn/zh-cn/cosmos-db/documentdb-python-samples</a></p><p>总结<br>Cosmos DB 采用本机方式对数据进行分区，实现高可用性和可伸缩性。 Cosmos DB 在可用性、吞吐量、低延迟和一致性方面提供 99.99% 保证。</p><p>Cosmos DB 采用由 SSD 提供支持的存储，具有低延迟毫秒级响应时间。</p><p>Cosmos DB 支持最终、一致前缀、会话和有限过期等一致性级别，从而实现最大的灵活性和很高的性价比。 在一致性级别方面，没有任何数据库服务的灵活性比 Cosmos DB 更高。</p><p>Cosmos DB 提供灵活的数据友好型定价模式，独立测量存储和吞吐量。</p><p>Cosmos DB 保留的吞吐量模型使你可以考虑读取/写入数量而不考虑基础硬件的 CPU/内存/IOP。</p><p>Cosmos DB 的设计允许扩展到每天约数十亿个请求的大规模请求量。</p><h2 id="Cosmos-DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。"><a href="#Cosmos-DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。" class="headerlink" title="Cosmos DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。"></a>Cosmos DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Azure Cosmos DB 是由 Microsoft 提供的全球分布式多模型数据库。 只需单击一个按钮，即可通过 Azure Cosmos DB 跨任意数量的 Azure 地理区域弹性且独立地缩放吞吐量和存储。 它通过综合服务级别协议 (SLA) 提供吞吐量、延迟、可用
      
    
    </summary>
    
      <category term="Azure" scheme="http://blog.ozairs.com/categories/Azure/"/>
    
    
      <category term="Cosmos DB" scheme="http://blog.ozairs.com/tags/Cosmos-DB/"/>
    
  </entry>
  
</feed>
