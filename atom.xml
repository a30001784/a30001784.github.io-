<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>带你走进美丽的墨尔本</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.ozairs.com/"/>
  <updated>2019-04-22T10:10:44.806Z</updated>
  <id>http://blog.ozairs.com/</id>
  
  <author>
    <name>Mark Wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Azure服务之旅</title>
    <link href="http://blog.ozairs.com/Cloud-Service/Azure%E6%9C%8D%E5%8A%A1%E4%B9%8B%E6%97%85/"/>
    <id>http://blog.ozairs.com/Cloud-Service/Azure服务之旅/</id>
    <published>2019-04-22T09:56:57.000Z</published>
    <updated>2019-04-22T10:10:44.806Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Azure服务"><a href="#Azure服务" class="headerlink" title="Azure服务"></a>Azure服务</h2><p>以下是Azure中可用服务和功能的全景图。</p><p><img src="/Cloud-Service/Azure服务之旅/1.png" alt=""></p><p>让我们仔细看看最常用的类别：</p><ul><li>计算</li><li>联网</li><li>存储</li><li>移动</li><li><p>数据库</p></li><li><p>卷筒纸</p></li><li>物联网</li><li>大数据</li><li>人工智能</li><li>DevOps的</li></ul><h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><p>计算服务通常是公司迁移到Azure平台的主要原因之一。Azure为托管应用程序和服务提供了一系列选项。以下是Azure中计算服务的一些示例：</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Vitual Machines</td><td>Azure中托管的Windows或Linux虚拟机（VM）</td></tr><tr><td>Azure Vitual Machine Scale Sets</td><td>扩展Azure中托管的Windows或Linux VM</td></tr><tr><td>Azure Kubernetes Service</td><td>支持管理运行容器化服务的VM群集</td></tr><tr><td>Azure Service Fabric</td><td>分布式系统平台。在Azure或本地运行</td></tr><tr><td>Azure Batch</td><td>为并行和高性能计算应用程序提供托管服务</td></tr><tr><td>Azure Container Instances</td><td>在Azure上运行容器化应用程序而无需配置服务器或VM</td></tr><tr><td>Azure Functions</td><td>事件驱动的无服务器计算服务</td></tr></tbody></table><h3 id="联网"><a href="#联网" class="headerlink" title="联网"></a>联网</h3><p>链接计算资源和提供对应用程序的访问是Azure网络的关键功能。Azure中的网络功能包括一系列选项，用于将外部世界连接到全局Microsoft Azure数据中心中的服务和功能。</p><p>Azure网络设施具有以下功能：</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Virtual Network</td><td>将VM连接到传入的虚拟专用网络（VPN）连接</td></tr><tr><td>Azure Load Balancer</td><td>平衡到应用程序或服务端点的入站和出站连接</td></tr><tr><td>Azure Application Gateway</td><td>优化应用服务器场传输，同时提高应用安全性</td></tr><tr><td>Azure VPN Gateway</td><td>通过高性能VPN网关访问Azure虚拟网络</td></tr><tr><td>Azure DNS</td><td>提供超快的DNS响应和超高域可用性</td></tr><tr><td>Azure VPN Gateway</td><td>为全球客户提供高带宽内容</td></tr><tr><td>Azure DDoS Protection</td><td>保护Azure托管的应用程序免受分布式拒绝服务（DDOS）攻击</td></tr><tr><td>Azure Traffic Manager</td><td>分布全球Azure区域的网络流量</td></tr><tr><td>Azure ExpressRoute</td><td>通过高带宽专用安全连接连接到Azure</td></tr><tr><td>Azure Network Watcher</td><td>使用基于场景的分析监控和诊断网络问题</td></tr><tr><td>Azure Firewall</td><td>实现具有无限可扩展性的高安全性，高可用性防火墙</td></tr><tr><td>Azure Virtual WAN</td><td>创建统一的广域网（WAN），连接本地和远程站点</td></tr></tbody></table><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><p>Azure提供四种主要类型的存储服务。这些服务是：</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Blob Storage</td><td>用于非常大的对象的存储服务，例如视频文件或位图</td></tr><tr><td>Azure FIle Storage</td><td>您可以像文件服务器一样访问和管理的文件共享</td></tr><tr><td>Azure Queue Storage</td><td>用于在应用程序之间排队并可靠地传递消息的数据存储</td></tr><tr><td>Azure Table Storage</td><td>存储非结构化数据的NoSQL存储，独立于任何模式</td></tr></tbody></table><p>这些服务都有几个共同特征：</p><ul><li><strong>耐用</strong>且高度可用，具有冗余和复制功能。</li><li>通过自动加密和基于角色的访问控制来<strong>保护安全</strong>。</li><li><strong>可扩展</strong>，几乎无限存储。</li><li><strong>管理</strong>，处理维护和任何关键问题。</li><li><strong>可</strong>通过HTTP或HTTPS从世界上任何地方<strong>访问</strong>。</li></ul><h3 id="移动"><a href="#移动" class="headerlink" title="移动"></a>移动</h3><p>Azure使开发人员能够快速，轻松地为iOS，Android和Windows应用程序创建移动后端服务。过去需要花费时间并增加项目风险的功能（例如添加公司登录，然后连接到SAP，Oracle，SQL Server和SharePoint等本地资源）现在很容易包含在内。</p><p>该服务的其他功能包括：</p><ul><li>离线数据同步。</li><li>与本地数据的连接。</li><li>广播推送通知。</li><li>自动缩放以满足业务需求。</li></ul><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>Azure提供多种数据库服务来存储各种数据类型和卷。通过全球连接，这些数据可立即供用户使用。</p><table><thead><tr><th>服务名称</th><th>服务功能</th></tr></thead><tbody><tr><td>Azure Cosmos DB</td><td>支持NoSQL选项的全局分布式数据库</td></tr><tr><td>Azure SQL Database</td><td>完全托管的关系数据库，具有自动扩展，集成智能和强大的安全性</td></tr><tr><td>Azure Database for MySQL</td><td>完全托管和可扩展的MySQL关系数据库，具有高可用性和安全性</td></tr><tr><td>Azure Database for PostgreSQL</td><td>完全托管和可扩展的PostgreSQL关系数据库，具有高可用性和安全性</td></tr><tr><td>SQL Server on VMs</td><td>在云中托管企业SQL Server应用程序</td></tr><tr><td>Azure SQL Data Warehouse</td><td>完全管理的数据仓库，无需额外费用即可在各种规模上实现完整的安全性</td></tr><tr><td>Azure Database Migration Service</td><td>无需更改应用程序代码即可将数据库迁移到云</td></tr><tr><td>Azure Redrest for Redis</td><td>缓存经常使用的静态数据以减少数据和应用程序延迟</td></tr><tr><td>Azure Database for MariaDB</td><td>完全托管且可扩展的MariaDB关系数据库，具有高可用性和安全性</td></tr></tbody></table><h3 id="Web"><a href="#Web" class="headerlink" title="Web"></a>Web</h3><p>拥有出色的网络体验对于当今的商业世界至关重要。Azure包括构建和托管Web应用程序以及基于HTTP的Web服务的一流支持。专注于Web托管的Azure服务包括：</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure App Service</td><td>快速创建功能强大的基于Web的云应用程序</td></tr><tr><td>Azure Notification Hubs</td><td>从任何后端向任何平台发送推送通知。</td></tr><tr><td>Azure API Management</td><td>安全且大规模地向开发人员，合作伙伴和员工发布API。</td></tr><tr><td>Azure Search</td><td>完全托管的搜索即服务。</td></tr><tr><td>Web Apps feature of Azure App Service</td><td>大规模创建和部署任务关键型Web应用程序。</td></tr><tr><td>Azure SignalR Service</td><td>轻松添加实时Web功能。</td></tr></tbody></table><h3 id="物联网"><a href="#物联网" class="headerlink" title="物联网"></a>物联网</h3><p>人们能够获得比以往更多的信息。它始于个人数字助理（PDA），然后演变为智能手机。现在有智能手表，智能恒温器，甚至智能冰箱。个人电脑曾经是常态。现在互联网允许任何在线能够访问有价值信息的项目。设备获取然后中继信息以进行数据分析的这种能力被称为物联网（IoT）。</p><p>有许多服务可以为Azure上的物联网提供协助和驱动端到端解决方案。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>IoT Central</td><td>全面管理的全球物联网软件即服务（SaaS）解决方案，可轻松连接，监控和管理您的物联网资产</td></tr><tr><td>Azure IoT Hub</td><td>消息中心，提供数百万个物联网设备之间的安全通信和监控</td></tr><tr><td>IoT Edge</td><td>将您的数据分析推送到您的IoT设备而不是云中，使他们能够更快地对状态变化做出反应。</td></tr></tbody></table><h3 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h3><p>数据有各种格式和大小。当我们谈论大数据时，我们指的是<em>大量</em>数据。来自天气系统，通信系统，基因组研究，成像平台和许多其他场景的数据会产生数百GB的数据。这些数据使得分析和制定决策变得困难。它往往是如此之大，以至于传统形式的处理和分析已不再合适。</p><p>已经开发了开源集群技术来处理这些大型数据集。Microsoft Azure支持广泛的技术和服务，以提供大数据和分析解决方案。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure SQL Datawarehouse</td><td>使用基于云的企业数据仓库（EDW）大规模运行分析，该数据仓库利用大规模并行处理（MPP）在数PB的数据中快速运行复杂查询</td></tr><tr><td>Azure HDInsight</td><td>使用云中的Hadoop集群托管集群处理大量数据</td></tr><tr><td>Azure Databricks（preview）</td><td>协作的基于Apache Spark的分析服务，可与Azure中的其他大数据服务集成。</td></tr></tbody></table><h3 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h3><p>在云计算的背景下，人工智能基于广泛的服务，其核心是机器学习。机器学习是一种数据科学技术，它允许计算机使用现有数据来预测未来的行为，结果和趋势。使用机器学习，计算机无需明确编程即可学习。</p><p>机器学习的预测或预测可以使应用和设备更加智能。例如，当您在线购物时，机器学习会根据您购买的产品帮助推荐您可能喜欢的其他产品。或者，当刷卡时，机器学习会将交易与交易数据库进行比较，并有助于检测欺诈行为。当您的机器人吸尘器吸尘房间时，机器学习可帮助它确定工作是否完成。</p><p>Azure中一些最常见的人工智能和机器学习服务类型是：</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure机Azure Machine Learning Service</td><td>基于云的环境，您可以使用它来开发，培训，测试，部署，管理和跟踪机器学习模型。它可以自动生成模型并为您自动调整模型。它将允许您开始在本地计算机上进行培训，然后扩展到云</td></tr><tr><td>Azure Machine Learning Studio</td><td>协作，拖放式可视化工作区，您可以使用预先构建的机器学习算法和数据处理模块构建，测试和部署机器学习解决方案</td></tr></tbody></table><p>一组密切相关的产品是<em>认知服务</em>。这些是您可以在应用程序中利用的预构建API，以解决复杂问题。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Vision</td><td>图像处理算法，可以智能识别，标题，索引和调节您的图片和视频。</td></tr><tr><td>Speech</td><td>将语音转换为文本，使用语音进行验证，或在应用中添加说话人识别。</td></tr><tr><td>Knowledge mapping</td><td>映射复杂的信息和数据，以解决智能推荐和语义搜索等任务。</td></tr><tr><td>Bing Search</td><td>将Bing搜索API添加到您的应用中，并利用单个API调用功能来梳理数十亿个网页，图片，视频和新闻。</td></tr><tr><td>Natural Language processing</td><td>允许您的应用使用预先构建的脚本处理自然语言，评估情绪并学习如何识别用户想要的内容。</td></tr></tbody></table><h3 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h3><p>DevOps（开发和运营）汇集了人员，流程和技术，自动化软件交付，为您的用户提供持续的价值。Azure DevOps Services允许您创建<em>构建</em>和<em>发布</em>为您的应用程序提供持续集成，交付和部署的管道。您可以集成存储库和应用程序测试，执行应用程序监视，以及使用构建工件。您还可以使用和积压项目进行跟踪，自动化基础架构部署以及集成一系列第三方工具和服务，例如Jenkins和Chef。所有这些功能以及更多功能都与Azure紧密集成，以便为您的应用程序提供一致，可重复的部署，从而提供简化的构建和发布流程。</p><p>Azure提供的一些主要DevOps服务是Azure DevOps Services和Azure DevTest Labs。</p><table><thead><tr><th>服务名称</th><th>描述</th></tr></thead><tbody><tr><td>Azure DevOps</td><td>Azure DevOps Services（以前称为Visual Studio Team Services，或VSTS）提供开发协作工具，包括高性能管道，免费的私有Git存储库，可配置的看板，以及广泛的自动化和基于云的负载测试</td></tr><tr><td>Azure DevTest Labs</td><td>快速创建按需Windows和Linux环境，您可以使用它们直接从部署管道测试或演示应用程序</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Azure服务&quot;&gt;&lt;a href=&quot;#Azure服务&quot; class=&quot;headerlink&quot; title=&quot;Azure服务&quot;&gt;&lt;/a&gt;Azure服务&lt;/h2&gt;&lt;p&gt;以下是Azure中可用服务和功能的全景图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/Cloud-Serv
      
    
    </summary>
    
      <category term="Cloud Service" scheme="http://blog.ozairs.com/categories/Cloud-Service/"/>
    
    
      <category term="Azure" scheme="http://blog.ozairs.com/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>Azure实战应用</title>
    <link href="http://blog.ozairs.com/Cloud-Service/Azure%E5%AE%9E%E6%88%98%E5%BA%94%E7%94%A8/"/>
    <id>http://blog.ozairs.com/Cloud-Service/Azure实战应用/</id>
    <published>2019-04-22T06:21:53.000Z</published>
    <updated>2019-04-22T06:23:00.410Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Cloud Service" scheme="http://blog.ozairs.com/categories/Cloud-Service/"/>
    
    
      <category term="Azure" scheme="http://blog.ozairs.com/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>Azure Cosmos DB简介</title>
    <link href="http://blog.ozairs.com/Azure/Azure-Cosmos-DB%E7%AE%80%E4%BB%8B/"/>
    <id>http://blog.ozairs.com/Azure/Azure-Cosmos-DB简介/</id>
    <published>2019-04-22T03:58:55.000Z</published>
    <updated>2019-04-22T04:12:42.045Z</updated>
    
    <content type="html"><![CDATA[<p>Azure Cosmos DB 是由 Microsoft 提供的全球分布式多模型数据库。 只需单击一个按钮，即可通过 Azure Cosmos DB 跨任意数量的 Azure 地理区域弹性且独立地缩放吞吐量和存储。 它通过综合服务级别协议 (SLA) 提供吞吐量、延迟、可用性和一致性保证，这是其他数据库服务无法提供的。</p><p>Azure Cosmos DB 提供关系数据库和非关系数据库的最佳功能<br>下表比较了关系DB，非关系DB和Cosmos DB的关系</p><p>功能    关系 DB    非关系 (NoSQL) DB    Azure Cosmos DB<br>全球分布    否    否    统包式解决方案，目前在中国有 2 个区域，多宿主，全球超过30个区域<br>横向缩放    否    是    独立缩放存储和吞吐量<br>延迟保证    否    是    在 99% 的情况下，读取操作的延迟 &lt; 10 毫秒，写入操作的延迟 &lt; 15 毫秒<br>高可用性    否    是    始终可用，PACELC 权衡，自动和手动故障转移<br>数据模型 + API关系    关系+SQL    多模型+OSS API    多模型 + SQL + OSS API（即将推出更多）<br>SLA    是    否    有关延迟、吞吐量、一致性和可用性的综合 SLA<br>*PACELC 解释：<a href="https://en.wikipedia.org/wiki/PACELC_theorem#Database_PACELC_ratings" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/PACELC_theorem#Database_PACELC_ratings</a></p><p>*OSS:对象存储（Object Storage Service，简称OSS）</p><p>关键功能<br>作为一种全球分布式数据库服务，Azure Cosmos DB 提供以下功能，帮助构建可缩放的、具有高响应性的全球分布式应用程序：</p><p>统包式全球分布</p><p>应用程序在任何地方都可以即时提供给用户使用。 现在，数据也可以这样。</p><p>不必担心硬件以及添加节点、VM 或内核等问题。 只需点击一下，即可获得数据。</p><p>多个数据模型和用于访问及查询数据的常用 API</p><p>支持多个数据模型，包括键值、文档和列式数据模型。</p><p>用于 Node.js、Java、.NET、.NET Core、Python 和 MongoDB 的可扩展 API。</p><p>用于查询的 SQL。</p><p>在全球范围内按需求弹性缩放吞吐量和存储</p><p>以秒和分钟为时间粒度轻松缩放吞吐量，并可以随时对其进行更改。</p><p>透明且自动地缩放存储以满足现在和将来对大小的要求。</p><p>构建具有高响应性的任务关键型应用程序</p><p>在全球任意位置均可访问你的数据，99% 的情况下延迟仅为几毫秒。</p><p>确保“始终可用”可用性</p><p>在单个区域内可用性为 99.99%。</p><p>部署到任意数量的 Azure 区域可提高可用性。</p><p>模拟一个或多个区域的故障而保证不丢失任何数据。</p><p>编写全球分布式应用程序的正确方式</p><p>五个一致性模型提供类似于 SQL 的非常一致性到类似于 NoSQL 的最终一致性，以及介于两者之间的一致性。</p><p>退款保证</p><p>要么数据快速到达，要么退款。</p><p>有关可用性、延迟、吞吐量和一致性的服务级别协议。</p><p>无数据库架构/索引管理</p><p>无需担心将数据库架构和索引与应用程序架构保持同步的问题。 我们免架构。</p><p>拥有成本低廉</p><p>比非托管解决方案的成本效益高五到十倍。</p><p>比 DynamoDB 便宜三倍。</p><p>创建Comos DB<br>点击Azure CosomosDB，出现如下界面，点击ID ，选择API，API目前有三种选择：MongoDB、SQL (DocumentDB) 和表（键/值），这里创建了一个 SQL(DocumentDB)测试。</p><p><img src="/Azure/Azure-Cosmos-DB简介/1.png" alt=""></p><p>创建成功后，点击：数据资源管理器</p><p><img src="/Azure/Azure-Cosmos-DB简介/2.png" alt=""></p><p>点击New Collection，创建数据集 ，输入数据库ID ,数据集的ID ， 容量，吞吐量，这里创建了 每秒400个的吞吐量， 400ru/s的能力。</p><p>这里创建了2个数据集，结果如下：</p><p><img src="/Azure/Azure-Cosmos-DB简介/3.png" alt=""></p><p>可以看到配置了区域是北京和上海，如果使用国际版意味着可以创建超过30个区域的配置。这就是DBA的梦想啊！！！</p><p>也可以进行缩放配置，也就是说可以进行某个区域的性能进行调整。</p><p><img src="/Azure/Azure-Cosmos-DB简介/4.png" alt=""></p><p>浏览数据</p><p><img src="/Azure/Azure-Cosmos-DB简介/5.png" alt=""></p><p><img src="/Azure/Azure-Cosmos-DB简介/6.png" alt=""></p><p>应用使用数据</p><p>.Nets示例，如何使用程序读取</p><p><a href="https://docs.azure.cn/zh-cn/cosmos-db/documentdb-dotnet-samples" target="_blank" rel="noopener">https://docs.azure.cn/zh-cn/cosmos-db/documentdb-dotnet-samples</a></p><p>其他示例：</p><p><a href="https://docs.azure.cn/zh-cn/cosmos-db/documentdb-nodejs-samples" target="_blank" rel="noopener">https://docs.azure.cn/zh-cn/cosmos-db/documentdb-nodejs-samples</a></p><p><a href="https://docs.azure.cn/zh-cn/cosmos-db/documentdb-python-samples" target="_blank" rel="noopener">https://docs.azure.cn/zh-cn/cosmos-db/documentdb-python-samples</a></p><p>总结<br>Cosmos DB 采用本机方式对数据进行分区，实现高可用性和可伸缩性。 Cosmos DB 在可用性、吞吐量、低延迟和一致性方面提供 99.99% 保证。</p><p>Cosmos DB 采用由 SSD 提供支持的存储，具有低延迟毫秒级响应时间。</p><p>Cosmos DB 支持最终、一致前缀、会话和有限过期等一致性级别，从而实现最大的灵活性和很高的性价比。 在一致性级别方面，没有任何数据库服务的灵活性比 Cosmos DB 更高。</p><p>Cosmos DB 提供灵活的数据友好型定价模式，独立测量存储和吞吐量。</p><p>Cosmos DB 保留的吞吐量模型使你可以考虑读取/写入数量而不考虑基础硬件的 CPU/内存/IOP。</p><p>Cosmos DB 的设计允许扩展到每天约数十亿个请求的大规模请求量。</p><h2 id="Cosmos-DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。"><a href="#Cosmos-DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。" class="headerlink" title="Cosmos DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。"></a>Cosmos DB可以全球部署，支持多区域，可区域性进行扩展。从应用角度讲，可以全球性继续部署应用。几乎实现应用的无限扩展。</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Azure Cosmos DB 是由 Microsoft 提供的全球分布式多模型数据库。 只需单击一个按钮，即可通过 Azure Cosmos DB 跨任意数量的 Azure 地理区域弹性且独立地缩放吞吐量和存储。 它通过综合服务级别协议 (SLA) 提供吞吐量、延迟、可用
      
    
    </summary>
    
      <category term="Azure" scheme="http://blog.ozairs.com/categories/Azure/"/>
    
    
      <category term="Cosmos DB" scheme="http://blog.ozairs.com/tags/Cosmos-DB/"/>
    
  </entry>
  
  <entry>
    <title>Azure入门</title>
    <link href="http://blog.ozairs.com/Azure/Azure%E5%85%A5%E9%97%A8/"/>
    <id>http://blog.ozairs.com/Azure/Azure入门/</id>
    <published>2019-04-22T03:28:48.000Z</published>
    <updated>2019-04-22T04:10:39.811Z</updated>
    
    <content type="html"><![CDATA[<p>Azure 有两种无服务器计算实现：</p><ul><li><strong>Azure Functions</strong>：可以执行几乎任何现代语言的代码</li><li>Azure 逻辑应用：在基于 Web 的设计器中设计，可执行由 Azure 服务触发的逻辑而无需编写代码。</li></ul><h2 id="Azure-Functions"><a href="#Azure-Functions" class="headerlink" title="Azure Functions"></a>Azure Functions</h2><p>若只关心运行服务的代码，而不关心基础平台或基础结构，Azure Functions 是理想选择。 需要执行工作以响应事件（通常通过 REST 请求、计时器或来自其他 Azure 服务的消息），并且该工作可在几秒钟或更短时间内快速完成时，通常会用到它们。</p><p>Azure Functions 会自动按需缩放，所以当需求变化时，它们是可靠的选择。 例如，你可能收到来自用于监控运输车队的 IoT 解决方案的消息。 可能会在工作时间内收到更多数据。</p><p>使用基于 VM 的方法将产生成本，即使 VM 处于空闲状态。 借助函数，Azure 会在触发代码时运行代码，并在函数完成时自动释放资源。 在此模型中，只需为函数运行时使用的 CPU 时间付费。</p><p>此外，Azure Functions 可以是无状态的（默认值），其行为就像每次响应事件时都要重新启动一样；也可以是有状态的（称为“Durable Functions”），其中通过函数传递上下文来跟踪之前的活动。</p><h2 id="Azure-逻辑应用"><a href="#Azure-逻辑应用" class="headerlink" title="Azure 逻辑应用"></a>Azure 逻辑应用</h2><p>Azure 逻辑应用类似于函数 - 两者都使你能够基于事件触发逻辑。 Functions 执行代码时，逻辑应用执行从预定义逻辑块构建的工作流。 具体而言，它们旨在将业务流程自动化。</p><p>可以在 Azure 门户或 Visual Studio 中使用可视化设计器创建逻辑应用工作流。 工作流将保留为具有已知工作流架构的 JSON 文件。</p><p>Azure 提供了 200 多个不同的连接器和处理块与不同服务交互 - 包括最受欢迎的企业应用。 如果未涵盖需要与之进行交互的服务，还可以构建自定义连接器和工作流步骤。 然后使用可视化设计器将连接器和块链接在一起，通过工作流传递数据进行自定义处理 - 通常不需要编写任何代码。</p><p>例如，假设 ZenDesk 收到一个票证。 你可以：</p><ol><li>使用认知服务检测消息的意图</li><li>在 Sharepoint 中创建一个项目来跟踪问题</li><li>如果客户不在数据库中，则将其添加到 Dynamics 365 CRM 系统</li><li>发送跟进电子邮件以确认他们的请求</li></ol><p>所有这些都可以在可视化设计器中进行设计，这让看到逻辑流变得非常容易，因而是业务分析师角色的理想选择。</p><h2 id="Azure-Functions与Azure逻辑应用"><a href="#Azure-Functions与Azure逻辑应用" class="headerlink" title="Azure Functions与Azure逻辑应用"></a>Azure Functions与Azure逻辑应用</h2><p>函数和逻辑应用都可以创建复杂的业务流程。 业务流程是函数或步骤的集合，将执行这些函数或步骤来完成复杂任务。 使用 Azure Functions，可以编写代码来完成每个步骤，使用逻辑应用，可以使用 GUI 来定义操作以及它们之间的关联方式。</p><p>在构建业务流程、从逻辑应用中调用函数以及从函数中调用逻辑应用时，可以混合使用各种服务。 下面是两者之间的一些常见差异。</p><table><thead><tr><th>-</th><th>Functions</th><th>逻辑应用</th></tr></thead><tbody><tr><td>状态</td><td>通常是无状态的，但 Durable Functions 会提供状态</td><td>有状态</td></tr><tr><td>开发</td><td>代码优先（命令性）</td><td>设计器优先（声明性）</td></tr><tr><td>连接</td><td>有关十多个内置的绑定类型，为自定义绑定编写代码</td><td>大型连接器集合、适用于 B2B 方案的 Enterprise Integration Pack、构建自定义连接器</td></tr><tr><td>操作</td><td>每个活动都是一个 Azure 函数；为活动函数编写代码</td><td>现成操作的大型集合</td></tr><tr><td>监视</td><td>Azure Application Insights</td><td>Azure 门户、Log Analytics</td></tr><tr><td>管理</td><td>REST API、Visual Studio</td><td>Azure 门户、REST API、PowerShell、Visual Studio</td></tr><tr><td>执行上下文</td><td>可以在本地或在云中运行</td><td>只能在云中运行。</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Azure 有两种无服务器计算实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Azure Functions&lt;/strong&gt;：可以执行几乎任何现代语言的代码&lt;/li&gt;
&lt;li&gt;Azure 逻辑应用：在基于 Web 的设计器中设计，可执行由 Azure 服务触发的逻辑而无
      
    
    </summary>
    
      <category term="Azure" scheme="http://blog.ozairs.com/categories/Azure/"/>
    
    
      <category term="Azure" scheme="http://blog.ozairs.com/tags/Azure/"/>
    
  </entry>
  
  <entry>
    <title>谈谈澳洲找工作心得</title>
    <link href="http://blog.ozairs.com/%E8%AF%84%E8%AE%BA/%E8%B0%88%E8%B0%88%E6%BE%B3%E6%B4%B2%E6%89%BE%E5%B7%A5%E4%BD%9C%E5%BF%83%E5%BE%97/"/>
    <id>http://blog.ozairs.com/评论/谈谈澳洲找工作心得/</id>
    <published>2019-04-14T09:34:05.000Z</published>
    <updated>2019-04-14T11:50:08.778Z</updated>
    
    <content type="html"><![CDATA[<p>2月初登陆澳洲，在经历了忙忙碌碌2个多月的学习、求职生涯后，终于在本周，我和一家Local Consultancy公司签订了正式合同。虽然在海外找工作的这段周期并不算太长，但是这其中也并非一番风顺，所以在即将开启一段新的职业生涯的时候，也想对过往的这段经历做个总结。 </p><p><strong>曾经有人说：“失败的原因只有一个，就是自己放弃了。</strong>可以说，过去的这2个多月，也是我从长登澳洲-初涉职场-尝试失败-重新开始-再次失败-重复失败-失败失败再失败-直至最终完成临门一脚的过程。这期间，我想主要可以分成三个阶段： 文化隔阂阶段，初涉职场阶段，和最终实现目标阶段。</p><h4 id="一、文化隔阂期"><a href="#一、文化隔阂期" class="headerlink" title="一、文化隔阂期"></a>一、文化隔阂期</h4><p>2月初刚登陆澳洲的时候，我对自己和前途还是充满了希望和憧憬。为了准备这次的登陆，前前后后我已经花了几年的时间在磨练自己的英语技能上。同时，为了能够提升自己的职业技能，逐步完成职业转型，去年我已经陆续通过了AWS SAA和SAP考试，对于时下如火如荼的Cloud Service基本也算是“门内汉”了。</p><p>但是，单单凭借几张业内职业资格PASS，显然是不足以叩开澳洲的Job Market的大门的。在经历了短暂的登陆海外的蜜月期之后，很快我就体会到了衣食无着，海投了N多简历，但是收到的Feedback寥寥，甚至有些过了很长时间，还收到了用人公司的婉拒邮件。这段时间，可以说对我的自信心是一种不断的蚕食。原本以为已经对澳洲足够的了解，对于在澳洲求职找工作做了充分的准备，但是倒头来却发现，在自己的技能、背景和澳洲的Job Market之间存在着无形的屏障，而随着时间的推移，这层屏障似乎变得越来越厚。</p><p>这期间，在某个周五的下午，突然从新西兰的Christchurch传来了恐怖袭击的噩耗，一名“土澳”极右主义分子，手持Machine Gun闯入Christchurch的一所清真寺进行疯狂扫射，导致了50名无辜穆斯林死亡。这一突如其来的消息，再加上到澳洲这段时间来所遇到的种种，让我越来越觉得自己对于西方社会，对于西方文化的了解是多么的匮乏，美好的理想和残酷的现实之间的距离是多么的遥远。那段时间，火车站的警察人数明显增多了，学校里的印度人，伊斯兰人都会不时地讨论这次的恐怖袭击，似乎大家对于这次的事件都心有余悸。我甚至一度认为，伊斯兰的极端分子将会采取报复行动。而行动的最佳地点，莫过于墨尔本的地标性建筑：Flinder Railway Startion了。</p><h4 id="二、初涉职场期"><a href="#二、初涉职场期" class="headerlink" title="二、初涉职场期"></a>二、初涉职场期</h4><p>虽然文化，习惯，语言的落差让我一度觉得很难适应，但好在在这段时期，我参加了墨尔本当地的OQP课程。说起OQP课程，之前曾经透过知乎，得到的一些过来的人的推荐。正如推荐的前辈所说，这门课程对于我们这些技术移民的专业人士来说，帮助是全方面的。她给予了我们一个很好的“Handle”，使我们这些刚刚涉足澳洲，但是并不了解澳洲的Work Practice 的专业人士，有了一个很好的缓冲期，透过缓冲期，我们可以逐渐养成一些新的习惯，这些习惯也在日后帮助我们在求职、应聘、面试的过程中，变得更加的从容和自信。就像在结业之际最后一堂课上，老师给我们总结的，OQP对于我们最显著的帮助来自以下几个方面：</p><h5 id="1、关于简历"><a href="#1、关于简历" class="headerlink" title="1、关于简历"></a>1、关于简历</h5><p>这里要特别感谢我OQP的负责老师Rosie，她是我来澳洲遇到的第一位教师，也是我非常尊敬的一份师长。她为我定义了澳洲教师这一职业的标准和要求，让我感受到了澳洲教师的责任心和专业的素质。在课程当中，Rosie对于我的简历给予了多次的指导和修改，使我有了一份在澳洲的Job Market拿的出手的“<strong>产品说明书</strong>”，也帮我逐步拓展了澳洲公司的渠道，为日后的面试打下了良好的基础。</p><h5 id="2、关于人脉"><a href="#2、关于人脉" class="headerlink" title="2、关于人脉"></a>2、关于人脉</h5><p>在参加OQP课程之前，我在澳洲仅有的人脉可能就是我的初中同学兼好友毛毛了。但是透过OQP课程，她在潜移默化中，帮我逐步积累了澳洲本地的人脉，包括课堂中认识的来自五湖四海（主要还是“印度”和“伊朗”）的兄弟姐妹，Linkedin上的猎头、中介、公司HR。虽然，在一开始的时候某些猎头看上去并不起眼，公司也不是十分的出名，但是有些确实在我求职的过程当中起到了十分重要的催化剂的作用。得益于OQP课程中一位同学的推荐，我结识了某猎头A，他们作为中间人，把我推荐给了猎头B，之后我作为猎头B的Cousultant，参加了澳洲4大银行之一的某家Bank的多轮面试，并顺利拿到了自己的第一个Offer（虽然最终因为其他原因，我没能和这家公司签约）。但是可以说OQP还是为我提供了很好的人脉资源，使我有机会能在看似无从下手的澳洲职场之中，找到一丝缝隙，并逐步将他扩展成了突破口。</p><h5 id="3、关于求职面试"><a href="#3、关于求职面试" class="headerlink" title="3、关于求职面试"></a>3、关于求职面试</h5><p>OQP的课程中，还有2个非常经典的环节，模拟面试问题和Mock Interview。特别是Mock Interview，有三位“面试官”参加，并且全程进行录像，最真实的还原面试现场的情形，使我们这些英语还不过关，对于澳洲的面试方式不十分习惯的“攻城狮”们多了一份实战的经验，帮助我们了解自身面试过程中存在的问题和不足，极大地积累了自信心，可以说也为我日后通关最终签订合同那家Consultancy的三轮面试，打下了坚实的基础。</p><h4 id="三、屡败屡战，最终顺利拿到Offer时期"><a href="#三、屡败屡战，最终顺利拿到Offer时期" class="headerlink" title="三、屡败屡战，最终顺利拿到Offer时期"></a>三、屡败屡战，最终顺利拿到Offer时期</h4><p>屈指算来，在过去的这2个多月的时间里，包括电面，Face-to-face interview，累计我也参加大大小小将近20场面试。其中，除了后期的几家公司面试外，之前的绝大多数面试都以失败告终。失败的原因多种多样，有的是Need more technical（虽然我至今搞不明白如何才算够Technical），有的是无法在电话里给出命令行公式，有的是因为没有在面试的时候， 在白板上画出系统架构图，还有许多根本无从知晓失败原因的。。。尽管如此，随着时间的推移，虽然失败的次数仍在增加，但是失败的效果似乎已是越来越好，我能感觉到自己在面试中的表现再不断的提升。</p><p>终于又到了某个星期五下午，和最终签约公司约了三面，是Team Leader和技术负责人面试环节。这次的环节也让我看到了国外面试的专业性的地方。面试的全过程，两位面试官都是按照事先准备好的问题进行提问，并且记录下我的回答要点。问题方向涵盖了专业知识、团队协作、冲突解决、自我意识、沟通技能等多个维度，可以说通过这样全方位的评估，基本可以对候选人得出一个比较公平、客观的评价了。</p><p>幸运的是，虽然某些技术环节还有欠缺，但好在Team Lead对我的表现还是比较认可，觉得我是个很好的Team Player，所以最终顺利地拿到了这家Offer。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>还记得刚来澳洲的时候，对于自己的职业生涯，一切都还是个未知数，甚至一度觉得十分的虚无缥缈。但就是在这段不稳定的时期内，我通过借助各种外力，试图在飘忽不定的职场的汪洋大海中，找寻前行的方向。很幸运，自己能够坚持既定的策略和方向，最终得以跨越非连续性，找到心仪的工作。</p><p>明天将是入职的第一天，似乎一切都又回到了初登澳洲的起点。把祝福送给自己，希望自己能调整状态，重新起航，能够做到知行合一，在新的征途上把前行的道路越走越宽，越走越远。</p><h2 id="“Stay-Hungry-Stay-Foolish-”"><a href="#“Stay-Hungry-Stay-Foolish-”" class="headerlink" title="“Stay Hungry!  Stay Foolish!”"></a>“Stay Hungry!  Stay Foolish!”</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2月初登陆澳洲，在经历了忙忙碌碌2个多月的学习、求职生涯后，终于在本周，我和一家Local Consultancy公司签订了正式合同。虽然在海外找工作的这段周期并不算太长，但是这其中也并非一番风顺，所以在即将开启一段新的职业生涯的时候，也想对过往的这段经历做个总结。 &lt;/p
      
    
    </summary>
    
      <category term="评论" scheme="http://blog.ozairs.com/categories/%E8%AF%84%E8%AE%BA/"/>
    
    
      <category term="Jobs" scheme="http://blog.ozairs.com/tags/Jobs/"/>
    
  </entry>
  
  <entry>
    <title>永远记得- Always Remember</title>
    <link href="http://blog.ozairs.com/%E8%AF%84%E8%AE%BA/%E6%B0%B8%E8%BF%9C%E8%AE%B0%E5%BE%97-Always-Remember/"/>
    <id>http://blog.ozairs.com/评论/永远记得-Always-Remember/</id>
    <published>2019-04-11T01:25:11.000Z</published>
    <updated>2019-04-11T01:28:42.151Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Published on March 30, 2019</li><li>Francisco D’Souza Influencer</li><li>Executive Vice Chairman at Cognizant</li></ul><p>这个星期天是我作为Cognizant首席执行官的最后一天。星期一，Brian Humphries将接替我领导Cognizant的增长和成功的下一章。我知道Cognizant面临最好的日子，我对未来充满乐观。当我们大胆前进时，我希望我们永远不会忘记过去的教训 - 毕竟，这些教训使我们成为今天的我们。所以，在我作为首席执行官发给你的最后一封电子邮件中，我想我会在过去的25年中分享一些经验教训。</p><p><strong>前线; 不是会议室</strong> - 我们从未制定战略，做出决策或采取行动离前线太远。在像我们这样的竞争市场中，战斗是在战斗中取得胜利并且接近行动。永远不要陷入在“象牙塔”或会议室做出决定的陷阱。现实更接近实际。</p><p><strong>我们团结一致**</strong> - 我们的团队运动在执行方面很重要。我们互相依赖，相互支持。当我们中的任何一个人跌倒时，我们其他人都会选择那个人。彼此做正确的事情总是我们如何保持强大，每天将我们的A-game带到现场。</p><p><strong>道德和善良比以往任何时候都更重要</strong> <strong>-</strong>世界变得越来越复杂，社会似乎比以往任何时候都更加分裂。面对这种复杂性，我们始终首先将决策建立在我们核心价值观所描述的道德指南针上。这样做可以让我们以统一的目的行事。对彼此的善意和对待我们的核心价值观比以往任何时候都更重要。</p><p><strong>挑选最好的人 -</strong>我从我的老朋友兼同事Raj Mehta那里学到了这一课。Raj是一位杰出的人才开发者。他的理念是，如果我们每个人都雇用比我们小的人，那么我们就会迅速变得无关紧要。但如果我们每个人都雇用比我们更大的人，那么没有任何障碍太大而无法克服。</p><p><strong>未来第一</strong> - 未来总是比我们预期的要快。我们通过比竞争对手更快地拥抱未来来驾驭每一波技术，规模和复杂性。永远不要害怕未来。它会在这里比我们想象的更快，我们可以塑造它比过去更好！</p><p>祝大家好运！在接下来的几个月里，我将与Brian合作以确保顺利过渡。而且我会在场边为队友Cognizant加油！我们建立了一个对世界很重要的强国。这是超越我们所有人的目标和使命。向前！</p><p>【原文】</p><p>This Sunday is my last day as the CEO of Cognizant. On Monday, Brian Humphries will take over from me to lead Cognizant’s next chapter of growth and success. I know that the best days for Cognizant lie ahead and I have great optimism for our future. As we march boldly forward, I hope that we never forget the lessons of the past – which, after all, made us who we are today. So, in my last email to you as CEO, I thought I’d share a few lessons from the last 25 years.</p><p><strong>Front lines; not conference rooms</strong> – We never developed strategy, made decisions or took action too far from the front lines. In competitive markets like ours, battles are fought and won close to the action. Never fall into the trap of making decisions in the “ivory tower” or conference room. Reality is much closer to the ground.</p><p><strong>United we stand strong</strong> – Ours is a team sport where execution matters. We rely on each other and stand by one another. When any one of us falls, the rest of us pick that person up. Doing the right thing by each other always is how we stay strong and bring our A-game to the field every day.</p><p><strong>Morals and kindness matter more than ever</strong> <strong>–</strong> The world is becoming more complicated and societies seem more divided than ever. In the face of this complexity, we have always based our decisions first and foremost on the moral compass described in our core values. Doing so allows us to act with unified purpose. Kindness to one another and living our core values matters more than ever.</p><p><strong>Pick the best people –</strong> I learned this lesson from my long-time friend and colleague Raj Mehta. Raj is an outstanding people developer. He lives the philosophy that if each of us hires people who are smaller than we are, then we rapidly become irrelevant. But if each of us hires people who are bigger than we are, then no obstacle is too large to overcome.</p><p><strong>Future first</strong> – The future always comes faster than we expect. We navigated each wave of technology, scale, and complexity by always embracing the future faster than the competition. Never fear the future. It will be here faster than we think, and we can shape it to be better than the past!</p><p>Good luck to all of you! Over the coming months, I’ll be working with Brian to ensure a smooth transition. And I’ll be cheering team Cognizant from the sidelines! We’ve built a powerhouse that matters to the world. That’s a purpose and mission that transcends all of us. Onward!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;Published on March 30, 2019&lt;/li&gt;
&lt;li&gt;Francisco D’Souza Influencer&lt;/li&gt;
&lt;li&gt;Executive Vice Chairman at Cognizant&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个星期天
      
    
    </summary>
    
      <category term="评论" scheme="http://blog.ozairs.com/categories/%E8%AF%84%E8%AE%BA/"/>
    
    
      <category term="Cognizant" scheme="http://blog.ozairs.com/tags/Cognizant/"/>
    
  </entry>
  
  <entry>
    <title>Helm：强大的Kubernetes包管理工具</title>
    <link href="http://blog.ozairs.com/Kubernetes/Helm%EF%BC%9A%E5%BC%BA%E5%A4%A7%E7%9A%84Kubernetes%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    <id>http://blog.ozairs.com/Kubernetes/Helm：强大的Kubernetes包管理工具/</id>
    <published>2019-04-10T00:36:34.000Z</published>
    <updated>2019-04-10T00:41:07.428Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>Helm是Kubernetes生态系统中的一个软件包管理工具。本文将介绍为何要使用Helm进行Kubernetes软件包管理，澄清Helm中使用到的相关概念，并通过一个具体的示例学习如何使用Helm打包，分发，安装，升级及回退Kubernetes应用。</p><p>Kubernetes应用部署的挑战<br>让我们首先来看看Kubernetes，kubernetes提供了基于容器的应用集群管理，为容器化应用提供了部署运行、资源调度、服务发现和动态伸缩等一系列完整功能。</p><p>kubernetes的核心设计理念是: 用户定义应用程序的规格，而kubernetes则负责按照定义的规则部署并运行应用程序，如果应用系统出现问题导致偏离了定义的规格，kubernetes负责对其进行自动修正。例如应用规格要求部署两个实例，其中一个实例异常终止了，kubernetes会检查到并重新启动一个新的实例。</p><p>用户通过使用kubernetes API对象来描述应用程序规格，包括Pod，Service，Volume，Namespace，ReplicaSet，Deployment，Job等等。一般这些对象需要写入一系列的yaml文件中，然后通过kubernetes命令行工具kubectl进行部署。</p><p>以下面的wordpress应用程序为例，涉及到多个kubernetes API对象，这些kubernetes API对象分散在多个yaml文件中。</p><p>可以看到，在进行kubernetes软件部署时，我们面临下述问题：</p><p>如何管理，编辑和更新这些这些分散的kubernetes应用配置文件？<br>如何把一套的相关配置文件作为一个应用进行管理？<br>如何分发和重用kubernetes的应用配置？<br>Helm的引入很好地解决上面这些问题。</p><p>Helm是什么？<br>很多人都使用过Ubuntu下的ap-get或者CentOS下的yum, 这两者都是Linux系统下的包管理工具。采用apt-get/yum,应用开发者可以管理应用包之间的依赖关系，发布应用；用户则可以以简单的方式查找、安装、升级、卸载应用程序。</p><p>我们可以将Helm看作Kubernetes下的apt-get/yum。Helm是Deis (<a href="https://deis.com/" target="_blank" rel="noopener">https://deis.com/</a>) 开发的一个用于kubernetes的包管理器。</p><p>对于应用发布者而言，可以通过Helm打包应用，管理应用依赖关系，管理应用版本并发布应用到软件仓库。</p><p>对于使用者而言，使用Helm后不用需要了解Kubernetes的Yaml语法并编写应用部署文件，可以通过Helm下载并在kubernetes上安装需要的应用。</p><p>除此以外，Helm还提供了kubernetes上的软件部署，删除，升级，回滚应用的强大功能。</p><p>Helm组件及相关术语<br>开始接触Helm时遇到的一个常见问题就是Helm中的一些概念和术语非常让人迷惑，我开始学习Helm就遇到这个问题。</p><p>因此我们先了解一下Helm的这些相关概念和术语。</p><p>Helm</p><p>Kubernetes的应用打包工具，也是命令行工具的名称。</p><p>Tiller</p><p>Helm的服务端，部署在Kubernetes集群中，用于处理Helm的相关命令。</p><p>Chart</p><p>Helm的打包格式，内部包含了一组相关的kubernetes资源。</p><p>Repoistory</p><p>Helm的软件仓库，repository本质上是一个web服务器，该服务器保存了chart软件包以供下载，并有提供一个该repository的chart包的清单文件以供查询。在使用时，Helm可以对接多个不同的Repository。</p><p>Release</p><p>使用Helm install命令在Kubernetes集群中安装的Chart称为Release。</p><p>需要特别注意的是， Helm中提到的Release和我们通常概念中的版本有所不同，这里的Release可以理解为Helm使用Chart包部署的一个应用实例。</p><p>其实Helm中的Release叫做Deployment更合适。估计因为Deployment这个概念已经被Kubernetes使用了，因此Helm才采用了Release这个术语。</p><p>下面这张图描述了Helm的几个关键组件Helm（客户端），Tiller（服务器），Repository（Chart软件仓库），Chart（软件包）之前的关系。</p><p>安装Helm<br>下面我们通过一个完整的示例来介绍Helm的相关概念，并学习如何使用Helm打包，分发，安装，升级及回退kubernetes应用。</p><p>可以参考Helm的帮助文档<a href="https://docs.helm.sh/using_helm/#installing-helm" target="_blank" rel="noopener">https://docs.helm.sh/using_helm/#installing-helm</a> 安装Helm</p><h3 id="采用二进制的方式安装Helm"><a href="#采用二进制的方式安装Helm" class="headerlink" title="采用二进制的方式安装Helm"></a>采用二进制的方式安装Helm</h3><p>下载 Helm <a href="https://github.com/kubernetes/helm/releases" target="_blank" rel="noopener">https://github.com/kubernetes/helm/releases</a><br>解压 tar -zxvf helm-v2.0.0-linux-amd64.tgz<br>拷贝到bin目录 mv linux-amd64/helm /usr/local/bin/helm<br>然后使用下面的命令安装服务器端组件Tiller</p><h3 id="通过-homebrew（macOS）"><a href="#通过-homebrew（macOS）" class="headerlink" title="通过 homebrew（macOS）"></a>通过 homebrew（macOS）</h3><p>Kubernetes 社区的成员为 Homebrew 贡献了 Helm。这个通常是最新的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install kubernetes-helm</span><br></pre></td></tr></table></figure><p>（注意：emacs-helm 也是一个软件，这是一个不同的项目。）</p><p>Helm init<br>构建一个Helm chart<br>让我们在实践中来了解Helm。这里将使用一个Go测试小程序，让我们先为这个小程序创建一个Helm chart。</p><p>git clone <a href="https://github.com/zhaohuabing/testapi.git" target="_blank" rel="noopener">https://github.com/zhaohuabing/testapi.git</a>;<br>cd testapi<br>首先创建一个chart的骨架</p><p>helm create testapi-chart<br>该命令创建一个testapi-chart目录，该目录结构如下所示，我们主要关注目录中的这三个文件即可: Chart.yaml，values.yaml 和 NOTES.txt。</p><p>testapi-chart<br>├── charts<br>├── Chart.yaml<br>├── templates<br>│   ├── deployment.yaml<br>│   ├── _helpers.tpl<br>│   ├── NOTES.txt<br>│   └── service.yaml<br>└── values.yaml<br>Chart.yaml 用于描述这个chart，包括名字，描述信息以及版本。<br>values.yaml 用于存储templates目录中模板文件中用到的变量。 模板文件一般是Go模板。如果你需要了解更多关于Go模板的相关信息，可以查看Hugo (<a href="https://gohugo.io" target="_blank" rel="noopener">https://gohugo.io</a>) 的一个关于Go模板的介绍 (<a href="https://gohugo.io/templates/go-templates/)。" target="_blank" rel="noopener">https://gohugo.io/templates/go-templates/)。</a><br>NOTES.txt 用于向部署该chart的用于介绍chart部署后的一些信息。例如介绍如何使用这个chart，列出缺省的设置等。<br>打开Chart.yaml, 填写你部署的应用的详细信息，以testapi为例：</p><p>apiVersion: v1<br>description: A simple api for testing and debugging<br>name: testapi-chart<br>version: 0.0.1<br>然后打开并根据需要编辑values.yaml。下面是testapi应用的values.yaml文件内容。</p><p>replicaCount: 2<br>image:<br>  repository: daemonza/testapi<br>  tag: latest<br>  pullPolicy: IfNotPresent<br>service:<br>  name: testapi<br>  type: ClusterIP<br>  externalPort: 80<br>  internalPort: 80<br>resources:<br>  limits:<br>    cpu: 100m<br>    memory: 128Mi<br>  requests:<br>    cpu: 100m<br>    memory: 128Mi<br>在 testapi_chart 目录下运行下面命令以对chart进行校验。</p><p>helm lint<br>==&gt; Linting .<br>[INFO] Chart.yaml: icon is recommended</p><p>1 chart(s) linted, no failures<br>如果文件格式错误，可以根据提示进行修改；如果一切正常，可以使用下面的命令对chart进行打包：</p><p>helm package testapi-chart –debug<br>这里添加了 –debug 参数来查看打包的输出，输出应该类似于：</p><p>Saved /Users/daemonza/testapi/testapi-chart/testapi-chart-0.0.1.tgz to current directory<br>Saved /Users/daemonza/testapi/testapi-chart/testapi-chart-0.0.1.tgz to /Users/daemonza/.helm/repository/local<br>chart被打包为一个压缩包testapi-chart-0.0.1.tgz，该压缩包被放到了当前目录下，并同时被保存到了helm的本地缺省仓库目录中。</p><p>Helm Repository<br>虽然我们已经打包了chart并发布到了helm的本地目录中，但通过Helm search命令查找，并不能找不到刚才生成的chart包。</p><p>helm search testapi<br>No results found<br>这是因为repository目录中的chart还没有被Helm管理。我们可以在本地启动一个Repository Server，并将其加入到Helm repo列表中。</p><p>通过helm repo list命令可以看到目前helm中只配置了一个名为stable的repo，该repo指向了google的一个服务器。</p><p>helm repo list<br>NAME    URL<br>stable  <a href="https://kubernetes-charts.storage.googleapis.com" target="_blank" rel="noopener">https://kubernetes-charts.storage.googleapis.com</a><br>使用helm serve命令启动一个repo server，该server缺省使用’$HELM_HOME/repository/local’目录作为chart存储，并在8879端口上提供服务。</p><p>helm serve&amp;<br>Now serving you on 127.0.0.1:8879<br>启动本地repo server后，将其加入helm的repo列表。</p><p>helm repo add local <a href="http://127.0.0.1:8879" target="_blank" rel="noopener">http://127.0.0.1:8879</a><br>“local” has been added to your repositories<br>现在再查找testapi chart包，就可以找到了。</p><p>helm search testapi</p><p>NAME                    CHART VERSION   APP VERSION     DESCRIPTION<br>local/testapi-chart     0.0.1                           A Helm chart for Kubernetes<br>在kubernetes中部署Chart<br>chart被发布到仓储后，可以通过Helm instal命令部署chart，部署时指定chart名及Release（部署的实例）名：</p><p> helm install local/testapi-chart –name testapi<br>该命令的输出应类似:</p><p>NAME:   testapi<br>LAST DEPLOYED: Mon Apr 16 10:21:44 2018<br>NAMESPACE: default<br>STATUS: DEPLOYED</p><p>RESOURCES:<br>==&gt; v1/Service<br>NAME                   TYPE       CLUSTER-IP    EXTERNAL-IP  PORT(S)  AGE<br>testapi-testapi-chart  ClusterIP  10.43.121.84  <none>       80/TCP   0s</none></p><p>==&gt; v1beta1/Deployment<br>NAME                   DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE<br>testapi-testapi-chart  1        1        1           0          0s</p><p>==&gt; v1/Pod(related)<br>NAME                                   READY  STATUS   RESTARTS  AGE<br>testapi-testapi-chart-9897d9f8c-nn6wd  0/1    Pending  0         0s</p><p>NOTES:</p><ol><li>Get the application URL by running these commands:<br>export POD_NAME=$(kubectl get pods –namespace default -l “app=testapi-testapi-chart” -o jsonpath=”{.items[0].metadata.name}”)<br>echo “Visit <a href="http://127.0.0.1:8080" target="_blank" rel="noopener">http://127.0.0.1:8080</a> to use your application”<br>kubectl port-forward $POD_NAME 8080:80<br>使用下面的命令列出所有已部署的Release以及其对应的Chart。</li></ol><p>helm ls<br>该命令的输出应类似:</p><p>NAME    REVISION        UPDATED                         STATUS          CHART                   NAMESPACE<br>testapi 1               Mon Apr 16 10:21:44 2018        DEPLOYED        testapi-chart-0.0.1     default<br>可以看到在输出中有一个Revision（更改历史）字段，该字段用于表示某一Release被更新的次数，可以用该特性对已部署的Release进行回滚。</p><p>升级和回退<br>修改Chart.yaml，将版本号从0.0.1 修改为 1.0.0, 然后使用Helm package命令打包并发布到本地仓库。</p><p>查看本地库中的Chart信息，可以看到在本地仓库中testapi-chart有两个版本</p><p>helm search testapi -l<br>NAME                    CHART VERSION   APP VERSION     DESCRIPTION<br>local/testapi-chart     0.0.1                           A Helm chart for Kubernetes<br>local/testapi-chart     1.0.0                           A Helm chart for Kubernetes<br>现在用helm upgrade将已部署的testapi升级到新版本。可以通过参数指定需要升级的版本号，如果没有指定版本号，则缺省使用最新版本。</p><p>helm upgrade testapi local/testapi-chart<br>已部署的testapi release被升级到1.0.0版本</p><p>helm list<br>NAME    REVISION        UPDATED                         STATUS          CHART                   NAMESPACE<br>testapi 2               Mon Apr 16 10:43:10 2018        DEPLOYED        testapi-chart-1.0.0     default<br>可以通过Helm history查看一个Release的多次更改。</p><p>helm history testapi<br>REVISION        UPDATED                         STATUS          CHART                   DESCRIPTION<br>1               Mon Apr 16 10:21:44 2018        SUPERSEDED      testapi-chart-0.0.1     Install complete<br>2               Mon Apr 16 10:43:10 2018        DEPLOYED        testapi-chart-1.0.0     Upgrade complete<br>如果更新后的程序由于某些原因运行有问题，我们则需要回退到旧版本的应用，可以采用下面的命令进行回退。其中的参数1是前面Helm history中查看到的Release的更改历史。</p><p>helm rollback testapi 1<br>使用Helm list命令查看，部署的testapi的版本已经回退到0.0.1</p><p>helm list<br>NAME    REVISION        UPDATED                         STATUS          CHART                   NAMESPACE<br>testapi 3               Mon Apr 16 10:48:20 2018        DEPLOYED        testapi-chart-0.0.1     default<br>总结</p><h5 id="Helm作为kubernetes应用的包管理以及部署工具，提供了应用打包，发布，版本管理以及部署，升级，回退等功能。Helm以Chart软件包的形式简化Kubernetes的应用管理，提高了对用户的友好性。"><a href="#Helm作为kubernetes应用的包管理以及部署工具，提供了应用打包，发布，版本管理以及部署，升级，回退等功能。Helm以Chart软件包的形式简化Kubernetes的应用管理，提高了对用户的友好性。" class="headerlink" title="Helm作为kubernetes应用的包管理以及部署工具，提供了应用打包，发布，版本管理以及部署，升级，回退等功能。Helm以Chart软件包的形式简化Kubernetes的应用管理，提高了对用户的友好性。"></a>Helm作为kubernetes应用的包管理以及部署工具，提供了应用打包，发布，版本管理以及部署，升级，回退等功能。Helm以Chart软件包的形式简化Kubernetes的应用管理，提高了对用户的友好性。</h5>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前言&lt;br&gt;Helm是Kubernetes生态系统中的一个软件包管理工具。本文将介绍为何要使用Helm进行Kubernetes软件包管理，澄清Helm中使用到的相关概念，并通过一个具体的示例学习如何使用Helm打包，分发，安装，升级及回退Kubernetes应用。&lt;/p&gt;

      
    
    </summary>
    
      <category term="Kubernetes" scheme="http://blog.ozairs.com/categories/Kubernetes/"/>
    
    
      <category term="Helm" scheme="http://blog.ozairs.com/tags/Helm/"/>
    
  </entry>
  
  <entry>
    <title>Kops：更便捷的使用Kubernetes</title>
    <link href="http://blog.ozairs.com/Kubernetes/Kops%EF%BC%9A%E6%9B%B4%E4%BE%BF%E6%8D%B7%E7%9A%84%E4%BD%BF%E7%94%A8Kubernetes/"/>
    <id>http://blog.ozairs.com/Kubernetes/Kops：更便捷的使用Kubernetes/</id>
    <published>2019-04-10T00:09:23.000Z</published>
    <updated>2019-04-10T00:11:43.969Z</updated>
    
    <content type="html"><![CDATA[<p>对于那些第一次接触Kubernetes（通常被称为k8s）并且想独自运行他们自己的第一个pods，services和deployments的人来说，通常存在很多的指南，例如可以使用Minikube在他们自己的电脑上设置和安装k8s。这也被认为是初次接触Kubernetes时的一种比较好的方式，到最后，这些文章会介绍如何将他们的应用栈发布到生产环境中。通常运行在一个类似Google Cloud Platform（GCP）或者Amazon Web Services（AWS）的云环境中可能会更利于使用kops。</p><h3 id="介绍一下Kops"><a href="#介绍一下Kops" class="headerlink" title="介绍一下Kops"></a>介绍一下Kops</h3><p>Kops</p><p>被描述为“用最容易的方式启动和运行生产级别的k8s集群” ，正好与Kelsey Hightower的文章 “</p><p>Kubernetes the Hard Way</p><p>”相对。 相对而言，我建议如果你想更倾向于使用，或想更好地了解使用k8s的容器编排，那么就应该尝试一下该教程，并在设置过程中执行每一个步骤。</p><p>虽然用户创建Kubernetes的高可用性集群的过程经常会被认为是“困难的方式”，但是kops可以将大部分流程自动化。它将执行至少8个任务，这其中包括在集群中创建子网和DHCP参数，自动分组你的主节点和工作节点，为这些节点读取配置文件信息， IAM定义和创建属于你的实例的EBS卷，进行网络设置安全组的配置。</p><h3 id="安装Kops和创建一个集群"><a href="#安装Kops和创建一个集群" class="headerlink" title="安装Kops和创建一个集群"></a>安装Kops和创建一个集群</h3><p>使用本教程，首先需要在AWS上</p><p>创建一个账户</p><p>，然后安装</p><p>AWS CLI</p><p>。同样你也可以安装kops在你自己的机器上。针对MacOS的用户，可以使用Homebrew：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew update &amp;&amp; brew install kops</span><br></pre></td></tr></table></figure><p>针对Linux用户：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://github.com/kubernetes/kops/releases/download/1.6.1/kops-linux-amd64</span><br><span class="line">$ chmod +x kops-linux-amd64</span><br><span class="line">$ mv kops-linux-amd64 /usr/local/bin/kops</span><br></pre></td></tr></table></figure><p>现在，我们将基于AWS Route53 DNS服务使用k8s来创建一个子域名。我使用的子域名是 kubernetes.mydomain.com，并且创建了一个主机区域：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ aws route53 create-hosted-zone --name kubernetes.mydomain.com --caller-reference 1</span><br></pre></td></tr></table></figure><p>这将返回关于主机区域的信息，包括域名服务器的DelegationSet.。我选择了.com作为顶级域名，并且输入我们的域名注册为NS记录。</p><p>我们同样需要创建一个S3存储，使kops可以为我们的集群存储配置信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ aws s3 mb s3://clusters.kubernetes.mydomain.com</span><br></pre></td></tr></table></figure><p>现在，如果你只控制一个集群，我们应该在你的当前shell环境或者你的bash设置中声明一个变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ export KOPS_STATE_STORE=s3://clusters.kubernetes.mydomain.com</span><br></pre></td></tr></table></figure><p>酷！我们已经准备好配置和运行集群：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kops create cluster --zones=us-west-2c us-west-2c.kubernetes.mydomain.com</span><br></pre></td></tr></table></figure><p>你也可以指定特殊的参数例如使用–network-cidr来设置子网参数，或者使用—vpc参数来设置你的AWS VPC。</p><h3 id="使Kops开始工作"><a href="#使Kops开始工作" class="headerlink" title="使Kops开始工作"></a>使Kops开始工作</h3><p>当一切都可以脚本化和自动化操作时，可以在不需要任何输入的情况下让Kops去执行这些任务。然而，如果你想去尝试自己做一些配置，通过”kops edit cluster $CLUSTER_NAME”命令，将会在你的电脑上打开Vim编辑器，允许你去编辑那些用于创建集群的.yml配置文件。同上，使用命令”kops edit ig –name=$CLUSTER_NAME”将会设置节点的分组，或者使用”using kops edit ig –name=$CLUSTER_NAME $ZONE”命令来设置主节点的分组。</p><p>你将会为现在的结果而感到高兴，因为现在不会使创建基础设施的费用超过你的预期，输入命令”kops update cluster”，并且使用参数–yes将会执行任务并且创建已经配置好的集群。再花费些时间将你的DNS记录指向其他的DNS服务器后，Route53将会响应请求的结果。当输入命令”kubectl get pods”后，可以看到你的k8s集群基础设施已经运行起来。当你看到没有找到任何资源时，你可以准备开始去创建deployments/replica sets。</p><p>任何人如果第一次去尝试在GCP或者AWS创建k8s集群时，可以去看看这个文章 “</p><p>Kubernetes the Hard Way</p><p>”，能够获得一些关于在云中创建k8s集群的准确方法。这将会使一个新手去学习k8s中基于DNS的服务依赖或者基于Etcd的K/V存储。到那时，小小的失望和一时兴起之后会产生更多的兴趣去理解k8s，你可能会发现去使用kops的话可以简化流程，并尝试使用pod，服务配置和其他应用程序问题，而不是操作问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于那些第一次接触Kubernetes（通常被称为k8s）并且想独自运行他们自己的第一个pods，services和deployments的人来说，通常存在很多的指南，例如可以使用Minikube在他们自己的电脑上设置和安装k8s。这也被认为是初次接触Kubernetes时
      
    
    </summary>
    
      <category term="Kubernetes" scheme="http://blog.ozairs.com/categories/Kubernetes/"/>
    
    
      <category term="Kops" scheme="http://blog.ozairs.com/tags/Kops/"/>
    
  </entry>
  
  <entry>
    <title>Docker ENTRYPOINT和CMD：Dockerfile最佳实践</title>
    <link href="http://blog.ozairs.com/Docker/Docker-ENTRYPOINT%E5%92%8CCMD%EF%BC%9ADockerfile%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>http://blog.ozairs.com/Docker/Docker-ENTRYPOINT和CMD：Dockerfile最佳实践/</id>
    <published>2019-04-09T23:18:05.000Z</published>
    <updated>2019-04-09T23:25:26.016Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/Docker/Docker-ENTRYPOINT和CMD：Dockerfile最佳实践/1*jllfM936gH4hVbdyjcFUZg.png" alt="img"><img src="https://cdn-images-1.medium.com/max/2000/1*jllfM936gH4hVbdyjcFUZg.png" alt="img"></p><p>本文重点介绍Docker的<code>CMD</code>和<code>ENTRYPOINT</code>命令，以及如何使用<a href="https://docs.docker.com/engine/reference/builder/#usage" target="_blank" rel="noopener">Dockerfiles</a>和Docker Compose文件来配置运行Docker容器。本教程将解释它们之间的差异以及如何在Dockerfiles中更好地使用他们。</p><ul><li><a href="https://medium.freecodecamp.org/docker-entrypoint-cmd-dockerfile-best-practices-abc591c30e21#6526" target="_blank" rel="noopener">Entrypoint</a></li><li><a href="https://medium.freecodecamp.org/docker-entrypoint-cmd-dockerfile-best-practices-abc591c30e21#a785" target="_blank" rel="noopener">CMD</a></li><li><a href="https://medium.freecodecamp.org/docker-entrypoint-cmd-dockerfile-best-practices-abc591c30e21#6b0b" target="_blank" rel="noopener">最佳实践</a></li><li><a href="https://medium.freecodecamp.org/docker-entrypoint-cmd-dockerfile-best-practices-abc591c30e21#3d7b" target="_blank" rel="noopener">摘要</a></li></ul><h3 id="Entrypoint"><a href="#Entrypoint" class="headerlink" title="Entrypoint"></a>Entrypoint</h3><p>Entrypoint设置在运行容器时将首先执行的命令和参数。</p><p>传递给的任何命令行参数<code>docker run &lt;image&gt;</code>都将附加到entrypoint命令，并将覆盖使用的所有指定元素<code>CMD</code>。例如，<code>docker run &lt;image&gt; bash</code>将命令参数添加<code>bash</code>到Entrypoint的末尾。</p><h4 id="Dockerfile-ENTRYPOINT"><a href="#Dockerfile-ENTRYPOINT" class="headerlink" title="Dockerfile ENTRYPOINT"></a>Dockerfile ENTRYPOINT</h4><p>Dockerfiles使用全部大写字母作为Entrypoint指令。有几种方法可以定义它。</p><h4 id="exec语法"><a href="#exec语法" class="headerlink" title="exec语法"></a>exec语法</h4><p>该<strong>高管</strong>的形式是，您所指定的命令和参数作为一个JSON数组。这意味着您需要使用双引号而不是单引号。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</span><br></pre></td></tr></table></figure><p>使用此语法，Docker将不使用命令shell，这意味着不会发生正常的shell处理。如果需要shell处理功能，则可以使用shell命令启动JSON数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENTRYPOINT [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]</span><br></pre></td></tr></table></figure><h4 id="使用Entrypoint脚本"><a href="#使用Entrypoint脚本" class="headerlink" title="使用Entrypoint脚本"></a>使用Entrypoint脚本</h4><p>另一种选择是使用脚本来运行容器的Entrypoint命令。按照惯例，它通常包含名称中的<strong>Entrypoint</strong>。在此脚本中，您可以设置应用程序以及加载任何配置和环境变量。下面是一个如何使用<code>ENTRYPOINT</code> <strong>exec</strong>语法在Dockerfile中运行它的示例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">COPY ./docker-entrypoint.sh /</span><br><span class="line">ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]</span><br><span class="line">CMD [&quot;postgres&quot;]</span><br></pre></td></tr></table></figure><p>例如，<a href="https://hub.docker.com/_/postgres/" target="_blank" rel="noopener">Postgres官方图像</a>使用以下脚本作为其<code>ENTRYPOINT</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">set -e</span><br><span class="line">if [ &quot;$1&quot; = &apos;postgres&apos; ]; then</span><br><span class="line">    chown -R postgres &quot;$PGDATA&quot;</span><br><span class="line">    if [ -z &quot;$(ls -A &quot;$PGDATA&quot;)&quot; ]; then</span><br><span class="line">        gosu postgres initdb</span><br><span class="line">    fi</span><br><span class="line">    exec gosu postgres &quot;$@&quot;</span><br><span class="line">fi</span><br><span class="line">exec &quot;$@&quot;</span><br></pre></td></tr></table></figure><h4 id="Docker撰写Entrypoint"><a href="#Docker撰写Entrypoint" class="headerlink" title="Docker撰写Entrypoint"></a>Docker撰写Entrypoint</h4><p>您在Docker Compose文件中使用的指令是相同的，除了您使用小写字母。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">entrypoint: /code/entrypoint.sh</span><br></pre></td></tr></table></figure><p>您还可以在docker-compose.yml中使用列表定义Entrypoint。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">entrypoint:</span><br><span class="line">    - php</span><br><span class="line">    - -d</span><br><span class="line">    - zend_extension=/usr/local/lib/php/xdebug.so</span><br><span class="line">    - -d</span><br><span class="line">    - memory_limit=-1</span><br><span class="line">    - vendor/bin/phpunit</span><br></pre></td></tr></table></figure><h4 id="覆盖Entrypoint"><a href="#覆盖Entrypoint" class="headerlink" title="覆盖Entrypoint"></a>覆盖Entrypoint</h4><p>您可以使用<code>docker run --entrypoint</code>或<code>docker-compose run --entrypoint</code>标记覆盖Entrypoint指令。</p><h3 id="CMD-命令"><a href="#CMD-命令" class="headerlink" title="CMD /命令"></a>CMD /命令</h3><p><code>CMD</code>（Dockerfiles）/ <code>command</code>（Docker Compose文件）的主要目的是在执行容器时提供默认值。这些将在Entrypoint之后执行。</p><p>例如，如果运行<code>docker run &lt;image&gt;</code>，则将执行Dockerfiles中<code>CMD</code>/ <code>command</code>中指定的命令和参数。</p><h4 id="Dockerfiles"><a href="#Dockerfiles" class="headerlink" title="Dockerfiles"></a>Dockerfiles</h4><p>在Dockerfiles中，您可以定义<code>CMD</code>包含可执行文件的默认值。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</span><br></pre></td></tr></table></figure><p>如果它们省略了可执行文件，则还必须指定一条<code>ENTRYPOINT</code>指令。</p><p><code>CMD [&quot;param1&quot;,&quot;param2&quot;]</code> （作为ENTRYPOINT的默认参数）</p><p><strong>注意</strong>：a中只能有一条<code>CMD</code>指令<code>Dockerfile</code>。如果列出多个<code>CMD</code>，则只有最后一个<code>CMD</code>生效。</p><h4 id="Docker-Compose命令"><a href="#Docker-Compose命令" class="headerlink" title="Docker Compose命令"></a>Docker Compose命令</h4><p>使用Docker Compose时，您可以在docker-compose.yml中定义相同的指令，但它以小写形式写成完整的单词<code>command</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">command: [&quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot;]</span><br></pre></td></tr></table></figure><h4 id="覆盖CMD"><a href="#覆盖CMD" class="headerlink" title="覆盖CMD"></a>覆盖CMD</h4><p>您可以覆盖<code>CMD</code>运行容器时指定的命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker运行rails_app rails console</span><br></pre></td></tr></table></figure><p>如果用户指定了参数<code>docker run</code>，那么它们将覆盖指定的默认值<code>CMD</code>。</p><h3 id="最佳做法"><a href="#最佳做法" class="headerlink" title="最佳做法"></a>最佳做法</h3><p>尽管使用这些指令有不同的方法，但Docker会就其使用和语法的<a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/" target="_blank" rel="noopener">最佳实践</a>提供一些指导。</p><h4 id="使用最佳做法"><a href="#使用最佳做法" class="headerlink" title="使用最佳做法"></a>使用最佳做法</h4><p><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#entrypoint" target="_blank" rel="noopener">Docker建议</a>使用<code>ENTRYPOINT</code>设置图像的主命令，然后使用<code>CMD</code>默认标志。这是一个使用这两个指令的示例Dockerfile。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]</span><br><span class="line">CMD [&quot;-c&quot;]</span><br></pre></td></tr></table></figure><h4 id="语法最佳实践"><a href="#语法最佳实践" class="headerlink" title="语法最佳实践"></a>语法最佳实践</h4><p>还有EXEC语法，泊坞窗允许shell语法两个另一个有效的选项<code>ENTRYPOINT</code>和<code>CMD</code>。这将以字符串形式执行此命令并执行变量替换。</p><ul><li><code>ENTRYPOINT command param1 param2</code></li><li><code>CMD command param1 param2</code></li></ul><p>但是，本教程没有强调它，因为<strong>exec</strong>语法被视为最佳实践。</p><blockquote><p><code>*CMD*</code>应该几乎总是以形式使用<code>*CMD [“executable”, “param1”, “param2”…]*</code>。因此，如果图像是用于服务的，例如Apache和Rails，那么你可以运行类似的东西<code>*CMD [&quot;apache2&quot;,&quot;-DFOREGROUND&quot;]*</code>。实际上，建议将这种形式的指令用于任何基于服务的图像。</p></blockquote><p>这个Dockerfile详细解释了一些问题。</p><blockquote><p>所述<code>*ENTRYPOINT*</code>壳形式防止任何<code>*CMD*</code>或<code>*run*</code>被使用命令行参数，但是具有你的缺点<code>*ENTRYPOINT*</code>将被开始作为一个子命令<code>*/bin/sh -c*</code>，其不通过信号。这意味着可执行文件不会是容器<code>*PID 1*</code>- 并且不会收到Unix信号 - 因此您的可执行文件将不会收到<code>*SIGTERM*</code>来自<code>*docker stop &lt;container&gt;*</code></p></blockquote><blockquote><p>如果<code>*CMD*</code>用于为<code>*ENTRYPOINT*</code>指令提供默认参数，则应使用JSON数组格式指定<code>*CMD*</code>和<code>*ENTRYPOINT*</code>指令。</p></blockquote><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在使用 <code>CMD</code>和<code>ENTRYPOINT</code>instructions指定运行容器时执行的命令。很少有规则描述它们如何相互作用。</p><ol><li>Dockerfiles应至少指定一个<code>CMD</code>或<code>ENTRYPOINT</code>命令。</li><li><code>ENTRYPOINT</code> 应该在将容器用作可执行文件时定义。</li><li><code>CMD</code>应该用作定义<code>ENTRYPOINT</code>命令的默认参数或在容器中执行ad-hoc命令的方法。</li><li><code>CMD</code> 在使用备用参数运行容器时将覆盖。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/Docker/Docker-ENTRYPOINT和CMD：Dockerfile最佳实践/1*jllfM936gH4hVbdyjcFUZg.png&quot; alt=&quot;img&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/
      
    
    </summary>
    
      <category term="Docker" scheme="http://blog.ozairs.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://blog.ozairs.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Git Workflow 工作指南</title>
    <link href="http://blog.ozairs.com/DevOps/Git-Workflow-%E5%B7%A5%E4%BD%9C%E6%8C%87%E5%8D%97/"/>
    <id>http://blog.ozairs.com/DevOps/Git-Workflow-工作指南/</id>
    <published>2019-04-06T12:01:52.000Z</published>
    <updated>2019-04-06T10:03:27.342Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分支策略"><a href="#分支策略" class="headerlink" title="分支策略"></a>分支策略</h3><ul><li>代码库的常设分支始终只有 master 和 develop，临时分支最后都删除。</li><li>临时分支合并到常用分支时，必须发起 Pull / Merge Requset ，并指定一个人 code review。</li><li>远程临时分支由发起者追踪和维护， reviewer 负责删除。</li><li>所有的开发和迭代尽量都在临时分支上。</li><li>开发记录、功能集成、测试历史由 develop 分支管理，正式发布记录由 master 分支管理。</li><li>发布和部署时，必须新建发布分支。（发布分支基于 develop 分支）</li><li>发布和部署完成后，必须将发布分支合并回 develop / master 分支，然后删除发布分支。</li><li>合并到 master 分支的代码必须打上 Tag。（Tag：版本号、描述、日期）</li></ul><h3 id="常用分支"><a href="#常用分支" class="headerlink" title="常用分支"></a>常用分支</h3><ul><li>master</li><li>develop</li></ul><h4 id="master-正式发布"><a href="#master-正式发布" class="headerlink" title="master: 正式发布"></a>master: 正式发布</h4><p>master 分支上存放的应该是随时可供在生产环境中部署的代码（Production Ready state）。当开发活动告一段落，产生了一份新的可供部署的代码时，master 分支上的代码会被更新。同时，每一次更新，需要添加对应的版本号标签（TAG）。</p><h4 id="develop-日常开发"><a href="#develop-日常开发" class="headerlink" title="develop: 日常开发"></a>develop: 日常开发</h4><p>develop 分支是保存当前最新开发成果的分支。通常这个分支上的代码也是可进行每日夜间发布的代码（Nightly build）。因此这个分支有时也可以被称作“integration branch”。</p><h4 id="临时分支"><a href="#临时分支" class="headerlink" title="临时分支"></a>临时分支</h4><ul><li>功能分支（feature）</li><li>发布分支（release）</li><li>修补分支（hotfix）</li></ul><h4 id="功能分支"><a href="#功能分支" class="headerlink" title="功能分支"></a>功能分支</h4><p>功能分支，开发新功能都从 develop 分支出来，从 develop 分支上面分出来的。开发完成后，要再并入 develop。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个功能分支：</span><br><span class="line">git checkout -b feature-x develop</span><br><span class="line"></span><br><span class="line"># 开发完成后，将功能分支合并到develop分支：</span><br><span class="line">git checkout develop</span><br><span class="line">git merge --no-ff feature-x</span><br><span class="line"></span><br><span class="line"># 删除feature 分支：</span><br><span class="line">git branch -d feature-x</span><br></pre></td></tr></table></figure><h5 id="发布分支"><a href="#发布分支" class="headerlink" title="发布分支"></a>发布分支</h5><p>发布分支，准备要 release 的版本，只修 bugs。从 develop 分支上面分出来，发布结束以后，必须合并进 develop 和 master 分支。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个发布分支：</span><br><span class="line">git checkout -b release-1.2 develop</span><br><span class="line"></span><br><span class="line"># 确认没有问题后，合并到master分支：</span><br><span class="line">git checkout master</span><br><span class="line">git merge --no-ff release-1.2</span><br><span class="line"></span><br><span class="line"># 对合并生成的新节点，做一个标签</span><br><span class="line">git tag -a 1.2</span><br><span class="line"></span><br><span class="line"># 再合并到develop分支：</span><br><span class="line">git checkout develop</span><br><span class="line">git merge --no-ff release-1.2</span><br><span class="line"></span><br><span class="line"># 最后，删除发布分支：</span><br><span class="line">git branch -d release-1.2</span><br></pre></td></tr></table></figure><h4 id="修补分支"><a href="#修补分支" class="headerlink" title="修补分支"></a>修补分支</h4><p>修补分支，是指等不及 release 版本就必须马上修 master 赶上线的情况。它是从 master 分支上面分出来的。修补结束以后， 再合并进 master 和 develop 分支。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个修补bug分支：</span><br><span class="line">git checkout -b hotfix-0.1 master</span><br><span class="line"></span><br><span class="line"># 修补结束后，合并到master分支：</span><br><span class="line">git checkout master</span><br><span class="line">git merge --no-ff hotfix-0.1</span><br><span class="line">git tag -a 0.1.1</span><br><span class="line"></span><br><span class="line"># 再合并到develop分支：</span><br><span class="line">git checkout develop</span><br><span class="line">git merge --no-ff hotfix-0.1</span><br><span class="line"></span><br><span class="line"># 最后，删除&quot;修补bug分支&quot;：</span><br><span class="line">git branch -d hotfix-0.1</span><br></pre></td></tr></table></figure><h3 id="Pull-Merge-Request"><a href="#Pull-Merge-Request" class="headerlink" title="Pull / Merge Request"></a>Pull / Merge Request</h3><p>代码合并到 master/develop 分支：</p><ol><li>将需要合并到 master / develop 的分支 push 到 gitlab。</li><li>进入工程 -&gt; merge request -&gt; create new merge request 。</li><li>选择源分支、目标分支，确定。</li><li>review 负责人进入 merge request，确认没有问题之后选择 Auto Merge（或者手动在本地合并之后再 push 到 gitlab），并关闭这个 merge request，完成。</li><li>如果发现问题那么在有问题的行下注释，并提醒 request 的发起人及时修改。</li><li>删除本地临时分支，本地 master / develop 更新到最新状态。</li></ol><h3 id="Code-Review"><a href="#Code-Review" class="headerlink" title="Code Review"></a>Code Review</h3><ul><li>提交 Pull / Merge Request 时， Commit 和 Message 要足够清晰详细。 切记，如果一次提交的内容包含很多 Commit，请不要使用自动生成的描述。 请用简短且足够说明问题的语言（理想是控制在3句话之内）来描述：</li></ul><blockquote><p>你改动了什么，解决了什么问题，需要代码审查的人留意那些影响比较大的改动。特别需要留意，如果对基础、公共的组件进行了改动，一定要另起一行特别说明。</p></blockquote><ul><li>审核人员邀请原则：项目参与人员 &amp; 团队同事 &amp; 团队 Leader。（对项目足够了解，对项目足够了解，对项目足够了解，重要的事情说三遍）；</li><li>评论中至少出现一个 lgtm 且保证代码评审通过之后 Pull / Merge Request 才可以被合并；（注：lgtm 即 looks good to me 的缩写）</li></ul><h3 id="Git-Command"><a href="#Git-Command" class="headerlink" title="Git Command"></a>Git Command</h3><h3 id="git-tag"><a href="#git-tag" class="headerlink" title="git tag"></a>git tag</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个带版本有描述的 tag</span><br><span class="line">git tag -a v0.1.0 -m &apos;commit&apos;</span><br><span class="line"># 覆盖该版本已有 v0.1.0 </span><br><span class="line">git tag -f v0.1.0 </span><br><span class="line"># 推送服务器</span><br><span class="line">git push origin --tags</span><br><span class="line"># 服务器已有 v0.1.0，强制推到服务器</span><br><span class="line">git push origin -f v0.1.0 </span><br><span class="line"># 服务器获取刚刚的 v0.1.0</span><br><span class="line">git fetch --tag</span><br><span class="line"># 删除本地版本</span><br><span class="line">git tag -d v0.1.0</span><br><span class="line"># 删除服务器上的tag</span><br><span class="line">git push origin :v0.1.0</span><br><span class="line">git merge</span><br><span class="line"></span><br><span class="line"># 不使用 fast-forward 方式合并，保留分支的 commit 历史</span><br><span class="line">git merge --no-ff develop</span><br><span class="line"># 使用 squash 方式合并，把多次分支commit历史压缩为一次</span><br><span class="line">git merge --squash develop</span><br><span class="line">git checkout</span><br><span class="line"></span><br><span class="line"># 放弃在 file.txt 的修改，恢复成未修改时的样子</span><br><span class="line">git checkout file.txt</span><br><span class="line"># 当前目录所有修改的文件，恢复成未修改时的样子</span><br><span class="line">git checkout .</span><br><span class="line"># 创建新的分支，并切换过去</span><br><span class="line">git checkout -b branchname</span><br><span class="line">git reset</span><br><span class="line"></span><br><span class="line"># 回退指定的 commit </span><br><span class="line">git reset 0c5602affd27d2224d151284bd1c6e033fd9023f</span><br><span class="line"># 回退上次修改</span><br><span class="line">git reset --hard</span><br><span class="line">git flow</span><br><span class="line"></span><br><span class="line"># git flow 初始化</span><br><span class="line">git flow init</span><br><span class="line"># 创建一个新的 feature 分支</span><br><span class="line">git flow feature start name</span><br><span class="line"># 将 feature 分支推送到远程仓库</span><br><span class="line">git flow feature publish name</span><br><span class="line"># 当特性开发完毕，需要将此分支合并到 develop 分支</span><br><span class="line">git flow feature finish name</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;分支策略&quot;&gt;&lt;a href=&quot;#分支策略&quot; class=&quot;headerlink&quot; title=&quot;分支策略&quot;&gt;&lt;/a&gt;分支策略&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;代码库的常设分支始终只有 master 和 develop，临时分支最后都删除。&lt;/li&gt;
&lt;li&gt;临时分支合并
      
    
    </summary>
    
      <category term="DevOps" scheme="http://blog.ozairs.com/categories/DevOps/"/>
    
    
      <category term="Git" scheme="http://blog.ozairs.com/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>接收了工作Offer之后可以拒绝吗？</title>
    <link href="http://blog.ozairs.com/%E8%AF%84%E8%AE%BA/%E6%8E%A5%E6%94%B6%E4%BA%86%E5%B7%A5%E4%BD%9COffer%E4%B9%8B%E5%90%8E%E5%8F%AF%E4%BB%A5%E6%8B%92%E7%BB%9D%E5%90%97%EF%BC%9F/"/>
    <id>http://blog.ozairs.com/评论/接收了工作Offer之后可以拒绝吗？/</id>
    <published>2019-04-05T23:15:44.000Z</published>
    <updated>2019-04-10T00:22:44.553Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/评论/接收了工作Offer之后可以拒绝吗？/1.jpg" alt=""></p><p>嗯，哦。那发生了吗？你把自己的心投入了工作 - 你让招聘经理着迷 - 你突破了面试过程，你获得了这个职位。当然你拿走了它！你努力工作以获得这份工作！在发生完全出乎意料的事情之前，一切都很美好，突然间你无法接受这份工作。</p><p>首先 - 不要压力。这事儿常常发生。请考虑以下方案：</p><ol><li>你从第一个选择中被拒绝了，但随后接到了招聘经理的电话，解释说他们选择的候选人已经不再可用，现在他们想要你。</li><li>你随机偶然发现了一份招聘广告，听起来比你刚刚提供的工作更好，你参加了他们的面试，但事实证明他们也想要你。</li><li>一场重大的生活事件发生了，你需要快速改变位置，或者只是改变职业方向。</li><li>您可以找到有关角色或公司的更多信息，而且您不再那么热衷了。也许你听说老板是可怕的奴隶主，或者公司的表现非常糟糕。</li><li>你有一个中年危机，任何时候的危机或意外的顿悟 - 你意识到这项工作不适合你。</li></ol><p>不管是什么原因，拒绝你已经接受的工作永远不会有趣。谁喜欢让人失望呢？但它不需要压力，甚至是一个大问题。当然，招聘经理可能会在一段时间内感到不安或不方便 - 但这与你被困在错误的工作中会如何影响你的生活相比毫无意义。</p><p>如果您知道自己无法通过，有办法拒绝提供，并希望仍然与雇主保持积极的关系。以下提示和示例信函将使您尽可能顺利地完成整个体验，甚至可能将其变为积极的。</p><p><strong>不要等待</strong> - 一旦你意识到你不再需要这份工作，就让雇主知道。你越早告诉他们，他们就能越早开始寻找你的替代品。如果你接受这份工作仅过了几天，你可能认为你不必费心，但这样做绝对是礼貌的，因为雇主已投入时间和金钱来帮助你。</p><p><strong>诚实但机智</strong> - 让雇主知道你改变主意的原因，但不要侮辱他们或公司。如果您认为自己不会与其他员工相处，那就简单地说您认为自己不符合<a href="https://www.thebalance.com/what-is-company-culture-2062000" target="_blank" rel="noopener">公司文化</a>。如果您找到了一份您更感兴趣的工作，请说明您获得的工作更符合您的<a href="https://www.thebalance.com/what-is-a-skill-set-2062103" target="_blank" rel="noopener">技能</a>。摆脱这种尴尬局面的最佳方式是确保您与<a href="https://www.roberthalf.com.au/blog/whats-one-piece-advice-youd-give-hiring-managers" target="_blank" rel="noopener">招聘经理的</a>所有互动都是礼貌的，所以不要对雇主或公司说任何负面的话。</p><p><strong>亲自或通过电话进行 -</strong>好的，所以亲自可能有点可怕，所以如果你对打电话更舒服，那很好。只是不要使用电子邮件或社交媒体来告知他们您的决定。表达你的决定，并表示遗憾，说明你有不便之处。提及您在公司或招聘过程中发现的一些积极因素也很有帮助，并提及您对这些因素的赞赏。你可以说拒绝工作是一个艰难的决定。最好不要和任何雇主过河拆桥， 你永远不知道你是否希望将来与他们合作。一旦你面对面或通过电话告诉他们，你可能想要用正式的信件（下面的模板）来跟进。</p><p><strong>了解您的底线</strong> - 招聘经理可能会尝试与您协商以让您留下来。在和他们沟通之前，确定你的底线是什么。你会留下更多的工资或某些福利吗？如果您决定不想谈判，如果他们开始引导那个方向的对话，请与雇主明确这一点。</p><p><strong>你能通过电子邮件拒绝工作机会吗？</strong> </p><p>是的，你可以，尽管大多数经理都会喜欢打个电话。对于招聘经理来说，面试过程很漫长。首先，他们需要做广告，然后将最佳候选人列入候选名单，然后进行多次面试，然后才有兴趣提供这份工作。如果您决定在接受工作后通过电子邮件拒绝工作机会，请使用以下示例：</p><p><strong>电子邮件样本</strong> </p><p>亲爱的琼斯女士，</p><p>非常感谢您为我提供Smith Industries的市场经理职位。很高兴与您交谈并了解您的公司。</p><p>不幸的是，在对这个职业机会进行了大量的思考之后，我认为拒绝你的优雅工作是符合我的最大利益和公司的利益。我最近决定接受另一个我认为更适合我的能力和技能的职位。</p><p>对于此决定可能造成的任何不便，我深感抱歉。我继续对史密斯工业的发展和市场地位留下深刻印象。</p><p>祝你未来的事业一切顺利。我希望在即将到来的6月营销会议上见到你。</p><p>亲切的问候，</p><p>你的名字</p><p><strong>如何在接受工作后通过电话拒绝工作机会</strong></p><p>在通过电话接受工作机会后拒绝工作可能是一项非常艰巨的经历，但事实并非如此。我们已经汇总了一个关于如何开始对话的脚本，以及招聘经理可能表达的任何问题或评论的答案：</p><p>嗨，达吉先生，</p><p>我只是想说谢谢你对我进行面试并告诉我公司的情况。这不是一个简单的对话，但是，我决定拒绝提供工作机会。</p><p><strong>达吉先生：</strong>但你已经接受了这个提议。这真的很令人失望。</p><p><strong>回应：</strong> 是的，我确实接受了这个提议，但我完全理解你的失望，但经过仔细考虑，我无法继续前进。我非常感谢你有机会，我希望你能为能够接受这份工作的人提供这个职位。</p><p><strong>达吉先生：</strong>你为什么要拒绝这份工作呢？</p><p><strong>回应:(</strong> 老实说，这始终是最好的方法。）我得到了另一份更合适的工作。再次感谢您考虑我的职位。如果我知道任何适合这个角色的人，我一定会把它们推荐给你。祝你好运。</p><p>最后但同样重要的是，你不应该对自己的决定感到不满。到目前为止，公司投资的金额与如果您在上岗和培训几周后就离开了，所投资金额相比微不足道。</p><p>积极思考，保持诚实。如果你有充分的理由，招聘经理可能会理解。尽力保持良好的条件，并在您的网络中保持便捷的联系。</p><p>【原文】</p><p>Uh-oh. So this happened? You had your heart set on a job – you charmed the hiring manager – you smashed the interview process, and you were offered the position. Of course you took it! You worked hard to get that job! Everything is rosy until something entirely unexpected happens and suddenly you are not in a position to take that job.</p><p>Firstly – don’t stress. This happens all the time. Consider the following scenarios:</p><ol><li><p>You were turned down from your first pick, but then received a phone call from the hiring manager, explaining that the candidate they chose was no longer available…and now they want you.</p></li><li><p>You randomly stumble across a job advertisement that sounds WAY better than the job you’ve just been offered…you interview with them for the hell of it, and it turns out they want you too.</p></li><li><p>A big life event happens and you either need to change location, or just career direction, fast.</p></li><li><p>You find out more about the role or the company and you’re not so keen anymore. Maybe you hear the boss is a slave-driver from hell, or the company is performing really poorly.</p></li><li><p>You have a mid-life crisis, an any-time crisis or an unexpected epiphany – and you realise that this job is just not right for you.</p></li></ol><p>Whatever the reason, turning down a job you’ve already accepted is never fun. Who likes letting people down? But it needn’t be stressful, or even a big deal. Sure, the hiring manager might be upset or inconvenienced for a short while – but that’s nothing compared to how you being stuck in the wrong job can impact your life.</p><p>If you know you can’t follow through, there are ways to turn down the offer and hopefully still maintain a positive relationship with the employer. The following tips and sample letter will allow you to make the whole experience as smooth as possible…and maybe even turn it into a positive.</p><p><strong>Don’t Wait</strong> – Let the employer know as soon as you realise you no longer want the job. The sooner you let them know, the sooner they can start looking for your replacement. If only a few days have passed since you accepted the job, you may think you needn’t bother, but it’s definitely common courtesy to do so, as the employer has already invested time and money into trying to help you.</p><p><strong>Be honest but tactful</strong> – Let the employer know why you changed your mind, but do so without insulting them, or the company. If you don’t think you’ll get along with the other employees, simply say you don’t think you would fit in with the <a href="https://www.thebalance.com/what-is-company-culture-2062000" target="_blank" rel="noopener">company culture</a>. If you found a job that you are much more interested in, explain that you were offered a job that is more in line with your <a href="https://www.thebalance.com/what-is-a-skill-set-2062103" target="_blank" rel="noopener">skill set</a>. The best way to come out of an awkward situation like this is to make sure all your interactions with the <a href="https://www.roberthalf.com.au/blog/whats-one-piece-advice-youd-give-hiring-managers" target="_blank" rel="noopener">hiring manager</a> are polite, so don’t say anything negative about the employer or the company.</p><p><strong>Do it in person or over the phone –</strong> Ok, so in person can be kinda scary, so if you’re more comfortable with a phone call, that’s fine. Just don’t use email or social media to inform them of your decision. Own your decision and express your regret that you have inconvenienced them. It’s also helpful to mention some of the positive factors you noticed in the company or during the recruitment process, and mention your appreciation for those. Explain that turning down the job was a tough decision. It’s best not to burn bridges with any employer – you never know if you might want to work with them in the future. Once you’ve told them face to face or over the phone, you may want to follow this up with a formal letter (template below).</p><p><strong>Know your bottom line</strong> – The hiring manager may try to negotiate with you to get you to stay. Before approaching them, decide what your bottom line is. Would you stay for more pay or certain benefits? If you decide you do not want to negotiate, be clear about this with the employer if they start to steer the conversation in that direction.</p><p><strong>Can you reject a job offer by email?</strong> </p><p>Yes, you can, although most managers would appreciate a phone call. The interview process is a lengthy one for hiring managers. First, they need to advertise, then shortlist the best candidates, followed by multiple interviews, before they have the pleasure to offer the job. If you do decide to turn down a job offer by email after you have accepted it, here is a sample to use:</p><p><strong>Sample email</strong> </p><p>Dear Ms Jones,</p><p>Thank you so much for offering me the position of Marketing Manager at Smith Industries. It has been a pleasure speaking with you and learning more about your company.</p><p>Unfortunately, after giving a great deal of thought to this career opportunity, I have decided that it is in my best interest, as well as the company’s, to turn down your gracious job offer. I have recently decided to accept another position that I believe is a better fit for my abilities and skill set.</p><p>I am truly sorry for any inconvenience this decision may cause. I continue to be impressed with Smith Industries growth and standing in the marketplace.</p><p>I wish you all the best in your future endeavors. I hope to see you at the upcoming Marketing conference in June.</p><p>Kind regards,</p><p>Your name</p><p><strong>How to reject a job offer over the phone after you have accepted the job</strong></p><p>Turning down a job offer after you have accepted it over the phone can be a massively daunting experience, but it doesn’t have to be. We have put together a script of how you should start the conversation, as well as answers to any questions or remarks the hiring manager might express:</p><p>Hi Mr. Dargie,</p><p>I just wanted to say thank you for the time you spent interviewing me and telling me about the company. This isn’t an easy conversation to have, but, I have decided to turn down the job offer.</p><p><strong>Mr. Dargie:</strong> But you have already accepted the offer. This is really disappointing.</p><p><strong>Response:</strong> Yes, I did accept the offer, and I completely understand your disappointment, however, after careful consideration I cannot move forward in the position. I am very grateful to you for the opportunity and I hope you can offer the position to someone in a better position to accept the job.</p><p><strong>Mr. Dargie:</strong> Why are you turning it down?</p><p><strong>Response:</strong> (Just be honest here, it is always the best approach.) I have been offered another job that is more suitable. Once again, thank you for considering me for the position. If I know of anyone suitable for the role, I will be sure to refer them to you. Best of luck.</p><p>Last but not least, you shouldn’t feel bad about your decision. The amount of money the company has invested in you so far is insignificant compared to the amount of money it would have invested, had you left after a few weeks of induction and training.</p><p>Think positive and stay honest. If you have a good reason, the hiring manager is likely to understand. Do your best to leave on good terms and keep a handy contact in your network.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/评论/接收了工作Offer之后可以拒绝吗？/1.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;嗯，哦。那发生了吗？你把自己的心投入了工作 - 你让招聘经理着迷 - 你突破了面试过程，你获得了这个职位。当然你拿走了它！你努力工作以获得这份工作！在发生完全出乎意
      
    
    </summary>
    
      <category term="评论" scheme="http://blog.ozairs.com/categories/%E8%AF%84%E8%AE%BA/"/>
    
    
      <category term="Job" scheme="http://blog.ozairs.com/tags/Job/"/>
    
  </entry>
  
  <entry>
    <title>主流CI/CD工具比较：Jenkins vs Bamboo vs Teamcity</title>
    <link href="http://blog.ozairs.com/Jenkins/%E4%B8%BB%E6%B5%81CI-CD%E5%B7%A5%E5%85%B7%E6%AF%94%E8%BE%83%EF%BC%9AJenkins-vs-Bamboo-vsTeamcity/"/>
    <id>http://blog.ozairs.com/Jenkins/主流CI-CD工具比较：Jenkins-vs-Bamboo-vsTeamcity/</id>
    <published>2019-04-01T02:29:11.000Z</published>
    <updated>2019-04-05T23:32:06.749Z</updated>
    
    <content type="html"><![CDATA[<p>你有没有看过1924年的奥运世界纪录？我知道你在这里可以获得一个很好的CI / CD工具，但请听我说。</p><p>如果将1924年的记录与2016年的记录进行比较，那些奥林匹克运动员甚至不会成为他们的国家队。这就是今天运动员的表现更好，更快，更强。</p><p>1924年夏季奥运会男子100米短跑结果</p><p><img src="/Jenkins/主流CI-CD工具比较：Jenkins-vs-Bamboo-vsTeamcity/1.png" alt="img"></p><p>2016年美国奥运选拔赛男子100米春季成绩。</p><p>大多数这种改进是更好的表现技巧和练习方案的结果。这是我们回到CI / CD的地方：部署软件的旧方式就像1924年试图在21世纪竞争的奥运选手。没有成功的机会。你会被留在尘土中。</p><p><a href="https://stackify.com/continuous-delivery-vs-continuous-deployment-vs-continuous-integration/" target="_blank" rel="noopener">持续集成和持续交付</a>是当今软件部署的最佳实践。<strong>这些技术可帮助您更快地部署更好的软件，减少错误并提供更快的反馈循环。</strong>这对公司，客户和开发人员来说是一个双赢的局面。所需要的只是一套工具来实现它。</p><p>我们将看看今天市场上的3种顶级CI / CD工具：Jenkins，TeamCity和Bamboo。在本文结束时，您应该有信心为您的团队选择一个工具。如果您已经使用其中一种工具并希望进行更改，那么本文将为您提供做出正确决策所需的洞察力。</p><p>在我们进入下降之前，让我们简要介绍一下每个工具的基础知识。</p><h3 id="Jenkins是什么？"><a href="#Jenkins是什么？" class="headerlink" title="Jenkins是什么？"></a>Jenkins是什么？</h3><p><a href="https://jenkins.io/" target="_blank" rel="noopener">Jenkins</a>是当今市场上最受欢迎的开源CI / CD工具。Jenkins允许开发人员在将代码提交到源存储库后自动构建，集成和测试代码。这使开发人员能够快速捕获错误并最终部署得更快。</p><p>最初创建的是用于Java应用程序的构建自动化工具，它已经发展成为具有1400多个其他软件工具插件的多方面平台。据<a href="https://www.infoworld.com/article/3239666/devops/what-is-jenkins-the-ci-server-explained.html" target="_blank" rel="noopener">InfoWorld称</a>，这些插件将Jenkins扩展到五个领域：平台，UI管理，源代码管理和构建管理。</p><h3 id="什么是Bamboo？"><a href="#什么是Bamboo？" class="headerlink" title="什么是Bamboo？"></a>什么是Bamboo？</h3><p><a href="https://www.atlassian.com/software/bamboo" target="_blank" rel="noopener">Bamboo</a>是<a href="https://www.atlassian.com/" target="_blank" rel="noopener">Atlassian</a>的CI / CD服务器。与其他CI / CD服务器一样，Bamboo允许开发人员自动构建，集成和测试源代码，然后准备应用程序以进行部署。Bamboo还可以与Atlassian的其他工具（如Jira（项目管理）和Hipchat（团队沟通））无缝协作。</p><h3 id="什么是TeamCity？"><a href="#什么是TeamCity？" class="headerlink" title="什么是TeamCity？"></a>什么是TeamCity？</h3><p><a href="https://www.jetbrains.com/teamcity/" target="_blank" rel="noopener">TeamCity</a>是另一个商业CI / CD服务器，这次来自<a href="https://www.jetbrains.com/" target="_blank" rel="noopener">JetBrains</a>公司。它以其极其简单的设置和漂亮的用户界面而闻名。它具有开箱即用的强大功能和不断增长的插件生态系统。</p><h3 id="CI-CD工具Throwdown"><a href="#CI-CD工具Throwdown" class="headerlink" title="CI / CD工具Throwdown"></a>CI / CD工具Throwdown</h3><p>女士们，先生们，为主要景点做好准备。现在是时候让这些CI / CD工具发出隆隆声了！我们将查看CI / CD最重要的属性，并了解这些工具如何叠加。到本节结束时，您将确切知道哪种CI / CD工具适合您。</p><p>在我们看看这些工具的不同之处之前，重要的是要指出它们是如何相似的。</p><p>Jenkins，TeamCity和Bamboo都是持续集成，自动构建，自动化测试和持续交付的绝佳工具。虽然工具之间的集成数量不同，但它们都提供了进一步扩展其功能的集成。这三者也提供了很好的支持和文档，但同样在深度和质量上也存在差异。</p><p>简而言之，我们比较这些工具的原因是它们是商业中最好的。</p><p>好的，足够的细节。让我们隆隆声！</p><h3 id=""><a href="#" class="headerlink" title=""></a><img src="/Jenkins/主流CI-CD工具比较：Jenkins-vs-Bamboo-vsTeamcity/2.png" alt="CI / CD表的功能和优点"></h3><h3 id="开源与商业"><a href="#开源与商业" class="headerlink" title="开源与商业"></a>开源与商业</h3><p>Jenkins是一个由世界各地的开发人员支持的开源项目。Bamboo和TeamCity都是由其母公司开发和维护的商业工具。用户最大的不同之处在于Jenkins周围的社区规模与其他两个工具相比。</p><h3 id="易于设置和使用"><a href="#易于设置和使用" class="headerlink" title="易于设置和使用"></a>易于设置和使用</h3><p>TeamCity可以轻松设置和使用。它以其开箱即用的可用性而闻名，尤其是其安全的默认配置。它还拥有华丽的用户界面，使CI新手更容易陷入困境。Bamboo具有可比性且易于使用，但用户界面并不是那么漂亮，而<a href="https://www.g2crowd.com/compare/bamboo-vs-teamcity" target="_blank" rel="noopener">G2 Crowd</a>将TeamCity列为高于Bamboo的“易于安装”。</p><p>Jenkins在这一类别中没有TeamCity和Bamboo。Jenkins的UI是一个更古老的学校，但新的Blue Ocean界面是一个重大升级。尽管如此，开源软件本身具有较低的可用性和易于设置。</p><h3 id="开箱即用的功能"><a href="#开箱即用的功能" class="headerlink" title="开箱即用的功能"></a>开箱即用的功能</h3><p>TeamCity的自带<a href="https://www.jetbrains.com/teamcity/features/" target="_blank" rel="noopener">堆叠</a>开箱，具有优良的建设历史，源头控制，建立连锁的工具。Bamboo具有较少的开箱即用功能，但与Atlassian的其他工具堆本身集成。这使Bamboo感觉功能更丰富，而不具备自身功能。Jenkins是三者中功能最稀疏的工具，但它可以通过庞大的插件生态系统弥补它，我们将在下面讨论。</p><h3 id="集成和插件"><a href="#集成和插件" class="headerlink" title="集成和插件"></a>集成和插件</h3><p>在集成和插件方面，竞争甚至不是很接近。Jenkins拥有庞大的插件生态系统，可实现前所未有的自定义和可扩展性。Bamboo和TeamCity正在慢慢增长他们的生态系统，但按照这个速度，他们可能永远不会赶上。</p><h3 id="支持"><a href="#支持" class="headerlink" title="支持"></a>支持</h3><p>作为一个开源项目，Jenkins拥有一个庞大而有用的贡献者社区，可以为彼此提供支持。因此，Jenkins拥有大量文档，但您只需自己梳理文档即可学习或解决问题。另一方面，Bamboo和TeamCity提供其母公司以及不断增长的用户社区的专业支持。Bamboo和TeamCity用户可以找到来自企业的实际支持以及来自社区的众包支持。</p><h3 id="在云上运行？"><a href="#在云上运行？" class="headerlink" title="在云上运行？"></a>在云上运行？</h3><p>许多中小型软件团队专门在云基础架构上运行。因此，当Atlassian停止使用Bamboo云时，一些<a href="https://community.atlassian.com/t5/Questions/Bamboo-Cloud-end-of-life/qaq-p/450934" target="_blank" rel="noopener">Bamboo用户</a>感到困惑，迫使团队在内部运行它。他们用<a href="https://bitbucket.org/product/features/pipelines" target="_blank" rel="noopener">BitBucket Pipelines</a>取代了这项服务，但很多人认为它不是一个完美的替代品。Jenkins和TeamCity仍可在云服务器上运行。</p><h3 id="价钱"><a href="#价钱" class="headerlink" title="价钱"></a>价钱</h3><p>作为开源软件，Jenkins完全免费使用，无论您的规模如何。TeamCity提供了一个相当实用的免费版本，可为您提供100个构建配置和无限构建。之后，定价从每年299美元起。</p><p>Bamboo是最昂贵的工具。它的起价仅为10美元，但这个价格的体验非常有限。对于整个体验，您必须为一个远程代理一次性支付880美元的<a href="https://www.atlassian.com/licensing/bamboo" target="_blank" rel="noopener">Bamboo</a>费用。</p><h2 id="哪种CI-CD工具最适合您？"><a href="#哪种CI-CD工具最适合您？" class="headerlink" title="哪种CI / CD工具最适合您？"></a>哪种CI / CD工具最适合您？</h2><p>显然，这次失败的赢家是一个折腾。要选择正确的CI / CD工具，您需要仔细查看预算，内部资源以及学习和设置所需的时间。如果你有DIY的态度并想要最大的功能，那么Jenkins可能就是你的工具。如果您更喜欢更简单的用户体验以及与现有技术堆栈集成的工具，请查看Bamboo。为了获得漂亮的界面和出色的开箱即用功能，TeamCity是您的最佳选择。</p><p>请记住，您的CI / CD工具只是赢得软件开发竞赛所需的工具之一。<a href="https://stackify.com/software-deployment-tools/" target="_blank" rel="noopener">部署</a>和<a href="https://stackify.com/application-performance-management-tools/" target="_blank" rel="noopener">应用程序监视</a>是敏捷开发的同等重要元素。永远不要满足你的过程; 不断探索升级技术和实践的方法。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;你有没有看过1924年的奥运世界纪录？我知道你在这里可以获得一个很好的CI / CD工具，但请听我说。&lt;/p&gt;
&lt;p&gt;如果将1924年的记录与2016年的记录进行比较，那些奥林匹克运动员甚至不会成为他们的国家队。这就是今天运动员的表现更好，更快，更强。&lt;/p&gt;
&lt;p&gt;192
      
    
    </summary>
    
      <category term="Jenkins" scheme="http://blog.ozairs.com/categories/Jenkins/"/>
    
    
      <category term="CI" scheme="http://blog.ozairs.com/tags/CI/"/>
    
  </entry>
  
  <entry>
    <title>Terraform简介</title>
    <link href="http://blog.ozairs.com/Terraform/Terraform%E7%AE%80%E4%BB%8B/"/>
    <id>http://blog.ozairs.com/Terraform/Terraform简介/</id>
    <published>2019-03-30T05:24:43.000Z</published>
    <updated>2019-03-30T06:36:19.919Z</updated>
    
    <content type="html"><![CDATA[<p>这是<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca#.b6sun4nkn" target="_blank" rel="noopener">Terraform</a>系列<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca#.b6sun4nkn" target="_blank" rel="noopener">综合指南的</a>第2部分。在第1部分中，我们解释了<a href="https://blog.gruntwork.io/why-we-use-terraform-and-not-chef-puppet-ansible-saltstack-or-cloudformation-7989dad2865c#.63ls7fpkq" target="_blank" rel="noopener">为什么我们选择Terraform作为我们选择的IAC工具而不是Chef，Puppet，Ansible，SaltStack或CloudFormation</a>。在这篇文章中，我们将介绍如何使用Terraform定义和管理基础架构的基础知识。</p><p>该<a href="https://www.terraform.io/intro/getting-started/install.html" target="_blank" rel="noopener">官员Terraform入门文档</a>不会引入Terraform的各个要素（即资源，输入变量，输出变量等）的一个很好的工作，所以在本指南中，我们将重点放在如何把这些元素结合在一起创建一个相当现实的例子。特别是，我们将在集群中的AWS上配置多个服务器，并部署负载均衡器以在该集群中分配负载。您将在此示例中创建的基础结构是运行可扩展，高可用性Web服务和微服务的基本起点。</p><p>本指南面向AWS和Terraform新手，所以如果您以前没有使用过任何一个，请不要担心。我们将逐步指导您完成整个过程：</p><ol><li>设置您的AWS账户</li><li>安装Terraform</li><li>部署单个服务器</li><li>部署单个Web服务器</li><li>部署Web服务器集群</li><li>部署负载均衡器</li><li>清理</li></ol><p>您可以在以下<a href="https://github.com/gruntwork-io/intro-to-terraform" target="_blank" rel="noopener">网址</a>找到以下示例的完整示例代码：<a href="https://github.com/gruntwork-io/intro-to-terraform" target="_blank" rel="noopener">https</a>：<a href="https://github.com/gruntwork-io/intro-to-terraform" target="_blank" rel="noopener">//github.com/gruntwork-io/intro-to-terraform</a>。请注意，所有代码示例都是为Terraform 0.7.x编写的。</p><h3 id="设置您的AWS账户"><a href="#设置您的AWS账户" class="headerlink" title="设置您的AWS账户"></a>设置您的AWS账户</h3><p>Terraform可以为许多不同类型的云提供商提供基础架构，包括AWS，Azure，Google Cloud，DigitalOcean <a href="https://www.terraform.io/docs/providers/index.html" target="_blank" rel="noopener">等等</a>。在本教程中，我们选择了<a href="https://aws.amazon.com/" target="_blank" rel="noopener">Amazon Web Services（AWS），</a>因为：</p><ul><li>它提供了大量可靠且可扩展的云托管服务，包括<a href="https://aws.amazon.com/ec2/" target="_blank" rel="noopener">弹性计算云（EC2）</a>，<a href="https://aws.amazon.com/autoscaling/" target="_blank" rel="noopener">Auto Scaling组（ASG）</a>和<a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank" rel="noopener">Elastic Load Balancing（ELB）</a>。如果您发现AWS术语令人困惑，请务必以<a href="https://www.expeditedssl.com/aws-in-plain-english" target="_blank" rel="noopener">简明英语</a>查看<a href="https://www.expeditedssl.com/aws-in-plain-english" target="_blank" rel="noopener">AWS</a>。</li><li>到目前为止，AWS是<a href="https://www.srgresearch.com/articles/aws-remains-dominant-despite-microsoft-and-google-growth-surges" target="_blank" rel="noopener">最受欢迎的云基础架构提供商</a>。</li><li>AWS提供了一个丰富的<a href="https://aws.amazon.com/free/" target="_blank" rel="noopener">免费套餐</a>，允许您<a href="https://aws.amazon.com/free/" target="_blank" rel="noopener">免费</a>运行所有这些示例。</li></ul><p>首次注册AWS时，您最初以<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html" target="_blank" rel="noopener">root用户</a>身份登录。此用户帐户具有对所有内容的访问权限，因此从安全角度来看，我们建议<em>仅</em>使用它来创建权限更有限的其他用户帐户（请参阅<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html" target="_blank" rel="noopener">IAM最佳实践</a>）。要创建更有限的用户帐户，请转到<a href="https://console.aws.amazon.com/iam/home?region=us-east-1#home" target="_blank" rel="noopener">身份和访问管理（IAM）控制台</a>，单击“用户”，然后单击蓝色的“创建新用户”按钮。输入用户的名称，并确保选中“为每个用户生成访问密钥”：</p><p><img src="/Terraform/Terraform简介/1.png" alt="img"></p><p>单击“创建”按钮，您将能够看到该用户的安全凭证，其中包括访问密钥ID和秘密访问密钥。你必须立即保存这些，因为它们永远不会再显示。我们建议将它们存储在安全的地方（例如密钥管理器，如Keychain或1Password），这样您可以在本教程中稍后使用它们。</p><p><img src="/Terraform/Terraform简介/2.png" alt="img"></p><p>将凭据保存在安全的地方。切勿与任何人分享。别担心，上面截图中的内容是假的。</p><p>保存凭据后，单击“关闭”（两次），您将进入用户列表。单击刚刚创建的用户，然后选择“权限”选项卡。默认情况下，新的IAM用户无权在AWS账户中执行任何操作。为了能够将Terraform用于本教程中的示例，请添加AmazonEC2FullAccess权限（<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html" target="_blank" rel="noopener">在此处</a>了解有关<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html" target="_blank" rel="noopener">托管IAM策略的</a>更多信息）：</p><p><img src="/Terraform/Terraform简介/3.png" alt="img"></p><h3 id="安装Terraform"><a href="#安装Terraform" class="headerlink" title="安装Terraform"></a>安装Terraform</h3><p>按照<a href="https://www.terraform.io/intro/getting-started/install.html" target="_blank" rel="noopener">此处</a>的<a href="https://www.terraform.io/intro/getting-started/install.html" target="_blank" rel="noopener">说明</a>安装Terraform。完成后，您应该能够运行terraform命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform </span><br><span class="line">用法：terraform [--version] [ -  help] &lt;command&gt; [args]</span><br><span class="line">（......）</span><br></pre></td></tr></table></figure><p>为了使Terraform能够在您的AWS账户中进行更改，您需要为之前创建的用户设置AWS凭证作为环境变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">导出AWS_ACCESS_KEY_ID =（您的访问密钥ID）</span><br><span class="line">导出AWS_SECRET_ACCESS_KEY =（您的密钥访问密钥）</span><br></pre></td></tr></table></figure><h3 id="部署单个服务器"><a href="#部署单个服务器" class="headerlink" title="部署单个服务器"></a>部署单个服务器</h3><p>Terraform代码使用扩展名为“.tf”的文件中名为<a href="https://www.terraform.io/docs/configuration/syntax.html" target="_blank" rel="noopener">HCL</a>的语言编写。它是一种声明性语言，因此您的目标是描述您想要的基础架构，Terraform将弄清楚如何创建它。Terraform可以在各种平台上创建基础架构，或称为<a href="https://www.terraform.io/docs/providers/" target="_blank" rel="noopener">提供商</a>，包括AWS，Azure，Google Cloud，DigitalOcean和许多其他平台。使用Terraform的第一步通常是配置您要使用的提供程序。创建一个名为“main.tf”的文件并将以下代码放入其中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">提供者“aws”&#123; </span><br><span class="line">  region =“us-east-1” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这告诉Terraform您将使用<a href="https://www.terraform.io/docs/providers/aws/" target="_blank" rel="noopener">AWS提供商</a>并希望在“us-east-1”区域部署您的基础架构（AWS在全球范围内拥有数据中心，分为<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html" target="_blank" rel="noopener">区域和可用区域</a>，以及我们-east-1是美国弗吉尼亚州数据中心的名称。您可以为<a href="https://www.terraform.io/docs/providers/aws/index.html" target="_blank" rel="noopener">AWS提供程序</a>配置其他设置，但是对于此示例，由于您已将凭据配置为环境变量，因此您只需指定该区域。</p><p>对于每个提供程序，您可以创建许多不同类型的“资源”，例如服务器，数据库和负载平衡器。在我们部署整个服务器集群之前，让我们首先弄清楚如何部署一个运行简单“Hello，World”Web服务器的服务器。在AWS lingo中，服务器称为“EC2实例”。要部署EC2实例，请将以下代码添加到main.tf：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_instance”“example”&#123; </span><br><span class="line">  ami =“ami-2d39803a” </span><br><span class="line">  instance_type =“t2.micro” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个资源指定一个类型（在本例中为“aws_instance”），一个名称（在本例中为“example”）用作Terraform代码中的标识符，以及一组特定于该资源的配置参数。该<a href="https://www.terraform.io/docs/providers/aws/r/instance.html" target="_blank" rel="noopener">aws_instance资源文件</a>列出了它所支持的所有参数。最初，您只需要设置以下内容：</p><ul><li><strong>ami</strong>：要在EC2实例上运行的<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html" target="_blank" rel="noopener">Amazon Machine Image</a>。上面的示例将此参数设置为us-east-1中<a href="https://aws.amazon.com/marketplace/pp/B00JV9TBA6?ref=cns_srchrow" target="_blank" rel="noopener">Ubuntu 14.04 AMI</a>的ID 。</li><li><strong>instance_type</strong>：要运行的EC2实例的类型。每个<a href="https://aws.amazon.com/ec2/instance-types/" target="_blank" rel="noopener">EC2实例类型</a>具有不同的CPU，内存，磁盘空间和网络规格。上面的示例使用“t2.micro”，它具有1个虚拟CPU，1GB内存，并且是AWS免费层的一部分。</li></ul><p>在终端中，进入创建main.tf的文件夹，然后运行“terraform plan”命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform计划</span><br><span class="line">在计划之前刷新Terraform内存状态...</span><br><span class="line">（......）</span><br><span class="line">+ aws_instance.example </span><br><span class="line">    ami：“ami-2d39803a” </span><br><span class="line">    availability_zone：“&lt;computed&gt;” </span><br><span class="line">    ebs_block_device。＃：“&lt;computed&gt;” </span><br><span class="line">    ephemeral_block_device。＃：“&lt;computed&gt;” </span><br><span class="line">    instance_state：“&lt;computed&gt;” </span><br><span class="line">    instance_type：“t2.micro” </span><br><span class="line">    key_name：“&lt;computed&gt;” </span><br><span class="line">    network_interface_id：“&lt;computed&gt;” </span><br><span class="line">    placement_group：“&lt;computed&gt;” </span><br><span class="line">    private_dns：“&lt;computed&gt;” </span><br><span class="line">    private_ip：“&lt;computed&gt;” </span><br><span class="line">    public_dns：“&lt;computed&gt;”</span><br><span class="line">    public_ip：“&lt;computed&gt;” </span><br><span class="line">    root_block_device。＃：“&lt;computed&gt;” </span><br><span class="line">    security_groups。＃：“&lt;computed&gt;”</span><br><span class="line">    source_dest_check：“true” </span><br><span class="line">    subnet_id：“&lt;computed&gt;” </span><br><span class="line">    租期：“&lt;computed&gt;” </span><br><span class="line">    vpc_security_group_ids。＃：“&lt;计算&gt;”</span><br><span class="line">计划：1添加，0改变，0破坏。</span><br></pre></td></tr></table></figure><p>plan命令可让您在实际执行之前查看Terraform将执行的操作。这是一种很好的方法，可以在将更改释放到世界之前检查您的更改。plan命令的输出有点像diff命令的输出：将创建带有加号（+）的资源，带有减号（ - ）的资源将被删除，带有波浪号的资源将被删除符号（〜）将被修改。在上面的输出中，您可以看到Terraform正计划创建单个EC2实例，而不是其他任何内容，这正是我们想要的。</p><p>要实际创建实例，请运行“terraform apply”命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform apply </span><br><span class="line">aws_instance.example：Creating ... </span><br><span class="line">  ami：“”=&gt;“ami-2d39803a” </span><br><span class="line">  availability_zone：“”=&gt;“&lt;computed&gt;” </span><br><span class="line">  ebs_block_device。＃：“”=&gt;“&lt;computed&gt;” </span><br><span class="line">  ephemeral_block_device。＃： “”=&gt;“&lt;计算&gt;”“ </span><br><span class="line">  instance_state：”“=&gt;”&lt;计算&gt;“ </span><br><span class="line">  instance_type：”“=&gt;”t2.micro“ </span><br><span class="line">  key_name：”“=&gt;”&lt;计算&gt;“ </span><br><span class="line">  network_interface_id：”“=&gt;”&lt; computed&gt;“ </span><br><span class="line">  placement_group：”“=&gt;”&lt;computed&gt;“ </span><br><span class="line">  private_dns：“”=&gt;“&lt;计算&gt;” </span><br><span class="line">  private_ip：“”=&gt;“&lt;计算&gt;”“ </span><br><span class="line">  public_dns：”“=&gt;”&lt;计算&gt;“ </span><br><span class="line">  public_ip：”“=&gt;”&lt;计算&gt;“</span><br><span class="line">  root_block_device。＃：“”=&gt;“&lt;计算&gt;”“ </span><br><span class="line">  security_groups。＃：”“=&gt;”&lt;计算&gt;“ </span><br><span class="line">  source_dest_check：”“=&gt;”true“ </span><br><span class="line">  subnet_id：”“=&gt;”&lt;计算&gt;“ </span><br><span class="line">  租期：”“ &gt;&gt; &lt;计算&gt;“ </span><br><span class="line">  vpc_security_group_ids。＃：”“=&gt;”&lt;计算&gt;“ </span><br><span class="line">aws_instance.example：仍在创建...（已过去10秒）</span><br><span class="line">aws_instance.example：仍在创建...（已过20秒）</span><br><span class="line">aws_instance.example：创作完成</span><br><span class="line">申请完成！资源：1添加，0更改，0销毁。</span><br></pre></td></tr></table></figure><p>恭喜，您刚刚部署了Terraform服务器！要验证这一点，您可以登录<a href="https://console.aws.amazon.com/ec2/v2/home" target="_blank" rel="noopener">EC2控制台</a>，您将看到如下内容：</p><p><img src="/Terraform/Terraform简介/4.png" alt="img"></p><p>这是有效的，但这不是最激动人心的例子。首先，Instance没有名称。要添加一个，您可以向EC2实例添加<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html" target="_blank" rel="noopener">标记</a>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_instance”“example”&#123; </span><br><span class="line">  ami =“ami-2d39803a” </span><br><span class="line">  instance_type =“t2.micro”</span><br><span class="line">  标签&#123; </span><br><span class="line">    Name =“terraform-example” </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再次运行计划命令以查看这将执行的操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform计划</span><br><span class="line">aws_instance.example：刷新状态...（ID：i-6a7c545b）</span><br><span class="line">（......）</span><br><span class="line">~aws_instance.example </span><br><span class="line">    tags。％：“0”=&gt;“1” </span><br><span class="line">    tags.Name：“”=&gt;“terraform-example”</span><br><span class="line">计划：0添加，1更改，0销毁。</span><br></pre></td></tr></table></figure><p>Terraform会跟踪它为这组模板创建的所有资源，因此它知道您的EC2实例已经存在（注意Terraform在运行计划命令时如何说“刷新状态…”），它可以显示两者之间的差异当前部署的内容以及Terraform代码中的内容（这是使用<a href="https://blog.gruntwork.io/why-we-use-terraform-and-not-chef-puppet-ansible-saltstack-or-cloudformation-7989dad2865c#.z5vvdu1q9" target="_blank" rel="noopener">声明性语言而不是程序性语言</a>的优势<a href="https://blog.gruntwork.io/why-we-use-terraform-and-not-chef-puppet-ansible-saltstack-or-cloudformation-7989dad2865c#.z5vvdu1q9" target="_blank" rel="noopener">之一</a>）。上面的差异显示Terraform想要创建一个名为“Name”的单个标签，这正是我们想要的，所以你应该再次运行“apply”命令。刷新EC2控制台时，您会看到：</p><p><img src="/Terraform/Terraform简介/5.png" alt="img"></p><h3 id="部署单个Web服务器"><a href="#部署单个Web服务器" class="headerlink" title="部署单个Web服务器"></a>部署单个Web服务器</h3><p>下一步是在此实例上运行Web服务器。在一个真实的用例中，您可能会安装一个功能齐全的Web框架，如Ruby on Rails或Django，但为了保持这个简单的示例，我们将运行一个简单的Web服务器，它始终返回文本“Hello，World”使用从<a href="https://gist.github.com/willurd/5720255" target="_blank" rel="noopener">http静态服务器单行列表中</a>借来的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">＃！/ bin / bash </span><br><span class="line">echo“Hello，World”&gt; index.html </span><br><span class="line">nohup busybox httpd -f -p 8080＆</span><br></pre></td></tr></table></figure><p>这是一个bash脚本，它将文本“Hello，World”写入index.html，并使用<a href="https://busybox.net/" target="_blank" rel="noopener">busybox</a>（在Ubuntu上默认安装）在端口8080上运行Web服务器，以便在URL“/”处提供该文件。我们使用<a href="https://en.wikipedia.org/wiki/Nohup" target="_blank" rel="noopener">nohup</a>包装busybox命令，以确保即使在此脚本退出后Web服务器仍在运行，并在命令末尾添加“＆”，以便Web服务器在后台进程中运行，因此脚本实际上可以退出而不是被阻止永远是由Web服务器。</p><p>如何让EC2实例运行此脚本？通常，您可以使用像<a href="https://www.packer.io/" target="_blank" rel="noopener">Packer</a>这样的工具来创建安装了Web服务器的自定义AMI ，而不是使用空的Ubuntu AMI 。但同样，为了保持这个例子的简单，我们将上面的脚本作为EC2 Instance的<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html" target="_blank" rel="noopener">用户数据的</a>一部分运行，AWS将在实例启动时执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_instance”“example”&#123; </span><br><span class="line">  ami =“ami-2d39803a” </span><br><span class="line">  instance_type =“t2.micro” </span><br><span class="line">  </span><br><span class="line">  user_data = &lt;&lt;  -  EOF </span><br><span class="line">              ＃！/ bin / bash </span><br><span class="line">              echo“Hello，World”&gt; index.html </span><br><span class="line">              nohup busybox httpd -f  - p 8080＆</span><br><span class="line">              EOF</span><br><span class="line">  标签&#123; </span><br><span class="line">    Name =“terraform-example” </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>“&lt;&lt; - EOF”和“EOF”是Terraform的heredoc语法，它允许您创建多行字符串而无需将“\ n”放在所有位置（<a href="https://www.terraform.io/docs/configuration/syntax.html" target="_blank" rel="noopener">在此处</a>了解有关<a href="https://www.terraform.io/docs/configuration/syntax.html" target="_blank" rel="noopener">Terraform语法的</a>更多信息）。</p><p>在此Web服务器工作之前，您需要再做一件事。默认情况下，AWS不允许来自EC2实例的任何传入或传出流量。要允许EC2实例在端口8080上接收流量，您需要创建一个<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html" target="_blank" rel="noopener">安全组</a>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_security_group”“instance”&#123; </span><br><span class="line">  name =“terraform-example-instance”</span><br><span class="line">  ingress &#123; </span><br><span class="line">    from_port = 8080 </span><br><span class="line">    to_port = 8080 </span><br><span class="line">    protocol =“tcp” </span><br><span class="line">    cidr_blocks = [“0.0.0.0/0”] </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码创建了一个名为<a href="https://www.terraform.io/docs/providers/aws/r/security_group.html" target="_blank" rel="noopener">aws_security_group</a>的新资源（注意AWS提供程序的所有资源如何以“aws_”开头）并指定该组允许来自CIDR块0.0.0.0/0的端口8080上的传入TCP请求。<a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing" target="_blank" rel="noopener">CIDR块</a>是指定IP地址范围的简明方法。例如，10.0.0.0/24的CIDR块表示10.0.0.0和10.0.0.255之间的所有IP地址。CIDR块0.0.0.0/0是包含所有可能IP地址的IP地址范围，因此上面的安全组允许来自任何IP的端口8080上的传入请求。</p><p>请注意，在上面的安全组中，我们复制并粘贴了端口8080.为了使代码保持<a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself" target="_blank" rel="noopener">干燥</a>并使配置代码变得容易，Terraform允许您定义<a href="https://www.terraform.io/intro/getting-started/variables.html" target="_blank" rel="noopener">输入变量</a>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">变量“server_port”&#123; </span><br><span class="line">  description =“服务器将用于HTTP请求的端口” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>您可以通过Terraform的<a href="https://www.terraform.io/docs/configuration/interpolation.html" target="_blank" rel="noopener">插值语法</a>在安全组中使用此变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from_port =“$ &#123;var.server_port&#125;” </span><br><span class="line">to_port =“$ &#123;var.server_port&#125;”</span><br></pre></td></tr></table></figure><p>您还可以在EC2实例的user_data中使用相同的语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup busybox httpd -f -p“$ &#123;var.server_port&#125;”＆</span><br></pre></td></tr></table></figure><p>如果您现在运行计划或应用命令，Terraform将提示您输入server_port变量的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform plan </span><br><span class="line">var.server_port </span><br><span class="line">  服务器将用于HTTP请求的端口</span><br><span class="line">输入值：8080</span><br></pre></td></tr></table></figure><p>为变量提供值的另一种方法是使用“-var”命令行选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform plan -var server_port =“8080”</span><br></pre></td></tr></table></figure><p>如果您不希望每次都手动输入端口，则可以将默认值指定为变量声明的一部分（请注意，仍可通过“-var”命令行选项覆盖此默认值）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">变量“server_port”&#123; </span><br><span class="line">  description =“服务器将用于HTTP请求的端口” </span><br><span class="line">  default = 8080 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后要做的事情是：您需要告诉EC2实例实际使用新的安全组。为此，您需要将安全组的ID传递到aws_instance资源的vpc_security_group_ids参数中。你怎么得到这个ID？</p><p>在Terraform中，每个资源都具有可以使用与插值相同的语法引用的属性。您可以在每个资源的文档中找到属性列表。例如，<a href="https://www.terraform.io/docs/providers/aws/r/security_group.html#attributes-reference" target="_blank" rel="noopener">aws_security_group属性</a>包括安全组的ID，您可以在EC2实例中引用该ID，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vpc_security_group_ids = [“$ &#123;aws_security_group.instance.id&#125;”]</span><br></pre></td></tr></table></figure><p>语法为“$ {TYPE.NAME.ATTRIBUTE}”。当一个资源引用另一个资源时，您将创建一个<a href="https://www.terraform.io/intro/getting-started/dependencies.html" target="_blank" rel="noopener">隐式依赖项</a>。Terraform解析这些依赖关系，从它们构建依赖关系图，并使用它来自动确定它应该以什么顺序创建资源（例如Terraform知道它需要在将其与EC2实例一起使用之前创建安全组）。实际上，Terraform将尽可能并行地创建尽可能多的资源，这意味着它可以非常快速地应用您的更改。这就是声明性语言的美妙之处：你只需指定你想要的东西，Terraform就会找出实现它的最有效方法。</p><p>如果运行计划命令，您将看到Terraform想要用具有新用户数据的新EC2实例（“ - / +”表示“替换”）替换原始EC2实例并添加安全组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform计划</span><br><span class="line">（......）</span><br><span class="line">-  / + aws_instance.example </span><br><span class="line">    ami：“ami-2d39803a”=&gt;“ami-2d39803a” </span><br><span class="line">    instance_state：“running”=&gt;“&lt;computed&gt;” </span><br><span class="line">    instance_type：“t2.micro”=&gt;“t2.micro” </span><br><span class="line">    security_groups。＃： “0”=&gt;“&lt;计算&gt;” </span><br><span class="line">    vpc_security_group_ids。＃：“1”=&gt;“&lt;计算&gt;”</span><br><span class="line">（......）</span><br><span class="line">+ aws_security_group.instance </span><br><span class="line">    描述：“由Terraform管理” </span><br><span class="line">    出口。＃：“&lt;计算&gt;” </span><br><span class="line">    入口。＃：“1” </span><br><span class="line">    ingress.516175195.cidr_blocks。＃：“1” </span><br><span class="line">    ingress.516175195.cidr_blocks.0：“0.0.0.0 / 0“ </span><br><span class="line">    ingress.516175195.from_port：”8080“ </span><br><span class="line">    ingress.516175195.protocol：”tcp“ </span><br><span class="line">    ingress.516175195.security_groups。＃：”0“ </span><br><span class="line">    ingress.516175195.self：”false“ </span><br><span class="line">    ingress.516175195.to_port：”8080“ </span><br><span class="line">    owner_id：“&lt;计算&gt;” </span><br><span class="line">    vpc_id：“&lt;计算&gt;”</span><br><span class="line">计划：2添加，0改变，1破坏。</span><br></pre></td></tr></table></figure><p>这正是我们想要的，所以再次运行apply命令，您将看到新的EC2实例部署：</p><p><img src="/Terraform/Terraform简介/6.png" alt="img"></p><p>在屏幕底部的描述面板中，您还将看到此EC2实例的公共IP地址。给它一两分钟启动，然后尝试在端口8080处卷曲此IP：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; curl http：// &lt;EC2_INSTANCE_PUBLIC_IP&gt;：8080 </span><br><span class="line">Hello，World</span><br></pre></td></tr></table></figure><p>耶，一个工作的网络服务器！但是，必须手动在EC2控制台周围找到这个IP地址并不好玩。幸运的是，您可以通过指定<a href="https://www.terraform.io/intro/getting-started/outputs.html" target="_blank" rel="noopener">输出变量</a>来做得更好：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输出“public_ip”&#123; </span><br><span class="line">  value =“ $ &#123;aws_instance.example.public_ip &#125;” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们再次使用插值语法来引用aws_instance资源的public_ip属性。如果再次运行apply命令，Terraform将不会应用任何更改（因为您没有更改任何资源），但它会显示新输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform apply </span><br><span class="line">aws_security_group.instance：刷新状态...（ID：sg-db91dba1）</span><br><span class="line">aws_instance.example：刷新状态...（ID：i-61744350）</span><br><span class="line">申请完成！资源：0添加，0更改，0销毁。</span><br><span class="line">输出：</span><br><span class="line">public_ip = 54.174.13.5</span><br></pre></td></tr></table></figure><p>输入和输出变量是Terraform强大功能的重要组成部分，特别是与模块结合使用时，我们将在第4部分中讨论的主题，<a href="https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d" target="_blank" rel="noopener">如何使用Terraform模块创建可重用的基础架构</a>。</p><h3 id="部署Web服务器集群"><a href="#部署Web服务器集群" class="headerlink" title="部署Web服务器集群"></a>部署Web服务器集群</h3><p>运行单个服务器是一个良好的开端，但在现实世界中，单个服务器是单点故障。如果该服务器崩溃，或者由于流量太大而导致服务器不堪重负，则用户将无法再访问您的站点。解决方案是运行服务器群集，绕过服务器路由，并根据流量调整群集大小（有关详细信息，请查看<a href="https://www.airpair.com/aws/posts/building-a-scalable-web-app-on-amazon-web-services-p1" target="_blank" rel="noopener">在Amazon Web Services上构建可扩展Web应用程序的综合指南</a>）。</p><p>手动管理这样的集群是很多工作。幸运的是，您可以让AWS使用<a href="https://aws.amazon.com/autoscaling/" target="_blank" rel="noopener">Auto Scaling Group（ASG）来处理它</a>。ASG可以自动启动EC2实例集群，监控其运行状况，自动重启故障节点，并根据需求调整集群大小。</p><p>创建ASG的第一步是创建<a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/LaunchConfiguration.html" target="_blank" rel="noopener">启动配置</a>，该<a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/LaunchConfiguration.html" target="_blank" rel="noopener">配置</a>指定如何在ASG中配置每个EC2实例。从早期部署单个EC2实例开始，您已经确切地知道如何配置它，并且您可以在<a href="https://www.terraform.io/docs/providers/aws/r/launch_configuration.html" target="_blank" rel="noopener">aws_launch_configuration</a>资源中重用几乎完全相同的参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_launch_configuration”“example”&#123; </span><br><span class="line">  image_id =“ami-2d39803a” </span><br><span class="line">  instance_type =“t2.micro” </span><br><span class="line">  security_groups = [“$ &#123;aws_security_group.instance.id&#125;”]</span><br><span class="line">  user_data = &lt;&lt;  -  EOF </span><br><span class="line">              ＃！/ bin / bash </span><br><span class="line">              echo“Hello，World”&gt; index.html </span><br><span class="line">              nohup busybox httpd -f -p“$ &#123;var.server_port&#125;”＆</span><br><span class="line">              EOF</span><br><span class="line">  生命周期&#123; </span><br><span class="line">    create_before_destroy = true </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>唯一新添加的是生命周期块，这是使用ASG启动配置所必需的。您可以向任何Terraform资源添加<a href="https://www.terraform.io/docs/configuration/resources.html#lifecycle" target="_blank" rel="noopener">生命周期块</a>以自定义其生命周期行为。其中一个可用的生命周期设置是create_before_destroy，它告诉Terraform在销毁原始文件之前始终创建替换资源（例如，在替换EC2实例时，始终在删除旧实例之前创建新实例）。</p><p>create_before_destroy参数的捕获是，如果在资源X上将其设置为true，则还必须在X依赖的每个资源上将其设置为true。对于启动配置，这意味着您需要在安全组上将create_before_destroy设置为true：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_security_group”“instance”&#123; </span><br><span class="line">  name =“terraform-example-instance”</span><br><span class="line">  ingress &#123; </span><br><span class="line">    from_port =“$ &#123;var.server_port&#125;” </span><br><span class="line">    to_port =“$ &#123;var.server_port&#125;” </span><br><span class="line">    protocol =“tcp” </span><br><span class="line">    cidr_blocks = [“0.0.0.0/0”] </span><br><span class="line">  &#125;</span><br><span class="line">  生命周期&#123; </span><br><span class="line">    create_before_destroy = true </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，您可以使用<a href="https://www.terraform.io/docs/providers/aws/r/autoscaling_group.html" target="_blank" rel="noopener">aws_autoscaling_group资源</a>创建ASG ：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_autoscaling_group”“example”&#123; </span><br><span class="line">  launch_configuration =“$ &#123;aws_launch_configuration.example.id&#125;”</span><br><span class="line">  min_size = 2 </span><br><span class="line">  max_size = 10</span><br><span class="line">  tag &#123; </span><br><span class="line">    key =“Name” </span><br><span class="line">    value =“terraform-asg-example” </span><br><span class="line">    propagate_at_launch = true </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此ASG将运行2到10个EC2实例（初始启动默认为2），每个实例都标记为“terraform-example”。每个EC2实例的配置由您之前创建的启动配置决定，我们使用Terraform的插值语法进行参考。</p><p>要使此ASG正常工作，您需要再指定一个参数：availability_zones。此参数指定应部署EC2实例的<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html" target="_blank" rel="noopener">可用区</a>（AZ）。每个AZ代表一个独立的AWS数据中心，因此通过跨多个AZ部署实例，即使某些AZ发生故障，也可确保您的服务可以继续运行。您可以对AZ列表进行硬编码（例如将其设置为[“us-east-1a”，“us-east-1b”]），但每个AWS账户都可以访问一组略有不同的AZ，因此您可以使用<a href="https://www.terraform.io/docs/providers/aws/d/availability_zones.html" target="_blank" rel="noopener">aws_availability_zones数据源</a>获取您帐户的确切列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">数据“aws_availability_zones”“全部”&#123;&#125;</span><br></pre></td></tr></table></figure><p>甲<a href="https://www.terraform.io/docs/configuration/data-sources.html" target="_blank" rel="noopener">数据源</a>表示一块的只读信息被取出从提供者（在此情况下，AWS）每次运行Terraform时间。除可用区域外，还有数据源可查找<a href="https://www.terraform.io/docs/providers/aws/d/ami.html" target="_blank" rel="noopener">AMI ID</a>，<a href="https://www.terraform.io/docs/providers/aws/d/ip_ranges.html" target="_blank" rel="noopener">IP地址范围</a>和<a href="https://www.terraform.io/docs/providers/aws/d/caller_identity.html" target="_blank" rel="noopener">当前用户的身份</a>。将数据源添加到Terraform模板不会创建任何新内容; 它只是一种检索动态数据的方法。</p><p>要使用数据源，请使用标准插值语法引用它：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_autoscaling_group”“example”&#123; </span><br><span class="line">  launch_configuration =“$ &#123;aws_launch_configuration.example.id&#125;” </span><br><span class="line">  availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”]</span><br><span class="line">  min_size = 2 </span><br><span class="line">  max_size = 10</span><br><span class="line">  tag &#123; </span><br><span class="line">    key =“Name” </span><br><span class="line">    value =“terraform-asg-example” </span><br><span class="line">    propagate_at_launch = true </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="部署负载均衡器"><a href="#部署负载均衡器" class="headerlink" title="部署负载均衡器"></a>部署负载均衡器</h3><p>在启动ASG之前，还有一个问题需要解决：现在您有许多实例，您需要一个负载均衡器来分配所有实例的流量。创建高可用性和可伸缩性的负载均衡器需要大量工作。您可以再次使用<a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank" rel="noopener">Elastic Load Balancer（ELB）</a>让AWS为您处理。要使用Terraform创建ELB，请使用<a href="https://www.terraform.io/docs/providers/aws/r/elb.html" target="_blank" rel="noopener">aws_elb资源</a>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_elb”“example”&#123; </span><br><span class="line">  name =“terraform-asg-example” </span><br><span class="line">  availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”] </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这会创建一个ELB，可以在您帐户中的所有AZ中使用。当然，在你告诉ELB如何路由请求之前，上面的定义并不多。为此，您添加一个或多个“侦听器”，指定ELB应侦听的端口以及应将请求路由到的端口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_elb”“example”&#123; </span><br><span class="line">  name =“terraform-asg-example” </span><br><span class="line">  availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”]</span><br><span class="line">  listener &#123; </span><br><span class="line">    lb_port = 80 </span><br><span class="line">    lb_protocol =“http” </span><br><span class="line">    instance_port =“$ &#123;var.server_port&#125;” </span><br><span class="line">    instance_protocol =“http” </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的代码中，我们告诉ELB在端口80（HTTP的默认端口）上接收HTTP请求，并将它们路由到ASG中Instances使用的端口。请注意，默认情况下，ELB不允许任何传入或传出流量（就像EC2实例一样），因此您需要添加一个安全组以明确允许端口80上的传入请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_security_group”“elb”&#123; </span><br><span class="line">  name =“terraform-example-elb”</span><br><span class="line">  ingress &#123; </span><br><span class="line">    from_port = 80 </span><br><span class="line">    to_port = 80 </span><br><span class="line">    protocol =“tcp” </span><br><span class="line">    cidr_blocks = [“0.0.0.0/0”] </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，您需要通过添加security_groups参数告诉ELB使用此安全组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_elb”“example”&#123; </span><br><span class="line">  name =“terraform-asg-example” </span><br><span class="line">  security_groups = [“$ &#123;aws_security_group.elb.id&#125;”] </span><br><span class="line">  availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”]</span><br><span class="line">  listener &#123; </span><br><span class="line">    lb_port = 80 </span><br><span class="line">    lb_protocol =“http” </span><br><span class="line">    instance_port =“$ &#123;var.server_port&#125;” </span><br><span class="line">    instance_protocol =“http” </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ELB还有另外一个漂亮的技巧：它可以定期检查你的EC2实例的运行状况，如果一个实例不健康，它会自动停止将流量路由到它。让我们添加一个HTTP运行状况检查，其中ELB将每隔30秒向每个EC2实例的“/”URL发送一个HTTP请求，并且只有在实例响应200 OK时才将其标记为正常：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_elb”“example”&#123; </span><br><span class="line">  name =“terraform-asg-example” </span><br><span class="line">  security_groups = [“$ &#123;aws_security_group.elb.id&#125;”] </span><br><span class="line">  availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”]</span><br><span class="line">  health_check &#123; </span><br><span class="line">    healthy_threshold = 2 </span><br><span class="line">    unhealthy_threshold = 2 </span><br><span class="line">    timeout = 3 </span><br><span class="line">    interval = 30 </span><br><span class="line">    target =“HTTP：$ &#123;var.server_port&#125; /” </span><br><span class="line">  &#125;</span><br><span class="line">  listener &#123; </span><br><span class="line">    lb_port = 80 </span><br><span class="line">    lb_protocol =“http” </span><br><span class="line">    instance_port =“$ &#123;var.server_port&#125;” </span><br><span class="line">    instance_protocol =“http” </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>要允许这些运行状况检查请求，您需要修改ELB的安全组以允许出站请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_security_group”“elb”&#123; </span><br><span class="line">  name =“terraform-example-elb”</span><br><span class="line">  出口&#123; </span><br><span class="line">    from_port = 0 </span><br><span class="line">    to_port = 0 </span><br><span class="line">    protocol =“ -  1” </span><br><span class="line">    cidr_blocks = [“0.0.0.0/0”] </span><br><span class="line">  &#125;</span><br><span class="line">  ingress &#123; </span><br><span class="line">    from_port = 80 </span><br><span class="line">    to_port = 80 </span><br><span class="line">    protocol =“tcp” </span><br><span class="line">    cidr_blocks = [“0.0.0.0/0”] </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ELB如何知道向哪些EC2实例发送请求？您可以使用ELB的实例参数将EC2实例的静态列表附加到ELB，但是使用ASG，实例将一直动态启动和终止，因此无法工作。相反，您可以使用aws_autoscaling_group资源的load_balancers参数告诉ASG在该实例启动时注册ELB中的每个实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_autoscaling_group”“example”&#123; </span><br><span class="line">  launch_configuration =“$ &#123;aws_launch_configuration.example.id&#125;” </span><br><span class="line">  availability_zones = [“$ &#123;data.aws_availability_zones.all.names&#125;”]</span><br><span class="line">  min_size = 2 </span><br><span class="line">  max_size = 10</span><br><span class="line">  load_balancers = [“$ &#123;aws_elb.example.name&#125;”] </span><br><span class="line">  health_check_type =“ELB”</span><br><span class="line">  tag &#123; </span><br><span class="line">    key =“Name” </span><br><span class="line">    value =“terraform-asg-example” </span><br><span class="line">    propagate_at_launch = true </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意，我们还将ASG的health_check_type配置为“ELB”。这告诉ASG使用ELB的运行状况检查来确定实例是否健康，并在ELB将其报告为不健康时自动重启实例。</p><p>在部署负载均衡器之前要做的最后一件事：让我们将其DNS名称添加为输出，以便更容易测试事情是否正常：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输出“elb_dns_name”&#123; </span><br><span class="line">  value =“$ &#123;aws_elb.example.dns_name&#125;” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行plan命令以验证您的更改，如果一切正常，请运行apply。应用完成后，您应该看到elb_dns_name输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输出：</span><br><span class="line">elb_dns_name = terraform-asg-example-123.us-east-1.elb.amazonaws.com</span><br></pre></td></tr></table></figure><p>复制此URL。实例启动并在ELB中显示为健康状态需要几分钟。在此期间，您可以检查已部署的内容。打开<a href="https://console.aws.amazon.com/ec2/autoscaling/home" target="_blank" rel="noopener">EC2控制台</a>的<a href="https://console.aws.amazon.com/ec2/autoscaling/home" target="_blank" rel="noopener">ASG部分</a>，您应该看到已创建ASG：</p><p><img src="/Terraform/Terraform简介/7.png" alt="img"></p><p>如果切换到Instances选项卡，您将在启动过程中看到两个实例：</p><p><img src="/Terraform/Terraform简介/8.png" alt="img"></p><p>最后，如果切换到Load Balancers选项卡，您将看到您的ELB：</p><p><img src="/Terraform/Terraform简介/9.png" alt="img"></p><p>等待“状态”指示符说“服务中有2个实例中的2个”。这通常需要1-2分钟。看到之后，测试先前复制的elb_dns_name输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; curl http：// &lt;elb_dns_name&gt; </span><br><span class="line">Hello，World</span><br></pre></td></tr></table></figure><p>成功！ELB将流量路由到您的EC2实例。每次点击URL时，它都会选择不同的实例来处理请求。您现在拥有一个完全可用的Web服务器集群！提醒一下，上面示例的完整示例代码位于：<a href="https://github.com/gruntwork-io/intro-to-terraform" target="_blank" rel="noopener">https</a>：<a href="https://github.com/gruntwork-io/intro-to-terraform" target="_blank" rel="noopener">//github.com/gruntwork-io/intro-to-terraform</a>。</p><p>此时，您可以看到群集如何响应启动新实例或关闭旧实例。例如，转到Instances选项卡，通过选中其复选框，选择顶部的“Actions”按钮，然后将“Instance State”设置为“Terminate”来终止其中一个Instances。继续测试ELB URL和你即使在终止实例时，也应该为每个请求获得“200 OK”，因为ELB将自动检测到Instance已关闭并停止路由到它。更有趣的是，在实例关闭后的短时间内，ASG将检测到正在运行的实例少于2个，并自动启动一个新实例来替换它（自我修复！）。您还可以通过更改min_size和max_size参数或向Terraform代码添加desired_size参数来查看ASG如何调整自身大小。</p><p>当然，ASG还有许多其他方面，我们在这里没有涉及。对于实际部署，您需要将IAM角色附加到EC2实例，设置机制以使用零停机时间更新ASG中的EC2实例，并配置自动扩展策略以调整ASG的大小以响应负载。对于完全预组装，经过实战考验，文档化，生产就绪的ASG版本，以及其他类型的基础架构（如Docker集群，关系数据库，VPC等），您可能需要查看<a href="https://blog.gruntwork.io/gruntwork-infrastructure-packages-7434dc77d0b1#.luxpdx7n6" target="_blank" rel="noopener">Gruntwork基础架构包裹</a>。</p><h3 id="清理"><a href="#清理" class="headerlink" title="清理"></a>清理</h3><p>当您尝试使用Terraform时，最好删除您创建的所有资源，以便AWS不会向您收取费用。由于Terraform会跟踪您创建的资源，因此清理工作变得轻而易举。您需要做的就是运行destroy命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">terraform destroy </span><br><span class="line">你真的想破坏吗？</span><br><span class="line">  Terraform将删除您的所有托管基础架构。</span><br><span class="line">  没有撤消。只接受&apos;是&apos;确认。</span><br><span class="line">输入一个值：</span><br></pre></td></tr></table></figure><p>输入“yes”并按Enter键后，Terraform将使用尽可能多的并行性构建依赖关系图并按正确的顺序删除所有资源。大约一分钟后，您的AWS账户应该再次清理。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>您现在已经掌握了如何使用Terraform的基本知识。声明性语言可以很容易地准确描述您要创建的基础结构。plan命令允许您在部署之前验证更改并捕获错误。变量，插值和依赖性允许您保持代码干燥和高效。</p><p>但是，我们只是触及了表面。在本系列的第3部分“ <a href="https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa" target="_blank" rel="noopener">如何管理Terraform状态”中</a>，我们将展示Terraform如何跟踪它已经创建的基础架构，以及对如何构建Terraform代码所产生的深远影响。在本系列的第4部分中，我们将展示<a href="https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d" target="_blank" rel="noopener">如何使用Terraform模块创建可重用的基础架构</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是&lt;a href=&quot;https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca#.b6sun4nkn&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Terraform
      
    
    </summary>
    
      <category term="Terraform" scheme="http://blog.ozairs.com/categories/Terraform/"/>
    
    
  </entry>
  
  <entry>
    <title>Docker Swarm架构、特性与基本实践</title>
    <link href="http://blog.ozairs.com/Docker/Docker-Swarm%E6%9E%B6%E6%9E%84%E3%80%81%E7%89%B9%E6%80%A7%E4%B8%8E%E5%9F%BA%E6%9C%AC%E5%AE%9E%E8%B7%B5/"/>
    <id>http://blog.ozairs.com/Docker/Docker-Swarm架构、特性与基本实践/</id>
    <published>2019-03-30T04:57:09.000Z</published>
    <updated>2019-03-30T05:02:08.209Z</updated>
    
    <content type="html"><![CDATA[<p>Docker集群管理和编排的特性是通过SwarmKit进行构建的， 其中Swarm mode是Docker Engine内置支持的一种默认实现。Docker 1.12以及更新的版本，都支持Swarm mode，我们可以基于Docker Engine来构建Swarm集群，然后就可以将我们的应用服务（Application Service）部署到Swarm集群中。创建Swarm集群的方式很简单，先初始化一个Swarm集群，然后将其他的Node加入到该集群即可。本文主要基于Docker Swarm官网文档，学习总结。</p><p><strong>基本特性</strong></p><p>Docker Swarm具有如下基本特性：</p><ul><li>集群管理集成进Docker Engine</li></ul><p>使用内置的集群管理功能，我们可以直接通过Docker CLI命令来创建Swarm集群，然后去部署应用服务，而不再需要其它外部的软件来创建和管理一个Swarm集群。</p><ul><li>去中心化设计</li></ul><p>Swarm集群中包含Manager和Worker两类Node，我们可以直接基于Docker Engine来部署任何类型的Node。而且，在Swarm集群运行期间，我们既可以对其作出任何改变，实现对集群的扩容和缩容等，如添加Manager Node，如删除Worker Node，而做这些操作不需要暂停或重启当前的Swarm集群服务。</p><ul><li>声明式服务模型（Declarative Service Model）</li></ul><p>在我们实现的应用栈中，Docker Engine使用了一种声明的方式，让我们可以定义我们所期望的各种服务的状态，例如，我们创建了一个应用服务栈：一个Web前端服务、一个后端数据库服务、Web前端服务又依赖于一个消息队列服务。</p><ul><li>服务扩容缩容</li></ul><p>对于我们部署的每一个应用服务，我们可以通过命令行的方式，设置启动多少个Docker容器去运行它。已经部署完成的应用，如果有扩容或缩容的需求，只需要通过命令行指定需要几个Docker容器即可，Swarm集群运行时便能自动地、灵活地进行调整。</p><ul><li>协调预期状态与实际状态的一致性</li></ul><p>Swarm集群Manager Node会不断地监控集群的状态，协调集群状态使得我们预期状态和实际状态保持一致。例如我们启动了一个应用服务，指定服务副本为10，则会启动10个Docker容器去运行，如果某个Worker Node上面运行的2个Docker容器挂掉了，则Swarm Manager会选择集群中其它可用的Worker Node，并创建2个服务副本，使实际运行的Docker容器数仍然保持与预期的10个一致。</p><ul><li>多主机网络</li></ul><p>我们可以为待部署应用服务指定一个Overlay网络，当应用服务初始化或者进行更新时，Swarm Manager在给定的Overlay网络中为Docker容器自动地分配IP地址，实际是一个虚拟IP地址（VIP）。</p><ul><li>服务发现</li></ul><p>Swarm Manager会给集群中每一个服务分配一个唯一的DNS名称，对运行中的Docker容器进行负载均衡。我们可以通过Swarm内置的DNS Server，查询Swarm集群中运行的Docker容器状态。</p><ul><li>负载均衡</li></ul><p>在Swarm内部，可以指定如何在各个Node之间分发服务容器（Service Container），实现负载均衡。如果想要使用Swarm集群外部的负载均衡器，可以将服务容器的端口暴露到外部。</p><ul><li>安全策略</li></ul><p>在Swarm集群内部的Node，强制使用基于TLS的双向认证，并且在单个Node上以及在集群中的Node之间，都进行安全的加密通信。我们可以选择使用自签名的根证书，或者使用自定义的根CA（Root CA）证书。</p><ul><li>滚动更新（Rolling Update）</li></ul><p>对于服务需要更新的场景，我们可以在多个Node上进行增量部署更新，Swarm Manager支持通过使用Docker CLI设置一个delay时间间隔，实现多个服务在多个Node上依次进行部署。这样可以非常灵活地控制，如果有一个服务更新失败，则暂停后面的更新操作，重新回滚到更新之前的版本。</p><p><strong>基本架构</strong></p><p>Docker Swarm提供了基本的集群能力，能够使多个Docker Engine组合成一个group，提供多容器服务。Swarm使用标准的Docker API，启动容器可以直接使用docker run命令。Swarm更核心的则是关注如何选择一个主机并在其上启动容器，最终运行服务。<br>Docker Swarm基本架构，如下图所示<br><img src="/Docker/Docker-Swarm架构、特性与基本实践/1.png" alt=""></p><p>如上图所示，Swarm Node表示加入Swarm集群中的一个Docker Engine实例，基于该Docker Engine可以创建并管理多个Docker容器。其中，最开始创建Swarm集群的时候，Swarm Manager便是集群中的第一个Swarm Node。在所有的Node中，又根据其职能划分为Manager Node和Worker Node，具体分别如下所示：</p><ul><li>Manager Node</li></ul><p>Manager Node负责调度Task，一个Task表示要在Swarm集群中的某个Node上启动Docker容器，一个或多个Docker容器运行在Swarm集群中的某个Worker Node上。同时，Manager Node还负责编排容器和集群管理功能（或者更准确地说，是具有Manager管理职能的Node），维护集群的状态。需要注意的是，默认情况下，Manager Node也作为一个Worker Node来执行Task。Swarm支持配置Manager只作为一个专用的管理Node，后面我们会详细说明。</p><ul><li>Worker Node</li></ul><p>Worker Node接收由Manager Node调度并指派的Task，启动一个Docker容器来运行指定的服务，并且Worker Node需要向Manager Node汇报被指派的Task的执行状态。</p><p><strong>构建Swarm集群</strong></p><p>我们实践Swarm集群，包括三个Node，对应的主机名和IP地址分别如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`manager  192.168.1.107``worker1  192.168.1.108``worker2  192.168.1.109`</span><br></pre></td></tr></table></figure><p>首先，需要保证各个Node上，docker daemon进程已经正常启动，如果没有则执行如下命令启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`systemctl start docker`</span><br></pre></td></tr></table></figure><p>接下来就可以创建Swarm集群，创建Swarm的命令，格式如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker swarm init --advertise-addr &lt;MANAGER-IP&gt;`</span><br></pre></td></tr></table></figure><p>我们在准备好的manager Node上，登录到该Node，创建一个Swarm，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker swarm init --advertise-addr 192.168.1.107`</span><br></pre></td></tr></table></figure><p>上面<code>--advertise-addr</code>选项指定Manager Node会publish它的地址为192.168.1.107，后续Worker Node加入到该Swarm集群，必须要能够访问到Manager的该IP地址。可以看到，上述命令执行结果，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`Swarm initialized: current node (5pe2p4dlxku6z2a6jnvxc4ve6) is now a manager.` `To add a worker to this swarm, run the following command:` `    ``docker swarm join \``    ``--token SWMTKN-1-4dm09nzp3xic15uebqja69o2552b75pcg7or0g9t2eld9ehqt3-1kb79trnv6fbydvl9vif3fsch \``    ``192.168.1.107:2377` `To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions.`</span><br></pre></td></tr></table></figure><p>该结果中给出了后续操作引导信息，告诉我们如何将一个Worker Node加入到Swarm集群中。也可以通过如下命令，来获取该提示信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker swarm ``join``-token worker`</span><br></pre></td></tr></table></figure><p>在任何时候，如果我们需要向已经创建的Swarm集群中增加Worker Node，只要新增一个主机（物理机、云主机等都可以），并在其上安装好Docker Engine并启动，然后执行上述docker swarm join命令，就可以加入到Swarm集群中。<br>这时，我们也可以查看当前Manager Node的基本信息，执行docker info命令，输出信息中可以看到，包含如下关于Swarm的状态信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`Swarm: active`` ``NodeID: qc42f6myqfpoevfkrzmx08n0r`` ``Is Manager: true`` ``ClusterID: qi4i0vh7lgb60qxy3mdygb27f`` ``Managers: 1`` ``Nodes: 1`</span><br></pre></td></tr></table></figure><p>可以看出，目前Swarm集群只有Manager一个Node，而且状态是active。也可以在Manager Node上执行docker node ls命令查看Node状态，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS``qc42f6myqfpoevfkrzmx08n0r *  manager   Ready   Active        Leader`</span><br></pre></td></tr></table></figure><p>接下来，我们可以根据上面提示信息，我们分别在worker1、worker2两个Worker Node 上，执行命令将Worker Node加入到Swarm集群中，命令如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker swarm ``join` `\``    ``--token SWMTKN-1-4dm09nzp3xic15uebqja69o2552b75pcg7or0g9t2eld9ehqt3-1kb79trnv6fbydvl9vif3fsch \``    ``192.168.1.107:2377`</span><br></pre></td></tr></table></figure><p>如果成功，可以看到成功加入Swarm集群的信息。这时，也可以在Manager Node上，查看Swarm集群的信息，示例如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`Swarm: active`` ``NodeID: qc42f6myqfpoevfkrzmx08n0r`` ``Is Manager: true`` ``ClusterID: qi4i0vh7lgb60qxy3mdygb27f`` ``Managers: 1`` ``Nodes: 3`</span><br></pre></td></tr></table></figure><p>想要查看Swarm集群中全部Node的详细状态信息，可以执行如下所示命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker node ``ls`</span><br></pre></td></tr></table></figure><p>Swarm集群Node的状态信息，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS``oibbiiwrgwjkw0ni38ydrfsre    worker1   Ready   Active       ``oocli2uzdt2hy6o50g5z6j7dq    worker2   Ready   Active       ``qc42f6myqfpoevfkrzmx08n0r *  manager   Ready   Active        Leader`</span><br></pre></td></tr></table></figure><p>上面信息中，AVAILABILITY表示Swarm Scheduler是否可以向集群中的某个Node指派Task，对应有如下三种状态：</p><ul><li>Active：集群中该Node可以被指派Task</li><li>Pause：集群中该Node不可以被指派新的Task，但是其他已经存在的Task保持运行</li><li>Drain：集群中该Node不可以被指派新的Task，Swarm Scheduler停掉已经存在的Task，并将它们调度到可用的Node上</li></ul><p>查看某一个Node的状态信息，可以在该Node上执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker node inspect self`</span><br></pre></td></tr></table></figure><p>我们在Manager Node上执行上述命令，查看的状态信息如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`[``    ``&#123;``        ``&quot;ID&quot;: &quot;qc42f6myqfpoevfkrzmx08n0r&quot;,``        ``&quot;Version&quot;: &#123;``            ``&quot;Index&quot;: 9``        ``&#125;,``        ``&quot;CreatedAt&quot;: &quot;2017-03-12T15:25:51.725341879Z&quot;,``        ``&quot;UpdatedAt&quot;: &quot;2017-03-12T15:25:51.84308356Z&quot;,``        ``&quot;Spec&quot;: &#123;``            ``&quot;Role&quot;: &quot;manager&quot;,``            ``&quot;Availability&quot;: &quot;active&quot;``        ``&#125;,``        ``&quot;Description&quot;: &#123;``            ``&quot;Hostname&quot;: &quot;manager&quot;,``            ``&quot;Platform&quot;: &#123;``                ``&quot;Architecture&quot;: &quot;x86_64&quot;,``                ``&quot;OS&quot;: &quot;linux&quot;``            ``&#125;,``            ``&quot;Resources&quot;: &#123;``                ``&quot;NanoCPUs&quot;: 1000000000,``                ``&quot;MemoryBytes&quot;: 1912082432``            ``&#125;,``            ``&quot;Engine&quot;: &#123;``                ``&quot;EngineVersion&quot;: &quot;17.03.0-ce&quot;,``                ``&quot;Plugins&quot;: [``                    ``&#123;``                        ``&quot;Type&quot;: &quot;Network&quot;,``                        ``&quot;Name&quot;: &quot;bridge&quot;``                    ``&#125;,``                    ``&#123;``                        ``&quot;Type&quot;: &quot;Network&quot;,``                        ``&quot;Name&quot;: &quot;host&quot;``                    ``&#125;,``                    ``&#123;``                        ``&quot;Type&quot;: &quot;Network&quot;,``                        ``&quot;Name&quot;: &quot;macvlan&quot;``                    ``&#125;,``                    ``&#123;``                        ``&quot;Type&quot;: &quot;Network&quot;,``                        ``&quot;Name&quot;: &quot;null&quot;``                    ``&#125;,``                    ``&#123;``                        ``&quot;Type&quot;: &quot;Network&quot;,``                        ``&quot;Name&quot;: &quot;overlay&quot;``                    ``&#125;,``                    ``&#123;``                        ``&quot;Type&quot;: &quot;Volume&quot;,``                        ``&quot;Name&quot;: &quot;local&quot;``                    ``&#125;``                ``]``            ``&#125;``        ``&#125;,``        ``&quot;Status&quot;: &#123;``            ``&quot;State&quot;: &quot;ready&quot;,``            ``&quot;Addr&quot;: &quot;127.0.0.1&quot;``        ``&#125;,``        ``&quot;ManagerStatus&quot;: &#123;``            ``&quot;Leader&quot;: true,``            ``&quot;Reachability&quot;: &quot;reachable&quot;,``            ``&quot;Addr&quot;: &quot;192.168.1.107:2377&quot;``        ``&#125;``    ``&#125;``]`</span><br></pre></td></tr></table></figure><p><strong>管理Swarm Node</strong></p><p>Swarm支持设置一组Manager Node，通过支持多Manager Node实现HA。那么这些Manager Node之间的状态的一致性就非常重要了，多Manager Node的Warm集群架构，如下图所示：</p><p><img src="/Docker/Docker-Swarm架构、特性与基本实践/2.png" alt=""><br>通过上图可以看到，Swarm使用了Raft协议来保证多个Manager之间状态的一致性。基于Raft协议，Manager Node具有一定的容错功能，假设Swarm集群中有个N个Manager Node，那么整个集群可以容忍最多有(N-1)/2个节点失效。如果是一个三Manager Node的Swarm集群，则最多只能容忍一个Manager Node挂掉。<br>下面，我们按照对Node的不同操作，通过命令的方式来详细说明：</p><p><strong>（1）Node状态变更管理</strong></p><p>前面我们已经提到过，Node的AVAILABILITY有三种状态：Active、Pause、Drain，对某个Node进行变更，可以将其AVAILABILITY值通过Docker CLI修改为对应的状态即可，下面是常见的变更操作：</p><ul><li>设置Manager Node只具有管理功能</li><li>对服务进行停机维护，可以修改AVAILABILITY为Drain状态</li><li>暂停一个Node，然后该Node就不再接收新的Task</li><li>恢复一个不可用或者暂停的Node</li></ul><p>例如，将Manager Node的AVAILABILITY值修改为Drain状态，使其只具备管理功能，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker node update --availability drain manager`</span><br></pre></td></tr></table></figure><p>这样，Manager Node不能被指派Task，也就是不能部署实际的Docker容器来运行服务，而只是作为管理Node的角色。</p><p><strong>（2）给Node添加标签元数据</strong></p><p>每个Node的主机配置情况可能不同，比如有的适合运行CPU密集型应用，有的适合运行IO密集型应用，Swarm支持给每个Node添加标签元数据，这样可以根据Node的标签，来选择性地调度某个服务部署到期望的一组Node上。<br>给SWarm集群中的某个Worker Node添加标签，执行如下命令格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker node update --label-add 键名称=值`</span><br></pre></td></tr></table></figure><p>例如，worker1主机在名称为bjidc这个数据中心，执行如下命令添加标签：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker node update --label-add datacenter=bjidc`</span><br></pre></td></tr></table></figure><p><strong>（3）Node提权/降权</strong></p><p>改变Node的角色，Worker Node可以变为Manager Node，这样实际Worker Node有工作Node变成了管理Node，对应提权操作，例如将worker1和worker2都升级为Manager Node，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker node promote worker1 worker2`</span><br></pre></td></tr></table></figure><p>对上面已提权的worker1和worker2执行降权，需要执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker node demote worker1 worker2`</span><br></pre></td></tr></table></figure><p><strong>（4）退出Swarm集群</strong></p><p>如果Manager想要退出Swarm集群， 在Manager Node上执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker swarm node leave`</span><br></pre></td></tr></table></figure><p>就可以退出集群，如果集群中还存在其它的Worker Node，还希望Manager退出集群，则加上一个强制选项，命令行如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker swarm node leave --force`</span><br></pre></td></tr></table></figure><p>同样，如果Worker想要退出Swarm集群，在Worker Node上，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker swarm node leave`</span><br></pre></td></tr></table></figure><p>即使Manager已经退出SWarm集群，执行上述命令也可以使得Worker Node退出集群，然后又可以加入到其它新建的Swarm集群中。</p><p><strong>管理服务</strong></p><p>在Swarm集群上部署服务，必须在Manager Node上进行操作。先说明一下Service、Task、Container（容器）这个三个概念的关系，如下图（出自Docker官网）非常清晰地描述了这个三个概念的含义：<br><img src="/Docker/Docker-Swarm架构、特性与基本实践/3.png" alt=""><br>在Swarm mode下使用Docker，可以实现部署运行服务、服务扩容缩容、删除服务、滚动更新等功能，下面我们详细说明。</p><p><strong>（1）创建服务</strong></p><p>创建Docker服务，可以使用docker service create命令实现，例如，我们要创建如下两个服务，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service create --replicas 1 --name myapp alpine ``ping` `shiyanjun.cn``docker service create --replicas 2 --name myredis redis`</span><br></pre></td></tr></table></figure><p>第一个命令行，从Docker镜像alpine创建了一个名称为myapp的服务，其中指定服务副本数为1，也就是启动一个Docker容器来运行该服务。第二个命令行， 创建一个Redis服务，服务副本数为2，那么会启动两个Docker容器来运行myredis服务。查看当前，已经部署启动的全部应用服务，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service ``ls`</span><br></pre></td></tr></table></figure><p>执行结果，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`ID            NAME     MODE        REPLICAS  IMAGE``kilpacb9uy4q  myapp    replicated  1/1       alpine:latest``vf1kcgtd5byc  myredis  replicated  2/2       redis`</span><br></pre></td></tr></table></figure><p>也可以查询指定服务的详细信息，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service ``ps` `myredis`</span><br></pre></td></tr></table></figure><p>查看结果信息，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`ID            NAME       IMAGE  NODE     DESIRED STATE  CURRENT STATE           ERROR  PORTS``0p3r9zm2uxpl  myredis.1  redis  manager  Running        Running 48 seconds ago         ``ty3undmoielo  myredis.2  redis  worker1  Running        Running 44 seconds ago`</span><br></pre></td></tr></table></figure><p>上面信息中，在manager和worker1这两个Node上部署了myredis这个应用服务，也包含了它们对应的当前状态信息。此时，也可以通过执行docker ps命令，在Manager Node上查看当前启动的Docker容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES``07f93f82a407        redis:latest        &quot;docker-entrypoint...&quot;   7 minutes ago       Up 7 minutes        6379/tcp            myredis.1.0p3r9zm2uxple5i1e2mqgnl3r`</span><br></pre></td></tr></table></figure><p>在Worker1上查看当前启动的Docker容器，也就是我们的另一个myredis实例在该Node上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES``41c31e96cccb        redis:latest        &quot;docker-entrypoint...&quot;   8 minutes ago       Up 8 minutes        6379/tcp            myredis.2.ty3undmoielo18g7pnvh0nutz`</span><br></pre></td></tr></table></figure><p>创建服务时，我们可以对运行时服务容器进行配置，例如如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service create --name helloworld \``  ``--``env` `MYVAR=myvalue \``  ``--workdir ``/tmp` `\``  ``--user my_user \``  ``alpine ``ping` `docker.com`</span><br></pre></td></tr></table></figure><p>上面，通过<code>--env</code>选项来设置环境变量，通过<code>--workdir</code>选项来设置工作目录，通过<code>--user</code>选项来设置用户信息。</p><p><strong>（2）扩容缩容服务</strong></p><p>Docker Swarm支持服务的扩容缩容，Swarm通过<code>--mode</code>选项设置服务类型，提供了两种模式：一种是replicated，我们可以指定服务Task的个数（也就是需要创建几个冗余副本），这也是Swarm默认使用的服务类型；另一种是global，这样会在Swarm集群的每个Node上都创建一个服务。如下图所示（出自Docker官网），是一个包含replicated和global模式的Swarm集群：</p><p><img src="/Docker/Docker-Swarm架构、特性与基本实践/4.png" alt=""></p><p>上图中，黄色表示的replicated模式下的Service Replicas，灰色表示global模式下Service的分布。<br>服务扩容缩容，在Manager Node上执行命令的格式，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service scale 服务ID=服务Task总数`</span><br></pre></td></tr></table></figure><p>例如，将前面我们部署的2个副本的myredis服务，扩容到3个副本，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service scale myredis=3`</span><br></pre></td></tr></table></figure><p>通过命令docker service ls 查看，扩容操作结果如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`ID            NAME     MODE        REPLICAS  IMAGE``kilpacb9uy4q  myapp    replicated  1/1       alpine:latest``vf1kcgtd5byc  myredis  replicated  3/3       redis`</span><br></pre></td></tr></table></figure><p>进一步通过docker service ps myredis查看一下myredis的各个副本的状态信息，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`ID            NAME       IMAGE  NODE     DESIRED STATE  CURRENT STATE                   ERROR  PORTS``0p3r9zm2uxpl  myredis.1  redis  manager  Running        Running 14 minutes ago                 ``ty3undmoielo  myredis.2  redis  worker1  Running        Running 14 minutes ago                 ``zxsvynsgqmpk  myredis.3  redis  worker2  Running        Running less than a second ago`</span><br></pre></td></tr></table></figure><p>可以看到，我们目前3个Node的Swarm集群，每个Node上都有一个myredis应用服务的副本，可见也实现了很好的负载均衡。<br>缩容服务，只需要将副本数小于当前应用服务拥有的副本数即可实现，大于指定缩容副本数的副本会被删除。</p><p><strong>（3）删除服务</strong></p><p>删除服务，只需要在Manager Node上执行如下命令即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service ``rm` `服务ID`</span><br></pre></td></tr></table></figure><p>例如，删除myredis应用服务，执行docker service rm myredis，则应用服务myredis的全部副本都会被删除。</p><p><strong>（4）滚动更新</strong></p><p>服务的滚动更新，这里我参考官网文档的例子说明。在Manager Node上执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service create \``  ``--replicas 3 \``  ``--name redis \``  ``--update-delay 10s \``  ``redis:3.0.6`</span><br></pre></td></tr></table></figure><p>上面通过指定<code>--update-delay</code>选项，表示需要进行更新的服务，每次成功部署一个，延迟10秒钟，然后再更新下一个服务。如果某个服务更新失败，则Swarm的调度器就会暂停本次服务的部署更新。<br>另外，也可以更新已经部署的服务所在容器中使用的Image的版本，例如执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service update --image redis:3.0.7 redis`</span><br></pre></td></tr></table></figure><p>将Redis服务对应的Image版本有3.0.6更新为3.0.7，同样，如果更新失败，则暂停本次更新。</p><p><strong>（5）添加Overlay网络</strong></p><p>在Swarm集群中可以使用Overlay网络来连接到一个或多个服务。具体添加Overlay网络，首先，我们需要创建在Manager Node上创建一个Overlay网络，执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker network create --driver overlay my-network`</span><br></pre></td></tr></table></figure><p>创建完Overlay网络my-network以后，Swarm集群中所有的Manager Node都可以访问该网络。然后，我们在创建服务的时候，只需要指定使用的网络为已存在的Overlay网络即可，如下命令所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`docker service create \``  ``--replicas 3 \``  ``--network my-network \``  ``--name myweb \``  ``nginx`</span><br></pre></td></tr></table></figure><p>这样，如果Swarm集群中其他Node上的Docker容器也使用my-network这个网络，那么处于该Overlay网络中的所有容器之间，通过网络可以连通。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Docker集群管理和编排的特性是通过SwarmKit进行构建的， 其中Swarm mode是Docker Engine内置支持的一种默认实现。Docker 1.12以及更新的版本，都支持Swarm mode，我们可以基于Docker Engine来构建Swarm集群，然后
      
    
    </summary>
    
      <category term="Docker" scheme="http://blog.ozairs.com/categories/Docker/"/>
    
    
      <category term="docker swarm" scheme="http://blog.ozairs.com/tags/docker-swarm/"/>
    
  </entry>
  
  <entry>
    <title>为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation</title>
    <link href="http://blog.ozairs.com/Terraform/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8Terraform%E8%80%8C%E4%B8%8D%E6%98%AFChef%EF%BC%8CPuppet%EF%BC%8CAnsible%EF%BC%8CSaltStack%E6%88%96CloudFormation/"/>
    <id>http://blog.ozairs.com/Terraform/为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation/</id>
    <published>2019-03-29T21:59:47.000Z</published>
    <updated>2019-03-29T22:04:21.895Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/Terraform/为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation/1.png" alt=""></p><p>这是<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca" target="_blank" rel="noopener">Terraform系列综合指南的</a>第1部分。在本系列的介绍中，我们讨论了<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca" target="_blank" rel="noopener">为什么每家公司都应该使用基础架构代码（IAC）</a>。在这篇文章中，我们将讨论为什么我们选择Terraform作为我们选择的IAC工具。</p><p>如果您在互联网上搜索“基础架构即代码”，那么很容易想出一个最受欢迎的工具列表：</p><ul><li><a href="https://www.chef.io/" target="_blank" rel="noopener">Chef</a></li><li><a href="https://puppet.com/" target="_blank" rel="noopener">Puppet</a></li><li><a href="https://www.ansible.com/" target="_blank" rel="noopener">Ansible</a></li><li><a href="https://saltstack.com/" target="_blank" rel="noopener">SaltStack</a></li><li><a href="https://aws.amazon.com/cloudformation/" target="_blank" rel="noopener">CloudFormation</a></li><li><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a></li></ul><p>什么不容易找出你应该使用哪一个。所有这些工具都可用于将基础架构作为代码进行管理。所有这些都是开源的，由大型贡献者社区支持，并与许多不同的云提供商合作（除了CloudFormation，它是闭源和仅AWS）。所有这些都提供企业支持。所有这些都有很好的文档记录，包括官方文档和社区资源，如博客文章和StackOverflow问题。那你怎么决定？</p><p>更难以理解的是，您在这些工具之间在线找到的大多数比较只是列出每个工具的一般属性，并使其听起来像您可以同样成功地使用它们。虽然这在技术上是正确的，但它没有帮助。这有点像告诉编程新手，你可以用PHP，C或汇编建立一个网站同样成功 - 这个声明在技术上是正确的，但是省略了大量的信息，这些信息在做出正确的决定时非常有用。</p><p>在这篇文章中，我们将深入探讨为什么我们选择Terraform而不是其他IAC工具的一些非常具体的原因。与所有技术决策一样，这是一个权衡和优先级的问题，虽然您的特定优先级可能与我们的不同，但我们希望分享我们的思维过程将帮助您做出自己的决定。以下是我们考虑的主要权衡因素：</p><ul><li>配置管理与业务流程</li><li>可变基础设施与不可变基础设施</li><li>程序性与陈述性</li><li>客户端/服务器架构与仅客户端架构</li></ul><h3 id="配置管理与业务流程"><a href="#配置管理与业务流程" class="headerlink" title="配置管理与业务流程"></a>配置管理与业务流程</h3><p>Chef，Puppet，Ansible和SaltStack都是“配置管理”工具，这意味着它们旨在安装和管理现有服务器上的软件。CloudFormation和Terraform是“业务流程工具”，这意味着它们旨在自行配置服务器，将这些服务器配置为其他工具。这两个类别并不相互排斥，因为大多数配置管理工具都可以进行一定程度的配置，大多数编排工具可以进行某种程度的配置管理。但是，对配置管理或编排的关注意味着某些工具将更适合某些类型的任务。</p><p>特别是，我们发现如果您使用<a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a>或<a href="https://www.packer.io/" target="_blank" rel="noopener">Packer</a>，您的绝大多数配置管理需求已经得到了解决。使用Docker和Packer，您可以创建已安装和配置服务器所需的所有软件的映像（例如容器或虚拟机映像）（有关Docker的优缺点的详细信息，<a href="http://www.ybrikman.com/writing/2015/05/19/docker-osx-dev/" target="_blank" rel="noopener">请参阅此处</a>）。拥有这样的图像后，您只需要一台服务器即可运行它。如果您需要做的就是配置一堆服务器，那么像Terraform这样的编排工具通常比配置管理工具更合适（这里是一个<a href="https://github.com/brikis98/infrastructure-as-code-talk" target="_blank" rel="noopener">如何使用Terraform在AWS上部署Docker</a>的示例）。</p><h3 id="可变基础设施与不可变基础设施"><a href="#可变基础设施与不可变基础设施" class="headerlink" title="可变基础设施与不可变基础设施"></a>可变基础设施与不可变基础设施</h3><p>Chef，Puppet，Ansible和SaltStack等配置管理工具通常默认为可变基础架构范例。例如，如果您告诉Chef安装新版本的OpenSSL，它将在现有服务器上运行软件更新，并且更改将在原地进行。随着时间的推移，当您应用越来越多的更新时，每个服务器都会构建一个独特的更改历史记录。这通常会导致称为<em>配置漂移</em>的现象，其中每个服务器与所有其他服务器略有不同，导致难以诊断且几乎不可能再现的细微配置错误。</p><p>如果您正在使用Terraform等编排工具来部署Docker或Packer创建的机器映像，那么每个“更改”实际上都是新服务器的部署（就像函数式编程中变量的每次“更改”实际返回一样）新变量）。例如，要部署新版本的OpenSSL，您可以使用Packer或Docker创建新映像，并安装新版本的OpenSSL，将该映像部署到一组全新的服务器上，然后取消部署旧服务器。这种方法降低了配置偏移错误的可能性，使您更容易确切知道服务器上运行的软件，并允许您随时轻松部署任何以前版本的软件。当然，也可以强制配置管理工具进行不可变部署，</p><h3 id="程序性与陈述性"><a href="#程序性与陈述性" class="headerlink" title="程序性与陈述性"></a>程序性与陈述性</h3><p>Chef和Ansible鼓励一种程序风格，您可以编写代码，逐步指定如何实现某些所需的最终状态。Terraform，CloudFormation，SaltStack和Puppet都鼓励更具说明性的风格，您可以编写指定所需最终状态的代码，IAC工具本身负责确定如何实现该状态。</p><p>例如，假设您要部署10台服务器（AWS术语中的“EC2 Instances”）来运行应用程序的v1。以下是使用过程方法执行此操作的Ansible模板的简化示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-  ec2：</span><br><span class="line">    count：10 </span><br><span class="line">    image：ami-v1     </span><br><span class="line">    instance_type：t2.micro</span><br></pre></td></tr></table></figure><p>以下是使用声明方法执行相同操作的Terraform模板的简化示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">资源“aws_instance”“example”&#123; </span><br><span class="line">  count = 10 </span><br><span class="line">  ami =“ami-v1” </span><br><span class="line">  instance_type =“t2.micro” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在在表面上，这两种方法可能看起来相似，当您最初使用Ansible或Terraform执行它们时，它们将产生类似的结果。有趣的是，当您想要进行更改时会发生什么。</p><p>例如，假设流量已经增加，并且您希望将服务器数量增加到15.使用Ansible，您之前编写的过程代码不再有用; 如果您刚刚将服务器数量更新为15并重新启动该代码，那么它将部署15台新服务器，总共提供25台服务器！因此，您必须了解已部署的内容并编写一个全新的过程脚本来添加5个新服务器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-  ec2：</span><br><span class="line">    count：5 </span><br><span class="line">    image：ami-v1     </span><br><span class="line">    instance_type：t2.micro</span><br></pre></td></tr></table></figure><p>使用声明性代码，因为你所做的就是声明你想要的结束状态，而Terraform计算出如何到达那个结束状态，Terraform也会知道它过去创建的任何状态。因此，要部署另外5台服务器，您只需返回相同的Terraform模板并将计数从10更新为15：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Resource “aws_instance”“example”&#123; </span><br><span class="line">  count = 15 </span><br><span class="line">  ami =“ami-v1” </span><br><span class="line">  instance_type =“t2.micro” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果你执行了这个模板，Terraform会意识到它已经创建了10个服务器，因此它需要做的只是创建5个新服务器。实际上，在运行此模板之前，您可以使用Terraform的“计划”命令来预览它将进行的更改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt; terraform计划</span><br><span class="line">+ aws_instance.example.11 </span><br><span class="line">    ami：“ami-v1” </span><br><span class="line">    instance_type：“t2.micro”</span><br><span class="line">+ aws_instance.example.12 </span><br><span class="line">    ami：“ami-v1” </span><br><span class="line">    instance_type：“t2.micro”</span><br><span class="line">+ aws_instance.example.13 </span><br><span class="line">    ami：“ami-v1” </span><br><span class="line">    instance_type：“t2.micro”</span><br><span class="line">+ aws_instance.example.14 </span><br><span class="line">    ami：“ami-v1” </span><br><span class="line">    instance_type：“t2.micro”</span><br><span class="line">+ aws_instance.example.15 </span><br><span class="line">    ami：“ami-v1” </span><br><span class="line">    instance_type：“t2.micro”</span><br><span class="line">计划：5添加，0改变，0破坏。</span><br></pre></td></tr></table></figure><p>现在，当您想要部署v2服务时会发生什么？使用过程方法，您之前的两个Ansible模板都没有用，所以您必须编写另一个模板来跟踪之前部署的10个服务器（或者现在是15个？）并仔细更新每个模板到新版本。使用Terraform的声明式方法，您可以再次返回完全相同的模板，只需将ami版本号更改为v2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Resource “aws_instance”“example”&#123; </span><br><span class="line">  count = 15 </span><br><span class="line">  ami =“ami-v2” </span><br><span class="line">  instance_type =“t2.micro” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显然，上述例子是简化的。Ansible允许您在部署新的EC2实例之前使用标签来搜索现有的EC2实例（例如，使用instance_tags和count_tag参数），但是必须根据每个资源的情况为Ansible管理的每个资源手动找出这种逻辑。过去的历史，可能会令人惊讶地复杂化（例如，不仅通过标签，还可以通过图像版本，可用区域等查找现有实例）。这突出了程序IAC工具的两个主要问题：</p><ol><li>处理过程代码时，代码中<em>未</em>完全捕获基础结构的状态。阅读我们上面创建的三个Ansible模板并不足以了解已部署的内容。您还必须知道我们应用这些模板的<em>顺序</em>。如果我们以不同的顺序应用它们，我们最终可能会使用不同的基础结构，而这不是您在代码库本身中可以看到的。换句话说，要推理Ansible或Chef代码库，您必须知道所发生的每个更改的完整历史记录。</li><li>过程代码的可重用性本质上是有限的，因为您必须手动考虑代码库的当前状态。由于该状态不断变化，因此一周前使用的代码可能不再可用，因为它旨在修改不再存在的基础架构状态。结果，程序代码库随着时间的推移趋于变大和变得复杂。</li></ol><p>另一方面，使用Terraform中使用的声明式方法，代码始终代表基础架构的最新状态。一目了然，您可以分辨当前部署的内容及其配置方式，而无需担心历史记录或时间安排。这也使得创建可重用代码变得容易，因为您不必手动考虑当前的世界状态。相反，您只需专注于描述您想要的状态，Terraform会自动确定如何从一个状态到另一个状态。因此，Terraform代码库往往保持小巧且易于理解。</p><p>当然，声明性语言也有缺点。如果无法使用完整的编程语言，您的表达能力就会受到限制。例如，某些类型的基础架构更改（例如滚动，零停机部署）很难用纯粹的声明性术语表达。同样，如果没有“逻辑”（例如if语句，循环）的能力，创建通用的，可重用的代码可能会很棘手（特别是在CloudFormation中）。幸运的是，Terraform提供了许多强大的原语 - 例如<a href="https://www.terraform.io/intro/getting-started/variables.html" target="_blank" rel="noopener">输入变量</a>，<a href="https://www.terraform.io/intro/getting-started/outputs.html" target="_blank" rel="noopener">输出变量</a>，<a href="https://www.terraform.io/docs/modules/usage.html" target="_blank" rel="noopener">模块</a>，<a href="https://www.terraform.io/docs/configuration/resources.html#create_before_destroy" target="_blank" rel="noopener">create_before_destroy</a>，<a href="https://www.terraform.io/docs/configuration/resources.html#using-variables-with-count" target="_blank" rel="noopener">count</a>和<a href="https://www.terraform.io/docs/configuration/interpolation.html" target="_blank" rel="noopener">插值函数 </a> - 即使在声明性语言中，也可以创建干净，可配置的模块化代码。我们将在第4部分，<a href="https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d" target="_blank" rel="noopener">如何使用Terraform模块创建可重用的基础架构</a>和第5部分，<a href="https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9" target="_blank" rel="noopener">Terraform提示和技巧：循环，if语句和陷阱中</a>更多地讨论这些工具。</p><h3 id="客户端-服务器架构与仅客户端架构"><a href="#客户端-服务器架构与仅客户端架构" class="headerlink" title="客户端/服务器架构与仅客户端架构"></a>客户端/服务器架构与仅客户端架构</h3><p>Chef，Puppet和SaltStack默认都使用客户端/服务器架构。客户端可以是Web UI或CLI工具，用于发出命令（例如“部署X”）。这些命令转到服务器，服务器负责执行命令并存储系统状态。要执行这些命令，服务器会与代理进行通信，代理必须在您要配置的每台服务器上运行。这有许多缺点：</p><ul><li>您必须在每台服务器上安装和运行额外的软件。</li><li>您必须部署额外的服务器（甚至是服务器集群以实现高可用性），仅用于配置管理。</li><li>您不仅需要安装这些额外的软件和硬件，而且还必须对其进行维护，升级，备份，监控以及在发生中断时进行恢复。</li><li>由于客户端，服务器和代理都需要通过网络进行通信，因此必须为它们打开额外的端口，并配置它们相互进行身份验证的方式，所有这些都会增加攻击者的表面积。</li><li>所有这些额外的移动部件都会在您的基础架构中引入大量新的故障模式。当您在凌晨3点收到错误报告时，您必须弄清楚它是否是您的应用程序代码，IAC代码，配置管理客户端软件，配置管理代理软件或配置管理服务器软件中的错误，或所有这些配置管理部件用于通信的端口，或者它们彼此进行身份验证的方式，或者……</li></ul><p>CloudFormation，Ansible和Terraform使用仅客户端架构。实际上，CloudFormation也是客户端/服务器，但AWS透明地处理所有服务器细节，作为最终用户，您只需要考虑客户端代码。Ansible客户端通过SSH直接连接到您的服务器。Terraform使用云提供商API来配置基础架构，因此除了您已经使用云提供商之外，没有新的身份验证机制，也不需要直接访问您的服务器。我们发现这是易用性，安全性和可维护性方面的最佳选择。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>总而言之，下面的表格显示了最流行的IAC工具如何叠加：</p><p><img src="/Terraform/为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation/2.png" alt="img"></p><p>比较流行的基础架构作为代码工具。点击图像查看大图。请注意，此表显示了使用每个工具的“惯用”方式。</p><p>在Gruntwork，我们想要的是一个开源的，与云无关的编排工具，它支持不可变基础架构，声明性语言和仅客户端架构。从上表中可以看出，Terraform是唯一符合我们所有标准的工具。</p><p>当然，Terraform并不完美。它比名单上的所有其他工具更年轻，更不成熟：虽然Puppet于2005年推出，2009年是Chef，2011年是SaltStack和CloudFormation，2012年是Ansible，Terraform仅在2年前推出，2014年.Terraform仍然是pre 1.0.0（最新版本为0.7.4），因此无法保证稳定或向后兼容的API。错误相对常见（例如，标签“bug” 存在超过<a href="https://github.com/hashicorp/terraform/issues?q=is%3Aopen+is%3Aissue+label%3Abug" target="_blank" rel="noopener">800个未解决的问题</a>），尽管绝大多数都是无害的最终一致性问题，当您重新运行Terraform时这些问题就会消失。Terraform如何存储状态也存在一些问题，尽管我们将在第3部分：<a href="https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa" target="_blank" rel="noopener">如何管理Terraform状态中</a>讨论这些问题的有效解决方案。</p><p>尽管有它的缺点，我们发现Terraform的优势远远超过它的弱点，并且没有其他IAC工具几乎符合我们的标准。如果Terraform听起来像是符合您标准的东西，请转到第2部分：<a href="https://blog.gruntwork.io/an-introduction-to-terraform-f17df9c6d180" target="_blank" rel="noopener">Terraform简介</a>，了解更多信息。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/Terraform/为什么我们使用Terraform而不是Chef，Puppet，Ansible，SaltStack或CloudFormation/1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;这是&lt;a href=&quot;https://blog.gruntw
      
    
    </summary>
    
      <category term="Terraform" scheme="http://blog.ozairs.com/categories/Terraform/"/>
    
    
      <category term="Iac" scheme="http://blog.ozairs.com/tags/Iac/"/>
    
  </entry>
  
  <entry>
    <title>使用Jenkins Pipeline进行持续集成</title>
    <link href="http://blog.ozairs.com/Jenkins/%E4%BD%BF%E7%94%A8Jenkins-Pipeline%E8%BF%9B%E8%A1%8C%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"/>
    <id>http://blog.ozairs.com/Jenkins/使用Jenkins-Pipeline进行持续集成/</id>
    <published>2019-03-29T06:16:10.000Z</published>
    <updated>2019-03-29T06:18:18.570Z</updated>
    
    <content type="html"><![CDATA[<p>本文<a href="http://syndicode.co/2016/06/02/continuous-integration-and-delivery-with-github-gitflow-and-jenkins/" target="_blank" rel="noopener">与Github，Gitflow和Jenkins持续集成和交付</a>的内容有关。但这次我将扩展与Jenkins持续集成的主题，并深入探讨Jenkins Pipelines的细节。在这里，您将找到有关与Jenkins Pipeline持续集成的所有信息！</p><p>好的，确定你知道这一切，但基本条款永远不会让情况更糟。我们将从他们开始。</p><h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><p><strong>Jenkins</strong>是一个开源的持续集成（CI）工具，可以通过自动化帮助协调开发过程（构建，测试和部署）。换句话说，Jenkins是帮助开发团队实现其流程工业化的领先工具之一。这是开发人员的队友，当您在特定分支（主控和开发）上推送代码时，您可以要求将代码投入生产（或升级）。</p><p>正如您所知，<strong>CI（持续集成）</strong>是将所有开发人员工作副本每天多次合并到共享主线的做法。</p><p>Jenkins很有用，因为它将自由式作业编排成CI管道。</p><p><strong>Pipeline（Jenkins Pipeline）</strong>是一套插件，支持在Jenkins中实现和集成连续交付管道。持续交付管道是您将软件从版本控制直至用户和客户的过程的自动表达。</p><p>Pipeline为Jenkins添加了一套功能强大的自动化工具。设置管道项目意味着编写一个脚本，该脚本将按顺序应用我们想要完成的流程的一些步骤。</p><p><strong>Jenkinsfile</strong>是一个文本文件，包含Jenkins管道的定义，并被检入源代码管理。</p><p><strong>构建作业</strong>是由Jenkins控制和监视的可运行任务。作业示例包括编译源代码，运行测试，配置测试环境，部署，归档，发布构建作业（如报告）以及执行任意脚本。</p><h3 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h3><h4 id="Jenkins管道功能"><a href="#Jenkins管道功能" class="headerlink" title="Jenkins管道功能"></a>Jenkins管道功能</h4><ul><li><strong>代码</strong>：管道在代码中实现，通常检查到源代码控制中，使团队能够编辑，审查和迭代其交付管道。</li><li><strong>持久</strong>：管道可以在Jenkins主计划的计划内和计划外重启中存活。</li><li><strong>Pausable</strong>：在继续管道运行之前，管道可以选择停止并等待人工输入或批准。</li><li><strong>功能多样</strong>：管道支持复杂的实际连续交付要求，包括并行分叉/连接，循环和执行工作的能力。</li><li><strong>可扩展</strong>：Pipeline插件支持其DSL（特定于域的语言）的自定义扩展以及与其他插件集成的多个选项。</li></ul><h4 id="Jenkins管道条款"><a href="#Jenkins管道条款" class="headerlink" title="Jenkins管道条款"></a>Jenkins管道条款</h4><p><strong>步骤</strong>  - 单个任务; 从根本上说步Jenkins<em>是什么</em>做的。</p><p><strong>节点</strong>。Pipeline执行的大多数<em>工作</em>是在一个或多个声明的<strong>节点步骤</strong>的上下文中完成的。节点选择管道将在何处执行。限制节点步骤内的工作有两个作用：</p><ol><li>通过向Jenkins队列添加项来计划要运行的块中包含的步骤。只要执行程序在节点上空闲，步骤就会运行。</li><li>创建工作空间（特定于该特定管道的目录），可以对从源控件检出的文件进行工作。</li></ol><p><strong>阶段</strong>是定义整个管道的概念上不同的子集的步骤，例如：“构建”，“测试”和“部署”，许多插件使用它来可视化或呈现Jenkins管道状态/进度。</p><p><strong>声明性和脚本化管道</strong></p><p>Jenkins Pipeline正在使用具有两种不同语法的域特定语言（DSL）：</p><ul><li>Declarative Pipeline<br>在Pipeline子系统之上提供了更简化和固定的语法。</li><li>Scripted Pipeline<br>遵循使用Groovy构建的更强制的编程模型。</li></ul><h3 id="Jenkinsfile"><a href="#Jenkinsfile" class="headerlink" title="Jenkinsfile"></a>Jenkinsfile</h3><p>Jenkinsfile用于替换当前使用的三个Jenkins构建作业：</p><ul><li>主要集成分支的<strong>多</strong>分支：开发，发布，修补程序和主服务器。</li><li><strong>合并</strong>自动测试GitLab合并请求的请求。</li><li><strong>参数化为</strong>按需测试。</li></ul><p><strong>使用Jenkinsfile可以解决的问题</strong></p><ul><li>将CI / CD管道定义为代码，使其自我记录，可重现和版本化。</li><li>对任何类型的构建作业都有单一的构建步骤定义，无论是多分支，合并请求还是参数化。</li><li>远离构建步骤的手动配置。</li><li>使管道易于扩展。例如，将新的静态分析工具报告添加到所有已配置的构建作业中应该不复杂。</li></ul><h3 id="将您的代码投入生产"><a href="#将您的代码投入生产" class="headerlink" title="将您的代码投入生产"></a>将您的代码投入生产</h3><h4 id="定义管道"><a href="#定义管道" class="headerlink" title="定义管道"></a>定义管道</h4><ol><li>设置/配置构建环境。</li><li>看看你的代码。</li><li>构建代码。确保您不使用任何特定于环境的构建过程设置可以独立于环境。</li><li>执行质量控制。此步骤包含两个主要任务：运行测试和执行代码质量检查。</li><li>在Continuous Integration环境中部署代码。</li><li>运行功能测试。</li><li>在测试环境中部署代码。</li><li>在用户接受环境中部署代码。</li><li>在生产环境中部署代码。</li></ol><p>触发作业的一种常见方法是将更改提交到存储库。这意味着当开发人员完成开发任务并将其更改推送到项目的存储库时（例如，如果您使用Git，则执行Git push命令），该作业将自动触发。一个简单的方法是通过<a href="https://wiki.jenkins-ci.org/display/JENKINS/GitHub+Plugin" target="_blank" rel="noopener">GitHub Jenkins插件</a>。</p><h4 id="Jenkins部署的最佳实践"><a href="#Jenkins部署的最佳实践" class="headerlink" title="Jenkins部署的最佳实践"></a>Jenkins部署的最佳实践</h4><ul><li>Jenkins不会将默认配置作为其默认配置的一部分执行任何安全检查，因此请始终确保对Jenkins服务器上的用户进行身份验证并强制实施访问控制。<strong>保护您的Jenkins服务器</strong>。</li><li>在包含多个配置作业的用户的大型复杂集成环境中，应确保它们不在主服务器上运行构建，并且可以无限制地访问JENKINS_HOME目录。<strong>小心的主机</strong>。</li><li>为确保在需要时可以<strong>使用</strong>所有配置和活动日志，请<strong>使用备份配置</strong>。</li><li>Jenkins需要磁盘空间来执行构建，存储数据日志和保存存档。要保持Jenkins的正常运行，请确保<strong>为Jenkins保留10％或更多的磁盘空间，</strong>以防止出现碎片。</li><li>Jenkins 2.0版本提供了代码管道，新的安装体验和一些UI改进。用它。（您可以在文章末尾添加“管道作为代码”链接找到更多相关信息）。</li></ul><h4 id="Jenkins-Pipeline插件的最佳实践："><a href="#Jenkins-Pipeline插件的最佳实践：" class="headerlink" title="Jenkins Pipeline插件的最佳实践："></a>Jenkins Pipeline插件的最佳实践：</h4><ol><li>不要使用像Build Pipeline插件或Buildflow插件这样的旧插件。相反，使用真正的Jenkins Pipeline插件套件。</li><li>将您的管道开发为代码。使用该功能将Jenkins文件存储在SCM中然后版本中，并像测试其他软件一样进行测试。</li><li>管道中的任何非设置工作都应在阶段块中进行。</li><li>Pipeline提供了一种简单的语法，用于将管道分支为并行步骤。用它！</li><li>Pipeline有一个简单的机制来超时管道的任何给定步骤。作为最佳实践，您应该始终计划输入周围的超时。</li><li>使用env全局变量设置环境变量。</li></ol><h3 id="有用的资源"><a href="#有用的资源" class="headerlink" title="有用的资源"></a>有用的资源</h3><ul><li><a href="https://jenkins.io/" target="_blank" rel="noopener">Jenkins官方网站</a></li><li>包含片段，提示和技巧的<a href="https://github.com/jenkinsci/pipeline-examples" target="_blank" rel="noopener">存储库</a>以及Jenkins管道插件的脚本示例</li><li>Jenkins Pipeline <a href="https://jenkins.io/doc/book/pipeline/getting-started/" target="_blank" rel="noopener">入门</a></li><li>管道<a href="https://jenkins.io/doc/book/pipeline/syntax/" target="_blank" rel="noopener">语法</a></li><li><a href="http://www.baeldung.com/jenkins-pipelines" target="_blank" rel="noopener">Jenkins简介2</a></li><li><a href="https://jenkins.io/solutions/pipeline/" target="_blank" rel="noopener">管道作为代码</a></li><li><a href="https://vetlugin.wordpress.com/2017/01/31/guide-jenkins-pipeline-merge-requests/" target="_blank" rel="noopener">处理Jenkins管道中的合并请求</a></li><li><a href="https://dzone.com/refcardz/declarative-pipeline-with-jenkins" target="_blank" rel="noopener">Jenkins的声明性管道</a></li><li><a href="https://www.atlassian.com/blog/continuous-delivery/practical-continuous-deployment" target="_blank" rel="noopener">实用的持续部署</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文&lt;a href=&quot;http://syndicode.co/2016/06/02/continuous-integration-and-delivery-with-github-gitflow-and-jenkins/&quot; target=&quot;_blank&quot; rel=&quot;noop
      
    
    </summary>
    
      <category term="Jenkins" scheme="http://blog.ozairs.com/categories/Jenkins/"/>
    
    
      <category term="Pipeline" scheme="http://blog.ozairs.com/tags/Pipeline/"/>
    
  </entry>
  
  <entry>
    <title>使用凭据文件向AWS进行身份验证</title>
    <link href="http://blog.ozairs.com/AWS/%E4%BD%BF%E7%94%A8%E5%87%AD%E6%8D%AE%E6%96%87%E4%BB%B6%E5%90%91AWS%E8%BF%9B%E8%A1%8C%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81/"/>
    <id>http://blog.ozairs.com/AWS/使用凭据文件向AWS进行身份验证/</id>
    <published>2019-03-29T03:44:36.000Z</published>
    <updated>2019-03-29T03:45:28.772Z</updated>
    
    <content type="html"><![CDATA[<p>这是<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799" target="_blank" rel="noopener">在命令行上对AWS进行身份验证</a>的<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799" target="_blank" rel="noopener">综合指南的</a>第1部分。在本<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799" target="_blank" rel="noopener">系列</a>的<a href="https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799" target="_blank" rel="noopener">介绍中</a>，我们介绍了AWS身份验证的基础知识，包括IAM用户，IAM角色和访问密钥。在这篇文章中，我们将介绍在命令行上对AWS进行身份验证的第一个选项：凭据文件。</p><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><p>您可以将AWS Access密钥存储在（或在Windows上）的<em>凭据文件</em>中。通常，您创建此文件的方式是<a href="https://docs.aws.amazon.com/cli/latest/userguide/installing.html" target="_blank" rel="noopener">安装AWS CLI</a>并运行命令：<code>~/.aws/credentials`</code>%UserProfile%.aws\credentials<code></code>aws configure`</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ aws configure </span><br><span class="line">AWS Access密钥ID：AKIAIOSFODNN7EXAMPLE </span><br><span class="line">AWS秘密访问密钥：wJalrXUtnFEMI / K7MDENG / bPxRfiCYEXAMPLEKEY </span><br><span class="line">默认区域名称[无]：us-west-2 </span><br><span class="line">默认输出格式[无]：json</span><br></pre></td></tr></table></figure><p>AWS会提示您输入您的访问密钥ID和秘密访问密钥，并将其存储在<code>~/.aws/credentials</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[默认] </span><br><span class="line">aws_access_key_id = AKIAIOSFODNN7EXAMPLE </span><br><span class="line">aws_secret_access_key = wJalrXUtnFEMI / K7MDENG / bPxRfiCYEXAMPLEKEY</span><br></pre></td></tr></table></figure><p>它还存储您输入的其他设置<code>~/.aws/config</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[default] </span><br><span class="line">region = us-west-2 </span><br><span class="line">output = json</span><br></pre></td></tr></table></figure><p>存在这些文件后，您可以运行与AWS通信的任何CLI或SDK工具，它将自动查找并使用此凭据文件和设置。</p><h3 id="使用多组访问密钥"><a href="#使用多组访问密钥" class="headerlink" title="使用多组访问密钥"></a>使用多组访问密钥</h3><p>如果您有多组访问密钥（例如，对于不同AWS账户中的多个IAM用户），您可以在凭证文件中为每个用户创建单独的<em>命名配置</em> 文件<code>~/.aws/credentials</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[默认] </span><br><span class="line">aws_access_key_id = AKIAIOSFODNN7EXAMPLE </span><br><span class="line">aws_secret_access_key = wJalrXUtnFEMI / K7MDENG / bPxRfiCYEXAMPLEKEY</span><br><span class="line">[user2] </span><br><span class="line">aws_access_key_id = AKIAI44QH8DHBEXAMPLE </span><br><span class="line">aws_secret_access_key = je7MtGbClwBF / 2Zp9Utk / h3yCo8nvbEXAMPLEKEY</span><br></pre></td></tr></table></figure><p>同样，您可以在配置文件中拥有多个命名配置文件<code>~/.aws/config</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[default] </span><br><span class="line">region = us-west-2 </span><br><span class="line">output = json</span><br><span class="line">[profile user2] </span><br><span class="line">region = us-east-1 </span><br><span class="line">output = text</span><br></pre></td></tr></table></figure><p>请注意，<code>default</code>默认情况下，您可能会使用所调用的命名配置文件。要告诉CLI工具使用除<code>default</code>配置文件之外的其他内容，您必须执行以下操作之一：</p><ol><li>设置<code>AWS_PROFILE</code>环境变量。例如，在Linux中，你会运行<code>export AWS_PROFILE=user2</code>。之后，您可以运行任何AWS CLI工具（例如<code>terraform apply</code>），它应该使用您的命名配置文件。</li><li>某些工具允许您将配置文件指定为命令行参数或代码中的参数。例如，<code>aws</code>CLI允许您指定<code>--profile</code>：<code>aws ec2 describe-instances --profile user2</code>。在Terraform中，您可以<code>profile</code>在<code>provider</code>块中设置参数：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">提供者“aws”&#123; </span><br><span class="line">  profile =“user2” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用IAM角色"><a href="#使用IAM角色" class="headerlink" title="使用IAM角色"></a>使用IAM角色</h3><p>如果您想假设IAM角色 - 例如，您在<code>security</code>帐户中有一个IAM用户并想在您的<code>dev</code>帐户中承担IAM角色- 您有两个选择。第一个选项取决于您正在使用的CLI工具。某些CLI工具允许您通过命令行参数或代码指定要承担的IAM角色。例如，使用Terraform，您可以<code>assume_role</code>在<code>provider</code>配置中指定设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">provider“aws”&#123; </span><br><span class="line">  assume_role &#123; </span><br><span class="line">    role_arn =“arn：aws：iam :: 123456789012：role / dev-full-access” </span><br><span class="line">  &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二个选项是<code>role_arn</code>在Config File中指定参数<code>~/.aws/config</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[profile dev-full-access] </span><br><span class="line">role_arn = arn：aws：iam :: 123456789012：role / dev-full-access</span><br></pre></td></tr></table></figure><p>使用任一选项，您指定的值<code>role_arn</code>是开发帐户中IAM角色的<a href="https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html" target="_blank" rel="noopener">Amazon资源名称（ARN）</a>，其格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ARN：AWS：IAM :: &lt;ACCOUNT_ID&gt;：角色/ &lt;ROLE_NAME&gt;</span><br></pre></td></tr></table></figure><p>下次运行使用<code>dev-full-access</code>命名配置文件的任何CLI命令时，AWS SDK将自动采用指定的IAM角色<code>role_arn</code>。</p><h3 id="与MFA合作"><a href="#与MFA合作" class="headerlink" title="与MFA合作"></a>与MFA合作</h3><p>如果您正在使用<code>aws</code>CLI，则使用带有凭据配置文件的MFA非常简单。您只需将其添加<code>mfa_serial</code>到您的配置文件中<code>~/.aws/config</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[profile with-mfa] </span><br><span class="line">mfa_serial = arn：aws：iam :: 123456789012：mfa / jon-doe</span><br></pre></td></tr></table></figure><p>该<code>mfa_serial</code>参数应设置为MFA设备的ARN，您可以从AWS Web Console 的<a href="https://console.aws.amazon.com/iam/home?#/users" target="_blank" rel="noopener">IAM用户页面</a>获取该ARN 。它应该是这样的格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ARN：AWS：IAM :: &lt;ACCOUNT_ID&gt;：MFA / &lt;USERNAME&gt;</span><br></pre></td></tr></table></figure><p>添加<code>mfa_serial</code>参数后，下次<code>aws</code>使用该命名配置文件运行CLI时，它将提示您输入MFA令牌：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ aws s3 ls --profile with-mfa</span><br><span class="line">输入MFA代码：</span><br></pre></td></tr></table></figure><p>但是如果你运行的东西不是<code>aws</code>，比如<code>terraform</code>或者<code>packer</code>怎么办？在这种情况下，事情变得有点毛茸茸，因为大多数其他工具<em>不会</em>自动提示您输入MFA令牌。相反，您必须在该工具之外执行MFA身份验证过程，这是一个<a href="https://aws.amazon.com/premiumsupport/knowledge-center/authenticate-mfa-cli/" target="_blank" rel="noopener">单调乏味的过程</a>。</p><p>首先，使用普通（永久）AWS Access Keys配置凭证文件（例如，通过运行<code>aws configure</code>）。接下来，您运行该<code>aws sts get-session-token</code>命令，将其传递给您的MFA设备的ARN以及来自Google身份验证器应用程序或您的密钥卡的MFA令牌：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aws sts get-session-token \ </span><br><span class="line">  --serial-number arn：aws：iam :: 123456789012：mfa / jon-doe \ </span><br><span class="line">  --token-code 123456 \ </span><br><span class="line">  --duration-seconds 43200</span><br></pre></td></tr></table></figure><p>这将返回一个包含<em>临时访问密钥</em>的JSON blob （请注意<code>--duration-seconds</code>前面命令中的参数，该参数指定这些临时访问密钥何时到期）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123; </span><br><span class="line">  “Credentials”：&#123; </span><br><span class="line">    “SecretAccessKey”：“secret-access-key”，</span><br><span class="line">    “SessionToken”：“temporary-session-token”，</span><br><span class="line">    “Expiration”：“expiration-date-time”，</span><br><span class="line">    “AccessKeyId”：“access-key -id“ </span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>您需要获取这些临时访问密钥并将其复制到凭证文件中的命名配置文件中<code>~/.aws/credentials</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[with-mfa] </span><br><span class="line">aws_access_key_id = &lt;Access-key-as-in-returned-output&gt; </span><br><span class="line">aws_secret_access_key = &lt;Secret-access-key-as-in-returned-output&gt; </span><br><span class="line">aws_session_token = &lt;Session-Token-as-in-returned-输出&gt;</span><br></pre></td></tr></table></figure><p>需要注意的是临时接入键，可以设置不仅<code>aws_access_key_id</code>和<code>aws_secret_access_key</code>你的证书文件，同时也<code>aws_session_token</code>。</p><p>现在，您可以使用此命名配置文件运行其他CLI工具：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">导出AWS_PROFILE = with-mfa </span><br><span class="line">terraform apply</span><br></pre></td></tr></table></figure><p>请注意，临时访问密钥在一段时间（通常为12小时）后过期，因此您必须反复执行此操作。不好玩。</p><h3 id="优点和缺点"><a href="#优点和缺点" class="headerlink" title="优点和缺点"></a>优点和缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>基本身份验证很容易。</li><li>使用IAM角色很容易。</li><li>命名配置文件可以轻松管理多组凭据和设置。</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>您的访问密钥以明文形式存储在磁盘上。<strong>这不安全。</strong></li><li>您始终使用永久访问密钥进行身份验证，而不是使用已轮换的临时访问密钥。</li><li>使用MFA很复杂且容易出错。</li><li>您的凭据永远位于磁盘上，如果您忘记指定其他命令，则默认的命名配置文件将用于所有命令，这很容易出错。</li><li>在您的代码中指定命名配置文件（例如，在您的Terraform代码中）很有诱惑力，以确保使用正确的凭据，但这需要您的所有团队成员为您的命名配置文件使用相同的名称，这可能很难强制执行。</li></ul><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>尽管许多AWS教程都使用凭证文件，但我们通常建议不要使用凭证文件，因为以明文形式将永久AWS凭证存储在磁盘上并不安全。更糟糕的是，使用凭据文件时，MFA的使用非常复杂，大多数用户都不会为此烦恼。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是&lt;a href=&quot;https://blog.gruntwork.io/a-comprehensive-guide-to-authenticating-to-aws-on-the-command-line-63656a686799&quot; target=&quot;_blank&quot; rel
      
    
    </summary>
    
      <category term="AWS" scheme="http://blog.ozairs.com/categories/AWS/"/>
    
    
      <category term="Credential" scheme="http://blog.ozairs.com/tags/Credential/"/>
    
  </entry>
  
  <entry>
    <title>【DevOps进阶之路Day1】精通Jenkins Pipeline PartI</title>
    <link href="http://blog.ozairs.com/Jenkins/%E7%B2%BE%E9%80%9AJenkins-Pipeline-PartI/"/>
    <id>http://blog.ozairs.com/Jenkins/精通Jenkins-Pipeline-PartI/</id>
    <published>2019-03-28T11:48:43.000Z</published>
    <updated>2019-03-28T12:00:08.126Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p><img src="/Jenkins/精通Jenkins-Pipeline-PartI/1.png" alt="jenkins的图像结果"></p><p>詹金斯</p><p>使用过水电工Travis-CI的朋友们，应该很多都试过翘胡子Jenkins。不过笔者猜应该大多数的朋友都是使用Jenkins的自由风格项目。</p><p>虽然Free Style项目可以让你客制化任何的Shell Script来执行你想要的脚本进行测试，但其脚本会依赖Jenkins节点上的环境来执行，Jenkins节点上的任何环境改变都可能影响到你的build job的状况，譬如说，系统套件的升级，工具路径的修改，不同的Job间互相的影响…等等。</p><p>此时，最好的做法是将每个Build Job都用VM或Container做隔离，确保每次执行建置的工作环境都是一样的。</p><p>Travis CI的做法是，为了避免给个建筑互相影响，会为每一个建置都开一台全新的GCE Instance，即使你的测试是在Container mode下执行，都会是全新的VM环境。</p><p>然而Travis CI采用YAML格式的设定档格式，这种做法虽然容易使用，但伴随而来的缺点就是动态性不足，你无法轻易的将某个Step产生出来的结果，做出一些逻辑判断，然后再把不同的操作逻辑丢到另外一台机器上平行执行。</p><p>在Jenkins上的选择相对得多，为了解决日渐庞大复杂的Build Flow，2016年四月Jenkins释出了Pipeline plugin，提供所谓的流水线建设功能来让建设工作变得容易扩大。而这个Pipeline Plugin是基于一种语言 - Apache Groovy开发的。</p><p>这系列文章不是要教读者一步一步如何使用Jenkins Pipeline，而是跟读者们解释Jenkins Pipeline的底层机制，在开发时，可以避免去踩到这些相关（你以为可以，但却不行）的陷阱。</p><h3 id="Apache-Groovy"><a href="#Apache-Groovy" class="headerlink" title="Apache Groovy"></a>Apache Groovy</h3><p>可能很多人对Apache Groovy很陌生，Apache Groovy是一位名叫James Strachan的Java开发者于2003年开发出的一套Java语法相容的新语言，在当时纳入了如Ruby，Perl，Python，Smalltalk ，功能语言等语言的特性，可以被静态编译，也可以被动态执行.Groovy可被编译为JVM字节码在JVM上执行，除此之外，Groovy也可使用Java原生套件，你可以一部分用Java写，一部分使用Groovy去调用Java的类。</p><p>在Groovy里的Closure也可以像函数式语言一样，使用Curry（部分申请）。</p><p>2007年约为Rails火红的年代，Groovy的设计在JAX 2007得到创新奖，2008年时的Grails（Groovy web framework）也在JAX 2008年得到创新奖。</p><p>后来设计Groovy和Grails的这家公司G2One被SpringSource收购，而2009年时VMware又收购了SpringSource。</p><p>一直谈Groovy的背景，可能很多人还是很难想像Groovy的程式码长什么样子，我们就来看几个范例：</p><p>很像Java的范例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class  AGroovyBean &#123; </span><br><span class="line">  String color </span><br><span class="line">&#125; </span><br><span class="line">def bean = new AGroovyBean（）; </span><br><span class="line">bean.color =“baby blue” </span><br><span class="line">bean.setColor（“baby blue”）</span><br></pre></td></tr></table></figure><p>很像Ruby + Perl的范例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//相当于：取（2.pills）.of（氯喹）。之后（6.hours）6小时后服用2.pill的氯喹</span><br></pre></td></tr></table></figure><p>同Perl与Ruby，在Groovy里面的函数调用的圆括号是可以省略的，Closure也有多种写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def run = &#123;println it&#125; </span><br><span class="line">def run = &#123; - &gt; println it&#125; </span><br><span class="line">def run = &#123;a  - &gt; println a&#125;</span><br></pre></td></tr></table></figure><p>上面三种写法都是一样的。</p><p>此外Groovy本身针对DSL提供一些特别的语言功能，让你可以写出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">withDocker（“mysql：5.7”）&#123; </span><br><span class="line">    sh“....” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>像上面这样的程式码，他在Pipeline里实际上的语意与下列程式码相同：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">this.withDocker（“mysql：5.7”，&#123; - &gt; </span><br><span class="line">    this.sh（“...”）</span><br><span class="line">&#125;）</span><br></pre></td></tr></table></figure><h3 id="管道DSL"><a href="#管道DSL" class="headerlink" title="管道DSL"></a>管道DSL</h3><p>回到Jenkins Pipeline，为什么Jenkins管道使用Groovy设计呢？主要是因为整个Jenkins生态系都是使用Java开发而成，而Java却不适合拿来设计Build Job的DSL（Domain Specific Language），Groovy既相容Java ，JVM就被Jenkins作者拿来设计Pipeline Plugin了。</p><p>编程语言有了DSL的强大功能，你就可以使用这样简化的语法，针对你的Build Pipeline写出一个以程序语言为基础的设定档案。</p><p>譬如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">节点（“ec2”）&#123; </span><br><span class="line">    sh“echo Hello World” </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的范例就是一个最简单的Scripted Pipeline，纯Groovy的写法，意思是找到一台label为<code>ec2</code>的机器，然后在这台机器上面执行shell命令：“echo Hello World”。</p><p>这边要稍微说明一下，Jenkins Pipeline的语法分为两种，Scripted Pipeline与Declarative Pipeline。</p><p>这两种语法官方网站上并没有详细解释底层机制的不同，由笔者解释的话，<code>Scripted Pipeline</code>就是原生的Groovy Script，会在Jenkins里面的Groovy Shell执行。</p><p>而<code>Declarative Pipeline</code>相对复杂一些，<code>pipeline</code>这个关键字在<code>Jenkinsfile</code>里面是一个步骤（实际上是方法），这个步骤（方法）会将后面整个封闭的代码，对…就是程式码，带入到Pipeline Model Plugin的核心，用一套Groovy写成的Pipeline Model Parser来重新剖析程式码，转为AST后，再经过Groovy的AST Transformer来重新建构整个Pipeline的逻辑。</p><p>也因此你常用的Declarative Pipeline里面，<code>pipeline { }</code>所包起来的部分并不是纯Groovy Syntax，他利用客制化的剖析器（Parser）来达成一些语意上的限制。</p><h3 id="Jenkinsfile"><a href="#Jenkinsfile" class="headerlink" title="Jenkinsfile"></a>Jenkinsfile</h3><p>在Groovy里面，万物皆为类，既使是脚本文件，也都被无形的类包装起来。</p><p>举例来说，你开一个纯文字档案叫<code>test.groovy</code>，然后在里面写入一段代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">println this.getClass（）</span><br></pre></td></tr></table></figure><p>结果会印出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">班级考试</span><br></pre></td></tr></table></figure><p>发现什么了吗？也就是说，当Jenkins在执行你的<code>Jenkinsfile</code>的时候，你在<code>Jenkinsfile</code>里就是在类的某个方法里面执行，而你的档案名称就变成你的类名。怎么证明呢？</p><p>如果你尝试把Call Stack dump出来会看到什么呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StackTraceElement [] cause = Thread.currentThread（）。getStackTrace（）; </span><br><span class="line">打印原因</span><br></pre></td></tr></table></figure><p>结果是：</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*xr_89aKHzfC7BkcnzOq5JQ.png" alt="img"></p><p>注意到上面，，<code>test.run</code>其实意味着我们脚本里面写的程式码，是被包装在一个叫做run的方法里面执行的。</p><p>Groovy会编译你的程式码，转换为一个继承<code>groovy.lang.Script</code>的类别，这个类别包含了一个抽象化的方法（方法）叫做<code>run</code>。</p><p>当这个脚本被编译时，脚本体会变成这个运行方法的一部分，而其他的方法定义会转为这个类实现的一部分。</p><p>这个Stack Call往上追，你会看到<code>GroovyShell.run</code>，这是什么东西呢？</p><p><code>GroovyShell</code> 提供了一个介面，让你可以在Groovy里面动态建立一个执行环境，然后在这个沙盒里面执行程式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def binding = new Binding（）               </span><br><span class="line">def shell = new GroovyShell（binding）binding.setVariable（      </span><br><span class="line">&apos;x&apos;，1）                </span><br><span class="line">binding.setVariable（&apos;y&apos;，3）</span><br><span class="line">shell.evaluate&apos;z = 2 * x + y&apos;assert                  </span><br><span class="line">binding。 getVariable（&apos;z&apos;）== 5</span><br></pre></td></tr></table></figure><p><code>Binding</code>就是用来连结目前的执行环境与沙盒执行环境的类别，而Jenkins就是利用Binding来将Jenkins的环境资讯注入到<code>Jenkinsfile</code>执行的。</p><p>而这个脚本基类可以被客制化，DSL的设计师可以将这个基类改为自己特制的类来提供一些特别功能。</p><p>举例来说：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DEF配置=新CompilerConfiguration（）config.scriptBaseClass = &apos;MyBaseClass&apos;高清壳=新GroovyShell（this.class.classLoader，配置）shell.evaluate “” “ </span><br><span class="line">     的setName &apos;朱迪思&apos; </span><br><span class="line">     迎接（） </span><br><span class="line">”“”</span><br></pre></td></tr></table></figure><p>而你可以实作一个类叫做<code>MyBaseClass</code>来来提供<code>setName</code>与<code>greet</code>方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">抽象类MyBaseClass扩展Script &#123; </span><br><span class="line">     String name </span><br><span class="line">     public void greet（）&#123; </span><br><span class="line">         println“Hello，$ name！” </span><br><span class="line">     &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这边我想读者已经很清楚了，为什么Jenkinsfile里面会有<code>sh</code>，<code>pipeline</code>，<code>echo</code>这些特有的函数可以用？</p><p>其实，你当使用<code>pipeline {}</code>的时候，他实际上就是等于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">this.pipeline（&#123; - &gt; </span><br><span class="line">&#125;）</span><br></pre></td></tr></table></figure><p>今天的Jenkins实作细节就先到这边，下集待续。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/Jenkins/精通Jenkins-Pipeline-PartI/1.png&quot; alt=&quot;jenkins的图像结果&quot;&gt;
      
    
    </summary>
    
      <category term="Jenkins" scheme="http://blog.ozairs.com/categories/Jenkins/"/>
    
    
      <category term="Pipeline" scheme="http://blog.ozairs.com/tags/Pipeline/"/>
    
  </entry>
  
  <entry>
    <title>如何遵循尽职调查法，做更多有效的工作</title>
    <link href="http://blog.ozairs.com/%E8%AF%84%E8%AE%BA/%E5%A6%82%E4%BD%95%E9%81%B5%E5%BE%AA%E5%B0%BD%E8%81%8C%E8%B0%83%E6%9F%A5%E6%B3%95%EF%BC%8C%E5%81%9A%E6%9B%B4%E5%A4%9A%E6%9C%89%E6%95%88%E7%9A%84%E5%B7%A5%E4%BD%9C/"/>
    <id>http://blog.ozairs.com/评论/如何遵循尽职调查法，做更多有效的工作/</id>
    <published>2019-03-26T02:56:31.000Z</published>
    <updated>2019-03-26T03:09:34.360Z</updated>
    
    <content type="html"><![CDATA[<p>【译文】</p><p>ç什么容易谈到apitalizing是人们如何成功往往会获得成功。它也是成功故事的一部分，经常被遗漏，因为如果没有被误解，几乎不可能谈论它。</p><p>成功的人不努力工作（这个词，“难”，有错误的含义）。成功人士不会继续向死胡同努力。他们也不会强迫什么是不可行的，无效的，或者根本就是不锻炼。他们在看到最多结果的地方一直工作，他们能够经常工作的原因 - 通常比同龄人更多 - 是因为工作对他们来说有点自然。如果没有，他们就会筋疲力尽，被烧毁，而且结果很少。</p><p>传统智慧告诉你不要放弃<em>，</em>无论如何。但人们总是告诉你，当你停止努力让事情发生时，好事往往会发生。最受欢迎的关系建议是，当我们停止寻找他们时，我们的合作伙伴会出现。对于许多夫妻来说，他们想要怀孕的那一刻就是他们怀孕的那一刻。</p><p>当你试图强迫幸福时，它就会让你失望。如果不这样做，它往往会自行发生。你最终在生活中所做的工作几乎从来都不是A计划; 这是计划B，当你放弃那些不自然的事情时，你就开始做了。当你试着不去思考像白象这样的东西时 - 你可以专注于它。你试图避免的东西越多，你到处都看得越多。你试图抓住充满干燥沙子的拳头越多，它越快滑过你的手指。</p><blockquote><p>有些事情是我们无法控制的，它们会将我们重新定向到比我们最初为自己选择的结果更大的结果。</p></blockquote><p>人们通常不希望将他们在生活中的成功归因于机会，命运或预先存在的条件，因为当然，这些并不是唯一的因素。但是，根本不承认它们是剥夺他人的重要见解。成功不仅仅是因为很多人努力工作而使某人“努力”。你可以说服务行业的人比拥有他们工作的机构的人工作更加困难。他们看到不同的结果，因为他们的能量是针对不同的事情。当我们不得不强迫自己去做时，工作变得艰难，当它本身无趣或没有吸引力时，我们必须强迫自己。</p><p>当我们承诺做一些我们倾向于擅长或有自然兴趣的事情时，我们会立即开始一个快速加强的反馈循环。当我们付出努力并立即获得积极成果时，我们的能量得到加强。当我们看到结果并且相信那些结果时，我们会变得纪律严明。出于这个原因，有些人认为我们最喜欢的东西往往只是我们擅长的东西。</p><p>当您忘记时间并完全沉浸在任务中时，“ 心流”就是最佳性能状态。这通常是我们生产出我们生活中最好的作品，而那些每天都能做到的人往往会为自己的长期成功做出令人难以置信的成功。但自然实现心流状态几乎是不可能的，你必须强迫自己去做。</p><p>任何成功的人都会告诉你 - 尽管他们确实做了很多工作 - 但几乎总是有一些无助的元素在起作用。这项工作是学习如何出现，脱离自己的头脑，让它发生，而不会让你产生怀疑和焦虑。</p><hr><p>牛逼最省力的他律是比生产力黑客更多。这不是一个快速，简单的成功计划。这是我们生活中不变的，经常令人沮丧的一部分。这是我们的自然法则如何治理的一个要素，它在某种程度上是一种比我们更大的力量，一种我们想要理解并对我们有利的工作。</p><p>大自然遵循蓝图。当我们不干扰治疗时，我们的身体会自愈。我们的生活往往以同样的方式运作。当我们谈论生活中“无法控制”的东西时，它几乎总是消极的，如票据或损失或疾病。但它也是相反的。有些事情是我们无法控制的，它们会将我们重新定向到比我们最初为自己选择的结果更大的结果。</p><p>我们每个人都有一套完全独特的优点和缺点，好奇心，激情，沮丧和伤口。这些交叉往往是我们生活中最肥沃的繁殖地。我们经常回顾并且可以看到这些看似随机的因素中的每一个都在我们最终结束的地方发挥了作用。它们不是随机的; 他们绘制了我们根本上是谁的蓝图。</p><blockquote><p>您需要清楚地了解最终目标，然后将其分解为更小的步骤。这不是魔术。这就是我们取得进步的方式。</p></blockquote><p>我们的选择是我们是否激活了潜在的潜力。我们的身体和生活就像能量系统。当我们用压力阻塞他们时，他们开始出现故障。这就像我们心灵河底的一个错误 - 水仍然在顶部涟漪。我们需要清楚地了解我们的最终目标，然后将其分解为更小的步骤。这不是魔术。这就是我们取得进步的方式。</p><p>但是，以一种破坏和窘迫的方式强迫事情会让他们失望。想要的东西让你处于没有它的能量之中。过度依赖于结果会使你如此着迷于完美和你自己的时间，最终破坏真正重要的东西，这是最终的结果。我们怀念成功不是世界给予我们的事实; 这是我们为世界提供的东西，然后从中获益。</p><p>成功始于我们。我们的兴趣，技能和激情; 我们的创伤和不满; 我们肩膀上的筹码和心中的梦想都不是随意的。它们交叉的地方是我们的呼唤，它对我们每个人来说都是完全独特的。我们不必强迫它。我们没有必要竞争它。我们只需要回应它，开始向它展示，然后，像我们手掌中的沙子，学会放松我们的抓地力，并让它成为现实。</p><p>【原文】</p><p>Capitalizing on what comes easily is how successful people tend to get ahead. It’s also part of the success story that’s often left out because it’s almost impossible to talk about without it becoming misconstrued.</p><p>Successful people don’t work hard (that word, “hard,” has the wrong connotation). Successful people don’t keep throwing effort at dead ends. They also don’t force what’s nonviable, ineffective, or just simply not working out. They work consistently where they see the most results, and the reason they are able to work so often—usually much more than their peers—is because the work comes somewhat naturally to them. If it didn’t, they’d be exhausted, burned out, and left with minimal results.</p><p>Conventional wisdom tells you not to give up—ever<em>,</em> no matter what. But people tell you all the time that good things tend to happen when you stop trying so hard to make them happen. The most popular relationship advice is that our partners will show up when we stop looking for them. For many couples, the moment they stop trying to get pregnant is the moment they conceive.</p><p>When you try to force happiness, it eludes you. If you don’t, it tends to happen on its own. The work you end up doing in your life is almost never Plan A; it’s Plan B, which is what you started doing when you gave up on what didn’t come naturally. When you try not to think about something—like a white elephant—it’s all you can focus on. The more you try to avoid something, the more you see it everywhere. The more you try to grip a fist full of dry sand, the faster it slips through your fingers.</p><blockquote><p>There are things out of our control that sort of redirect us to outcomes greater than we would have initially chosen for ourselves.</p></blockquote><p>People generally don’t want to misattribute their successes in life to chance, fate, or pre-existing conditions because, of course, those aren’t the only factors at play. But to not acknowledge them at all is to deprive others of vital insight. Success is more than just how “hard” someone works because a lot of people work hard. You could argue that people in the service industry work a whole lot harder than the people who own the establishment they’re working in. They see different results because their energy is directed toward different things. Work becomes hard when we have to force ourselves to do it, and we have to force ourselves when it’s inherently uninteresting or unappealing.</p><p>When we commit to doing something we are inclined to be good at or have a natural interest in, we start an immediate feedback loop that strengthens quickly. When we put effort toward something and immediately receive positive results, our energy is reinforced. We become disciplined when we see results and when we trust those results. For this very reason, some people suggest that the things we enjoy most are often just the things we are good at.</p><p>“<a href="https://whatis.techtarget.com/definition/flow" target="_blank" rel="noopener">Flow</a>” is that peak performance state when you lose track of time and become fully immersed in your task. This is often when we produce the best work of our lives, and those who can do it every day often position themselves for incredible long-term success. But it’s almost impossible to achieve a flow state doing something you have to force yourself to do.</p><p>Any successful person will tell you that—although they have certainly worked a lot—there is almost always an element of effortlessness at play. The work is learning how to show up, get out of your own head, and allow it to happen without your doubts and anxieties stopping you.</p><hr><p>The law of least effort is more than a productivity hack. It’s not a quick, easy success scheme. It’s a constant, often frustrating, part of our lives. It’s an element of how our natural laws are governed, and it’s in some ways a force greater than we are, one that we want to understand and have work in our favor.</p><p>Nature follows a blueprint. Our bodies heal themselves when we don’t interfere with the healing. Our lives tend to function the same way. When we talk about what we “can’t control” in life, it’s almost always negative—like bills or loss or illness. But it works the opposite way too. There are things out of our control that sort of redirect us to outcomes greater than we would have initially chosen for ourselves.</p><p>Within each of us is a completely unique set of strengths and weaknesses, curiosities, passions, distastes, and wounds. Where these intersect tends to be the most fertile breeding ground of our lives. We often look back and can see that each of these seemingly random factors played a role in where we ultimately ended up. They weren’t random; they mapped a blueprint of who we fundamentally are.</p><blockquote><p>You need to clearly understand the end goal and then break it down into smaller steps. This isn’t magic. This is how we make progress.</p></blockquote><p>Our choice is whether we activate the latent potential. Our bodies and our lives are like energy systems. When we clog them with stress, they start to malfunction. It’s like a fault at the bottom of the river of our psyches—the water still ripples at the top. We need to clearly understand our end goals and then break them down into smaller steps. This isn’t magic. This is how we make progress.</p><p>But forcing things in a way that wreaks havoc and distress holds them back. Wanting something puts you in the energy of not having it. Being overly attached to an outcome makes you so obsessed with perfection and your own timing that you end up sabotaging what really matters, which is the end result. We miss the fact that success is not something the world gives us; it’s something we offer the world and then reap the benefits of doing so.</p><p>Success starts with us. Our interests, skills, and passions; our trauma and our grievances; the chips on our shoulders and the dreams in our hearts are not random. The place where they intersect is our calling, and it is wholly and completely unique to each of us. We don’t have to force it. We don’t have to compete for it. We simply have to respond to it, start showing up to it, and then, like the sand in our palms, learn to loosen our grip, and allow it to be.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;【译文】&lt;/p&gt;
&lt;p&gt;ç什么容易谈到apitalizing是人们如何成功往往会获得成功。它也是成功故事的一部分，经常被遗漏，因为如果没有被误解，几乎不可能谈论它。&lt;/p&gt;
&lt;p&gt;成功的人不努力工作（这个词，“难”，有错误的含义）。成功人士不会继续向死胡同努力。他们也不会强
      
    
    </summary>
    
      <category term="评论" scheme="http://blog.ozairs.com/categories/%E8%AF%84%E8%AE%BA/"/>
    
    
      <category term="励志" scheme="http://blog.ozairs.com/tags/%E5%8A%B1%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins自动化部署</title>
    <link href="http://blog.ozairs.com/Jenkins/Jenkins%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"/>
    <id>http://blog.ozairs.com/Jenkins/Jenkins自动化部署/</id>
    <published>2019-03-25T10:13:57.000Z</published>
    <updated>2019-03-25T11:48:37.525Z</updated>
    
    <content type="html"><![CDATA[<p>一、 Pipeline平台部署</p><ol><li><a href="https://www.cnblogs.com/shenh/p/8963688.html" target="_blank" rel="noopener">jenkins + pipeline构建自动化部署</a></li></ol><p><a href="https://www.cnblogs.com/shenh/p/8963688.html" target="_blank" rel="noopener">https://www.cnblogs.com/shenh/p/8963688.html</a></p><ol start="2"><li><p><a href="https://zhuanlan.zhihu.com/p/51533506" target="_blank" rel="noopener">Jenkins pipeline脚本编写实践分享（一）上篇</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/59160884" target="_blank" rel="noopener">Jenkins pipeline脚本编写实践分享（二）</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/41604558" target="_blank" rel="noopener">jenkins学习之pipeline</a></p></li><li><a href="https://www.xncoding.com/2017/03/22/fullstack/jenkins02.html" target="_blank" rel="noopener">Jenkins持续集成 - 管道详解</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一、 Pipeline平台部署&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/shenh/p/8963688.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;jenkins + pipeline构建自动
      
    
    </summary>
    
      <category term="Jenkins" scheme="http://blog.ozairs.com/categories/Jenkins/"/>
    
    
      <category term="Jenkins" scheme="http://blog.ozairs.com/tags/Jenkins/"/>
    
  </entry>
  
</feed>
